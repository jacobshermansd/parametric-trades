<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Design of Experiments for Modeling and Simulation</title>
  <meta name="description" content="Design of Experiments for Modeling and Simulation" />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Design of Experiments for Modeling and Simulation" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Design of Experiments for Modeling and Simulation" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.28/datatables.js"></script>
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<script src="libs/plotly-binding-4.9.3/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Design of Experiments for Modeling and Simulation</h1>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#introduction-to-doe-for-ms"><span class="toc-section-number">1</span> Introduction to DOE for M&amp;S</a><ul>
<li><a href="#background."><span class="toc-section-number">1.1</span> Background.</a></li>
<li><a href="#mission."><span class="toc-section-number">1.2</span> Mission.</a><ul>
<li><a href="#simulation-analysis."><span class="toc-section-number">1.2.1</span> Simulation Analysis.</a></li>
<li><a href="#enduring-resource."><span class="toc-section-number">1.2.2</span> Enduring Resource.</a></li>
<li><a href="#community."><span class="toc-section-number">1.2.3</span> Community.</a></li>
</ul></li>
<li><a href="#concept."><span class="toc-section-number">1.3</span> Concept.</a></li>
<li><a href="#training-concept"><span class="toc-section-number">1.4</span> Training Concept</a><ul>
<li><a href="#lessons."><span class="toc-section-number">1.4.1</span> Lessons.</a></li>
<li><a href="#projects."><span class="toc-section-number">1.4.2</span> Projects.</a></li>
<li><a href="#assessments."><span class="toc-section-number">1.4.3</span> Assessments.</a></li>
<li><a href="#curriculum."><span class="toc-section-number">1.4.4</span> Curriculum.</a></li>
</ul></li>
<li><a href="#community-concept"><span class="toc-section-number">1.5</span> Community Concept</a></li>
<li><a href="#admin"><span class="toc-section-number">1.6</span> Admin</a><ul>
<li><a href="#contact"><span class="toc-section-number">1.6.1</span> Contact</a></li>
<li><a href="#errors"><span class="toc-section-number">1.6.2</span> Errors</a></li>
<li><a href="#resources"><span class="toc-section-number">1.6.3</span> Resources</a></li>
</ul></li>
</ul></li>
<li><a href="#introduction-to-r"><span class="toc-section-number">2</span> Introduction to R</a><ul>
<li><a href="#introduction-to-r---part-i"><span class="toc-section-number">2.1</span> Introduction to R - Part I</a><ul>
<li><a href="#objectives-1"><span class="toc-section-number">2.1.1</span> Objectives</a></li>
<li><a href="#task-1---read-chapter-1-and-install-tidyverse"><span class="toc-section-number">2.1.2</span> Task 1 - Read Chapter 1 and Install Tidyverse</a></li>
<li><a href="#basic-operations"><span class="toc-section-number">2.1.3</span> Basic Operations</a></li>
<li><a href="#variable-types"><span class="toc-section-number">2.1.4</span> Variable Types</a></li>
<li><a href="#data-structures"><span class="toc-section-number">2.1.5</span> Data Structures</a></li>
<li><a href="#relational-and-logical-operators"><span class="toc-section-number">2.1.6</span> Relational and Logical Operators</a></li>
</ul></li>
<li><a href="#introduction-to-r---part-ii"><span class="toc-section-number">2.2</span> Introduction to R - Part II</a><ul>
<li><a href="#reading-tasks"><span class="toc-section-number">2.2.1</span> Reading Tasks</a></li>
<li><a href="#problem-set"><span class="toc-section-number">2.2.2</span> Problem Set</a></li>
</ul></li>
</ul></li>
<li><a href="#statistics-review"><span class="toc-section-number">3</span> Statistics Review</a><ul>
<li><a href="#introduction"><span class="toc-section-number">3.1</span> Introduction</a><ul>
<li><a href="#resources-1"><span class="toc-section-number">3.1.1</span> Resources</a></li>
<li><a href="#organization"><span class="toc-section-number">3.1.2</span> Organization</a></li>
<li><a href="#poc"><span class="toc-section-number">3.1.3</span> POC</a></li>
</ul></li>
<li><a href="#descriptive-statistics"><span class="toc-section-number">3.2</span> Descriptive Statistics</a><ul>
<li><a href="#descriptive-statistics---description"><span class="toc-section-number">3.2.1</span> Descriptive Statistics - Description</a></li>
<li><a href="#descriptive-statistics---tutorial"><span class="toc-section-number">3.2.2</span> Descriptive Statistics - Tutorial</a></li>
<li><a href="#descriptive-statistics---problem-set"><span class="toc-section-number">3.2.3</span> Descriptive Statistics - Problem Set</a></li>
</ul></li>
<li><a href="#statistical-concepts"><span class="toc-section-number">3.3</span> Statistical Concepts</a><ul>
<li><a href="#statistical-concepts---description"><span class="toc-section-number">3.3.1</span> Statistical Concepts - Description</a></li>
<li><a href="#statistical-concepts---tutorial"><span class="toc-section-number">3.3.2</span> Statistical Concepts - Tutorial</a></li>
<li><a href="#statistical-concepts---problem-set"><span class="toc-section-number">3.3.3</span> Statistical Concepts - Problem Set</a></li>
</ul></li>
<li><a href="#statistical-inference"><span class="toc-section-number">3.4</span> Statistical Inference</a><ul>
<li><a href="#statistical-inference---description"><span class="toc-section-number">3.4.1</span> Statistical Inference - Description</a></li>
<li><a href="#statistical-inference---tutorial"><span class="toc-section-number">3.4.2</span> Statistical Inference - Tutorial</a></li>
<li><a href="#statistical-inference---conclusion"><span class="toc-section-number">3.4.3</span> Statistical Inference - Conclusion</a></li>
<li><a href="#statistical-inference---problem-set"><span class="toc-section-number">3.4.4</span> Statistical Inference - Problem Set</a></li>
</ul></li>
</ul></li>
<li><a href="#analysis-of-variance-anova"><span class="toc-section-number">4</span> Analysis of Variance (ANOVA)</a><ul>
<li><a href="#introduction-1"><span class="toc-section-number">4.1</span> Introduction</a></li>
<li><a href="#anova-overview"><span class="toc-section-number">4.2</span> ANOVA Overview</a><ul>
<li><a href="#motivation"><span class="toc-section-number">4.2.1</span> Motivation</a></li>
<li><a href="#broad-concept"><span class="toc-section-number">4.2.2</span> Broad Concept</a></li>
<li><a href="#terminology"><span class="toc-section-number">4.2.3</span> Terminology</a></li>
</ul></li>
<li><a href="#single-factor-fixed-effects-anova"><span class="toc-section-number">4.3</span> Single Factor, Fixed Effects ANOVA</a><ul>
<li><a href="#example"><span class="toc-section-number">4.3.1</span> Example</a></li>
<li><a href="#model"><span class="toc-section-number">4.3.2</span> Model</a></li>
<li><a href="#single-factor-anova-assumptions"><span class="toc-section-number">4.3.3</span> Single Factor ANOVA Assumptions</a></li>
<li><a href="#conducting-single-factor-fixed-effects-anova"><span class="toc-section-number">4.3.4</span> Conducting Single Factor (Fixed Effects) ANOVA</a></li>
<li><a href="#single-factor-fixed-effects-anova-problem-set"><span class="toc-section-number">4.3.5</span> Single Factor, Fixed Effects ANOVA Problem Set</a></li>
</ul></li>
<li><a href="#single-factor-random-effects-model"><span class="toc-section-number">4.4</span> Single Factor, Random Effects Model</a><ul>
<li><a href="#single-factor-random-effects-problem-set"><span class="toc-section-number">4.4.1</span> Single Factor, Random Effects Problem Set</a></li>
</ul></li>
<li><a href="#two-factor-fixed-effects-anova"><span class="toc-section-number">4.5</span> Two Factor, Fixed Effects ANOVA</a><ul>
<li><a href="#including-interaction-effects"><span class="toc-section-number">4.5.1</span> Including Interaction Effects</a></li>
<li><a href="#two-factor-anova-problem-set"><span class="toc-section-number">4.5.2</span> Two Factor ANOVA Problem Set</a></li>
</ul></li>
<li><a href="#anova-for-more-than-two-factors"><span class="toc-section-number">4.6</span> ANOVA For More Than Two Factors</a><ul>
<li><a href="#multi-factor-anova-problem-set"><span class="toc-section-number">4.6.1</span> Multi-Factor ANOVA Problem Set</a></li>
</ul></li>
<li><a href="#multiple-comparisons"><span class="toc-section-number">4.7</span> Multiple Comparisons</a><ul>
<li><a href="#tukey-test-example"><span class="toc-section-number">4.7.1</span> Tukey Test Example</a></li>
<li><a href="#tukey-test-in-r"><span class="toc-section-number">4.7.2</span> Tukey Test in R</a></li>
<li><a href="#tukey-test-multiple-factors"><span class="toc-section-number">4.7.3</span> Tukey Test, Multiple Factors</a></li>
<li><a href="#multiple-comparisons-problem-set"><span class="toc-section-number">4.7.4</span> Multiple Comparisons Problem Set</a></li>
</ul></li>
<li><a href="#anova-summary"><span class="toc-section-number">4.8</span> ANOVA Summary</a><ul>
<li><a href="#how-to-calculate-anova"><span class="toc-section-number">4.8.1</span> How to Calculate ANOVA</a></li>
<li><a href="#anova-hypothesis-tests"><span class="toc-section-number">4.8.2</span> ANOVA Hypothesis Test(s)</a></li>
<li><a href="#anova-assumptions"><span class="toc-section-number">4.8.3</span> ANOVA Assumptions</a></li>
<li><a href="#multiple-comparisons-1"><span class="toc-section-number">4.8.4</span> Multiple Comparisons</a></li>
<li><a href="#further-extensions-of-anova"><span class="toc-section-number">4.8.5</span> Further Extensions of ANOVA</a></li>
</ul></li>
</ul></li>
<li><a href="#fundamentals-of-design-of-experiments"><span class="toc-section-number">5</span> Fundamentals of Design of Experiments</a><ul>
<li><a href="#introduction-2"><span class="toc-section-number">5.1</span> Introduction</a><ul>
<li><a href="#admin-1"><span class="toc-section-number">5.1.1</span> Admin</a></li>
</ul></li>
<li><a href="#doe-overview"><span class="toc-section-number">5.2</span> DOE Overview</a><ul>
<li><a href="#what-is-design-of-experiments"><span class="toc-section-number">5.2.1</span> What is Design of Experiments?</a></li>
<li><a href="#why-design-experiments"><span class="toc-section-number">5.2.2</span> Why Design Experiments?</a></li>
<li><a href="#strategies-for-experimental-design"><span class="toc-section-number">5.2.3</span> Strategies for Experimental Design</a></li>
<li><a href="#history-and-applications-of-experimental-design"><span class="toc-section-number">5.2.4</span> History and Applications of Experimental Design</a></li>
<li><a href="#principles"><span class="toc-section-number">5.2.5</span> Principles</a></li>
<li><a href="#guidelines"><span class="toc-section-number">5.2.6</span> Guidelines</a></li>
<li><a href="#problem-set-1"><span class="toc-section-number">5.2.7</span> Problem Set</a></li>
</ul></li>
<li><a href="#factorial-designs"><span class="toc-section-number">5.3</span> Factorial Designs</a><ul>
<li><a href="#introduction-3"><span class="toc-section-number">5.3.1</span> Introduction</a></li>
<li><a href="#assessing-and-estimating-effects"><span class="toc-section-number">5.3.2</span> Assessing and Estimating Effects</a></li>
<li><a href="#blocking"><span class="toc-section-number">5.3.3</span> Blocking</a></li>
<li><a href="#problem-set-2"><span class="toc-section-number">5.3.4</span> Problem Set</a></li>
</ul></li>
<li><a href="#k-factorial-design"><span class="toc-section-number">5.4</span> <span class="math inline">\(2^K\)</span> Factorial Design</a><ul>
<li><a href="#introduction-4"><span class="toc-section-number">5.4.1</span> Introduction</a></li>
<li><a href="#coding-variables-and-effects-signs"><span class="toc-section-number">5.4.2</span> Coding Variables and Effects Signs</a></li>
<li><a href="#estimating-effects-and-contrasts"><span class="toc-section-number">5.4.3</span> Estimating Effects and Contrasts</a></li>
<li><a href="#unreplicated-2k-designs"><span class="toc-section-number">5.4.4</span> Unreplicated <span class="math inline">\(2^K\)</span> Designs</a></li>
<li><a href="#problem-set-3"><span class="toc-section-number">5.4.5</span> Problem Set</a></li>
</ul></li>
</ul></li>
<li><a href="#fractional-factorial-designs"><span class="toc-section-number">6</span> Fractional Factorial Designs</a><ul>
<li><a href="#introduction-5"><span class="toc-section-number">6.1</span> Introduction</a><ul>
<li><a href="#admin-2"><span class="toc-section-number">6.1.1</span> Admin</a></li>
<li><a href="#overview"><span class="toc-section-number">6.1.2</span> Overview</a></li>
</ul></li>
<li><a href="#frac12-fractional-factorial-design-2k-1"><span class="toc-section-number">6.2</span> <span class="math inline">\(\frac{1}{2}\)</span> Fractional Factorial Design (<span class="math inline">\(2^{K-1}\)</span>)</a><ul>
<li><a href="#motivation-and-example"><span class="toc-section-number">6.2.1</span> Motivation and Example</a></li>
<li><a href="#design-generator"><span class="toc-section-number">6.2.2</span> Design Generator</a></li>
<li><a href="#estimating-effects"><span class="toc-section-number">6.2.3</span> Estimating Effects</a></li>
<li><a href="#geometric-view"><span class="toc-section-number">6.2.4</span> Geometric View</a></li>
<li><a href="#example-24-1-design"><span class="toc-section-number">6.2.5</span> Example <span class="math inline">\(2^{4-1}\)</span> Design</a></li>
<li><a href="#frac12-fractional-factorial-design-2k-1-problem-set"><span class="toc-section-number">6.2.6</span> <span class="math inline">\(\frac{1}{2}\)</span> Fractional Factorial Design (<span class="math inline">\(2^{K-1}\)</span>) Problem Set</a></li>
</ul></li>
<li><a href="#general-2k-p-designs"><span class="toc-section-number">6.3</span> General <span class="math inline">\(2^{K-P}\)</span> Designs</a><ul>
<li><a href="#introduction-6"><span class="toc-section-number">6.3.1</span> Introduction</a></li>
<li><a href="#quarter-fractional-design"><span class="toc-section-number">6.3.2</span> Quarter Fractional Design</a></li>
<li><a href="#general-2k-p-design"><span class="toc-section-number">6.3.3</span> General <span class="math inline">\(2^{K-P}\)</span> Design</a></li>
<li><a href="#resolution"><span class="toc-section-number">6.3.4</span> Resolution</a></li>
<li><a href="#general-2k-p-designs-problem-set"><span class="toc-section-number">6.3.5</span> General <span class="math inline">\(2^{K-P}\)</span> Designs Problem Set</a></li>
</ul></li>
<li><a href="#additional-notes-on-2k-p-designs"><span class="toc-section-number">6.4</span> Additional Notes on <span class="math inline">\(2^{K-P}\)</span> Designs</a><ul>
<li><a href="#additional-topics"><span class="toc-section-number">6.4.1</span> Additional Topics</a></li>
<li><a href="#sequencing-experiments"><span class="toc-section-number">6.4.2</span> Sequencing Experiments</a></li>
<li><a href="#fractional-factorial-design-simulation-problem-set"><span class="toc-section-number">6.4.3</span> Fractional Factorial Design Simulation Problem Set</a></li>
</ul></li>
<li><a href="#screening-experiments-and-selecting-factors"><span class="toc-section-number">6.5</span> Screening Experiments and Selecting Factors</a></li>
<li><a href="#conclusion"><span class="toc-section-number">6.6</span> Conclusion</a></li>
</ul></li>
<li><a href="#fundamentals-of-regression"><span class="toc-section-number">7</span> Fundamentals of Regression</a><ul>
<li><a href="#admin-3"><span class="toc-section-number">7.1</span> Admin</a></li>
<li><a href="#simple-linear-regression"><span class="toc-section-number">7.2</span> Simple Linear Regression</a><ul>
<li><a href="#least-squares-method-manually"><span class="toc-section-number">7.2.1</span> Least Squares Method Manually</a></li>
<li><a href="#goodness-of-fit"><span class="toc-section-number">7.2.2</span> Goodness of Fit</a></li>
<li><a href="#least-squares-method-in-r"><span class="toc-section-number">7.2.3</span> Least Squares Method In <em>R</em></a></li>
<li><a href="#simple-linear-regression-problem-set"><span class="toc-section-number">7.2.4</span> Simple Linear Regression Problem Set</a></li>
</ul></li>
<li><a href="#assumptions-and-diagnostics"><span class="toc-section-number">7.3</span> Assumptions and Diagnostics</a><ul>
<li><a href="#linearity"><span class="toc-section-number">7.3.1</span> Linearity</a></li>
<li><a href="#homoscedasticity"><span class="toc-section-number">7.3.2</span> Homoscedasticity</a></li>
<li><a href="#independence"><span class="toc-section-number">7.3.3</span> Independence</a></li>
<li><a href="#normality"><span class="toc-section-number">7.3.4</span> Normality</a></li>
<li><a href="#unusual-observations"><span class="toc-section-number">7.3.5</span> Unusual Observations</a></li>
<li><a href="#linear-regression-assumptions-and-diagnostics-problem-set"><span class="toc-section-number">7.3.6</span> Linear Regression Assumptions and Diagnostics Problem Set</a></li>
</ul></li>
<li><a href="#multiple-linear-regression"><span class="toc-section-number">7.4</span> Multiple Linear Regression</a><ul>
<li><a href="#r-example"><span class="toc-section-number">7.4.1</span> <em>R</em> Example</a></li>
<li><a href="#multiple-linear-regression-problem-set"><span class="toc-section-number">7.4.2</span> Multiple Linear Regression Problem Set</a></li>
</ul></li>
<li><a href="#categorical-variables"><span class="toc-section-number">7.5</span> Categorical Variables</a><ul>
<li><a href="#categorical-linear-regression-problem-set"><span class="toc-section-number">7.5.1</span> Categorical Linear Regression Problem Set</a></li>
</ul></li>
<li><a href="#transformation"><span class="toc-section-number">7.6</span> Transformation</a><ul>
<li><a href="#identifying-non-linear-relationships"><span class="toc-section-number">7.6.1</span> Identifying Non-Linear Relationships</a></li>
<li><a href="#checking-model-structure"><span class="toc-section-number">7.6.2</span> Checking Model Structure</a></li>
<li><a href="#how-to-transform-variables-in-r"><span class="toc-section-number">7.6.3</span> How To Transform Variables In <em>R</em></a></li>
<li><a href="#transformed-regression-problem-set"><span class="toc-section-number">7.6.4</span> Transformed Regression Problem Set</a></li>
</ul></li>
<li><a href="#logistic-regression"><span class="toc-section-number">7.7</span> Logistic Regression</a><ul>
<li><a href="#motivating-example"><span class="toc-section-number">7.7.1</span> Motivating Example</a></li>
<li><a href="#logit-function"><span class="toc-section-number">7.7.2</span> Logit Function</a></li>
<li><a href="#logistic-regression-in-r"><span class="toc-section-number">7.7.3</span> Logistic Regression in <em>R</em></a></li>
<li><a href="#logistic-regression-diagnostics"><span class="toc-section-number">7.7.4</span> Logistic Regression Diagnostics</a></li>
<li><a href="#logistic-regression-problem-set"><span class="toc-section-number">7.7.5</span> Logistic Regression Problem Set</a></li>
</ul></li>
</ul></li>
<li><a href="#model-selection"><span class="toc-section-number">8</span> Model Selection</a><ul>
<li><a href="#admin-4"><span class="toc-section-number">8.1</span> Admin</a></li>
<li><a href="#introduction-7"><span class="toc-section-number">8.2</span> Introduction</a></li>
<li><a href="#testing-based-methods"><span class="toc-section-number">8.3</span> Testing-Based Methods</a></li>
<li><a href="#criterion-based-methods"><span class="toc-section-number">8.4</span> Criterion-Based Methods</a><ul>
<li><a href="#criterion-problem-set"><span class="toc-section-number">8.4.1</span> Criterion Problem Set</a></li>
</ul></li>
<li><a href="#cross-validation"><span class="toc-section-number">8.5</span> Cross Validation</a><ul>
<li><a href="#what-about-the-test-set"><span class="toc-section-number">8.5.1</span> What About The Test Set?</a></li>
</ul></li>
<li><a href="#lasso-regression"><span class="toc-section-number">8.6</span> Lasso Regression</a><ul>
<li><a href="#background-reading"><span class="toc-section-number">8.6.1</span> Background Reading</a></li>
<li><a href="#lasso-regression-in-r"><span class="toc-section-number">8.6.2</span> Lasso Regression In R</a></li>
</ul></li>
<li><a href="#parting-thought"><span class="toc-section-number">8.7</span> Parting Thought</a></li>
<li><a href="#lasso-regression-problem-set"><span class="toc-section-number">8.8</span> Lasso Regression Problem Set</a></li>
</ul></li>
<li><a href="#application-of-doe-to-the-advanced-warfighting-simulation"><span class="toc-section-number">9</span> Application of DoE to the Advanced Warfighting Simulation</a></li>
<li><a href="#advanced-experimental-designs"><span class="toc-section-number">10</span> Advanced Experimental Designs</a><ul>
<li><a href="#admin-5"><span class="toc-section-number">10.1</span> Admin</a></li>
<li><a href="#introduction-and-background"><span class="toc-section-number">10.2</span> Introduction and Background</a></li>
<li><a href="#central-composite-designs"><span class="toc-section-number">10.3</span> Central Composite Designs</a><ul>
<li><a href="#augmented-central-composite-designs"><span class="toc-section-number">10.3.1</span> Augmented Central Composite Designs</a></li>
</ul></li>
<li><a href="#response-surface-methodology"><span class="toc-section-number">10.4</span> Response Surface Methodology</a><ul>
<li><a href="#ccd-problem-set"><span class="toc-section-number">10.4.1</span> CCD Problem Set</a></li>
</ul></li>
<li><a href="#nearly-orthogonal-latin-hypercube-designs"><span class="toc-section-number">10.5</span> Nearly Orthogonal Latin Hypercube Designs</a><ul>
<li><a href="#factor-codings"><span class="toc-section-number">10.5.1</span> Factor Codings</a></li>
</ul></li>
<li><a href="#orthogonality-and-variance-inflation-factors"><span class="toc-section-number">10.6</span> Orthogonality and Variance Inflation Factors</a></li>
<li><a href="#shifting-and-stacking"><span class="toc-section-number">10.7</span> Shifting and Stacking</a><ul>
<li><a href="#nolh-problem-set"><span class="toc-section-number">10.7.1</span> NOLH Problem Set</a></li>
</ul></li>
</ul></li>
<li><a href="#non-parametric-regression"><span class="toc-section-number">11</span> Non-Parametric Regression</a><ul>
<li><a href="#admin-6"><span class="toc-section-number">11.1</span> Admin</a></li>
<li><a href="#non-parametric-anova"><span class="toc-section-number">11.2</span> Non-Parametric ANOVA</a><ul>
<li><a href="#multiple-comparisons-2"><span class="toc-section-number">11.2.1</span> Multiple Comparisons</a></li>
<li><a href="#non-parametric-anova-problem-set"><span class="toc-section-number">11.2.2</span> Non-Parametric ANOVA Problem Set</a></li>
</ul></li>
<li><a href="#generalized-additive-models"><span class="toc-section-number">11.3</span> Generalized Additive Models</a><ul>
<li><a href="#loess"><span class="toc-section-number">11.3.1</span> Loess</a></li>
<li><a href="#splines"><span class="toc-section-number">11.3.2</span> Splines</a></li>
<li><a href="#cross-validation-1"><span class="toc-section-number">11.3.3</span> Cross Validation</a></li>
<li><a href="#gam-problem-set"><span class="toc-section-number">11.3.4</span> GAM Problem Set</a></li>
</ul></li>
<li><a href="#support-vector-machines"><span class="toc-section-number">11.4</span> Support Vector Machines</a><ul>
<li><a href="#support-vector-regression"><span class="toc-section-number">11.4.1</span> Support Vector Regression</a></li>
<li><a href="#support-vector-classification"><span class="toc-section-number">11.4.2</span> Support Vector Classification</a></li>
<li><a href="#svm-problem-set"><span class="toc-section-number">11.4.3</span> SVM Problem Set</a></li>
</ul></li>
<li><a href="#classification-and-regression-trees"><span class="toc-section-number">11.5</span> Classification and Regression Trees</a><ul>
<li><a href="#regression-trees"><span class="toc-section-number">11.5.1</span> Regression Trees</a></li>
<li><a href="#random-forest-regression"><span class="toc-section-number">11.5.2</span> Random Forest Regression</a></li>
<li><a href="#random-forest-classification"><span class="toc-section-number">11.5.3</span> Random Forest Classification</a></li>
<li><a href="#cart-problem-set"><span class="toc-section-number">11.5.4</span> CART Problem Set</a></li>
</ul></li>
</ul></li>
<li><a href="#optional-advanced-doe-topics"><span class="toc-section-number">12</span> Optional Advanced DOE Topics</a><ul>
<li><a href="#robust-design"><span class="toc-section-number">12.1</span> Robust Design</a></li>
<li><a href="#sequential-designs"><span class="toc-section-number">12.2</span> Sequential Designs</a></li>
<li><a href="#ridge-regression"><span class="toc-section-number">12.3</span> Ridge Regression</a></li>
<li><a href="#neural-network-regression"><span class="toc-section-number">12.4</span> Neural Network Regression</a><ul>
<li><a href="#simple-neural-network-model"><span class="toc-section-number">12.4.1</span> Simple Neural Network Model</a></li>
<li><a href="#gradient-descent"><span class="toc-section-number">12.4.2</span> Gradient Descent</a></li>
<li><a href="#multiple-linear-regression-1"><span class="toc-section-number">12.4.3</span> Multiple Linear Regression</a></li>
<li><a href="#hidden-layer"><span class="toc-section-number">12.4.4</span> Hidden Layer</a></li>
</ul></li>
<li><a href="#neural-network-classification"><span class="toc-section-number">12.5</span> Neural Network Classification</a></li>
<li><a href="#multivariate-adaptive-regression-splines"><span class="toc-section-number">12.6</span> Multivariate Adaptive Regression Splines</a></li>
<li><a href="#non-parametric-statistics"><span class="toc-section-number">12.7</span> Non-Parametric Statistics</a></li>
</ul></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Design of Experiments for Modeling and Simulation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="introduction-to-doe-for-ms" class="section level1">
<h1><span class="header-section-number">1</span> Introduction to DOE for M&amp;S</h1>
<div id="background." class="section level2">
<h2><span class="header-section-number">1.1</span> Background.</h2>
<p>This course was developed at the behest of the leadership of the Wargaming and Simulation Directorate (WSD) at TRAC Fort Leavenworth as a means of institutionalizing the use of design of experiments (DOE) for simulation in the directorate. As part of an evolving mission, the organization found it prudent to develop and use this capability to support studies for Army Futures Command and others.</p>
<p>The primary authors of the course, Majors Steve Gillespie and John King have used DOE for simulation based on the curricula offered by the Naval Postgraduate School’s Systems Engineering and Operations Research departments. We do not claim to have originated any of these ideas, we are simply conveying them. We make every attempt to properly cite the relevant authority for ideas. Any and all errors are ours alone.</p>
</div>
<div id="mission." class="section level2">
<h2><span class="header-section-number">1.2</span> Mission.</h2>
<p>The purpose of this training is to educate and train analysts in the use of design of experiments (DOE) for simulation analysis. It is intended to be approximately as in depth as a general college course in DOE, but focused specifically on the needs of military (uniformed and civilian) analysts using simualtion to inform senior military leaders.</p>
<p>This training has three major goals:</p>
<ol style="list-style-type: decimal">
<li>Enable and support simulation analysis.</li>
<li>Serve as an enduring resource.</li>
<li>Build the community of simulation analyst practitioners.</li>
</ol>
<div id="simulation-analysis." class="section level3">
<h3><span class="header-section-number">1.2.1</span> Simulation Analysis.</h3>
<p>First and foremost, this training must enable the Wargaming and Simulation Directorate to support TRAC and Army Futures Command answer expansive, ill-defined, and quick turn problems using modern simulation techniques. This means developing capable practitioners in the design and analysis of experiments and equipping them with the appropriate methodology, knowledge, experiments, and tools for this requirement.</p>
<p>This training is unapologetically focused on WSD requirements and the application of Design and Analysis of Experiments to simulation, but is broadly useful to others.</p>
</div>
<div id="enduring-resource." class="section level3">
<h3><span class="header-section-number">1.2.2</span> Enduring Resource.</h3>
<p>While distinct training events are useful, people change jobs, PCS, and forget. As much as possible, this training will develop and consolidate resources for learning and applying the Design and Analysis of Experiments so that others may use it for their own purposes and analysts can refer back to it.</p>
</div>
<div id="community." class="section level3">
<h3><span class="header-section-number">1.2.3</span> Community.</h3>
<p>Analysis is a team sport. This training is intended to bring the Design and Analysis of Experiments team together, across divisions, directorates, centers, and the wider ORSA community. This enables knowledge sharing and innovation.</p>
</div>
</div>
<div id="concept." class="section level2">
<h2><span class="header-section-number">1.3</span> Concept.</h2>
<p>This project has two major, mutually supporting, efforts:</p>
<ul>
<li>The first is developing and executing the training itself.</li>
<li>The second is building the community that can use the training and enabling community sharing and innovation.</li>
</ul>
</div>
<div id="training-concept" class="section level2">
<h2><span class="header-section-number">1.4</span> Training Concept</h2>
<p>The training LOE is the most significant portion of this project. The precise curriculum is defined below. In general, the training consists of lessons, projects, and assessments.</p>
<div id="lessons." class="section level3">
<h3><span class="header-section-number">1.4.1</span> Lessons.</h3>
<p>Lessons form the bulk of the curriculum. We take an active learning approach, where instructors provide learning resources (readings, videos, and tutorials) for students who prepare ahead of the lesson meeting. When students and instructors meet, they then use that time to answer any questions on the material and work through problems or projects by applying the material from the lesson. This: 1) allows students to devote the appropriate amount of time toward preparing for their lesson based on their own background knowledge and learning style, 2) affords flexibility for basic knowledge acquisition at a time that is convenient to each person, and 3) maximizes “in class” time for learning by doing.</p>
<p>The general flow of each lesson follows the format below:</p>
<div id="develop-lesson.-instructor" class="section level4">
<h4><span class="header-section-number">1.4.1.1</span> Develop lesson. (Instructor)</h4>
<p>For each lesson, the instructor will do the following:</p>
<ol style="list-style-type: decimal">
<li>Identify lesson objectives.</li>
<li>Develop / provide resources.</li>
<li>Develop / provide practice problems.</li>
<li>Develop / provide assessment mechanism.</li>
</ol>
</div>
<div id="prepare-for-lesson.-student" class="section level4">
<h4><span class="header-section-number">1.4.1.2</span> Prepare for lesson. (Student)</h4>
<p>For each lesson students will (ahead of the lesson):</p>
<ol style="list-style-type: decimal">
<li>Study any assigned readings / videos.</li>
<li>Work through any assigned tutorials.</li>
<li>Prepare for the lesson lab (i.e., install appropriate software, download appropriate data).</li>
</ol>
</div>
<div id="conduct-lesson-lab.-student-instructor" class="section level4">
<h4><span class="header-section-number">1.4.1.3</span> Conduct lesson lab. (Student &amp; Instructor)</h4>
<p>For each lesson lab, the students and instructors will:</p>
<ol style="list-style-type: decimal">
<li>Review and answer any questions about the material.</li>
<li>Work through a set of problems.</li>
</ol>
<p><font color = 'red'> Lesson labs will <strong>NOT</strong> be a rehashing of the reading and videos. Students who do not prepare ahead of time will likely not be able to work through the lab. </font></p>
</div>
<div id="assess-progress.-student-instructor" class="section level4">
<h4><span class="header-section-number">1.4.1.4</span> Assess progress. (Student &amp; Instructor)</h4>
<p>For each lesson, the students and instructors will jointly assess their progress, either formally or through an informal discussion. Instructors will then decide if and how to modify the curriculum to either provide additional instruction or speed up the pace of the instruction.</p>
<p>For each lesson, students will provide feedback on the reading, videos, and/or tutorial so that the final published version of the lesson captures any lessons learned.</p>
</div>
</div>
<div id="projects." class="section level3">
<h3><span class="header-section-number">1.4.2</span> Projects.</h3>
<p>We find that projects are the most useful means of learning. Due to the nature of the course, most of the projects will involve the use of TRAC’s internal simulations which reside on classified networks. Unfortunately, we will not be able to share these openly.</p>
</div>
<div id="assessments." class="section level3">
<h3><span class="header-section-number">1.4.3</span> Assessments.</h3>
<p>Each section will have a problem set with an associated solution set. Students may work these problem sets and the course directors will provide feedback for local students.</p>
</div>
<div id="curriculum." class="section level3">
<h3><span class="header-section-number">1.4.4</span> Curriculum.</h3>
<p>The curriculum for this course is divided into sections. Each section has multiple lessons, and each lesson has multiple objectives. These are seen as follows:</p>
<div id="sections" class="section level4">
<h4><span class="header-section-number">1.4.4.1</span> Sections</h4>
<div id="htmlwidget-7067d910a6645737ced8" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7067d910a6645737ced8">{"x":{"filter":"none","vertical":false,"data":[[1,2,3,4,5,6,7],["R Fundamentals","Statistics Review","Fundamentals of Design of Experiments (DOE)","Basic Regression","Applications","Advanced Topics","Optional Advanced Topics"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Number<\/th>\n      <th>Name<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"scrollX":true,"initComplete":"function(settings, json) {\n$(this.api().table().container()).css({'font-size': '50%'});\n}","columnDefs":[{"className":"dt-right","targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.initComplete"],"jsHooks":[]}</script>
</div>
<div id="lessons" class="section level4">
<h4><span class="header-section-number">1.4.4.2</span> Lessons</h4>
<div id="htmlwidget-7202d448f00ab6c97f41" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7202d448f00ab6c97f41">{"x":{"filter":"top","vertical":false,"filterHTML":"<tr>\n  <td data-type=\"number\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"display: none;position: absolute;width: 200px;opacity: 1\">\n      <div data-min=\"1\" data-max=\"7\"><\/div>\n      <span style=\"float: left;\"><\/span>\n      <span style=\"float: right;\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"factor\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"width: 100%; display: none;\">\n      <select multiple=\"multiple\" style=\"width: 100%;\" data-options=\"[&quot;Advanced Topics&quot;,&quot;Applications&quot;,&quot;Basic Regression&quot;,&quot;Fundamentals of Design of Experiments (DOE)&quot;,&quot;Optional Advanced Topics&quot;,&quot;R Fundamentals&quot;,&quot;Statistics Review&quot;]\"><\/select>\n    <\/div>\n  <\/td>\n  <td data-type=\"number\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"display: none;position: absolute;width: 200px;opacity: 1\">\n      <div data-min=\"1\" data-max=\"7\"><\/div>\n      <span style=\"float: left;\"><\/span>\n      <span style=\"float: right;\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"factor\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"width: 100%; display: none;\">\n      <select multiple=\"multiple\" style=\"width: 100%;\" data-options=\"[&quot;Aliasing&quot;,&quot;ANOVA&quot;,&quot;Assessing Designs&quot;,&quot;AWARS Project - Fundamentals&quot;,&quot;Basic Statistical Concepts&quot;,&quot;Blocking&quot;,&quot;Central Composite Designs&quot;,&quot;Classification and Regression Trees&quot;,&quot;Confounding&quot;,&quot;Decision Trees&quot;,&quot;Descriptive Statistics&quot;,&quot;Fractional Factorial Design&quot;,&quot;Full Factorial Design&quot;,&quot;Generalized Additive Model&quot;,&quot;Intro to DOE&quot;,&quot;Introduction to R&quot;,&quot;Lasso Regression&quot;,&quot;Latin Hypercubes&quot;,&quot;Logistic Regression&quot;,&quot;Markdown&quot;,&quot;Multiple Linear Regression&quot;,&quot;Nearly Orthogonal Latin Hypercubes&quot;,&quot;Neural Networks&quot;,&quot;Polynomial Regression&quot;,&quot;R for Data Science&quot;,&quot;Regression on Transformed Variables&quot;,&quot;Ridge Regression&quot;,&quot;Robust Design&quot;,&quot;Sequential Designs&quot;,&quot;Shifting &amp; Stacking&quot;,&quot;Simple Linear Regression&quot;,&quot;Statistical Inference&quot;,&quot;Support Vector Machines&quot;]\"><\/select>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n<\/tr>","data":[[1,1,1,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,5,6,6,6,6,6,6,6,7,7,7,7,7,7,7],["R Fundamentals","R Fundamentals","R Fundamentals","Statistics Review","Statistics Review","Statistics Review","Statistics Review","Fundamentals of Design of Experiments (DOE)","Fundamentals of Design of Experiments (DOE)","Fundamentals of Design of Experiments (DOE)","Fundamentals of Design of Experiments (DOE)","Fundamentals of Design of Experiments (DOE)","Fundamentals of Design of Experiments (DOE)","Fundamentals of Design of Experiments (DOE)","Basic Regression","Basic Regression","Basic Regression","Basic Regression","Applications","Advanced Topics","Advanced Topics","Advanced Topics","Advanced Topics","Advanced Topics","Advanced Topics","Advanced Topics","Optional Advanced Topics","Optional Advanced Topics","Optional Advanced Topics","Optional Advanced Topics","Optional Advanced Topics","Optional Advanced Topics","Optional Advanced Topics"],[1,2,3,1,2,4,3,1,2,3,4,5,6,7,1,2,3,4,1,1,2,3,4,5,6,7,1,2,3,4,5,6,7],["Introduction to R","R for Data Science","Markdown","Descriptive Statistics","Basic Statistical Concepts","ANOVA","Statistical Inference","Intro to DOE","Full Factorial Design","Fractional Factorial Design","Blocking","Confounding","Aliasing","Assessing Designs","Simple Linear Regression","Multiple Linear Regression","Polynomial Regression","Regression on Transformed Variables","AWARS Project - Fundamentals","Central Composite Designs","Latin Hypercubes","Nearly Orthogonal Latin Hypercubes","Lasso Regression","Ridge Regression","Classification and Regression Trees","Generalized Additive Model","Shifting &amp; Stacking","Robust Design","Sequential Designs","Logistic Regression","Decision Trees","Support Vector Machines","Neural Networks"],["Introduce the programming language R, standard data types, basic functionality, and R resources.","Introduce R concepts for data science.","Introduce the concept of R markdown for analysis visualization.","Review foundational descriptive statistics and methods for conducting descriptive statistics in R.",null,null,null,"Montgomery Chapter 1",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"TBP","TBP","TBP","TBP","TBP","TBP","TBP"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Section #<\/th>\n      <th>Section Name<\/th>\n      <th>Lesson Number<\/th>\n      <th>Lesson_Name<\/th>\n      <th>Lesson Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"scrollX":true,"pagelength":5,"initComplete":"function(settings, json) {\n$(this.api().table().container()).css({'font-size': '50%'});\n}","columnDefs":[{"className":"dt-right","targets":[0,2]}],"order":[],"autoWidth":false,"orderClasses":false,"orderCellsTop":true},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.initComplete"],"jsHooks":[]}</script>
</div>
<div id="objectives" class="section level4">
<h4><span class="header-section-number">1.4.4.3</span> Objectives</h4>
<p>The individual objectives for each lesson are listed in their corresponding chapter.</p>
</div>
</div>
</div>
<div id="community-concept" class="section level2">
<h2><span class="header-section-number">1.5</span> Community Concept</h2>
<p>Analytic skills and knowledge in of themselves are:</p>
<ol style="list-style-type: decimal">
<li>Useless in a vacuum.</li>
<li>Perishable.</li>
</ol>
<p>As such, we believe it is important to build a self-sustaining community that innovates, shares, and includes others. This course is purposefully being shared on the web (as opposed to a single organization’s sharepoint) as it allows analysts from across the community to participate.</p>
<p>As this project develops, we will advance the capacity to share DOE and simulation specific topics. In the meantime, please contact us if you would like to participate.</p>
</div>
<div id="admin" class="section level2">
<h2><span class="header-section-number">1.6</span> Admin</h2>
<div id="contact" class="section level3">
<h3><span class="header-section-number">1.6.1</span> Contact</h3>
<p>If you need to contact us, please email us at <a href="mailto:stephen.e.gillespie.mil@mail.mil" class="email">stephen.e.gillespie.mil@mail.mil</a> or <a href="mailto:john.f.king1.mil@mail.mil" class="email">john.f.king1.mil@mail.mil</a>.</p>
</div>
<div id="errors" class="section level3">
<h3><span class="header-section-number">1.6.2</span> Errors</h3>
<p>If you identify errors:</p>
<ol style="list-style-type: decimal">
<li>The errors are ours alone and we sincerely apologize.</li>
<li>Please contact us and we will rectify them.</li>
</ol>
</div>
<div id="resources" class="section level3">
<h3><span class="header-section-number">1.6.3</span> Resources</h3>
<p>As much as possible, we attempt to use freely available resources.</p>
<ul>
<li>In general, resources are cited as direct links to where the content is hosted.</li>
<li>We attempt to minimize the use of books with one exception: <em>The Design and Analysis of Experiments</em> by Douglas Montgomery which is widely available.</li>
<li>Analytic resources:
<ul>
<li>We have opted to use <em>R</em> as it is 1) freely available and 2) widely used across the military analytic community.</li>
<li>We are developing this course using <em>R</em> on www.matrixds.com as it is 1) free and 2) free of the restrictions of NIPR.<br />
</li>
<li>You are more than welcome to use other resources, programming languages, and other such things. For example, the python package <em>pyDOE</em> is quite useful. If you recreate any of our tutorials using a different language (or in R, but better), please share!</li>
</ul></li>
<li>Simulation resources:
<ul>
<li>We will provide simple examples using toy simulations, but developing a large, open-source, easy to use simulation for everyone is beyond the scope of this project. If someone has a good option, please share!</li>
<li>For analysts working at TRAC Fort Leavenworth, we will work examples for projects using the AWARS simulation. Unfortunately, we cannot share this beyond TRAC Fort Leavenworth.</li>
</ul></li>
</ul>
<!--chapter:end:index.Rmd-->
</div>
</div>
</div>
<div id="introduction-to-r" class="section level1">
<h1><span class="header-section-number">2</span> Introduction to R</h1>
<p>For any noted issues in this chapter (especially errors), please contact: <a href="mailto:john.f.king1.mil@mail.mil">John King</a> or <a href="jacob.s.sherman2.civ@mail.mil">Jacob Sherman</a>.</p>
<p>R is a programming language and free software environment widely used for statistical computing and graphics. R may be launched from Windows by selecting the Start menu, opening the R folder, and choosing R x64 3.6.0. This starts an R session and opens an R Console where you may interact with R via one-line commands. Many R users prefer a more full-featured environment to interact with R, and for this course of instruction we will use the popular R Studio Interactive Development Environment (IDE).</p>
<p>R Studio may be launched via Windows start menu, but there are also cloud-based options such as Amazon Web Services and MatrixDS. If you are launching R Studio for the first time, when it starts, you should see three panels. On the left is the console, and on the right are two panels with several tabs each that display charts, allow for file browsing, etc. To start a new R script, go to File &gt;&gt; New File &gt;&gt; R Script. This will open a fourth panel on the left that is essentially just a text editor where you write R code. For an R Studio IDE cheat sheet, click <a href = "https://github.com/rstudio/cheatsheets/raw/master/rstudio-ide.pdf"> here </a>. To interact with R in R Studio, simply type a command in the text editor panel, place the cursor anywhere on the command line, and press CTRL+ENTER (no need to select the text as in SQL).</p>
<div id="introduction-to-r---part-i" class="section level2">
<h2><span class="header-section-number">2.1</span> Introduction to R - Part I</h2>
<p>For this course, we will use the online tutorial <a href = "https://r4ds.had.co.nz"> R for Data Science </a> to develop your R skills. The tutorial assumes that users have no knowledge of R or any other programming language. When completing these exercises, write your code in an R Markdown file. Generally, one code block per question will be appropriate. You can either start your own R markdown file from R Studio, or you can download <a href = "/docsArchive/_Chapter2_ProblemSets/Chapter2_Questions.Rmd">Introduction to R Problem Set</a> to get started.</p>
<div id="objectives-1" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Objectives</h3>
<p>By the end of the Introduction to R - Part I, you will have:</p>
<ul>
<li>A working version of R Studio.</li>
<li>Installed the <code>tidyverse</code> package.</li>
<li>An understanding of basic operations in R.</li>
<li>An understanding of the primary variable types and data structures used in R.</li>
</ul>
</div>
<div id="task-1---read-chapter-1-and-install-tidyverse" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Task 1 - Read Chapter 1 and Install Tidyverse</h3>
<p>Click on the link to <em>R for Data Science</em> and read Chapter 1. Be sure to follow the instructions on installing the <code>tidyverse</code> package. After you finished reading Chapter 1, return here and continue.</p>
</div>
<div id="basic-operations" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Basic Operations</h3>
<p>R can be used as a fancy calculator, and mathematical operations are as you would expect. Run each of the commands below in your own R script. Note that you can add comments to your code with #.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span>          <span class="co"># Comments can be at the end of a line</span></a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] -1</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co"># Or they can be on their own line</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="dv">2</span><span class="op">^</span><span class="dv">2</span>            <span class="co"># exponent</span></a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="dv">5</span> <span class="op">%%</span><span class="st"> </span><span class="dv">2</span>         <span class="co"># division remainder</span></a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="dv">5</span> <span class="op">%/%</span><span class="st"> </span><span class="dv">2</span>        <span class="co"># division quotient</span></a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw">sqrt</span>(<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 1.414214</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw">exp</span>(<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 7.389056</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="kw">log</span>(<span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.6931472</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="kw">sin</span>(pi<span class="op">/</span><span class="dv">6</span>)      <span class="co"># Note that trig functions assume angles are in radians.</span></a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">factorial</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 120</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw">choose</span>(<span class="dv">10</span>, <span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 45</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="co"># order of operations is as you&#39;d expect</span></a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span></a></code></pre></div>
<pre><code>## [1] 1.666667</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1">(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span>)<span class="op">/</span><span class="dv">3</span></a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>R also has a number of useful built-in constants.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">pi</a></code></pre></div>
<pre><code>## [1] 3.141593</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1">letters</a></code></pre></div>
<pre><code>##  [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot;
## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot;</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1">LETTERS</a></code></pre></div>
<pre><code>##  [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot;
## [20] &quot;T&quot; &quot;U&quot; &quot;V&quot; &quot;W&quot; &quot;X&quot; &quot;Y&quot; &quot;Z&quot;</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1">month.abb</a></code></pre></div>
<pre><code>##  [1] &quot;Jan&quot; &quot;Feb&quot; &quot;Mar&quot; &quot;Apr&quot; &quot;May&quot; &quot;Jun&quot; &quot;Jul&quot; &quot;Aug&quot; &quot;Sep&quot; &quot;Oct&quot; &quot;Nov&quot; &quot;Dec&quot;</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1">month.name</a></code></pre></div>
<pre><code>##  [1] &quot;January&quot;   &quot;February&quot;  &quot;March&quot;     &quot;April&quot;     &quot;May&quot;       &quot;June&quot;     
##  [7] &quot;July&quot;      &quot;August&quot;    &quot;September&quot; &quot;October&quot;   &quot;November&quot;  &quot;December&quot;</code></pre>
<p>We often want to assign a value to a variable so that we have access to that variable value at any time. Common R syntax for variable assignment is as follows, where the value of 1 is assigned to the variable x. When you assign the value to the variable, notice that the Environment panel in the upper right now shows the variable and its value.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="co"># variable assignment</span></a>
<a class="sourceLine" id="cb41-2" data-line-number="2">x &lt;-<span class="st"> </span><span class="dv">1</span></a></code></pre></div>
<p>The <code>&lt;-</code> syntax is a graphical reminder of which direction the assignment is going. An alternative syntax is to use the equal sign.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1">x =<span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<p>If you want to print the value of x to the console, you can either use the print command or simply type the variable name.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">print</span>(x)</a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1">x</a></code></pre></div>
<pre><code>## [1] 2</code></pre>
</div>
<div id="variable-types" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Variable Types</h3>
<p>There are different types of variables in R, and the most common types we’ll encounter are numeric (integers and floats), strings, and factors. Integers are what you’d expect, floats are numeric non-integers, strings are text, and factors are categorical variables such as Likert scale responses. If you are unsure of a variable type, you can determine it using <code>class()</code>.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="kw">class</span>(x)  <span class="co"># numeric</span></a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1">x =<span class="st"> </span><span class="kw">as.integer</span>(x)</a>
<a class="sourceLine" id="cb49-2" data-line-number="2"><span class="kw">class</span>(x)  <span class="co"># now specifically an integer</span></a></code></pre></div>
<pre><code>## [1] &quot;integer&quot;</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1">myWord =<span class="st"> &quot;Hello&quot;</span></a>
<a class="sourceLine" id="cb51-2" data-line-number="2"><span class="kw">class</span>(myWord) <span class="co"># character (aka string)</span></a></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1">myFactors =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;agree&quot;</span>, <span class="st">&quot;neutral&quot;</span>, <span class="st">&quot;disagree&quot;</span>)</a>
<a class="sourceLine" id="cb53-2" data-line-number="2"><span class="kw">class</span>(myFactors) <span class="co"># these variables are considered strings at this point</span></a></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1"><span class="co"># use as.factor to convert from character to factor</span></a>
<a class="sourceLine" id="cb55-2" data-line-number="2">myFactors =<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">c</span>(<span class="st">&quot;agree&quot;</span>, <span class="st">&quot;neutral&quot;</span>, <span class="st">&quot;disagree&quot;</span>)) </a>
<a class="sourceLine" id="cb55-3" data-line-number="3"><span class="kw">class</span>(myFactors) <span class="co"># now a factor with 3 levels</span></a></code></pre></div>
<pre><code>## [1] &quot;factor&quot;</code></pre>
</div>
<div id="data-structures" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Data Structures</h3>
<p>When dealing with multiple variables, we’ll often want to combine them into a data structure so that we can perform operations on the entire group. The data structures we’ll use most are vectors, lists, and data frames.</p>
<div id="vectors" class="section level4">
<h4><span class="header-section-number">2.1.5.1</span> Vectors</h4>
<p>Vectors are one of the most common objects in R. They are a collection of values of the same type (e.g., the numbers 1 through 5, or a collection of unit names). To construct a vector from scratch, use the format <code>c(value1, value2, etc.)</code>.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb57-2" data-line-number="2">x</a></code></pre></div>
<pre><code>## [1] 1 2 3 4 5</code></pre>
<p>If we use <code>class()</code> on a vector, R will return the class of the data in the vector. Another useful function is <code>length()</code>, which will return the number of values in a vector.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1"><span class="kw">class</span>(x)   <span class="co"># class is referring to the class of the data in the vector</span></a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1"><span class="kw">length</span>(x)  <span class="co"># the number of elements in the vector</span></a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>Recall that vector elements must be the same type. If they are not, R will coerce the elements to be consistent. For example, R will coerce a mix of characters and numbers into characters.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="st">&quot;foo&quot;</span>)</a>
<a class="sourceLine" id="cb63-2" data-line-number="2"><span class="co"># note that the number 1 was coerced into a character as </span></a>
<a class="sourceLine" id="cb63-3" data-line-number="3"><span class="co"># indicated by the quotes around the number: &quot;1&quot;</span></a>
<a class="sourceLine" id="cb63-4" data-line-number="4">x</a></code></pre></div>
<pre><code>## [1] &quot;1&quot;   &quot;foo&quot;</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1"><span class="kw">class</span>(x)</a></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="kw">is.numeric</span>(x)    <span class="co"># this tests whether the vector contains numbers or not</span></a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<p>A benefit of having like elements in a vector is that you can then perform operations on the entire vector at once, rather than one element at a time. For example, say we have a vector containing the numbers 1 through 5. If we want to add 1 to each element, we do the following:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb69-2" data-line-number="2">x <span class="op">+</span><span class="st"> </span><span class="dv">1</span>     <span class="co"># 1 is added to each vector element</span></a></code></pre></div>
<pre><code>## [1] 2 3 4 5 6</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1">x =<span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="co"># if we want to update the value of x, we need to asign the result back to it</span></a></code></pre></div>
<div id="vector-math" class="section level5">
<h5><span class="header-section-number">2.1.5.1.1</span> Vector Math</h5>
<p>Having values in a vector allows us to quickly perform mathematical operations on the entire vector.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1"><span class="kw">sum</span>(x)                 <span class="co"># sum up the values in x</span></a></code></pre></div>
<pre><code>## [1] 20</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1"><span class="kw">mean</span>(x)                <span class="co"># the mean of the values</span></a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"><span class="kw">median</span>(x)              <span class="co"># the median value</span></a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1"><span class="kw">sd</span>(x)                  <span class="co"># standard deviation</span></a></code></pre></div>
<pre><code>## [1] 1.581139</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="kw">mean</span>(x) <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(x)    <span class="co"># upper bound of a 95% confidence interval</span></a></code></pre></div>
<pre><code>## [1] 7.162278</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1"><span class="kw">max</span>(x)                 <span class="co"># the maximum value in x</span></a></code></pre></div>
<pre><code>## [1] 6</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1"><span class="kw">min</span>(x)                 <span class="co"># the minimum value in x</span></a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1"><span class="kw">summary</span>(x)             <span class="co"># a statistical summary of the values in x</span></a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##       2       3       4       4       5       6</code></pre>
<p>If needed, vectors can also be sorted in either ascending or descending order. Sorting a vector of characters will put them in alphabetical order.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb88-2" data-line-number="2"><span class="kw">sort</span>(x)                     <span class="co"># default behavior is ascending order</span></a></code></pre></div>
<pre><code>## [1] 1 2 3 4 5</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1"><span class="kw">sort</span>(x, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)  <span class="co"># to specify descending order</span></a></code></pre></div>
<pre><code>## [1] 5 4 3 2 1</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" data-line-number="1">x                           <span class="co"># note that the original vector didn&#39;t change</span></a></code></pre></div>
<pre><code>## [1] 2 1 4 3 5</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1">x =<span class="st"> </span><span class="kw">sort</span>(x)                 <span class="co"># to update the original vector, assign the results back to it</span></a>
<a class="sourceLine" id="cb94-2" data-line-number="2">x</a></code></pre></div>
<pre><code>## [1] 1 2 3 4 5</code></pre>
</div>
<div id="vector-indexing-and-slicing" class="section level5">
<h5><span class="header-section-number">2.1.5.1.2</span> Vector Indexing and Slicing</h5>
<p>Often, we need to access one or more individual elements in a vector. Each element in a vector can be accessed using its index number. The first element in a vector has an index of 1, the second has an index of 2, etc.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb96-2" data-line-number="2">x[<span class="dv">1</span>]             <span class="co"># access the first element</span></a></code></pre></div>
<pre><code>## [1] 2</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" data-line-number="1">x[<span class="dv">2</span>]             <span class="co"># access the second element</span></a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" data-line-number="1">x[<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>]           <span class="co"># access the second through fourth elements</span></a></code></pre></div>
<pre><code>## [1] 1 4 3</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" data-line-number="1">x[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>)]    <span class="co"># the first, third, and fifth element</span></a></code></pre></div>
<pre><code>## [1] 2 4 5</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" data-line-number="1">x[<span class="op">-</span><span class="dv">1</span>]            <span class="co"># remove the first element</span></a></code></pre></div>
<pre><code>## [1] 1 4 3 5</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" data-line-number="1">x[<span class="op">-</span><span class="dv">2</span>]            <span class="co"># remove the second element</span></a></code></pre></div>
<pre><code>## [1] 2 4 3 5</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" data-line-number="1">x[<span class="op">-</span><span class="kw">length</span>(x)]    <span class="co"># remove the last element</span></a></code></pre></div>
<pre><code>## [1] 2 1 4 3</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" data-line-number="1"><span class="kw">which.max</span>(x)     <span class="co"># the index of the maximum value</span></a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" data-line-number="1">x[<span class="kw">which.max</span>(x)]  <span class="co"># same as max(x)</span></a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>Indexing strings is slightly different than indexing a vector. Recall our variable <code>myWord</code>, which consists of the string “Hello”. If we want to access the second letter in the string, we don’t use <code>myWord[2]</code> because a string is not a vector of characters. Instead, use <code>substr()</code>, which returns a sub-string based on a starting and stopping position.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" data-line-number="1">myWord[<span class="dv">2</span>]                     <span class="co"># fail!</span></a></code></pre></div>
<pre><code>## [1] NA</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1"><span class="kw">substr</span>(myWord, <span class="dv">1</span>, <span class="dv">1</span>)          <span class="co"># the first letter</span></a></code></pre></div>
<pre><code>## [1] &quot;H&quot;</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1"><span class="kw">substr</span>(myWord, <span class="dv">1</span>, <span class="dv">2</span>)          <span class="co"># the first two letters</span></a></code></pre></div>
<pre><code>## [1] &quot;He&quot;</code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1"><span class="kw">substr</span>(myWord, <span class="dv">2</span>, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] &quot;ello&quot;</code></pre>
<p>If we need to split a string based on a repeated character, we can use the <code>strsplit()</code> function and specify the character to split on. Note that we can also split on the space caracter, which allows us to split a sentence into individual words. <code>strsplit()</code> returns a list, which is a data type we’ll discuss in more detail later.</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1"><span class="co"># Example 1</span></a>
<a class="sourceLine" id="cb122-2" data-line-number="2">fiple =<span class="st"> &quot;platform:weapon:mount:munition:target&quot;</span></a>
<a class="sourceLine" id="cb122-3" data-line-number="3"><span class="kw">strsplit</span>(fiple, <span class="st">&quot;:&quot;</span>) </a></code></pre></div>
<pre><code>## [[1]]
## [1] &quot;platform&quot; &quot;weapon&quot;   &quot;mount&quot;    &quot;munition&quot; &quot;target&quot;</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1"><span class="co"># Example 2</span></a>
<a class="sourceLine" id="cb124-2" data-line-number="2">sentence =<span class="st"> &quot;this is an example sentence&quot;</span></a>
<a class="sourceLine" id="cb124-3" data-line-number="3"><span class="kw">strsplit</span>(sentence, <span class="st">&quot; &quot;</span>)</a></code></pre></div>
<pre><code>## [[1]]
## [1] &quot;this&quot;     &quot;is&quot;       &quot;an&quot;       &quot;example&quot;  &quot;sentence&quot;</code></pre>
<p>The reverse of parsing strings is pasting them back together with either <code>paste()</code> or <code>paste0()</code>. These methods can be combined with <code>print()</code> for console display.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" data-line-number="1">fiple =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;platform&#39;</span>, <span class="st">&#39;weapon&#39;</span>, <span class="st">&#39;mount&#39;</span>, <span class="st">&#39;muntion&#39;</span>, <span class="st">&#39;target&#39;</span>)</a>
<a class="sourceLine" id="cb126-2" data-line-number="2">fiple</a></code></pre></div>
<pre><code>## [1] &quot;platform&quot; &quot;weapon&quot;   &quot;mount&quot;    &quot;muntion&quot;  &quot;target&quot;</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" data-line-number="1"><span class="kw">paste</span>(fiple, <span class="dt">collapse=</span><span class="st">&quot;:&quot;</span>)                 <span class="co"># use collapse to specify how to delimit the vector elements</span></a></code></pre></div>
<pre><code>## [1] &quot;platform:weapon:mount:muntion:target&quot;</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" data-line-number="1"><span class="co"># combining print and paste</span></a>
<a class="sourceLine" id="cb130-2" data-line-number="2"><span class="kw">print</span>(myWord)</a></code></pre></div>
<pre><code>## [1] &quot;Hello&quot;</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">paste</span>(myWord, <span class="st">&quot;World!&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>))  <span class="co"># use sep to specify how to separate the elements</span></a></code></pre></div>
<pre><code>## [1] &quot;Hello World!&quot;</code></pre>
</div>
<div id="vector-construction-methods" class="section level5">
<h5><span class="header-section-number">2.1.5.1.3</span> Vector Construction Methods</h5>
<p>R provides some useful methods for quickly creating long vectors.</p>
<ul>
<li><code>seq.int()</code> creates a sequence of integers</li>
<li><code>seq()</code> creates a sequence of floats</li>
<li><code>rep()</code> replicates a pattern</li>
</ul>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" data-line-number="1">x =<span class="st"> </span><span class="kw">seq.int</span>(<span class="dt">from =</span> <span class="dv">4</span>, <span class="dt">to =</span> <span class="dv">12</span>) <span class="co"># note: from and to are optional</span></a>
<a class="sourceLine" id="cb134-2" data-line-number="2">x</a></code></pre></div>
<pre><code>## [1]  4  5  6  7  8  9 10 11 12</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" data-line-number="1"><span class="co"># a shortcut to create a sequence of integers</span></a>
<a class="sourceLine" id="cb136-2" data-line-number="2">x =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span></a>
<a class="sourceLine" id="cb136-3" data-line-number="3">x</a></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" data-line-number="1"><span class="co"># if you need breaks in the sequence</span></a>
<a class="sourceLine" id="cb138-2" data-line-number="2">x =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dv">7</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">15</span>)</a>
<a class="sourceLine" id="cb138-3" data-line-number="3">x</a></code></pre></div>
<pre><code>## [1]  1  2  3  7  8  9 10 15</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" data-line-number="1"><span class="co"># a sequence of floats</span></a>
<a class="sourceLine" id="cb140-2" data-line-number="2">x =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">0.1</span>, <span class="dt">to =</span> <span class="fl">1.0</span>, <span class="dt">by =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb140-3" data-line-number="3">x</a></code></pre></div>
<pre><code>##  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" data-line-number="1"><span class="co"># replication</span></a>
<a class="sourceLine" id="cb142-2" data-line-number="2"><span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>)          <span class="co"># replicate 1, 10 times</span></a></code></pre></div>
<pre><code>##  [1] 1 1 1 1 1 1 1 1 1 1</code></pre>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" data-line-number="1"><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dv">2</span>)         <span class="co"># replicate 1:4, two times</span></a></code></pre></div>
<pre><code>## [1] 1 2 3 4 1 2 3 4</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" data-line-number="1"><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">each =</span> <span class="dv">2</span>)  <span class="co"># replicate 1 twice, 2 twice, etc.</span></a></code></pre></div>
<pre><code>## [1] 1 1 2 2 3 3 4 4</code></pre>
</div>
<div id="applying-regular-expressions-to-character-vectors" class="section level5">
<h5><span class="header-section-number">2.1.5.1.4</span> Applying Regular Expressions To Character Vectors</h5>
<p>A common task with character vectors is to detect, locate, extract, or replace strings based on a pattern. Using the base R <code>grep</code> methods, the syntax is <code>grep(pattern, string)</code>. Methods from other R packages (such as the <code>str_detect</code> method from the stringr package that we’ll cover later) reverse the syntax: <code>str_detect(string, pattern)</code>. The <em>Basic Regular Expressions in R Cheatsheet</em> is a useful reference for a more complete list of methods and pattern matching options.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" data-line-number="1"><span class="co"># using base R</span></a>
<a class="sourceLine" id="cb148-2" data-line-number="2">string =<span class="st"> </span>fiple  </a>
<a class="sourceLine" id="cb148-3" data-line-number="3">pattern =<span class="st"> &quot;p&quot;</span></a>
<a class="sourceLine" id="cb148-4" data-line-number="4"></a>
<a class="sourceLine" id="cb148-5" data-line-number="5"><span class="co"># detect patterns</span></a>
<a class="sourceLine" id="cb148-6" data-line-number="6"><span class="kw">grep</span>(pattern, string)                 <span class="co"># returns the index of words that contain the letter p</span></a></code></pre></div>
<pre><code>## [1] 1 2</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" data-line-number="1"><span class="kw">grep</span>(pattern, string, <span class="dt">value =</span> <span class="ot">TRUE</span>)   <span class="co"># returns the matching words</span></a></code></pre></div>
<pre><code>## [1] &quot;platform&quot; &quot;weapon&quot;</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb152-1" data-line-number="1"><span class="kw">grepl</span>(pattern, string)                <span class="co"># returns a logical vector of matches</span></a></code></pre></div>
<pre><code>## [1]  TRUE  TRUE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb154-1" data-line-number="1">stringr<span class="op">::</span><span class="kw">str_detect</span>(string, pattern)  <span class="co"># the stringr equivalent</span></a></code></pre></div>
<pre><code>## [1]  TRUE  TRUE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb156-1" data-line-number="1"><span class="co"># replace patterns</span></a>
<a class="sourceLine" id="cb156-2" data-line-number="2"><span class="kw">gsub</span>(pattern, <span class="st">&quot;XX&quot;</span>, string)           <span class="co"># replace &#39;p&#39; with &#39;XX&#39;</span></a></code></pre></div>
<pre><code>## [1] &quot;XXlatform&quot; &quot;weaXXon&quot;   &quot;mount&quot;     &quot;muntion&quot;   &quot;target&quot;</code></pre>
</div>
</div>
<div id="lists" class="section level4">
<h4><span class="header-section-number">2.1.5.2</span> Lists</h4>
<p>As opposed to vectors which must contain elements of the same data type, lists can contain more than one data type. Indexing a list is slightly different than a vector: use double brackets instead.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb158-1" data-line-number="1">myList =<span class="st"> </span><span class="kw">list</span>(<span class="dv">1</span>, <span class="st">&quot;foo&quot;</span>)   <span class="co"># can contain different data types</span></a>
<a class="sourceLine" id="cb158-2" data-line-number="2">myList                    <span class="co"># note the double brackets</span></a></code></pre></div>
<pre><code>## [[1]]
## [1] 1
## 
## [[2]]
## [1] &quot;foo&quot;</code></pre>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb160-1" data-line-number="1">myList[[<span class="dv">1</span>]]               <span class="co"># indexing a list</span></a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb162-1" data-line-number="1">myList[[<span class="dv">1</span>]] <span class="op">+</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb164-1" data-line-number="1">myList =<span class="st"> </span><span class="kw">list</span>(<span class="dt">units =</span> <span class="kw">c</span>(<span class="st">&quot;ADA&quot;</span>, <span class="st">&quot;EN&quot;</span>, <span class="st">&quot;FA&quot;</span>, <span class="st">&quot;MI&quot;</span>), x)   <span class="co"># can contain elements with different lengths</span></a>
<a class="sourceLine" id="cb164-2" data-line-number="2">myList</a></code></pre></div>
<pre><code>## $units
## [1] &quot;ADA&quot; &quot;EN&quot;  &quot;FA&quot;  &quot;MI&quot; 
## 
## [[2]]
##  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0</code></pre>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb166-1" data-line-number="1">myList[[<span class="dv">1</span>]]               <span class="co"># the units vector back</span></a></code></pre></div>
<pre><code>## [1] &quot;ADA&quot; &quot;EN&quot;  &quot;FA&quot;  &quot;MI&quot;</code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb168-1" data-line-number="1">myList[[<span class="dv">1</span>]][<span class="dv">2</span>]            <span class="co"># the second element in the first vector</span></a></code></pre></div>
<pre><code>## [1] &quot;EN&quot;</code></pre>
<p>Lists are commonly used to pass paramters to a function (details in a later section). For example, I was recently exploring the <code>ReinforcementLearning</code> package. With this package, tuning parameters are passed to one of the functions with a list that contains names and values for the parameters. Values in the list can be accessed either by index numer or using its name preceeded by <code>$</code>.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" data-line-number="1">control =<span class="st"> </span><span class="kw">list</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>, <span class="dt">gamma =</span> <span class="fl">0.4</span>, <span class="dt">epsilon =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb170-2" data-line-number="2">control</a></code></pre></div>
<pre><code>## $alpha
## [1] 0.2
## 
## $gamma
## [1] 0.4
## 
## $epsilon
## [1] 0.1</code></pre>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb172-1" data-line-number="1">control[[<span class="dv">1</span>]]  </a></code></pre></div>
<pre><code>## [1] 0.2</code></pre>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb174-1" data-line-number="1">control<span class="op">$</span>alpha  <span class="co"># equivalent to control[[1]]</span></a></code></pre></div>
<pre><code>## [1] 0.2</code></pre>
</div>
<div id="matrices" class="section level4">
<h4><span class="header-section-number">2.1.5.3</span> Matrices</h4>
<p>Matrices are not commonly encountered in the WAD workflow, but they are worth mentioning for situational awareness. Matrix construction is column-wise by default, but that can be overwritten by specifying <code>byrow=TRUE</code> as shown below.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" data-line-number="1">M =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>), <span class="dt">ncol =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb176-2" data-line-number="2">M </a></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    4
## [2,]    2    5
## [3,]    3    6</code></pre>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" data-line-number="1">M =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>), <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb178-2" data-line-number="2">M</a></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4
## [3,]    5    6</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1"><span class="kw">dim</span>(M) <span class="co"># dimensions in rows, columns</span></a></code></pre></div>
<pre><code>## [1] 3 2</code></pre>
<p>R provides the ability to perform linear algebra. For example, to solve the system of equations:</p>
<p><span class="math inline">\(2x_{1} + x_{2} + 3x_{3} = 19\)</span></p>
<p><span class="math inline">\(x_{1} + 2x_{2} + x_{3} = 12\)</span></p>
<p><span class="math inline">\(3x_{1} + x_{2} + 2x_{3} = 17\)</span></p>
<p>Solve <span class="math inline">\(Ax = b\)</span></p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" data-line-number="1">A =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>,</a>
<a class="sourceLine" id="cb182-2" data-line-number="2">             <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, </a>
<a class="sourceLine" id="cb182-3" data-line-number="3">             <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">ncol=</span><span class="dv">3</span>, <span class="dt">byrow=</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb182-4" data-line-number="4">b =<span class="st"> </span><span class="kw">c</span>(<span class="dv">19</span>, <span class="dv">12</span>, <span class="dv">17</span>)</a>
<a class="sourceLine" id="cb182-5" data-line-number="5">x =<span class="st"> </span><span class="kw">solve</span>(A) <span class="op">%*%</span><span class="st"> </span>b</a>
<a class="sourceLine" id="cb182-6" data-line-number="6">x                   <span class="co"># x[1] is x1, x[2] is x2, x[3] is x3</span></a></code></pre></div>
<pre><code>##      [,1]
## [1,]    2
## [2,]    3
## [3,]    4</code></pre>
</div>
<div id="dataframes" class="section level4">
<h4><span class="header-section-number">2.1.5.4</span> Dataframes</h4>
<p>Dataframes are one of the most common data structures you will encounter when working with AWARS data. Think of a dataframe as an Excel spreadsheet or an AWARS postprocessor table. Dataframes have one or more columns, typically with column names, and the length of the columns must be equal. The values in a dataframe column must be of the same type, but columns can be of different types. For example, column 1 can be a unit name (string) and column 2 can be strength (numeric). In this course of instruction, we will use a specific type of dataframe called a tibble, which is available in the tidyverse package.</p>
<p>To create a tibble from scratch, think of the columns as vectors and wrap them into the tibble function.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_unnamed&#39; by
## &#39;rlang::check_dots_unnamed&#39; when loading &#39;tibble&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_used&#39; by
## &#39;rlang::check_dots_used&#39; when loading &#39;tibble&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_empty&#39; by
## &#39;rlang::check_dots_empty&#39; when loading &#39;tibble&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_unnamed&#39; by
## &#39;rlang::check_dots_unnamed&#39; when loading &#39;pillar&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_used&#39; by
## &#39;rlang::check_dots_used&#39; when loading &#39;pillar&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_empty&#39; by
## &#39;rlang::check_dots_empty&#39; when loading &#39;pillar&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_unnamed&#39; by
## &#39;rlang::check_dots_unnamed&#39; when loading &#39;hms&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_used&#39; by
## &#39;rlang::check_dots_used&#39; when loading &#39;hms&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_empty&#39; by
## &#39;rlang::check_dots_empty&#39; when loading &#39;hms&#39;</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✔ ggplot2 3.3.3     ✔ purrr   0.3.4
## ✔ tibble  3.0.6     ✔ dplyr   1.0.4
## ✔ tidyr   1.1.2     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" data-line-number="1">tb =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb197-2" data-line-number="2">  <span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,</a>
<a class="sourceLine" id="cb197-3" data-line-number="3">  <span class="dt">y =</span> <span class="dv">5</span><span class="op">:</span><span class="dv">14</span>, </a>
<a class="sourceLine" id="cb197-4" data-line-number="4">  <span class="dt">z =</span> <span class="kw">rep</span>(month.name[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>], <span class="dv">2</span>))     <span class="co"># create a tibble with three columns</span></a>
<a class="sourceLine" id="cb197-5" data-line-number="5">tb</a></code></pre></div>
<pre><code>## # A tibble: 10 x 3
##        x     y z       
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;   
##  1     1     5 January 
##  2     2     6 February
##  3     3     7 March   
##  4     4     8 April   
##  5     5     9 May     
##  6     6    10 January 
##  7     7    11 February
##  8     8    12 March   
##  9     9    13 April   
## 10    10    14 May</code></pre>
<p>We’ll cover dataframe operations in depth when we get to Chapter 5 of <em>R for Data Science</em>.</p>
</div>
</div>
<div id="relational-and-logical-operators" class="section level3">
<h3><span class="header-section-number">2.1.6</span> Relational and Logical Operators</h3>
<p>R uses relational and logical operators in addition to the arithmethic operators presented earlier (+, -, *, /, etc.). The following summarizes the primary relational and logical operators. When relational and logical operations are performed on vectors, the result is a logical vector of TRUE or FALSE. R treats a TRUE as a 1 and FALSE as a 0, which is useful for counting the number of matches.</p>
<div id="htmlwidget-0f1bad237696505f8eeb" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-0f1bad237696505f8eeb">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6"],["&lt;","&lt;=","&gt;","&gt;=","==","!="],["Less than","Less than or equal to","Greater than","Greater than or equal to","Equal to","Not equal to"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Operator<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>Examples of relational operations.</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" data-line-number="1">x =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span></a>
<a class="sourceLine" id="cb199-2" data-line-number="2">x <span class="op">&lt;</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>##  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1">x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" data-line-number="1">x <span class="op">==</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>##  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" data-line-number="1">x <span class="op">!=</span><span class="st"> </span><span class="dv">5</span></a></code></pre></div>
<pre><code>##  [1]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE</code></pre>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb207-1" data-line-number="1"><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Logical operations with examples.</p>
<div id="htmlwidget-514391f4b0bf08c40be0" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-514391f4b0bf08c40be0">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6"],["&amp;","|","!","&amp;&amp;","||","%in%"],["Element-wise AND","Element-wise OR","Element-wise NOT","Operand-wise AND","Operand-wise OR","Is an element in a vector"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Operator<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>Logical operations are often useful when comparing two vectors.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" data-line-number="1">x =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span></a>
<a class="sourceLine" id="cb209-2" data-line-number="2">y =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">5</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb209-3" data-line-number="3">x <span class="op">==</span><span class="st"> </span>y </a></code></pre></div>
<pre><code>##  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb211-1" data-line-number="1">x <span class="op">!=</span><span class="st"> </span>y </a></code></pre></div>
<pre><code>##  [1]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE</code></pre>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb213-1" data-line-number="1"><span class="kw">which</span>(x <span class="op">==</span><span class="st"> </span>y)     <span class="co"># the index where they are equal</span></a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb215-1" data-line-number="1">x[<span class="kw">which</span>(x <span class="op">==</span><span class="st"> </span>y)]  <span class="co"># the value of x where they are equal</span></a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb217-1" data-line-number="1"><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span>y) </a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb219-1" data-line-number="1"><span class="co"># %in% operator</span></a>
<a class="sourceLine" id="cb219-2" data-line-number="2">units =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ADA&quot;</span>, <span class="st">&quot;EN&quot;</span>, <span class="st">&quot;FA&quot;</span>, <span class="st">&quot;MI&quot;</span>)</a>
<a class="sourceLine" id="cb219-3" data-line-number="3">myUnit =<span class="st"> &quot;EN&quot;</span></a>
<a class="sourceLine" id="cb219-4" data-line-number="4">myUnit <span class="op">%in%</span><span class="st"> </span>units</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb221-1" data-line-number="1">myUnit =<span class="st"> &quot;AR&quot;</span></a>
<a class="sourceLine" id="cb221-2" data-line-number="2">myUnit <span class="op">%in%</span><span class="st"> </span>units</a></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
</div>
</div>
<div id="introduction-to-r---part-ii" class="section level2">
<h2><span class="header-section-number">2.2</span> Introduction to R - Part II</h2>
<div id="reading-tasks" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Reading Tasks</h3>
<p>Read <em>R for Data Science</em> Chapters 3 and 5. Each section of the reading has associated exercises. Follow the link to the problem set below for which exercises you should complete. After completing the exercises, briefly skim through <em>R for Data Science</em> Chapters 11, 13-15, and 18-21 to get an idea of what they contain. We’ll revisit and apply these concepts later in the course.</p>
</div>
<div id="problem-set" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Problem Set</h3>
<p>The problem set for this section is located <a href = '/docsArchive/_Chapter2_ProblemSets/Chapter2_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/docsArchive/_Chapter2_ProblemSets/Chapter2_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/docsArchive/_Chapter2_ProblemSets/Chapter2_Solutions.html'>here</a>.</p>
<!--chapter:end:02-Intro_To_R.Rmd-->
</div>
</div>
</div>
<div id="statistics-review" class="section level1">
<h1><span class="header-section-number">3</span> Statistics Review</h1>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>In this section, we will briefly review the probability and statistics topics that are relevant to the design and analysis of experiments for modeling and simulation. In particular, we will cover:</p>
<ul>
<li>Descriptive Statistics</li>
<li>Statistical Concepts</li>
<li>Statistical Inference</li>
<li>Analysis of Variance</li>
</ul>
<div id="resources-1" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Resources</h3>
<p>The following are useful resources to review these topics:</p>
<ul>
<li><a href = "https://www.khanacademy.org/math/ap-statistics"> The Khan Academy AP Statistics Course </a></li>
<li><a href = "https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/index.htm"> The MIT Open Courseware <em>Introduction to Probability and Statistics</em> taught by Orloff and Bloom in Spring 2014 </a></li>
<li>Any standard probability and statistics text, e.g.:
<ul>
<li><a href = "https://www.cengage.com/c/probability-and-statistics-for-engineering-and-the-sciences-9e-devore/9781305251809PF/"> Devore’s *Probability and Statistics for Engineering and the Sciences</a></li>
<li><a href="https://www.cengage.com/c/probability-and-statistics-for-engineers-and-scientists-4e-hayter/9781111827045/"> Hayter’s Probability and Statistics for Engineers and Scientists </a></li>
<li>Please note, there is no need to buy anything or especially the latest version. Older versions are almost always perfectly accurate and significantly cheaper.</li>
<li>There are a variety of free texts, for example: <a href = "https://moderndive.com/"><em>Statistical Inference via Data Science</em></a> hosted via <a href = 'https://bookdown.org'>Bookdown</a> is nice. The <a href = "https://www.itl.nist.gov/div898/handbook/"><em>NIST Engineering Statistics</em></a> from NIST is also incredibly useful.</li>
</ul></li>
</ul>
<p>Given the extensive coverage of these topics, most of this section will be terse and/or refer to external resources as anything I might write is likely redundant. That stated, if you are familiar with these topics, try your hand at the problem sets if you’re rusty or have not ever done statistics using <em>R</em>.</p>
</div>
<div id="organization" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Organization</h3>
<p>The remainder of this chapter is organized as follows:</p>
<ul>
<li>Lesson
<ul>
<li>Lesson Description</li>
<li>Lesson Tutorial</li>
<li>Lesson Problem Set</li>
</ul></li>
</ul>
</div>
<div id="poc" class="section level3">
<h3><span class="header-section-number">3.1.3</span> POC</h3>
<p>For any noted issues (especially errors), please contact: Steve Gillespie at <a href="mailto:stephen.e.gillespie.mil@mail.mil" class="email">stephen.e.gillespie.mil@mail.mil</a> or Emma Schlagenhauff at <a href="mailto:emma.schlagenhauff.civ@mail.mil" class="email">emma.schlagenhauff.civ@mail.mil</a>.</p>
</div>
</div>
<div id="descriptive-statistics" class="section level2">
<h2><span class="header-section-number">3.2</span> Descriptive Statistics</h2>
<div id="descriptive-statistics---description" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Descriptive Statistics - Description</h3>
<p>This section is a refresher for analysts on basic descriptive statistics including the following concepts:</p>
<ul>
<li>Measures of central tendency: mean, median, mode.</li>
<li>Measures of dispersion: standard deviation and variance, interquartile range, and range.</li>
<li>Standard plots including: boxplots, histograms, density plots.</li>
<li>Empirical probability distributions and cumulative distribution functions.</li>
</ul>
</div>
<div id="descriptive-statistics---tutorial" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Descriptive Statistics - Tutorial</h3>
<p>For this tutorial, we assume one is familiar with the measures identified above. If not, please view the following videos:</p>
<ul>
<li><a href = "https://www.khanacademy.org/math/ap-statistics/quantitative-data-ap"> Khan Academy AP Statistics Displaying and Describing Quantitative Data </a></li>
<li><a href = "https://www.khanacademy.org/math/ap-statistics/summarizing-quantitative-data-ap"> Khan Academy AP Statistics Summarizing Quantitative Data </a></li>
<li><a href = "https://www.khanacademy.org/math/ap-statistics/density-curves-normal-distribution-ap"> Khan Academy AP Statistics Modeling Data Distributions </a></li>
</ul>
<p>The remainder of this tutorial is simply brief concept descriptions and examples in R.</p>
<div id="measures-of-central-tendency" class="section level4">
<h4><span class="header-section-number">3.2.2.1</span> Measures of Central Tendency</h4>
<div id="mean" class="section level5">
<h5><span class="header-section-number">3.2.2.1.1</span> Mean</h5>
<p>The mean of a set of <span class="math inline">\(n\)</span> numbers: <span class="math inline">\({a_1, a_2, ... a_n}\)</span> is <span class="math inline">\(\frac{\sum_{i=1}^na_i}{n}\)</span></p>
<p>In <em>R</em> we can calculate the mean of a vector as follows:</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="dv">0</span><span class="op">:</span><span class="dv">10</span></a>
<a class="sourceLine" id="cb223-2" data-line-number="2">x</a></code></pre></div>
<pre><code>##  [1]  0  1  2  3  4  5  6  7  8  9 10</code></pre>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1"><span class="kw">mean</span>(x)</a></code></pre></div>
<pre><code>## [1] 5</code></pre>
</div>
<div id="median" class="section level5">
<h5><span class="header-section-number">3.2.2.1.2</span> Median</h5>
<p>The mean of a set of <span class="math inline">\(n\)</span> numbers as listed above is:</p>
<ul>
<li>If the set is finite and has odd cardinality, the number “in the middle” of the set when ordered.</li>
<li>If the set is finite and has even cardinality, the average of the two numbers “in the middle” of the set when ordered.</li>
<li>If the set is infinite, the value of the 50 percentile.</li>
</ul>
<p>Using the same data as above <code>x</code>, we can calculate the median as:</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" data-line-number="1"><span class="kw">median</span>(x)</a></code></pre></div>
<pre><code>## [1] 5</code></pre>
</div>
<div id="mean-and-median-note---treatment-of-na" class="section level5">
<h5><span class="header-section-number">3.2.2.1.3</span> Mean and Median Note - Treatment of NA</h5>
<p>As you may have experienced, often data sets are incomplete. In <em>R</em> these missing values are often represented as <code>NA</code>. Both <code>mean()</code> and <code>median()</code> have an argument called <code>na.rm</code> that is defaulted to <code>FALSE</code>. Let’s see what happens:</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="kw">c</span>(x, <span class="ot">NA</span>) <span class="co"># Add an NA to the data set</span></a>
<a class="sourceLine" id="cb229-2" data-line-number="2">x</a></code></pre></div>
<pre><code>##  [1]  0  1  2  3  4  5  6  7  8  9 10 NA</code></pre>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1"><span class="co"># The mean and median will return NA</span></a>
<a class="sourceLine" id="cb231-2" data-line-number="2"><span class="kw">mean</span>(x)</a></code></pre></div>
<pre><code>## [1] NA</code></pre>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb233-1" data-line-number="1"><span class="kw">median</span>(x)</a></code></pre></div>
<pre><code>## [1] NA</code></pre>
<p>This is a logical result as it lets us know we really can’t determine the mean (you can’t sum an NA either). If you want to drop the NAs and calculate the mean or median with only the values available (understanding that you are missing data), you can do this by changing the default for <code>na.rm</code> as follows:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb235-1" data-line-number="1">x</a></code></pre></div>
<pre><code>##  [1]  0  1  2  3  4  5  6  7  8  9 10 NA</code></pre>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" data-line-number="1"><span class="kw">mean</span>(x, <span class="dt">na.rm =</span> T)</a></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb239-1" data-line-number="1"><span class="kw">median</span>(x, <span class="dt">na.rm =</span> T)</a></code></pre></div>
<pre><code>## [1] 5</code></pre>
</div>
<div id="mode" class="section level5">
<h5><span class="header-section-number">3.2.2.1.4</span> Mode</h5>
<p>The mode of a discrete set of numbers is the number (or numbers) that occurs most frequently in the set.</p>
<p>Inexplicably, <em>R</em> does not have a base function for mode. If you want to find the mode of a set, you can solve this problem in any number of ways. Here is one approach, I recommend you trying to do this in a different way!</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" data-line-number="1">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb241-2" data-line-number="2">y</a></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10  2  3  2  3  2  3  2  3  2  3</code></pre>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb243-1" data-line-number="1"><span class="co"># Note that the mode is not what you would expect. It tells you something about the data type</span></a>
<a class="sourceLine" id="cb243-2" data-line-number="2"><span class="kw">mode</span>(y)</a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb245-1" data-line-number="1"><span class="co"># Create a data frame with the values of y, then group by the individual values and count them.  I&#39;ll use dplyr to manipulate the dataframe</span></a>
<a class="sourceLine" id="cb245-2" data-line-number="2"><span class="kw">library</span>(dplyr)</a></code></pre></div>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_unnamed&#39; by
## &#39;rlang::check_dots_unnamed&#39; when loading &#39;tibble&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_used&#39; by
## &#39;rlang::check_dots_used&#39; when loading &#39;tibble&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_empty&#39; by
## &#39;rlang::check_dots_empty&#39; when loading &#39;tibble&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_unnamed&#39; by
## &#39;rlang::check_dots_unnamed&#39; when loading &#39;pillar&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_used&#39; by
## &#39;rlang::check_dots_used&#39; when loading &#39;pillar&#39;</code></pre>
<pre><code>## Warning: replacing previous import &#39;ellipsis::check_dots_empty&#39; by
## &#39;rlang::check_dots_empty&#39; when loading &#39;pillar&#39;</code></pre>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" data-line-number="1">myDF &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Num =</span> y)</a>
<a class="sourceLine" id="cb252-2" data-line-number="2">myDF &lt;-<span class="st"> </span>myDF <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Num) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">summarise</span>(<span class="dt">Count =</span> <span class="kw">n</span>(), <span class="dt">.groups=</span><span class="st">&#39;drop&#39;</span>) <span class="co"># We create a data frame that gives us the count of y </span></a>
<a class="sourceLine" id="cb252-3" data-line-number="3">myDF</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##      Num Count
##  * &lt;dbl&gt; &lt;int&gt;
##  1     1     1
##  2     2     6
##  3     3     6
##  4     4     1
##  5     5     1
##  6     6     1
##  7     7     1
##  8     8     1
##  9     9     1
## 10    10     1</code></pre>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb254-1" data-line-number="1">myMode &lt;-<span class="st"> </span>myDF<span class="op">$</span>Num[myDF<span class="op">$</span>Count <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(myDF<span class="op">$</span>Count)]</a>
<a class="sourceLine" id="cb254-2" data-line-number="2">myMode</a></code></pre></div>
<pre><code>## [1] 2 3</code></pre>
<p>While that is a bit annoying, if one was frequently finding the mode of a set, we could define a function that does this and save it and reference it later.</p>
</div>
</div>
<div id="measures-of-dispersion" class="section level4">
<h4><span class="header-section-number">3.2.2.2</span> Measures of Dispersion</h4>
<div id="standard-deviation" class="section level5">
<h5><span class="header-section-number">3.2.2.2.1</span> Standard Deviation</h5>
<p>The standard deviation <span class="math inline">\(\sigma\)</span> and variance <span class="math inline">\(\sigma^2\)</span> of a set of numbers measures the “spread” or “dispersion” of the set of data from its mean. It is calculated as:</p>
<ul>
<li><span class="math inline">\(\sigma = \sqrt{\frac{\sum(x_i - \mu)^2}{N}}\)</span> where <span class="math inline">\(\mu\)</span> is the population mean.</li>
</ul>
<p>Often we do not know the population mean and estimate it from the sample, so we must get the sample standard deviation as:</p>
<ul>
<li><span class="math inline">\(s = \sqrt{\frac{\sum(x_i - x\bar)^2}{N-1}}\)</span> where <span class="math inline">\(\bar{x}\)</span> is the sample mean.</li>
</ul>
<p><em>R</em> defaults to use the sample standard deviation and variance (i.e., the <span class="math inline">\(N-1\)</span> denominator), though for sufficiently large sample sizes, the effect of this is minimal.</p>
<p>Let’s see how to do this:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" data-line-number="1"><span class="co"># Create a random set of data.  We&#39;ll use the function rnorm(n, mean, standard deviation) </span></a>
<a class="sourceLine" id="cb256-2" data-line-number="2"><span class="co"># which produces random numbers from a normal distribution with the provided mean and the </span></a>
<a class="sourceLine" id="cb256-3" data-line-number="3"><span class="co"># provided standard deviation.</span></a>
<a class="sourceLine" id="cb256-4" data-line-number="4">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">30</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb256-5" data-line-number="5">x</a></code></pre></div>
<pre><code>##  [1]  6.354516 11.132540  9.798129 11.915537  8.352485  8.718668 10.106117
##  [8] 10.154289  8.920113  8.517626  9.149977 11.855159 10.195301  7.610222
## [15] 12.221281  9.409073 11.174899  8.412771  7.531644 12.414193  7.255384
## [22] 10.615774 11.476541  9.349505  7.708578  9.328469  7.793352 10.374259
## [29] 12.213837 10.969795</code></pre>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb258-1" data-line-number="1"><span class="kw">mean</span>(x)</a></code></pre></div>
<pre><code>## [1] 9.701001</code></pre>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb260-1" data-line-number="1"><span class="kw">sd</span>(x)</a></code></pre></div>
<pre><code>## [1] 1.675795</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb262-1" data-line-number="1"><span class="kw">var</span>(x)</a></code></pre></div>
<pre><code>## [1] 2.808287</code></pre>
<p>Note that the provided (i.e., true) mean is 10 and the provided (i.e, true) standard deviation is 2, but our estimates are just that, statistical estimates.</p>
</div>
<div id="median-absolute-deviation" class="section level5">
<h5><span class="header-section-number">3.2.2.2.2</span> Median Absolute Deviation</h5>
<p>The median absolute deviation (MAD) is a robust measure of the spread of a set of data. It is <em>robust</em> in the sense that it is not highly sensitive to outliers or non-normality. The MAD is defined as the median of the absolute value of the difference between each observation in a set and the set’s median:</p>
<p><span class="math inline">\(MAD = median(|Y_i - median(Y)|)\)</span></p>
<p>Where <span class="math inline">\(Y_i \in Y\)</span> and Y is the set under question.</p>
<p>For example, consider the set: <span class="math inline">\(Y = 1, 2, 3... 10\)</span>. This set has a median of 5.5. We can then make a new set, <span class="math inline">\(W\)</span>, of the absolute value of the difference between the median and the observation, i.e.:</p>
<p><span class="math inline">\(W = {|1-5.5|, |2-5.5|,|3-5.5|, ... |10-5.5|} = {4.5, 3.5, 2.5, ..., 4.5}\)</span></p>
<p>The MAD is then the median of <span class="math inline">\(W\)</span>. We can calculate this as follows:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" data-line-number="1">Y &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span> <span class="co"># Define Y as the set 1, 2, .. 10</span></a>
<a class="sourceLine" id="cb264-2" data-line-number="2">Y</a></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb266-1" data-line-number="1">Y.median &lt;-<span class="st"> </span><span class="kw">median</span>(Y) <span class="co"># Calculate the median of Y</span></a>
<a class="sourceLine" id="cb266-2" data-line-number="2">Y.median</a></code></pre></div>
<pre><code>## [1] 5.5</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb268-1" data-line-number="1"><span class="co"># Note how R applies the operation below to each member of the vector</span></a>
<a class="sourceLine" id="cb268-2" data-line-number="2">W &lt;-<span class="st"> </span><span class="kw">abs</span>(Y<span class="op">-</span>Y.median) <span class="co"># Define W as the set of the absolute value of the difference between Y and its median</span></a>
<a class="sourceLine" id="cb268-3" data-line-number="3">W</a></code></pre></div>
<pre><code>##  [1] 4.5 3.5 2.5 1.5 0.5 0.5 1.5 2.5 3.5 4.5</code></pre>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb270-1" data-line-number="1">W.median &lt;-<span class="st"> </span><span class="kw">median</span>(W)</a>
<a class="sourceLine" id="cb270-2" data-line-number="2">W.median</a></code></pre></div>
<pre><code>## [1] 2.5</code></pre>
<p>So, we see that the <span class="math inline">\(MAD\)</span> of {1, 2, …10} is 2.5. Of course, the above coding was onerous; fortunately, <em>R</em> has a function, <code>mad()</code> to do this for us; however, the default in <em>R</em> is to add a normalizing factor above and beyond the standard <span class="math inline">\(MAD\)</span> calculation. What <code>mad()</code> returns is the <span class="math inline">\(MAD\)</span> as defined above times a constant. In <em>R</em>, the default constant is 1.4826 (read the <em>R</em> help on <code>mad()</code> for an explanation as to why). If you simply want the standard <span class="math inline">\(MAD\)</span>, adjust the constant to 1 as seen below:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" data-line-number="1"><span class="kw">mad</span>(Y, <span class="dt">constant =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 2.5</code></pre>
</div>
<div id="range" class="section level5">
<h5><span class="header-section-number">3.2.2.2.3</span> Range</h5>
<p>While not a typical statistic, it is often useful to know the maximum and minimum of a set, and, sometimes, their difference. These numbers are self explanatory and can be quickly computed in <em>R</em> as follows:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb274-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">100</span> <span class="co"># Note the max is 100 and the minimum is 1</span></a>
<a class="sourceLine" id="cb274-2" data-line-number="2"></a>
<a class="sourceLine" id="cb274-3" data-line-number="3"><span class="co"># Maximum</span></a>
<a class="sourceLine" id="cb274-4" data-line-number="4"><span class="kw">max</span>(x)</a></code></pre></div>
<pre><code>## [1] 100</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb276-1" data-line-number="1"><span class="co"># Minimum</span></a>
<a class="sourceLine" id="cb276-2" data-line-number="2"><span class="kw">min</span>(x)</a></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb278-1" data-line-number="1"><span class="co"># Both</span></a>
<a class="sourceLine" id="cb278-2" data-line-number="2"><span class="kw">range</span>(x) <span class="co"># note this returns a vector c(minimum, maximum)</span></a></code></pre></div>
<pre><code>## [1]   1 100</code></pre>
</div>
<div id="interquartile-range-iqr" class="section level5">
<h5><span class="header-section-number">3.2.2.2.4</span> Interquartile Range (IQR)</h5>
<p>The interquartile range of a set is the middle 50% of the set, or the difference between the value associated with the 75th percentile and the 25th percentile. We can calculate this in a number of ways in <em>R</em>.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb280-1" data-line-number="1"><span class="co"># First define a set of numbers.  Let&#39;s take 100 samples of the normal distribution with a </span></a>
<a class="sourceLine" id="cb280-2" data-line-number="2"><span class="co"># mean of 0 and a standard deviation of 1.</span></a>
<a class="sourceLine" id="cb280-3" data-line-number="3">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>) <span class="co"># Note the defaults for rnorm are the mean and standard deviation as listed above.</span></a>
<a class="sourceLine" id="cb280-4" data-line-number="4"></a>
<a class="sourceLine" id="cb280-5" data-line-number="5"><span class="co"># If you simply want the interquartile range, this function provides it:</span></a>
<a class="sourceLine" id="cb280-6" data-line-number="6"><span class="kw">IQR</span>(x)</a></code></pre></div>
<pre><code>## [1] 1.277415</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb282-1" data-line-number="1"><span class="co"># If you want to see the quartiles explicitly, you can use quantile:</span></a>
<a class="sourceLine" id="cb282-2" data-line-number="2"><span class="kw">quantile</span>(x)</a></code></pre></div>
<pre><code>##          0%         25%         50%         75%        100% 
## -1.98959508 -0.58071596 -0.02559552  0.69669863  2.38616256</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb284-1" data-line-number="1"><span class="co"># You could do this and retype in the numbers explicitly, but that is not robust to </span></a>
<a class="sourceLine" id="cb284-2" data-line-number="2"><span class="co"># varying data sets. Understanding the output of quantile() is helpful.  We can see this </span></a>
<a class="sourceLine" id="cb284-3" data-line-number="3"><span class="co"># by saving the output</span></a>
<a class="sourceLine" id="cb284-4" data-line-number="4">myQuantile &lt;-<span class="st"> </span><span class="kw">quantile</span>(x)</a>
<a class="sourceLine" id="cb284-5" data-line-number="5"><span class="co"># You can see what myQuantile is by looking at its type (note, it&#39;s a double)</span></a>
<a class="sourceLine" id="cb284-6" data-line-number="6"><span class="kw">typeof</span>(myQuantile)</a></code></pre></div>
<pre><code>## [1] &quot;double&quot;</code></pre>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb286-1" data-line-number="1"><span class="co"># If you noted in the output that as opposed to what happens when you output a normal </span></a>
<a class="sourceLine" id="cb286-2" data-line-number="2"><span class="co"># vector, you had associated names, you can see these names as follows</span></a>
<a class="sourceLine" id="cb286-3" data-line-number="3"><span class="kw">names</span>(myQuantile)</a></code></pre></div>
<pre><code>## [1] &quot;0%&quot;   &quot;25%&quot;  &quot;50%&quot;  &quot;75%&quot;  &quot;100%&quot;</code></pre>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb288-1" data-line-number="1"><span class="co"># But, with this knowledge, you can call the specific indices you want (recall, R indexes vectors starting at 1!!!)</span></a>
<a class="sourceLine" id="cb288-2" data-line-number="2">myQuantile[<span class="dv">4</span>]</a></code></pre></div>
<pre><code>##       75% 
## 0.6966986</code></pre>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb290-1" data-line-number="1">myQuantile[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>##       25% 
## -0.580716</code></pre>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb292-1" data-line-number="1"><span class="co"># You could then subtract the two</span></a>
<a class="sourceLine" id="cb292-2" data-line-number="2">myQuantile[<span class="dv">4</span>] <span class="op">-</span><span class="st"> </span>myQuantile[<span class="dv">2</span>] <span class="co"># note this preserves the names of the first result (annoying and inaccurate in this case)</span></a></code></pre></div>
<pre><code>##      75% 
## 1.277415</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb294-1" data-line-number="1"><span class="co"># We can see that the two methods produce the same result:</span></a>
<a class="sourceLine" id="cb294-2" data-line-number="2"><span class="kw">IQR</span>(x) <span class="op">==</span><span class="st"> </span>myQuantile[<span class="dv">4</span>] <span class="op">-</span><span class="st"> </span>myQuantile[<span class="dv">2</span>]</a></code></pre></div>
<pre><code>##  75% 
## TRUE</code></pre>
</div>
</div>
<div id="standard-plots" class="section level4">
<h4><span class="header-section-number">3.2.2.3</span> Standard Plots</h4>
<p>This section assumes one is somewhat familiar with <code>ggplot()</code>. If not, please refer to the introduction to <em>R</em> chapter.</p>
<div id="boxplot" class="section level5">
<h5><span class="header-section-number">3.2.2.3.1</span> Boxplot</h5>
<p>A boxplot, or sometimes a box and whisker plot, shows dispersion of data according to its median, 75th and 25th percentiles (IQR) (which form the box), plus &quot;whiskers that extend to 1.5 * IQR beyond the 25th and 75th percentiles and then any outliers. This picture from wikipedia shows it very well:</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/1/1a/Boxplot_vs_PDF.svg" alt="Boxplot Description From  Wikipedia " />
<p class="caption">Boxplot Description From <a href = "https://en.wikipedia.org/wiki/Interquartile_range"> Wikipedia </a></p>
</div>
<p>To plot a boxplot in R, use <code>geom_boxplot()</code> as described below:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb296-1" data-line-number="1"><span class="kw">library</span>(ggplot2) <span class="co"># We will use ggplot for all graphing </span></a>
<a class="sourceLine" id="cb296-2" data-line-number="2"></a>
<a class="sourceLine" id="cb296-3" data-line-number="3"><span class="co"># This plot uses mtcars and shows the dispersion of miles per gallon across all observations</span></a>
<a class="sourceLine" id="cb296-4" data-line-number="4"><span class="co"># Note, since we consolidated all of our observations into a single category, </span></a>
<a class="sourceLine" id="cb296-5" data-line-number="5"><span class="co"># we have no need to have an x axis.</span></a>
<a class="sourceLine" id="cb296-6" data-line-number="6"><span class="kw">ggplot</span>(<span class="dt">data =</span> mtcars) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">&#39;&#39;</span>, <span class="dt">y =</span> mpg))</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Often we want to understand the variability by some other explanatory variable, in this case we can assess by the number of cylinders in a car</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb297-1" data-line-number="1"><span class="co"># This plot uses mtcars and shows the dispersion of miles per gallon across all observations</span></a>
<a class="sourceLine" id="cb297-2" data-line-number="2"><span class="co"># Note that in mtcars$cyl, the number of cylinders is numeric, but geom_boxplot will fail </span></a>
<a class="sourceLine" id="cb297-3" data-line-number="3"><span class="co"># with this input as an x, it needs a factor</span></a>
<a class="sourceLine" id="cb297-4" data-line-number="4"><span class="kw">ggplot</span>(<span class="dt">data =</span> mtcars) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(cyl), <span class="dt">y =</span> mpg)) </a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="histograms-density-plots" class="section level5">
<h5><span class="header-section-number">3.2.2.3.2</span> Histograms &amp; Density Plots</h5>
<p>Histograms and density plots are useful to understanding how data is distributed across a variable (i.e., how frequently it occurs). We can plot these by using <code>geom_histogram()</code> and <code>geom_density()</code> respectively.</p>
<p>Histogram:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb298-1" data-line-number="1"><span class="co"># Note you have many different options with geom_histogram such as binwidth.  I recommend </span></a>
<a class="sourceLine" id="cb298-2" data-line-number="2"><span class="co"># you spend some time playing with the options and understand what is occurring</span></a>
<a class="sourceLine" id="cb298-3" data-line-number="3"><span class="kw">ggplot</span>(mtcars) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mpg)) </a></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" data-line-number="1"><span class="co"># You can also facet this, perhaps by cylinder</span></a>
<a class="sourceLine" id="cb300-2" data-line-number="2"><span class="kw">ggplot</span>(mtcars) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mpg)) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>cyl)</a></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Density plots</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb302-1" data-line-number="1"><span class="kw">ggplot</span>(mtcars) <span class="op">+</span><span class="st"> </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mpg)) </a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Often it is nice to look at density plots overlayed on each other across some aesthetic (e.g., cylinders)</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb303-1" data-line-number="1"><span class="co"># note that aesthetics often do not work with numeric values, it&#39;s often better to term them a factor</span></a>
<a class="sourceLine" id="cb303-2" data-line-number="2"><span class="kw">ggplot</span>(mtcars) <span class="op">+</span><span class="st"> </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mpg, <span class="dt">color =</span> <span class="kw">as.factor</span>(cyl))) </a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="bar-or-column-charts" class="section level5">
<h5><span class="header-section-number">3.2.2.3.3</span> Bar or Column Charts</h5>
<p>Sometimes we want to represent counts or means or other statistics for some set of data, <code>geom_col()</code> and <code>geom_bar()</code> both allow us to do this. This is also a good exercise in grouping and summarizing data.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb304-1" data-line-number="1">myData &lt;-<span class="st"> </span>mtcars <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb304-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(cyl) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb304-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Mean.MPG =</span> <span class="kw">mean</span>(mpg), <span class="dt">Number =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb304-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">cyl =</span> <span class="kw">as.factor</span>(cyl))</a>
<a class="sourceLine" id="cb304-5" data-line-number="5"><span class="co"># Note this gives us a new data frame that makes cyl a factor and give us the mean miles </span></a>
<a class="sourceLine" id="cb304-6" data-line-number="6"><span class="co"># per gallon for each sized engine and the number of observations for each engine size.</span></a>
<a class="sourceLine" id="cb304-7" data-line-number="7">myData </a></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   cyl   Mean.MPG Number
## * &lt;fct&gt;    &lt;dbl&gt;  &lt;int&gt;
## 1 4         26.7     11
## 2 6         19.7      7
## 3 8         15.1     14</code></pre>
<p>The column plot shows the mean miles per gallon.</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" data-line-number="1"><span class="kw">ggplot</span>(myData) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb306-2" data-line-number="2"><span class="st">    </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x =</span> cyl, <span class="dt">y =</span> Mean.MPG)) <span class="op">+</span><span class="st"> </span><span class="co"># This gives us a column chart with cylinders on the x axis and miles per gallon on the y</span></a>
<a class="sourceLine" id="cb306-3" data-line-number="3"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;Cylinders&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># It&#39;s a good idea to label your axes usefully</span></a>
<a class="sourceLine" id="cb306-4" data-line-number="4"><span class="st">    </span><span class="kw">ylab</span>(<span class="st">&#39;Mean Miles Per Gallon&#39;</span>)</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>This bar plot shows</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb307-1" data-line-number="1"><span class="kw">ggplot</span>(myData) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> cyl, <span class="dt">y =</span> Number), <span class="dt">stat =</span> <span class="st">&#39;identity&#39;</span>) </a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>We can also turn this into a pie chart by changing coordinates:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" data-line-number="1"><span class="kw">ggplot</span>(myData) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">&#39;&#39;</span>, <span class="dt">y =</span> Number, <span class="dt">fill =</span> cyl), <span class="dt">stat =</span> <span class="st">&#39;identity&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb308-2" data-line-number="2"><span class="st">    </span><span class="kw">coord_polar</span>(<span class="st">&#39;y&#39;</span>, <span class="dt">start =</span> <span class="dv">0</span>)</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
</div>
<div id="understanding-calculating-and-plotting-distributions" class="section level4">
<h4><span class="header-section-number">3.2.2.4</span> Understanding, Calculating, and Plotting Distributions</h4>
<p>Probability distributions are fundamental to statistics. In this section, we’ll cover three things:</p>
<ol style="list-style-type: decimal">
<li>How <em>R</em> produces standard probability distributions.</li>
<li>How <em>R</em> can be used to build an empirical distribution from a set of data.</li>
<li>How <em>R</em> can be used to plot any probability distribution.</li>
</ol>
<div id="standard-probability-distributions" class="section level5">
<h5><span class="header-section-number">3.2.2.4.1</span> Standard Probability Distributions</h5>
<p>It is worth reviewing probability theory and probability distributions before beginning. Please see the resources above. Additionally:</p>
<ul>
<li>This <a href = "http://www.math.wm.edu/~leemis/chart/UDR/UDR.html" > link from William and Mary </a> is really cool. It shows the linkage of all univariate probability distributions!</li>
<li>This <a href = "https://www.stat.umn.edu/geyer/old/5101/rlook.html" > link from the University of Minnesota </a> is very useful. It shows all the basic random variable functions in <em>R</em>. I’ll only show a few so as not to be redundant.</li>
</ul>
<p>First, let’s recall the normal (or Gaussian) <a href = "https://en.wikipedia.org/wiki/Gaussian_function" > distribution </a>. This (or its approximation) is likely the most commonly used distribution in all of statistics.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/7/74/Normal_Distribution_PDF.svg" alt=" Wikipedia Depiction of the Normal Curve " />
<p class="caption"><a href = "https://en.wikipedia.org/wiki/Gaussian_function"> Wikipedia Depiction of the Normal Curve </a></p>
</div>
<p><em>R</em> has built in functions to get a random number from this distribution, <code>rnorm()</code>, which stands for random normal. It works as follows:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb309-1" data-line-number="1"><span class="co">#rnorm(n, mean, sd) where n is the number of random numbers desired, mean is the mean </span></a>
<a class="sourceLine" id="cb309-2" data-line-number="2"><span class="co"># for your distribution, and sd is the standard deviation</span></a>
<a class="sourceLine" id="cb309-3" data-line-number="3"><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 1.966572</code></pre>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb311-1" data-line-number="1"><span class="co"># note that it is random</span></a>
<a class="sourceLine" id="cb311-2" data-line-number="2"><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] -0.168124</code></pre>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb313-1" data-line-number="1"><span class="co"># Note that if you ask for a vector, it will return N independent, identically </span></a>
<a class="sourceLine" id="cb313-2" data-line-number="2"><span class="co"># distributed values</span></a>
<a class="sourceLine" id="cb313-3" data-line-number="3"><span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>##  [1]  0.06985819 -0.50000276  0.00915744  0.22071307  0.36325894  0.73418848
##  [7] -0.12614313  1.37919949 -0.32345019 -0.55231402</code></pre>
<p>As a side note, the <code>set.seed()</code> command is useful if you want to set the random number generator seed for <em>R</em> if you’re concerned about replicability. As a side note, <em>R</em>, like nearly every (or perhaps all) other programming languages actually generates pseudorandom numbers. See the documentation <a href = "https://www.rdocumentation.org/packages/gsl/versions/2.1-6/topics/Rng" > here </a> if you’re really concerned about it. Back to <code>set.seed()</code>:</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb315-1" data-line-number="1"><span class="co"># recall that rnorm() returns a random number, and invoking it twice will almost </span></a>
<a class="sourceLine" id="cb315-2" data-line-number="2"><span class="co"># assuredly return two different numbers.</span></a>
<a class="sourceLine" id="cb315-3" data-line-number="3"><span class="kw">rnorm</span>(<span class="dv">1</span>) <span class="co"># recall that we can rely on the defaults for mean and standard deviation </span></a></code></pre></div>
<pre><code>## [1] 1.252882</code></pre>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" data-line-number="1"><span class="co"># as 0 and 1 are OK for this</span></a>
<a class="sourceLine" id="cb317-2" data-line-number="2"><span class="kw">rnorm</span>(<span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 1.06575</code></pre>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" data-line-number="1"><span class="co"># But, if we want to reproduce the same number every time **randomly** we can set the seed</span></a>
<a class="sourceLine" id="cb319-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">173</span>)</a>
<a class="sourceLine" id="cb319-3" data-line-number="3"><span class="kw">rnorm</span>(<span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 1.053903</code></pre>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" data-line-number="1"><span class="co"># If we do it again, we&#39;ll get the same result!!!</span></a>
<a class="sourceLine" id="cb321-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">173</span>)</a>
<a class="sourceLine" id="cb321-3" data-line-number="3"><span class="kw">rnorm</span>(<span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 1.053903</code></pre>
<p>Now that we can create a random number or set of numbers from the normal distribution, we may ask ourselves other things, like, given a distribution, what’s the probability that I’ll randomly select a number in a given range. <em>R</em>, conveniently provides us this with the <code>pnorm()</code> function. It works as follows:</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb323-1" data-line-number="1"><span class="co"># The syntax is: pnorm(q, mean, standard deviation)</span></a>
<a class="sourceLine" id="cb323-2" data-line-number="2"><span class="co"># This returns P(X &lt;= q) where X ~ N(mean, standard deviation)</span></a>
<a class="sourceLine" id="cb323-3" data-line-number="3"><span class="co"># Recall the normal distribution is symmetric about its mean, so you have a 50% chance of </span></a>
<a class="sourceLine" id="cb323-4" data-line-number="4"><span class="co"># seeing a value less than the mean.</span></a>
<a class="sourceLine" id="cb323-5" data-line-number="5"><span class="kw">pnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb325-1" data-line-number="1"><span class="co"># To test it a little, let&#39;s vary the parameters</span></a>
<a class="sourceLine" id="cb325-2" data-line-number="2"><span class="kw">pnorm</span>(<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">5</span>) <span class="co"># note that this should return .5</span></a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb327-1" data-line-number="1"><span class="co"># And we know that we should get some number smaller than .5 if we choose a value less than the mean</span></a>
<a class="sourceLine" id="cb327-2" data-line-number="2"><span class="kw">pnorm</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.1586553</code></pre>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb329-1" data-line-number="1"><span class="co"># Similarly we should see some number that is higher than .5 if we choose a value greater than the mean</span></a>
<a class="sourceLine" id="cb329-2" data-line-number="2"><span class="kw">pnorm</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.8413447</code></pre>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb331-1" data-line-number="1"><span class="co"># We can of course, find the probability that a number is between two values by taking the </span></a>
<a class="sourceLine" id="cb331-2" data-line-number="2"><span class="co"># differences, for example, the probability that a number drawn from N(0, 1) is between -.5 </span></a>
<a class="sourceLine" id="cb331-3" data-line-number="3"><span class="co"># and .6 is calculated as:</span></a>
<a class="sourceLine" id="cb331-4" data-line-number="4"><span class="kw">pnorm</span>(.<span class="dv">6</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="op">-</span>.<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1] 0.4172093</code></pre>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb333-1" data-line-number="1"><span class="co"># Note, up until now, we have been operating with a default argument, lower.tail = TRUE</span></a>
<a class="sourceLine" id="cb333-2" data-line-number="2"><span class="co"># This argument makes it so that we calculate P(X &lt;= q).  If we switch it to false, we&#39;ll </span></a>
<a class="sourceLine" id="cb333-3" data-line-number="3"><span class="co"># calculate the inverse, P(X &gt;= q). For example: we can say what is the probability that </span></a>
<a class="sourceLine" id="cb333-4" data-line-number="4"><span class="co"># a number randomly drawn from the standard normal is greater than 2:</span></a>
<a class="sourceLine" id="cb333-5" data-line-number="5"><span class="kw">pnorm</span>(<span class="dv">2</span>, <span class="dt">lower.tail =</span> F)</a></code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb335-1" data-line-number="1"><span class="co"># We could, of course be mathy and calculate this as 1 - P(X &lt;= 2), X~N(0,1)</span></a>
<a class="sourceLine" id="cb335-2" data-line-number="2"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">2</span>) <span class="co"># Fortunately, this gives us the same result (which it should!!).</span></a></code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb337-1" data-line-number="1"><span class="co"># Finally, pnorm has another argument, log.p = FALSE.  If you opt for this to be true, </span></a>
<a class="sourceLine" id="cb337-2" data-line-number="2"><span class="co"># it will return the log of the probability.  This can be useful, </span></a>
<a class="sourceLine" id="cb337-3" data-line-number="3"><span class="co"># see: https://en.wikipedia.org/wiki/Log_probability but I rarely, if ever do this.</span></a>
<a class="sourceLine" id="cb337-4" data-line-number="4"><span class="co"># See for example what happens when we change the flag:</span></a>
<a class="sourceLine" id="cb337-5" data-line-number="5"><span class="kw">pnorm</span>(<span class="dv">0</span>, <span class="dt">log.p =</span> T)</a></code></pre></div>
<pre><code>## [1] -0.6931472</code></pre>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb339-1" data-line-number="1"><span class="co"># This returns the same as:</span></a>
<a class="sourceLine" id="cb339-2" data-line-number="2"><span class="kw">log</span>(<span class="kw">pnorm</span>(<span class="dv">0</span>))</a></code></pre></div>
<pre><code>## [1] -0.6931472</code></pre>
<p><code>pnorm()</code> returns the “probability” (i.e. the cumulative distribution function). Sometimes we may want its inverse, that is, for a given percentile (or quantile), we want to know the value. We get this with the <code>qnorm()</code> function. Note that it has all of the same arguments as pnorm.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb341-1" data-line-number="1"><span class="co"># We know that the normal distribution is symmetric, so the 50th percentile should be at </span></a>
<a class="sourceLine" id="cb341-2" data-line-number="2"><span class="co"># the mean and we can validate that here:</span></a>
<a class="sourceLine" id="cb341-3" data-line-number="3"><span class="kw">qnorm</span>(.<span class="dv">5</span>) <span class="co"># This returns 0 as we have a mean of 0</span></a></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb343-1" data-line-number="1"><span class="co"># We know that you can never get a 100 percentile as the normal distribution doesn&#39;t have </span></a>
<a class="sourceLine" id="cb343-2" data-line-number="2"><span class="co"># an upper limit</span></a>
<a class="sourceLine" id="cb343-3" data-line-number="3"><span class="kw">qnorm</span>(<span class="dv">1</span>) <span class="co"># R returns infinite, though, the most appropriate thing to say here, is the limit </span></a></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb345-1" data-line-number="1"><span class="co"># of qnorm(x) as x goes to 1 is infinity!  Let&#39;s not be pedantic though.</span></a>
<a class="sourceLine" id="cb345-2" data-line-number="2"><span class="co"># Similarly, we get an inverse result for a 0th percentile</span></a>
<a class="sourceLine" id="cb345-3" data-line-number="3"><span class="kw">qnorm</span>(<span class="dv">0</span>)</a></code></pre></div>
<pre><code>## [1] -Inf</code></pre>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb347-1" data-line-number="1"><span class="co"># You can get standard quartiles in a similar fashion:</span></a>
<a class="sourceLine" id="cb347-2" data-line-number="2"><span class="kw">qnorm</span>(.<span class="dv">25</span>)</a></code></pre></div>
<pre><code>## [1] -0.6744898</code></pre>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb349-1" data-line-number="1"><span class="kw">qnorm</span>(.<span class="dv">75</span>)</a></code></pre></div>
<pre><code>## [1] 0.6744898</code></pre>
<p>Finally, sometimes we want the “density” (i.e., the values for the probability distribution function) or, colloquially, the y value for a given x on the distribution curve. We get this with <code>dnorm()</code>:</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb351-1" data-line-number="1"><span class="co">#dnorm(x value, mean, standard deviation)</span></a>
<a class="sourceLine" id="cb351-2" data-line-number="2"><span class="kw">dnorm</span>(<span class="dv">0</span>)</a></code></pre></div>
<pre><code>## [1] 0.3989423</code></pre>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb353-1" data-line-number="1"><span class="co"># This implies that when one plots the height of the standard normal function, at 0, it </span></a>
<a class="sourceLine" id="cb353-2" data-line-number="2"><span class="co"># would be ~.39 (note, this does NOT mean you have a 40% chance of randomly selecting a </span></a>
<a class="sourceLine" id="cb353-3" data-line-number="3"><span class="co"># 0 out of the standard normal). There is no lower.tail argument as that is not meaningful </span></a>
<a class="sourceLine" id="cb353-4" data-line-number="4"><span class="co"># for this function, but the log argument defaults to FALSE</span></a></code></pre></div>
<p><em>R</em> has a similar standard set up of:</p>
<ul>
<li>r[distribution handle] for random number from a distribution.</li>
<li>d[distribution handle] for density of a number from a distribution.</li>
<li>p[distribution handle] for the cumulative distribution function.</li>
<li>q[distribution handle] for the inverse cumulative distribution function.</li>
</ul>
<p>I recommend you look up your favorite distribution and try it out. <font color = 'red'> Be careful, </font> make sure you read the documentation!!! <em>R</em> (and any computer language) will return exactly what you ask of it. Make sure you know what the parameters are asking for. For example, if you assume that <em>R</em> wants the variance instead of the standard deviation, you will get results for a distribution with a much larger spread than you intended!</p>
<p>Finally, if base <em>R</em> does not have your preferred distribution, I recommend Googling it. Many packages provide additional distributions.</p>
<p>Let’s briefly look at a discrete distribution and then continue on. Recall the <a href = "https://en.wikipedia.org/wiki/Binomial_distribution" > binomial distribution </a> which returns the number of successful results out of N trials where you have a probability P of success (you can only succeed or fail in this distribution). <code>*binom()</code> (where * is r, d, p, or q) is what we want.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb354-1" data-line-number="1"><span class="co"># Please look at the documentation for the syntax, type the command: ?rbinom to view it</span></a>
<a class="sourceLine" id="cb354-2" data-line-number="2"><span class="co"># in RStudio. Let&#39;s look at 10 random variables of 4 trials where we have a 50% chance </span></a>
<a class="sourceLine" id="cb354-3" data-line-number="3"><span class="co"># of succeeding</span></a>
<a class="sourceLine" id="cb354-4" data-line-number="4"><span class="kw">rbinom</span>(<span class="dv">16</span>, <span class="dv">4</span>, <span class="fl">.5</span>)</a></code></pre></div>
<pre><code>##  [1] 2 3 4 2 2 2 2 2 1 2 2 1 4 1 3 1</code></pre>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb356-1" data-line-number="1"><span class="co"># This likely makes sense, we could analytically think of the probabilities (think of your</span></a>
<a class="sourceLine" id="cb356-2" data-line-number="2"><span class="co"># odds of flipping four fair coins), but we can take this to a few edge cases to test the</span></a>
<a class="sourceLine" id="cb356-3" data-line-number="3"><span class="co"># results: Consider a guranteed success (i.e., probability of 1)</span></a>
<a class="sourceLine" id="cb356-4" data-line-number="4"><span class="kw">rbinom</span>(<span class="dv">10</span>, <span class="dv">4</span>, <span class="dv">1</span>) <span class="co"># This will return all 4s as we can only win</span></a></code></pre></div>
<pre><code>##  [1] 4 4 4 4 4 4 4 4 4 4</code></pre>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb358-1" data-line-number="1"><span class="co"># Consider the opposite, it&#39;s impossible to win</span></a>
<a class="sourceLine" id="cb358-2" data-line-number="2"><span class="kw">rbinom</span>(<span class="dv">10</span>, <span class="dv">4</span>, <span class="dv">0</span>)</a></code></pre></div>
<pre><code>##  [1] 0 0 0 0 0 0 0 0 0 0</code></pre>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb360-1" data-line-number="1"><span class="co"># Let&#39;s now consider the probabilities that we&#39;ll have n or fewer successes in 4 trials of </span></a>
<a class="sourceLine" id="cb360-2" data-line-number="2"><span class="co"># a 50-50 experiment where n is 0, 1, 2, 3, or 4</span></a>
<a class="sourceLine" id="cb360-3" data-line-number="3"><span class="kw">pbinom</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="fl">.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.0625 0.3125 0.6875 0.9375 1.0000</code></pre>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb362-1" data-line-number="1"><span class="co"># You can get the probability of getting exactly n successes as we did above.  For example, </span></a>
<a class="sourceLine" id="cb362-2" data-line-number="2"><span class="co"># the probability of seeing exactly 3 successes is:</span></a>
<a class="sourceLine" id="cb362-3" data-line-number="3"><span class="kw">pbinom</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="fl">.5</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pbinom</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="fl">.5</span>)</a></code></pre></div>
<pre><code>## [1] 0.25</code></pre>
</div>
<div id="build-empirical-distributions" class="section level5">
<h5><span class="header-section-number">3.2.2.4.2</span> Build Empirical Distributions</h5>
<p>Sometimes, we have a dataset and we want to build our own distribution out of it (for any number of reasons). <em>R</em> has a few functions that help us replicate the above type functions.</p>
<p>First, let’s build a data set:</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb364-1" data-line-number="1"><span class="co"># We&#39;ll build a dataset that is a sample of 100 random variables of two normal </span></a>
<a class="sourceLine" id="cb364-2" data-line-number="2"><span class="co"># distributions with differing means and standard deviations</span></a>
<a class="sourceLine" id="cb364-3" data-line-number="3">myData &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dv">20</span>, <span class="dv">3</span>), <span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">5</span>)) </a>
<a class="sourceLine" id="cb364-4" data-line-number="4"><span class="co"># note we can combine two or more vectors with the c() command</span></a>
<a class="sourceLine" id="cb364-5" data-line-number="5"><span class="co"># Let&#39;s look at the data to get an idea of what we&#39;re working with</span></a>
<a class="sourceLine" id="cb364-6" data-line-number="6"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> myData))</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>We can draw a random sample (from this data set!) using the sample function.</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb365-1" data-line-number="1"><span class="co"># Note 1: This is not the same as a random sample from a probability distribution, this is # only sampling from the given data.</span></a>
<a class="sourceLine" id="cb365-2" data-line-number="2"><span class="co"># Note 2: Please see the documentation on sample using ?sample to read about your </span></a>
<a class="sourceLine" id="cb365-3" data-line-number="3"><span class="co"># arguments.  For example, the default is that replace is FALSE</span></a>
<a class="sourceLine" id="cb365-4" data-line-number="4"><span class="kw">sample</span>(myData, <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## [1]  5.702567  4.645398  7.479771 20.364705 20.308881</code></pre>
<p>If we want to build a cumulative distribution function, we can use the command <code>ecdf()</code> (empirical cumulative distribution function). This then gives us a function similar to <code>p[distro]()</code>.</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb367-1" data-line-number="1">myCDF &lt;-<span class="st"> </span><span class="kw">ecdf</span>(myData)</a>
<a class="sourceLine" id="cb367-2" data-line-number="2"><span class="co"># We can then use myCDF as a function. Note, it does not have the same optional arguments as p[distro]</span></a>
<a class="sourceLine" id="cb367-3" data-line-number="3"><span class="kw">myCDF</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>)</a></code></pre></div>
<pre><code>##  [1] 0.105 0.125 0.145 0.160 0.185 0.235 0.265 0.315 0.375 0.410 0.440 0.460
## [13] 0.475 0.505 0.520 0.545 0.560 0.605 0.660 0.730</code></pre>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb369-1" data-line-number="1"><span class="co"># if we want to plot this, we can make up data points and assess them with this function</span></a>
<a class="sourceLine" id="cb369-2" data-line-number="2">myX &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">floor</span>(<span class="kw">min</span>(myData)), <span class="kw">ceiling</span>(<span class="kw">max</span>(myData)), <span class="dt">by =</span> <span class="fl">.01</span>) <span class="co"># Note here, we are nesting</span></a>
<a class="sourceLine" id="cb369-3" data-line-number="3"><span class="co"># functions, we are getting the minimum of myData, which is about -7.6 and taking the</span></a>
<a class="sourceLine" id="cb369-4" data-line-number="4"><span class="co"># floor, which rounds us down to -8, and doing a similar process for the maximum, then</span></a>
<a class="sourceLine" id="cb369-5" data-line-number="5"><span class="co"># building a vector that is a sequence from -8 to 27 by .01</span></a>
<a class="sourceLine" id="cb369-6" data-line-number="6">myY &lt;-<span class="st"> </span><span class="kw">myCDF</span>(myX) <span class="co"># we then calculate the cumulative distribution for each number in &#39;myX&#39; </span></a>
<a class="sourceLine" id="cb369-7" data-line-number="7"></a>
<a class="sourceLine" id="cb369-8" data-line-number="8"><span class="co"># Now we can plot each of the assessed points</span></a>
<a class="sourceLine" id="cb369-9" data-line-number="9"><span class="co"># Note the \n in the middle of the y label indicates a new line</span></a>
<a class="sourceLine" id="cb369-10" data-line-number="10"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb369-11" data-line-number="11"><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> myX, <span class="dt">y =</span> myY)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb369-12" data-line-number="12"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;X Value&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb369-13" data-line-number="13"><span class="st">    </span><span class="kw">ylab</span>(<span class="st">&#39;Probability that a random variable drawn</span><span class="ch">\n</span><span class="st">from this distribution is less than or equal to X&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb369-14" data-line-number="14"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;Example Empirical Cumulative Distribution Function&#39;</span>)</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>Sometimes we want the inverse (i.e., the quantiles for a given data set). The <code>quantile()</code> function gives us this, though it does not return a function. You simply provide it the data set and the desired quantiles:</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb370-1" data-line-number="1"><span class="co"># the defaults are to return 0%, 25%, 50%, 75%, and 100% (note that 0 &amp; 100 percentiles</span></a>
<a class="sourceLine" id="cb370-2" data-line-number="2"><span class="co"># are equivalent to the maximum and minimum values)  </span></a>
<a class="sourceLine" id="cb370-3" data-line-number="3"><span class="kw">quantile</span>(myData) </a></code></pre></div>
<pre><code>##        0%       25%       50%       75%      100% 
## -8.325318  6.178409 13.932411 20.314173 28.332020</code></pre>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb372-1" data-line-number="1"><span class="co"># If you want to return specific quantiles, you can pass a single value:</span></a>
<a class="sourceLine" id="cb372-2" data-line-number="2"><span class="kw">quantile</span>(myData, <span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##       10% 
## 0.8716211</code></pre>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb374-1" data-line-number="1"><span class="co"># Or you can pass a vector of values:</span></a>
<a class="sourceLine" id="cb374-2" data-line-number="2"><span class="kw">quantile</span>(myData, <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">.1</span>))</a></code></pre></div>
<pre><code>##         0%        10%        20%        30%        40%        50%        60% 
## -8.3253183  0.8716211  5.2561141  7.6465339  9.8870812 13.9324113 17.9613913 
##        70%        80%        90%       100% 
## 19.6611832 20.9977018 22.8964485 28.3320200</code></pre>
<p>If we want to turn this into a distribution we can use, however, we can build a probability distribution function with the <code>density()</code> command:</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb376-1" data-line-number="1"><span class="co"># This outputs the density for a set of Xs (i.e. values) and their associated densities as</span></a>
<a class="sourceLine" id="cb376-2" data-line-number="2"><span class="co"># Y&#39;s. Note that this is not a data frame, it is a list</span></a>
<a class="sourceLine" id="cb376-3" data-line-number="3">myPDF &lt;-<span class="st"> </span><span class="kw">density</span>(myData)</a>
<a class="sourceLine" id="cb376-4" data-line-number="4">myPDF</a></code></pre></div>
<pre><code>## 
## Call:
##  density.default(x = myData)
## 
## Data: myData (200 obs.); Bandwidth &#39;bw&#39; = 2.626
## 
##        x                y            
##  Min.   :-16.20   Min.   :8.990e-06  
##  1st Qu.: -3.10   1st Qu.:1.849e-03  
##  Median : 10.00   Median :1.797e-02  
##  Mean   : 10.00   Mean   :1.906e-02  
##  3rd Qu.: 23.11   3rd Qu.:3.277e-02  
##  Max.   : 36.21   Max.   :5.153e-02</code></pre>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb378-1" data-line-number="1"><span class="co"># If we want to understand this object better, first note:</span></a>
<a class="sourceLine" id="cb378-2" data-line-number="2"><span class="co"># It is a list: </span></a>
<a class="sourceLine" id="cb378-3" data-line-number="3"><span class="kw">typeof</span>(myPDF)</a></code></pre></div>
<pre><code>## [1] &quot;list&quot;</code></pre>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb380-1" data-line-number="1"><span class="co"># With a specific class called &#39;density&quot;</span></a>
<a class="sourceLine" id="cb380-2" data-line-number="2"><span class="kw">class</span>(myPDF)</a></code></pre></div>
<pre><code>## [1] &quot;density&quot;</code></pre>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb382-1" data-line-number="1"><span class="co"># With 7 elements</span></a>
<a class="sourceLine" id="cb382-2" data-line-number="2"><span class="kw">summary</span>(myPDF)</a></code></pre></div>
<pre><code>##           Length Class  Mode     
## x         512    -none- numeric  
## y         512    -none- numeric  
## bw          1    -none- numeric  
## n           1    -none- numeric  
## call        2    -none- call     
## data.name   1    -none- character
## has.na      1    -none- logical</code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb384-1" data-line-number="1"><span class="co"># And note that it has a call that produces a nice summary when you call the object, the</span></a>
<a class="sourceLine" id="cb384-2" data-line-number="2"><span class="co"># function is called density.default</span></a>
<a class="sourceLine" id="cb384-3" data-line-number="3">myPDF<span class="op">$</span>call</a></code></pre></div>
<pre><code>## density.default(x = myData)</code></pre>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb386-1" data-line-number="1"><span class="co"># If we want to plot the Xs and Ys, we can&#39;t treat this as a data frame, but we can access</span></a>
<a class="sourceLine" id="cb386-2" data-line-number="2"><span class="co"># the set of Xs and Ys by calling them directly</span></a>
<a class="sourceLine" id="cb386-3" data-line-number="3"><span class="co"># Note, this produces the same thing as a geom_density plot as described above</span></a>
<a class="sourceLine" id="cb386-4" data-line-number="4"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> myPDF<span class="op">$</span>x, <span class="dt">y =</span> myPDF<span class="op">$</span>y))</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
</div>
<div id="probability-distribution-conclusions" class="section level5">
<h5><span class="header-section-number">3.2.2.4.3</span> Probability Distribution Conclusions</h5>
<p>You should now be able to generate random variables, calculate probabilities, and plot probability distributions in a number of ways. We specifically showed how to use the normal, binomial, and empirical distributions in <em>R</em>. I recommend you try to do this for other common distributions (e.g., the uniform, the student t, <span class="math inline">\(\chi^2\)</span>, etc.).</p>
<p>Finally, ensure you understand the distribution you are using. Many (perhaps most) have important parameters that are: 1) not necessarily intuitive, and 2) have specific meanings. Often, the parameters are defined in a certain way in <em>R</em> that may or may not be your favorite way of doing it (e.g., using the variance vs. the standard deviation).</p>
</div>
</div>
</div>
<div id="descriptive-statistics---problem-set" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Descriptive Statistics - Problem Set</h3>
<ul>
<li>You can view the problem set here <a href = "/_Chapter3_ProblemSets/2-1_Descriptive_Statistics.html"> Descriptive Statistics Problem Set </a>.</li>
<li>For your convenience, <a href = "/_Chapter3_ProblemSets/2-1_Descriptive_Statistics.Rmd">here is the problem set as an R Markdown.</a></li>
<li>You can download the Ames Iowa data set here <a href = "/_Chapter3_ProblemSets/ames.csv"> Ames, Iowa Data Set </a>.</li>
<li>You can view the problem set solution <a href = "/_Chapter3_ProblemSets/2-1_Descriptive_Statistics_Answers.html"> here </a>.</li>
</ul>
</div>
</div>
<div id="statistical-concepts" class="section level2">
<h2><span class="header-section-number">3.3</span> Statistical Concepts</h2>
<div id="statistical-concepts---description" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Statistical Concepts - Description</h3>
<p>This section is a refresher for analysts on fundamental statistical concepts including the following:</p>
<ul>
<li>Statistical terminology.</li>
<li>Sampling distributions and the central limit theorem.</li>
</ul>
</div>
<div id="statistical-concepts---tutorial" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Statistical Concepts - Tutorial</h3>
<div id="statistical-terminology." class="section level4">
<h4><span class="header-section-number">3.3.2.1</span> Statistical Terminology.</h4>
<p>When doing and discussing statistics, it is important to be precise in your use of language. Here are a few terms we will use:</p>
<div id="random-sample" class="section level5">
<h5><span class="header-section-number">3.3.2.1.1</span> Random Sample</h5>
<p>“A sample [i.e., a subset] that has been selected from the population in such a way that every possible sample has an equal probability of being selected.” (Montgomery, 2012, pg. 30).</p>
<p>There are many sampling techniques (see, e.g., <a href = 'https://www.khanacademy.org/math/statistics-probability/designing-studies#sampling-methods-stats'> Khan Academy Sampling </a>), however, for us, there are two important points:</p>
<ul>
<li>Many statistical tests assume a random sample. We need to ensure we know which tests assume what <em>and</em> if the data we are using can be assumed to be a reasonably random sample.</li>
<li>We are largely concerned with computer simulation. This means that we can generally look at the random variables we use. That stated, we must be careful when we are assessing results of a simulation, because we may not have independent results (we will have more discussion on this in a future chapter).</li>
<li>We must be deliberate when sampling from a population to consider whether we want <em>with</em> or <em>without</em> replacement.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
<ul>
<li>With replacement means we allow for the possibility of selecting the same member of a set more than once when we sample.</li>
<li>Without replacement means we do not allow for the above possibility.</li>
<li>Drawing without replacement alters the underlying distribution from which we are sampling, thus negating the assumption that a sample is drawn from an independent, identically distributed population that is used in many statistical tests.</li>
<li>The default in <em>R</em> for <code>sample</code> and <code>sample_n</code> is to sample without replacement. Be aware of your choice.</li>
</ul></li>
</ul>
</div>
<div id="statistic" class="section level5">
<h5><span class="header-section-number">3.3.2.1.2</span> Statistic</h5>
<p>A statistic is “any function of the observations in a sample that does not contain unknown parameters” (Montgomery, 2012, pg. 31).</p>
<p>This is a precise way of saying a statistic is an unambiguous function of a sample. Common statistics are the (sample) mean, (sample) standard deviation, etc.</p>
<p>Note that statistics are often used to estimate the <em>parameter</em> of a population. The <em>parameter</em> of a population is a function of the entire population. For example, I work in an organization of ~150 people. Each of these people has an unambiguous age, and, if I were nosy enough, I could record all of the ages and get the mean for my organization (at that point in time). This is the true mean. Conversely, if I weren’t so nosy, or did not have the resources, I could randomly sample a subset of the organization and estimate the (true) mean with the statistic the (sample) mean. It will (almost assuredly) not be correct, but will likely be “close enough” for our purposes (we’ll make “close enough” more precise in a future section).</p>
<p>As an example, we can see this visually by plotting the mean of several samples of the normal distribution and comparing that to the true mean:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb387-1" data-line-number="1"><span class="co"># create a useful function that returns the mean of a sample of size X of the standard</span></a>
<a class="sourceLine" id="cb387-2" data-line-number="2"><span class="co"># normal distribution</span></a>
<a class="sourceLine" id="cb387-3" data-line-number="3">myFunc &lt;-<span class="st"> </span><span class="cf">function</span>(X){<span class="kw">return</span>(<span class="kw">mean</span>(<span class="kw">rnorm</span>(X)))}</a>
<a class="sourceLine" id="cb387-4" data-line-number="4"></a>
<a class="sourceLine" id="cb387-5" data-line-number="5"><span class="co"># Generate a vector of the mean of 10 random samples of 10 observations of the standard</span></a>
<a class="sourceLine" id="cb387-6" data-line-number="6"><span class="co"># normal. It is beyond the scope of this section to discuss the various apply functions in</span></a>
<a class="sourceLine" id="cb387-7" data-line-number="7"><span class="co"># R, but they are highly useful and I recommend learning about the apply functions.</span></a>
<a class="sourceLine" id="cb387-8" data-line-number="8">myMeans &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">rep</span>(<span class="dv">30</span>, <span class="dv">10</span>), myFunc)</a>
<a class="sourceLine" id="cb387-9" data-line-number="9"></a>
<a class="sourceLine" id="cb387-10" data-line-number="10"><span class="co"># Plot the results:</span></a>
<a class="sourceLine" id="cb387-11" data-line-number="11"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb387-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> myMeans, <span class="dt">y =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">10</span>))) <span class="op">+</span><span class="st"> </span><span class="co"># Plot each point</span></a>
<a class="sourceLine" id="cb387-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">y =</span> <span class="dv">0</span>), <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">fill =</span> <span class="ot">NA</span>, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">shape =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span><span class="co"># Plot the parameter mean and make it distinct</span></a>
<a class="sourceLine" id="cb387-14" data-line-number="14"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="co"># I prefer a minimal background</span></a>
<a class="sourceLine" id="cb387-15" data-line-number="15"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Sample Means of 10 observations of the Standard Normal Distribution&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># Label our axes and title</span></a>
<a class="sourceLine" id="cb387-16" data-line-number="16"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb387-17" data-line-number="17"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Sample Means vs. the Mean Parameter</span><span class="ch">\n</span><span class="st">Standard Normal Distribution&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb387-18" data-line-number="18"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_blank</span>()) <span class="op">+</span><span class="st"> </span><span class="co"># The y axis is meaningless, so remove it</span></a>
<a class="sourceLine" id="cb387-19" data-line-number="19"><span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">1.1</span><span class="op">*</span><span class="kw">max</span>(<span class="kw">abs</span>(myMeans)), <span class="fl">1.1</span><span class="op">*</span><span class="kw">max</span>(<span class="kw">abs</span>(myMeans)))) <span class="co"># Choose a symmetric x axis </span></a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
</div>
<div id="estimator" class="section level5">
<h5><span class="header-section-number">3.3.2.1.3</span> Estimator</h5>
<p>As discussed above, many (perhaps all) statistics are estimations of some true population parameter. An estimator is defined as:</p>
<p>“An estimator of an unknown parameter is a statistic that corresponds to that parameter. Note that a point estimator is a random variable.” (Montgomery, 2012, pg. 31). We can see this randomness in the plot above of the ten random samples and corresponding point estimates of the mean of the standard normal distribution.</p>
<p>Statisticians have done much work to identify the <em>best</em> estimators for various population parameters. In general, estimators should be:</p>
<ul>
<li><strong>Unbiased.</strong> That is, the expected value of the estimator should equal the parameter. You can read more about this <a href = "https://en.wikipedia.org/wiki/Bias_of_an_estimator">here</a>.</li>
<li><strong>Minimum Variance.</strong> The estimator should have variance that is smaller than any other possible estimator of that parameter. You can read more about this <a href = "https://en.wikipedia.org/wiki/Minimum-variance_unbiased_estimator">here</a>.</li>
</ul>
<p>There are many different ways to estimate a parameter</p>
</div>
<div id="degrees-of-freedom" class="section level5">
<h5><span class="header-section-number">3.3.2.1.4</span> Degrees of Freedom</h5>
<p>Related to the discussion of estimators is the concept of “degrees of freedom”. Degrees of freedom are the number of values in the calculation of a statistic that are free to vary. This is generally related to the sample size and the statistic(s) one is calculating. You can read more about degrees of freedom <a href = "https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)">here</a>.</p>
<p>We’ll cover the calculation of degrees of freedom for specific instances (e.g., regression, ANOVA) as required.</p>
</div>
</div>
<div id="sampling-distribution" class="section level4">
<h4><span class="header-section-number">3.3.2.2</span> Sampling Distribution</h4>
<p>Finally, the concept of a sampling distribution is highly important in the understanding of statistics. <a href = "https://www.khanacademy.org/math/ap-statistics/sampling-distribution-ap">Khan Academy</a> has a good overview of the sampling distribution, so we will not repeat the entire discussion here. That stated, there are a few important things to note:</p>
<ul>
<li>Recall that a statistic is, in and of itself, a random variable.</li>
<li>This random variable has a probability distribution (i.e., the <em>sampling distribution</em>).</li>
<li>If the statistic is a <em>good</em> estimator, it has a mean centered on the value of the population parameter and minimal variance.</li>
<li>For a statistic with a well defined mean and standard deviation, the sampling distribution of that statistic converges on the normal distribution with a mean centered on the parameter value associated with that statistic as defined by the Central Limit Theorem.</li>
</ul>
<div id="central-limit-theorem" class="section level5">
<h5><span class="header-section-number">3.3.2.2.1</span> Central Limit Theorem</h5>
<p>The Central Limit Theorem is a highly important concept in statistics, particularly as it relates to sampling distributions. <a href = "https://www.khanacademy.org/math/ap-statistics/sampling-distribution-ap/sampling-distribution-mean/v/central-limit-theorem">Khan Academy</a> has a good overview of it that is worth watching.</p>
<p>It is sometimes useful to observe the central limit theorem in action. We can plot the sampling distribution for the mean of an arbitrary population using multiple sample sizes as an example. Let’s do that here:</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb388-1" data-line-number="1"><span class="co"># Let&#39;s look at the population as described by the exponential distribution with lambda = 2</span></a>
<a class="sourceLine" id="cb388-2" data-line-number="2"><span class="co"># Recall what this distribution looks like</span></a>
<a class="sourceLine" id="cb388-3" data-line-number="3"></a>
<a class="sourceLine" id="cb388-4" data-line-number="4"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb388-5" data-line-number="5"><span class="st">    </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">rexp</span>(<span class="dv">100000</span>, <span class="dt">rate =</span> <span class="dv">2</span>))) <span class="op">+</span><span class="st"> </span><span class="co"># We&#39;ll take a large random sample using rexp() (i.e. random exponential)</span></a>
<a class="sourceLine" id="cb388-6" data-line-number="6"><span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="co"># We&#39;ll plot the mean which is defined as 1/lambda</span></a>
<a class="sourceLine" id="cb388-7" data-line-number="7"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;Exponential Distribution - Lambda = 2&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb388-8" data-line-number="8"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;X&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Density&#39;</span>)</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb389-1" data-line-number="1"><span class="co"># Now, let&#39;s look at the sampling distribution of the mean of the random exponential for a</span></a>
<a class="sourceLine" id="cb389-2" data-line-number="2"><span class="co"># given sample size. </span></a>
<a class="sourceLine" id="cb389-3" data-line-number="3"><span class="co"># First, let&#39;s write a function that returns the mean of a sample of a the variable</span></a>
<a class="sourceLine" id="cb389-4" data-line-number="4"><span class="co"># note, writing functions is beyond the scope of this section.  Just understand that what</span></a>
<a class="sourceLine" id="cb389-5" data-line-number="5"><span class="co"># this function does is return the mean of a random sample of size `Sample.Size` from the</span></a>
<a class="sourceLine" id="cb389-6" data-line-number="6"><span class="co"># population described by the random exponential with lambda = 2</span></a>
<a class="sourceLine" id="cb389-7" data-line-number="7">mySampleMeanFunction &lt;-<span class="st"> </span><span class="cf">function</span>(Sample.Size){<span class="kw">mean</span>(<span class="kw">rexp</span>(Sample.Size, <span class="dt">rate =</span> <span class="dv">2</span>))}</a>
<a class="sourceLine" id="cb389-8" data-line-number="8"></a>
<a class="sourceLine" id="cb389-9" data-line-number="9"><span class="co">## Second, let&#39;s build a data frame that contains many observations of this mean for</span></a>
<a class="sourceLine" id="cb389-10" data-line-number="10"><span class="co"># varying sample sizes</span></a>
<a class="sourceLine" id="cb389-11" data-line-number="11">mySampleDF &lt;-<span class="st"> </span><span class="kw">data.frame</span>() <span class="co">#define an empty data frame</span></a>
<a class="sourceLine" id="cb389-12" data-line-number="12"></a>
<a class="sourceLine" id="cb389-13" data-line-number="13"><span class="co"># This builds a data frame of 1000 sample mean observations with varying sample sizes </span></a>
<a class="sourceLine" id="cb389-14" data-line-number="14"><span class="co"># (5, 10, ... 35)</span></a>
<a class="sourceLine" id="cb389-15" data-line-number="15"><span class="cf">for</span>(n <span class="cf">in</span> <span class="kw">seq</span>(<span class="dv">5</span>, <span class="dv">35</span>, <span class="dt">by =</span> <span class="dv">5</span>)){</a>
<a class="sourceLine" id="cb389-16" data-line-number="16">  mySampleMeanObservations &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">rep</span>(n, <span class="dv">1000</span>), mySampleMeanFunction)</a>
<a class="sourceLine" id="cb389-17" data-line-number="17">  mySampleDF &lt;-<span class="st"> </span><span class="kw">rbind</span>(mySampleDF, <span class="kw">data.frame</span>(<span class="dt">SampleObservations =</span> mySampleMeanObservations, <span class="dt">SampleSize =</span> n))</a>
<a class="sourceLine" id="cb389-18" data-line-number="18">}</a>
<a class="sourceLine" id="cb389-19" data-line-number="19">mySampleDF<span class="op">$</span>SampleSize &lt;-<span class="st"> </span><span class="kw">as.factor</span>(mySampleDF<span class="op">$</span>SampleSize) <span class="co"># It&#39;s helpful to have these as a factor</span></a>
<a class="sourceLine" id="cb389-20" data-line-number="20"></a>
<a class="sourceLine" id="cb389-21" data-line-number="21"><span class="kw">ggplot</span>(<span class="dt">data =</span> mySampleDF) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb389-22" data-line-number="22"><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> SampleObservations, <span class="dt">color =</span> SampleSize)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb389-23" data-line-number="23"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&#39;black&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb389-24" data-line-number="24"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>SampleSize) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb389-25" data-line-number="25"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Sample Mean&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Density&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb389-26" data-line-number="26"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Sampling Distribution of the Mean of</span><span class="ch">\n</span><span class="st">the Exponential Distribution with Lambda = 2</span><span class="ch">\n</span><span class="st">for Varying Sample Sizes&#39;</span>)</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-34-2.png" width="672" /></p>
<p>Note how the above plots become more normal as the sample size increases and their mean converges on the population mean.</p>
</div>
</div>
</div>
<div id="statistical-concepts---problem-set" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Statistical Concepts - Problem Set</h3>
<p>No problem set for this section. If you desire:</p>
<ul>
<li>Prove the central limit theorem. Here are some solutions from <a href = "http://mathworld.wolfram.com/CentralLimitTheorem.html">Math World </a>.</li>
<li>Prove that the sample mean is an unbiased estimator of the population mean.</li>
</ul>
</div>
</div>
<div id="statistical-inference" class="section level2">
<h2><span class="header-section-number">3.4</span> Statistical Inference</h2>
<div id="statistical-inference---description" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Statistical Inference - Description</h3>
<p>Statistical inference is a large field focused on the desire to describe the properties of a population from a sample such as the population distribution and associated parameters. There are different types of inference with different underlying philosophies and assumptions (e.g., parametric vs. non-parametric, frequentist vs. Bayesian). We do not claim to, nor do we have the time to cover all (or even most) types of statistical inference in this section. We will only review the typical, foundational types of inference seen in any general statistics course and/or as required for our specific analysis.</p>
</div>
<div id="statistical-inference---tutorial" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Statistical Inference - Tutorial</h3>
<div id="confidence-intervals" class="section level4">
<h4><span class="header-section-number">3.4.2.1</span> Confidence Intervals</h4>
<p>In this section, we review standard confidence intervals. Since they are so commonly taught and used and because we will not make great use of them in this course, this section will be highly terse. For a reasonable treatment, please see the resources at <a href='https://www.khanacademy.org/math/ap-statistics/estimating-confidence-ap'>Khan Academy</a> or your other preferred statistics resource.</p>
<div id="what-is-a-confidence-interval" class="section level5">
<h5><span class="header-section-number">3.4.2.1.1</span> What is a Confidence Interval?</h5>
<p>A confidence interval is a range for an estimate of an unknown parameter of a distribution and an associated plausibility that the unknown parameter falls in that range. For example, we can estimate the mean of a distribution and develop a number of confidence intervals to estimate the mean and picture it as seen below:</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb390-1" data-line-number="1"><span class="co"># First, let&#39;s choose a known population - the standard normal distribution N(0, 1)</span></a>
<a class="sourceLine" id="cb390-2" data-line-number="2"><span class="co"># The pdf of N(0,1) is well known</span></a>
<a class="sourceLine" id="cb390-3" data-line-number="3">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-4</span>, <span class="dt">to =</span> <span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.01</span>)</a>
<a class="sourceLine" id="cb390-4" data-line-number="4">prob.x &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi))<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>.<span class="dv">5</span><span class="op">*</span>(x<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb390-5" data-line-number="5"><span class="co"># We can see what this looks like.  We&#39;ll plot the mean as a red vertical line</span></a>
<a class="sourceLine" id="cb390-6" data-line-number="6"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> prob.x)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>)</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>We know that for this distribution, the true (population) mean is 0 and the true (population) standard deviation is 1. We can sample from the distribution (using, <code>rnorm()</code>) and build confidence intervals. Note that in this example, we see that one of the confidence intervals does not contain the mean. (Note that the code is not shown as we’ll review how to calculate the interval in the next section).</p>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
</div>
<div id="how-do-i-calculate-a-confidence-interval" class="section level5">
<h5><span class="header-section-number">3.4.2.1.2</span> How do I calculate a Confidence Interval?</h5>
<p>As previously stated, a confidence interval is a range of values that are thought to contain the true population parameter with some level of plausibility. If our parameter is <span class="math inline">\(\theta\)</span>, we want to find a lower, <span class="math inline">\(L\)</span>, and an upper, <span class="math inline">\(U\)</span>, bound such that the following statement is true:</p>
<p><span class="math inline">\(P(L &lt;= \theta &lt;= U) = 1 - \alpha\)</span></p>
<p>Where <span class="math inline">\(\alpha\)</span> is a generally small percentage, often 1, 5, or 10 percent such that we can have 99, 95, or 90 percent confidence respectively.</p>
<p>We can see this graphically if, for example, our parameter <span class="math inline">\(\theta\)</span> can be described by the standard normal distribution and we want 95% confidence that theta is between an upper and lower bound:</p>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>If we know, or can reasonably assume, the distribution for our parameter of interest, <span class="math inline">\(\theta\)</span> we can then solve for this explicitly. Often times, we can assume that our population is <em>approximately</em> normally distributed; if that is the case we can use the T-Distribution with an appropriate number of degrees of freedom.</p>
<!--
Fortunately for us, recall the *Central Limit Theorem* that tells us for a sufficiently large sample size, our sampling distribution (i.e., the distribution of the estimate of the parameter) tends toward the normal distribution for as the sample size tends toward infinity (assuming the variance is finite).  For smaller sizes, we typically use the T-Distribution with an appropriate number of degrees of freedom.
-->
<p>For further, detailed treatment of how confidence intervals work, see, e.g., <a href = 'https://www.youtube.com/playlist?list=PLdxWrq0zBgPXeOw0XI6c5TIRjbzEoHUE2'>Confidence Intervals Using Normality</a> or <a href = 'https://www.youtube.com/playlist?list=PLdxWrq0zBgPXA5gIL7DJBki6lHs70-jzc'>Confidence Intervals Using the T-Distribution</a>. As a side note, <a href = 'https://www.youtube.com/channel/UCjknLK_siVSCY14qfDu-f-w'>this channel (“Professor Knudson”)</a> seems to have pretty useful videos.</p>
<p>Finally, there are a number of standard (i.e., pre-solved) equations for confidence intervals of various parameters. You can generally find them in any statistics book, though <a href = 'http://www.mathcs.duq.edu/larget/math225/equations2.pdf'>here is a handy reference from Duquesne</a>.</p>
</div>
</div>
<div id="hypothesis-tests" class="section level4">
<h4><span class="header-section-number">3.4.2.2</span> Hypothesis Tests</h4>
<div id="what-is-a-hypothesis-test" class="section level5">
<h5><span class="header-section-number">3.4.2.2.1</span> What is a Hypothesis Test?</h5>
<p>A hypothesis test is a statistical means of stating whether or not it is plausible that a claim is true. These claims are typically questions like:</p>
<ul>
<li>It is likely that these two samples have the same parameter (e.g., the mean, mode, etc.).</li>
<li>It is likely that this data came from a certain type of distribution (e.g., this data is normally distributed).</li>
</ul>
<p>Answering a hypothesis test is one of the ways we can say a result is “statistically significant.” <strong>Having a solid, foundational understanding of hypothesis testing is requisite for understanding all of our future analysis.</strong> It comes up, in various forms, in all of our analysis including ANOVA and regression.</p>
<p>Understanding how hypothesis testing works in general is most important, followed by understanding specific hypothesis tests. Khan Academy has a good overview of hypothesis testing across three sets of videos:</p>
<ul>
<li><a href = "https://www.khanacademy.org/math/ap-statistics/tests-significance-ap">Khan Academy Significance Tests (Hypothesis Testing)</a>.</li>
<li><a href = "https://www.khanacademy.org/math/ap-statistics/two-sample-inference">Khan Academy Inference Comparing Two Groups or Populations</a>.</li>
<li><a href = "https://www.khanacademy.org/math/ap-statistics/chi-square-tests">Khan Academy Chi-Square Tests for Categorical Data</a>.</li>
</ul>
</div>
<div id="hypothesis-test-standard-operating-procedure-sop" class="section level5">
<h5><span class="header-section-number">3.4.2.2.2</span> Hypothesis Test “Standard Operating Procedure” (SOP)</h5>
<p>In the text, <em>Applied Statistics and Probability for Engineers</em> by Montgomery and Runger, the authors provide a seven step SOP for hypothesis testing:</p>
<ol style="list-style-type: decimal">
<li>Identify the parameter of interest.</li>
<li>State the null hypothesis.</li>
<li>State the alternative hypothesis.</li>
<li>Give the formula for the test statistic (based upon the assumptions).</li>
<li>State the rejection region for the selected significance level (i.e., find the critical value(s)).</li>
<li>Compute the test statistic.</li>
<li>Draw conclusions.
<ul>
<li>Decide to reject or fail to reject <span class="math inline">\(H_0\)</span>.</li>
<li>State conclusion in the appropriate problem context.</li>
</ul></li>
</ol>
<p>The first step, “Identify the parameter of interest,” is most important. As with any study, clearly defining your question is vital, because if you answer the wrong question perfectly, you still have a wrong answer. Along with identifying the parameter of interest, an analyst should also identify the reasonable assumptions he or she is willing to make to answer this question.</p>
<p>The second and third steps, “Identify the null and alternative hypothesis” are merely formalizing the question. These are typically formulated as:</p>
<p><span class="math inline">\(H_0: Claim\)</span></p>
<p><span class="math inline">\(H_A: Opposite\)</span></p>
<p>Where <span class="math inline">\(H_0\)</span> (sometimes listed as <span class="math inline">\(H_1\)</span>) is the “null hypothesis”. This is the hypothesis that you believe to be true and, if your hypothesis test results in a <em>plausible</em> value, it is the claim you will say is likely true. <span class="math inline">\(H_A\)</span> is the “alternative hypothesis” which is what you are claiming is likely true if you come up with a highly unlikely value for your test. It is typically framed as the inverse of <span class="math inline">\(H_0\)</span>.</p>
<p>The fourth step involves choosing the appropriate “test statistic.” In many (perhaps most) cases, statisticians have developed these statistics along with the appropriately identified assumptions and the analyst merely needs to choose the most appropriate test for his or her purposes. <strong>This choice, particularly, the assumptions you are making about this is significant.</strong></p>
<p>The fifth and sixth steps involve identifying, <em>a priori</em>, what the significance level is (e.g., 95%, 99%, etc.), then calculating the “rejection region” and then calculating the statistic, and seeing if the result falls in or out of the rejection region.</p>
<p>Finally, the analyst draws the appropriate conclusions based on the results of the tests. A few things to consider:</p>
<ul>
<li>It is not good statistical practice, assuming you set up the test appropriately, to adjust your critical values (i.e. your level) because you do not <em>like</em> your results. Similarly, one should not re-sample data to do the same test repeatedly. This so called “p-hacking” puts you at risk of eventually finding a false-positive or false-negative that will tell you what you want if you ignore all of the error you’ve introduced by doing the same test repeatedly.</li>
<li>The p-value (i.e., the probability that your observed statistic falls in the distribution of interest) does not come with varying levels of significance. Significance is stated up front (i.e., testing for a 90% significance, and then is binary - your results are significant or not).</li>
<li>Do not confuse statistical significance with practical significance. For example, consider two machines that produce widgets. You have identified that the mean weight of the widgets produced by the two machines is different by .01g to the 99.9% significance level. This <em>is</em> a statistically significant result, for sure, but the difference of .01g likely makes no <em>practical</em> difference if these widgets are used for all but the most precise machines.</li>
<li>Finally, recall that we are either <em>rejecting</em> or <em>failing to reject</em> the null hypothesis. When we reject the null hypothesis, we are saying it is unlikely</li>
</ul>
</div>
<div id="example-hypothesis-test-using-r" class="section level5">
<h5><span class="header-section-number">3.4.2.2.3</span> Example Hypothesis Test Using <em>R</em></h5>
<p>All of the above information has thus far (unfortunately) been largely theoretical. Let’s look at an example where we compare the mean of two samples of a population to see if they have the same mean. We will use the built in <em>R</em> data set, <code>iris</code>.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb391-1" data-line-number="1"><span class="co"># First, let&#39;s take two samples of size n from iris</span></a>
<a class="sourceLine" id="cb391-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="dv">30</span></a>
<a class="sourceLine" id="cb391-3" data-line-number="3"></a>
<a class="sourceLine" id="cb391-4" data-line-number="4"><span class="co"># the dplyr function sample_n is a nice function that samples n rows of a data frame.  </span></a>
<a class="sourceLine" id="cb391-5" data-line-number="5"><span class="co"># We have opted to replace (i.e., you can select the same row more than once)</span></a>
<a class="sourceLine" id="cb391-6" data-line-number="6"></a>
<a class="sourceLine" id="cb391-7" data-line-number="7"><span class="kw">set.seed</span>(<span class="dv">212</span>) <span class="co"># Setting the seed is not good practice in general, but for consistency of</span></a>
<a class="sourceLine" id="cb391-8" data-line-number="8"><span class="co"># production and pedagogical purposes, we&#39;re setting it here</span></a>
<a class="sourceLine" id="cb391-9" data-line-number="9">sample<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">sample_n</span>(iris, n, <span class="dt">replace =</span> T)</a>
<a class="sourceLine" id="cb391-10" data-line-number="10"><span class="kw">set.seed</span>(<span class="dv">112</span>)</a>
<a class="sourceLine" id="cb391-11" data-line-number="11">sample<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">sample_n</span>(iris, n, <span class="dt">replace =</span> T)</a>
<a class="sourceLine" id="cb391-12" data-line-number="12"><span class="co"># For convenience, we&#39;ll only look at the vector of the associated sepal lengths</span></a>
<a class="sourceLine" id="cb391-13" data-line-number="13">sample<span class="fl">.1</span> &lt;-<span class="st"> </span>sample<span class="fl">.1</span><span class="op">$</span>Sepal.Length</a>
<a class="sourceLine" id="cb391-14" data-line-number="14">sample<span class="fl">.2</span> &lt;-<span class="st"> </span>sample<span class="fl">.2</span><span class="op">$</span>Sepal.Length</a>
<a class="sourceLine" id="cb391-15" data-line-number="15"></a>
<a class="sourceLine" id="cb391-16" data-line-number="16"><span class="co"># Let&#39;s visualize our data, we&#39;ll use green for sample 1 and blue for sample 2</span></a>
<a class="sourceLine" id="cb391-17" data-line-number="17"><span class="co"># The means are the solid lines</span></a>
<a class="sourceLine" id="cb391-18" data-line-number="18"><span class="co"># I like using density plots as they&#39;re a quick way to approximately visualize the distribution</span></a>
<a class="sourceLine" id="cb391-19" data-line-number="19"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb391-20" data-line-number="20"><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sample<span class="fl">.1</span>), <span class="dt">color =</span> <span class="st">&#39;green&#39;</span>, <span class="dt">fill =</span> <span class="st">&#39;green&#39;</span>, <span class="dt">alpha =</span> <span class="fl">.25</span>) <span class="op">+</span><span class="st"> </span><span class="co">#, binwidth = .2) + </span></a>
<a class="sourceLine" id="cb391-21" data-line-number="21"><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sample<span class="fl">.2</span>), <span class="dt">color =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">fill =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">alpha =</span> <span class="fl">.25</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb391-22" data-line-number="22"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;Sepal Length&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Density&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&#39;Density Plot and Sample Means</span><span class="ch">\n</span><span class="st">Green is Sample 1</span><span class="ch">\n</span><span class="st">Blue is Sample 2&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb391-23" data-line-number="23"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(sample<span class="fl">.1</span>), <span class="dt">color =</span> <span class="st">&#39;green&#39;</span>, <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb391-24" data-line-number="24"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(sample<span class="fl">.2</span>), <span class="dt">color =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">size =</span> <span class="fl">1.5</span>) </a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Clearly we know two things:</p>
<ol style="list-style-type: decimal">
<li>We sampled these from the same population.</li>
<li>Despite that, they produced somewhat different results in terms of the sample means and the distribution.</li>
</ol>
<p>The question for our hypothesis test is then, do these two samples “have the same mean”? i.e., do they come from the same population? We can therefore follow our hypothesis testing SOP.</p>
<p><strong>SOP Step 1:</strong> State the parameter of interest. In our case, the parameter of interest is the mean.</p>
<p><strong>SOP Step 2 &amp; 3:</strong> State the null and alternate hypotheses. In our case we can state these as:</p>
<p><span class="math inline">\(H_0: \mu_1 = \mu_2\)</span></p>
<p><span class="math inline">\(H_A: \mu_1 \neq \mu_2\)</span></p>
<p>Where <span class="math inline">\(\mu_i\)</span> is the mean of the ith sample.</p>
<p><strong>SOP Step 4:</strong> Give the formula for the test statistic. In this case, we can refer to any standard statistics text and identify the appropriate test statistic. In our case, we know that we have a sample size of <code>n = 30</code>, and we do not know the variance of our underlying population or even its distribution. However, our sample distributions are <em>approximately</em> normal (as we see from the plot above), and it is commonly accepted that the T-Test is appropriate for samples from approximately normal distributions as long as the sample size of ~30 or more. We’ll therefore use the T-Test.</p>
<p>The T-Test has the following statistic (note, you can read more about this test on the <a href = "https://www.itl.nist.gov/div898/handbook/eda/section3/eda353.htm#:~:text=">NIST Engineering Statistics Handbook</a>):</p>
<p><span class="math inline">\(T = \frac{\bar{x_1} - \bar{x_2}}{\sqrt{s_1^2/N_1 + s_2^2/N_2}}\)</span></p>
<p>Where <span class="math inline">\(\bar{x_i}\)</span> is the mean of the ith sample, <span class="math inline">\(s_i^2\)</span> is the sample variance of the ith sample, and <span class="math inline">\(N_i\)</span> is the ith sample size.</p>
<p><strong>SOP Step 5:</strong> State the chosen significance level and define the rejection region. Let’s assume our significance level is 95%. For convenience, we typically say this as the <span class="math inline">\(1-\alpha\)</span> level, so we have <span class="math inline">\(\alpha = .05\)</span>. What we are really saying is::</p>
<ol style="list-style-type: decimal">
<li>The distribution of our test statistic is the T distribution with the appropriate degrees of freedom for our sample size.</li>
<li>We will accept any test statistic that falls into the “middle 95%” of our distribution.</li>
<li>We will reject that our test statistic plausibly came from this distribution if the result is outside of this “middle 95%”.</li>
</ol>
<p>We can visualize this as follows:</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb392-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-4</span>, <span class="dt">to =</span> <span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.01</span>)</a>
<a class="sourceLine" id="cb392-2" data-line-number="2"></a>
<a class="sourceLine" id="cb392-3" data-line-number="3"><span class="co"># First show the distribution</span></a>
<a class="sourceLine" id="cb392-4" data-line-number="4">myPlot &lt;-<span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb392-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dt</span>(x, (n<span class="op">*</span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="dv">2</span>))) <span class="op">+</span><span class="st"> </span><span class="co"># Plot the t distribution with 58 degrees of freedom</span></a>
<a class="sourceLine" id="cb392-6" data-line-number="6"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;X&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Probability of X&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb392-7" data-line-number="7"></a>
<a class="sourceLine" id="cb392-8" data-line-number="8">myPlot</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>We can then identify the areas of this t-distribution where the probability of being above or below the number is 2.5% (as the distribution is symmetrical and we want to exclude <span class="math inline">\(\alpha = .05\)</span> from our plausible region).</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb393-1" data-line-number="1"><span class="co"># We can calculate the plausible region using the qt() function.  Recall from the</span></a>
<a class="sourceLine" id="cb393-2" data-line-number="2"><span class="co"># probability discussion that q[distro name] is the quantile for that distribution. </span></a>
<a class="sourceLine" id="cb393-3" data-line-number="3"><span class="co"># Please read about the qt() function with ?qt  </span></a>
<a class="sourceLine" id="cb393-4" data-line-number="4"></a>
<a class="sourceLine" id="cb393-5" data-line-number="5">lower.crit.value &lt;-<span class="st"> </span><span class="kw">qt</span>(.<span class="dv">025</span>, <span class="dv">58</span>)</a>
<a class="sourceLine" id="cb393-6" data-line-number="6">upper.crit.value &lt;-<span class="st"> </span><span class="kw">qt</span>(.<span class="dv">975</span>, <span class="dv">58</span>)</a>
<a class="sourceLine" id="cb393-7" data-line-number="7"></a>
<a class="sourceLine" id="cb393-8" data-line-number="8"><span class="co"># We can then plot these on our graph to show the regions where the test statistic might</span></a>
<a class="sourceLine" id="cb393-9" data-line-number="9"><span class="co"># fall and we would reject the null hypothesis</span></a>
<a class="sourceLine" id="cb393-10" data-line-number="10">myPlot <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb393-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> lower.crit.value, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb393-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> upper.crit.value, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb393-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_area</span>(<span class="kw">aes</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,lower.crit.value, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="kw">dt</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,lower.crit.value, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="dv">38</span>)), <span class="dt">fill =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">alpha =</span> <span class="fl">.25</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb393-14" data-line-number="14"><span class="st">  </span><span class="kw">geom_area</span>(<span class="kw">aes</span>(<span class="kw">seq</span>(upper.crit.value,<span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="kw">dt</span>(<span class="kw">seq</span>(upper.crit.value,<span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="dv">38</span>)), <span class="dt">fill =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">alpha =</span> <span class="fl">.25</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb393-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">3</span>, <span class="dt">y =</span> <span class="fl">.3</span>, <span class="dt">label =</span> <span class="st">&#39;Upper Critical Region</span><span class="ch">\n</span><span class="st">If our Test Statistic falls in here,</span><span class="ch">\n</span><span class="st">we reject the null.&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb393-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">-3</span>, <span class="dt">y =</span> <span class="fl">.3</span>, <span class="dt">label =</span> <span class="st">&#39;Lower Critical Region</span><span class="ch">\n</span><span class="st">If our Test Statistic falls in here,</span><span class="ch">\n</span><span class="st">we reject the null.&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb393-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">y =</span> <span class="fl">.15</span>, <span class="dt">label =</span> <span class="st">&#39;Plausible Region</span><span class="ch">\n</span><span class="st">If our Test Statistic falls in here,</span><span class="ch">\n</span><span class="st">we fail to reject the null.&#39;</span>)) </a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p><strong>SOP Step 6:</strong> Calculate the test statistic.
We can solve for this using the following <em>R</em> code:</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb394-1" data-line-number="1">T.value &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample<span class="fl">.1</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(sample<span class="fl">.2</span>))<span class="op">/</span>(((<span class="kw">sd</span>(sample<span class="fl">.1</span>)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">20</span>)<span class="op">+</span>((<span class="kw">sd</span>(sample<span class="fl">.2</span>)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">20</span>))<span class="op">^</span>.<span class="dv">5</span></a>
<a class="sourceLine" id="cb394-2" data-line-number="2">T.value</a></code></pre></div>
<pre><code>## [1] 0.835691</code></pre>
<p><strong>SOP Step 7:</strong></p>
<p>As we calculated our test statistic to be 0.836, we see it falls squarely in the “plausible region.” We can see that here:</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb396-1" data-line-number="1">myPlot <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb396-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> lower.crit.value, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb396-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> upper.crit.value, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb396-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_area</span>(<span class="kw">aes</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,lower.crit.value, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="kw">dt</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>,lower.crit.value, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="dv">38</span>)), <span class="dt">fill =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">alpha =</span> <span class="fl">.25</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb396-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_area</span>(<span class="kw">aes</span>(<span class="kw">seq</span>(upper.crit.value,<span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="kw">dt</span>(<span class="kw">seq</span>(upper.crit.value,<span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.01</span>), <span class="dv">38</span>)), <span class="dt">fill =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>, <span class="dt">alpha =</span> <span class="fl">.25</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb396-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> T.value, <span class="dt">color =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb396-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_label</span>(<span class="kw">aes</span>(<span class="dt">x =</span> T.value, <span class="dt">y =</span> <span class="fl">.3</span>, <span class="dt">label =</span> <span class="st">&#39;Observed Value&#39;</span>))</a></code></pre></div>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>As we see, we observed a value squarely in the “plausible region”. It is, therefore highly likely (95% level) that these two samples have the same mean. Of course, we already knew this since we drew are samples from the same population!</p>
</div>
<div id="that-was-annoying-cant-r-make-my-life-easier" class="section level5">
<h5><span class="header-section-number">3.4.2.2.4</span> That Was Annoying, Can’t <em>R</em> Make my Life Easier</h5>
<p>Of course, that was a lot of work just to get to the right critical values and test statistic. <em>R</em> has many built in functions that allow us to do this same sort of analysis. In our case, the <code>t.test()</code> function is what we want. We just have to set up our data slightly differently:</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb397-1" data-line-number="1"><span class="co"># t.test requires data to be set up in a manner that looks something like this:</span></a>
<a class="sourceLine" id="cb397-2" data-line-number="2">myDF &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">sepal.length =</span> <span class="kw">c</span>(sample<span class="fl">.1</span>, sample<span class="fl">.2</span>), <span class="dt">sample.number =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;Sample 1&#39;</span>, n), <span class="kw">rep</span>(<span class="st">&#39;Sample 2&#39;</span>, n)))</a>
<a class="sourceLine" id="cb397-3" data-line-number="3"><span class="kw">head</span>(myDF)</a></code></pre></div>
<pre><code>##   sepal.length sample.number
## 1          6.1      Sample 1
## 2          7.0      Sample 1
## 3          5.7      Sample 1
## 4          6.1      Sample 1
## 5          5.5      Sample 1
## 6          5.0      Sample 1</code></pre>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb399-1" data-line-number="1"><span class="co"># We then run the test </span></a>
<a class="sourceLine" id="cb399-2" data-line-number="2"><span class="kw">t.test</span>(sepal.length <span class="op">~</span><span class="st"> </span>sample.number, <span class="dt">data =</span> myDF)</a></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  sepal.length by sample.number
## t = 1.0235, df = 57.983, p-value = 0.3103
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.1879648  0.5812982
## sample estimates:
## mean in group Sample 1 mean in group Sample 2 
##               5.920000               5.723333</code></pre>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb401-1" data-line-number="1"><span class="co"># We can also store the results:</span></a>
<a class="sourceLine" id="cb401-2" data-line-number="2">myT.Test &lt;-<span class="st"> </span><span class="kw">t.test</span>(sepal.length <span class="op">~</span><span class="st"> </span>sample.number, <span class="dt">data =</span> myDF)</a></code></pre></div>
<p>This gives us a nice summary of the test. You’ll note a few things:</p>
<ol style="list-style-type: decimal">
<li>We get the same test statistic result. Our hand result was: t = 0.835691 and the t.test() was t = 1.0235083.</li>
<li>The <code>t.test()</code> function had a slightly more accurate assessment of degrees of freedom of 57.983 vs. my estimate of 58. We could have calculated the degrees of freedom more exactly manually (see the calculation in the NIST handbook link above), but the rough estimate was sufficiently good.</li>
<li>The <code>t.test()</code> gives us the alternative hypothesis, the confidence interval, the p-value, etc… all rather conveniently.</li>
</ol>
<p>Finally, if you look at the documentation for <code>t.test()</code> you’ll see you have a number of options, e.g., what your alternative is, what the difference between the two means is (equality implies the difference is 0, sometimes you may want some different distinction, etc.).</p>
</div>
<div id="standard-tests-in-r" class="section level5">
<h5><span class="header-section-number">3.4.2.2.5</span> Standard Tests in <em>R</em></h5>
<p><em>R</em> has a number of very useful tests pre-built in. Here are a few:</p>
<ul>
<li><code>t.test()</code>:
<ul>
<li>Description: This function allows one to do the standard T-Test of the mean. It has options to do one or two sided, paired or not, equal or unequal variance.<br />
</li>
<li>Assumptions: The T-Test assumes one’s sample(s) are independent, identically distributed, and come from a normal distribution. That stated, the T-Test is generally accepted for data where we know the population is not normally distributed so long as we: 1) have “approximately normal” conditions and 2) have a sufficiently large sample size (generally ~N = 30).</li>
</ul></li>
<li><code>prop.test()</code>:
<ul>
<li>Description: This function considers the Pearson’s Chi Squared test as a proportion test. It is slightly more onerous to do this by hand than the large sample proportion test commonly taught in most statistics classes, but it’s a bit more powerful! Also, it’s not onerous in <em>R</em>. It has options for being a one or two sided test and various ways to input data. It also has the option to use “Yate’s Continuity Correction”, which is a way of correcting for bias introduced by small samples.<br />
</li>
<li>Assumptions: It assumes that the samples are independent and identically distributed. A general rule of thumb is that one should have at least five observations for each of the proportions (i.e., one cannot have too small of a count).<br />
</li>
</ul></li>
<li><code>chisq.test()</code>:
<ul>
<li>Description: This test does a standard chi squared test for goodness of fit. It is very similar to <code>prop.test</code> though used in a slightly different manner. Look closely at the documentation to see the differences.</li>
<li>Assumptions: These are the same as prop.test.</li>
</ul></li>
<li><code>binom.test()</code>:
<ul>
<li>Description: This is an “exact test” of a simple null hypothesis about the probability of success in a Bernoulli experiment (recall, a Bernoulli trial is an experiment where one can only have a success with probability p or failure with probability 1-p). One provides the number of success <code>x</code>, the number of trials <code>n</code>, the probability <code>p</code>, and if one wants a one or two sided test.</li>
<li>Assumptions: This assumes that one is doing 1) Bernoulli trials, 2) they are independent of each other, and 3) they are from the same distribution (i.e., the p for each trial is consistent).<br />
</li>
</ul></li>
<li><code>shapiro.test()</code>:
<ul>
<li>Description: This function performs the Shapiro Wilk test of normality. It’s null hypothesis is that the data is normally distributed (it does not say anything about the mean or variance). A low p-value for this (e.g., &lt; 0.01) implies one should reject the null hypothesis and conclude the data is not normally distributed.</li>
<li>Assumptions: No significant assumptions.</li>
</ul></li>
</ul>
<p>There are many other built in tests, these are simply a few. As a reminder, before doing a test:</p>
<ol style="list-style-type: decimal">
<li>Ensure you understand the test itself: what the null and alternative hypotheses are; what assumptions are necessary to make the test valid; what the test is sensitive to.<br />
</li>
<li>Ensure you understand the function that is doing the test: read the documentation; format your data correctly; choose the appropriate parameters. I often find myself checking <em>R</em> functions with toy problems that I can calculate by hand to understand what is actually occurring in the test if I’m not familiar with it.</li>
</ol>
</div>
<div id="error" class="section level5">
<h5><span class="header-section-number">3.4.2.2.6</span> Error</h5>
<p>The above discussion of inference focuses on <em>plausibility</em> of some hypothesis or event as defined by the likelihood of seeing a result given a presumed distribution.</p>
<p>For example, presume we have an absolutely fair coin. If we flip the coin ten times, we can count the proportion of heads and do a hypothesis test to assess if it is plausible that this coin is truly fair. In general, we’ll likely see about five heads, though it would not be unexpected to see 3, 4, 5, 6, or 7. That stated, we would certainly start questioning the fairness of the coin if we observed 10 heads. It <em>is</em> a possible outcome of flipping a fair coin 10 times, but a highly unlikely one (1 in 1024) and we would almost certainly reject the null hypothesis (erroneously) that the coin is fair. We call this an <em>error</em>.</p>
<p>More specifically, there are four possible states of the world based on absolute truth of <span class="math inline">\(H_0\)</span> and the decision based on the hypothesis test. Two of the states result in no error and the other two result in an error. We can see this as:</p>
<ul>
<li><span class="math inline">\(H_0\)</span> is true and we fail to reject <span class="math inline">\(H_0\)</span>: No error.</li>
<li><span class="math inline">\(H_0\)</span> is true and we reject <span class="math inline">\(H_0\)</span>: <font color = 'red'>Type I Error</font></li>
<li><span class="math inline">\(H_0\)</span> is false and we fail to reject <span class="math inline">\(H_0\)</span>: <font color = 'red'>Type II Error</font></li>
<li><span class="math inline">\(H_0\)</span> is false and reject <span class="math inline">\(H_0\)</span>: No error.</li>
</ul>
<p>If you recall from our discussion of hypothesis testing, we had a <span class="math inline">\(1 - \alpha\)</span> level of significance. The <span class="math inline">\(\alpha\)</span> is specifically the probability of making a Type I error. The probability of making a Type II Error is generally termed as <span class="math inline">\(\beta\)</span> and the power of a test is known as the power of the test.</p>
<p><strong>There is an intrinsic and unavoidable trade-off between the significance of a test and the power of a test.</strong> The specific trade that an analyst makes in this trade-off is not of general importance; what is important is that the analyst understands the trade and makes a decision that is appropriate and acceptable for the problem at hand.</p>
<p>We can visualize this error as follows:</p>
<p><img src="03-Statistics_Review_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>In the above figure we can really see what is occurring with a hypothesis test. First, note that our null hypothesis (depicted as the curve in black) is really asking us whether or not our observed value likely comes from a distribution (as we identified by our test statistic). Second, we see that in reality our sample comes from some population described by a probability distribution (shown as the curve in green). Ideally, this distribution is either closely aligned with our hypothesis so that we can fail to reject or very distinct from our hypothesis so that we can correctly reject the null. We see our critical value as the vertical blue line. We choose to reject or fail to reject the null hypothesis based on where our observation falls on the X axis. If it is to the “left” of the critical value, we fail to reject. If it so happens that our true alternative is not aligned with our null hypothesis, we may still observe a value that causes us to fail to reject and get a Type II error. Conversely, if our true alternative is the same as the null hypothesis (not depicted), we may observe an unlikely X value and reject anyway as seen in the Type I error. You can see then, that as you vary your critical value you are trading Type I errors for Type II errors and Significance for Power.</p>
<!--  Not ready to show this - we'll cover it in a future iteration of the advanced topics section of the course.

#### Randomization Tests

This may not be a familiar topic, but it is highly powerful.  David Howell of the University of Vermont has a really useful overview <a href = "https://www.uvm.edu/~statdhtx/StatPages/Randomization%20Tests/RandomizationTestsOverview.html">here</a>.  His main page is <a href = "https://www.uvm.edu/~statdhtx/StatPages/">here</a>.

-->
</div>
</div>
</div>
<div id="statistical-inference---conclusion" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Statistical Inference - Conclusion</h3>
<p>Statistical inference is an expansive field<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. This tutorial assumes some initial familiarity with hypothesis testing, and reviewed a few of the common methods and tests. At the end of the day, it is important to recall three things:</p>
<ol style="list-style-type: decimal">
<li>Understand what a statistical test is asking. It is asking if it is plausible to observe one’s sample given a set of conditions (i.e., one’s assumptions and the test one is doing). There is always an inherent possibility of error (both Type I and II).</li>
<li>Understand the conditions for a given test - what the parameters are, what the assumptions are, etc. This holds true for both the mathematics of it (i.e., what you would find in a text book) and the computational aspects of it (i.e., how one codes it in a computer).</li>
<li>If you don’t know a test, it is entirely worth researching it, working to understand it, and talking with others about it.</li>
</ol>
</div>
<div id="statistical-inference---problem-set" class="section level3">
<h3><span class="header-section-number">3.4.4</span> Statistical Inference - Problem Set</h3>
<ul>
<li>You can view the problem set here <a href = "/_Chapter3_ProblemSets/Chapter_2-3_Problem_Set_Questions.html"> Statistical Inference Problem Set </a>.</li>
<li>The problem set as an R Markdown is here for your convenience: <a href = "/_Chapter3_ProblemSets/Chapter_2-3_Problem_Set_Questions.Rmd"> Statistical Inference Problem Set </a>.</li>
<li>You can download the Ames Iowa data set here <a href = "/_Chapter3_ProblemSets/ames.csv"> Ames, Iowa Data Set </a>.</li>
<li>You can download the the sample simulation data <a href = '/_Chapter3_ProblemSets/Chap2_DataSet.csv'> here (Chap2_DataSet.csv)</a>.</li>
<li>You can view the problem set solution here <a href = "/_Chapter3_ProblemSets/Chapter_2-3_Problem_Set_Answers.html"> Here </a>.</li>
</ul>
<!--chapter:end:03-Statistics_Review.Rmd-->
</div>
</div>
</div>
<div id="analysis-of-variance-anova" class="section level1">
<h1><span class="header-section-number">4</span> Analysis of Variance (ANOVA)</h1>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>This chapter introduces the idea of Analysis of Variance (ANOVA). ANOVA is a powerful analytic technique in its own right and important to understanding DOE.</p>
<ul>
<li><strong>POC:</strong> For any comments or identified errors, please contact Steve Gillespie at <a href="mailto:stephen.e.gillespie.mil@mail.mil" class="email">stephen.e.gillespie.mil@mail.mil</a> or Emma Schlagenhauff at <a href="mailto:emma.schlagenhauff.civ@mail.mil" class="email">emma.schlagenhauff.civ@mail.mil</a>.</li>
<li>This section was rendered using R version 3.6.0 (2019-04-26) on 18 Aug 2023.</li>
<li>The chapter is organized into 8 sections. Each section includes a description, a tutorial, and a problem set.</li>
</ul>
</div>
<div id="anova-overview" class="section level2">
<h2><span class="header-section-number">4.2</span> ANOVA Overview</h2>
<div id="motivation" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Motivation</h3>
<p>In the previous sections, we had done hypothesis tests to estimate parameters for either a single sample (e.g., estimating the mean of a population from a single sample) or compared two samples to see if they likely came from the same population (e.g., comparison of two means). Often we have more than two samples that we want to compare. In particular, we often know something distinguishing about these samples and want to see if that distinction makes a difference.</p>
<p>For example, consider a simulation where we were testing to see if variations on a system had an effect on the simulation outcome. If we only had two systems, say A and B, we could do any number of hypothesis tests, e.g., a T-test for comparison on the means. If we have three systems: say A, B, and C, we run into a problem. We don’t have a three-way hypothesis test. We could do multiple hypothesis tests, say A vs. B, A vs. C, and B vs. C, but we run into a problem. Recall that each time we conduct a hypothesis test we have a probability of a Type I error, <span class="math inline">\(\alpha\)</span> for a test with a <span class="math inline">\(1-\alpha\)</span> confidence level. When we run multiple hypothesis tests for effectively the same question (i.e., does the system make a difference on our outcome), we start to see that our confidence level goes down rather rapidly. That is, if our <span class="math inline">\(\alpha\)</span> levels are: <span class="math inline">\(\alpha_{A vs. B}, \alpha_{A vs. C}, \alpha_{B vs. C}\)</span>, our confidence level is the product of our individual confidence levels, i.e. <span class="math inline">\((1-\alpha_{A vs. B})*(1-\alpha_{A vs. C})*(1-\alpha_{B vs. C})\)</span>. This number decreases rapidly. For example, if we have <span class="math inline">\(\alpha = .05\)</span> in our example, we would have a confidence of <span class="math inline">\((1-.05)*(1-.05)*(1-.05)\approx .86\)</span>. In fact, for a consistent <span class="math inline">\(\alpha\)</span>, this number scales by <span class="math inline">\(N \choose 2\)</span>, where N is the number of factors. For <span class="math inline">\(\alpha=.05\)</span> this scales down quickly.</p>
<pre><code>## Warning: Continuous limits supplied to discrete scale.
## Did you mean `limits = factor(...)` or `scale_*_continuous()`?</code></pre>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>This clearly won’t do as we need a test that can tell us if there is an effect caused by a change to a factor in a set of observations.</p>
</div>
<div id="broad-concept" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Broad Concept</h3>
<p>Analysis of Variance (ANOVA) solves this exact problem. It does this by assessing the variance observed in the total population (i.e., all of the observations from all samples) and comparing this variance to the variance observed between the different groups and the variance internal to each group. This sounds somewhat esoteric, but <a href = 'https://www.khanacademy.org/math/statistics-probability/analysis-of-variance-anova-library'> this set of videos from Khan Academy explain it very clearly.</a></p>
</div>
<div id="terminology" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Terminology</h3>
<p>There is a variety of terminology used in the ANOVA literature. To aid in communication, we’ll adopt the following definitions:</p>
<ul>
<li><strong>(Treatment) Effect</strong>: A change to the mean response based on a changing level of a factor.</li>
<li><strong>Factor</strong>: An independent variable with two or more levels that may have an effect on the mean response.</li>
<li><strong>Level</strong>: A value a factor may take.</li>
<li><strong>Replicate</strong>: An observation for a given factor or set of factors in an experiment.</li>
<li><strong>Response</strong>: A dependent variable whose mean we value we would like to measure.</li>
</ul>
<p>More concretely, consider a simple combat simulation that assesses an indirect fire (IDF) system. Assume the simulation has a variety of possible inputs, but we are only going to vary the the munition the system fires. Further, the simulation has multiple possible outputs, but we will only measure the number of armored vehicle kills achieved. In this situation:</p>
<ul>
<li>The munition the system fires is the <strong>factor</strong>.</li>
<li>The various types of munitions (e.g., high explosive, hit-to-kill, etc.) are the <strong>levels</strong> for that factor (this is sometimes called a <strong>treatment</strong>).</li>
<li>Each simulation run is a <strong>replicate</strong>.</li>
<li>The output, the number of armored vehicle kills achieved is the <strong>response</strong>.</li>
<li>The (treatment) effect is a change in the average number of kills based on the choice of munition.</li>
</ul>
</div>
</div>
<div id="single-factor-fixed-effects-anova" class="section level2">
<h2><span class="header-section-number">4.3</span> Single Factor, Fixed Effects ANOVA</h2>
<div id="example" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Example</h3>
<p>Consider the IDF simulation described above and imagine you are an analyst charged with telling the Army what the best type of ammunition to buy for killing armored vehicles is. You have four possible munitions:</p>
<ul>
<li>Dual Purpose, Improved Conventional Munition (DPICM).</li>
<li>High Explosive, Anti-Tank (HEAT).</li>
<li>Hit to Kill (HTK).</li>
<li>Precision Guided Munition (PGM).</li>
</ul>
<p>You ran your simulation using the data for each of these munitions five times and recorded the number of armored vehicle kills achieved and got the following results<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>:<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<div id="htmlwidget-4094207bda44d8502e79" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-4094207bda44d8502e79">{"x":{"filter":"none","vertical":false,"caption":"<caption>Armored Vehicle Kills For Each of Five Replicates for Each Munition<\/caption>","data":[["DPICM","HEAT","HTK","PGM"],[23,19,28,29],[10,17,28,32],[13,31,34,27],[27,15,38,26],[27,13,30,19]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Round<\/th>\n      <th>1<\/th>\n      <th>2<\/th>\n      <th>3<\/th>\n      <th>4<\/th>\n      <th>5<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5]}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"none","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>Before analyzing this data, it is important to note a few things:</p>
<ul>
<li>Your <strong>factor</strong> is the munition.</li>
<li>You have four <strong>levels</strong> (or treatments) for the munition factor are: DPICM, HEAT, HTK, PGM. The number of levels is typically represented as <span class="math inline">\(a\)</span>, so we say <span class="math inline">\(a = 4\)</span>.</li>
<li>You had five <strong>replicates</strong> for each level (i.e., <span class="math inline">\(n = 5\)</span>). You had a total of 20 observations as you had four levels each with five observations.</li>
<li>As each level has the same number of replicates, we say this is balanced.</li>
<li>Your <strong>response</strong> was the number of armored vehicles killed. Each response is typically represented mathematically as <span class="math inline">\(y_{ij}\)</span> where <span class="math inline">\(i\)</span> is the level number and <span class="math inline">\(j\)</span> is the replicate number. For example, in the above table, <span class="math inline">\(y_{12}\)</span> is the value for the 2nd replicate of the first level (DPICM) and it has a value of 14 kills, so $y_{12} = $ 10.</li>
</ul>
<p>The first question we might have is, does the choice of round even make a difference? We will do this mathematically with ANOVA! Often time, however, it is also good to visualize the data. For these types of problems, boxplots are often useful:</p>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="model" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Model</h3>
<p>Consider the following generic description of data for an experiment (i.e., a simulation) with a <strong>single factor</strong> with <span class="math inline">\(a\)</span> levels, and <span class="math inline">\(n\)</span> replicates at each level. The results for each observation can be described as <span class="math inline">\(y_{ij}\)</span> where <span class="math inline">\(i \in {1, 2, ... a}\)</span> and <span class="math inline">\(j \in {1, 2, ... n}\)</span> are the indices for the treatments and replicates respectively. This can be seen as a table such as this:</p>
<br>
<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 16px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 16px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}
.tg .tg-cly1{text-align:left;vertical-align:middle}
.tg .tg-yla0{font-weight:bold;text-align:left;vertical-align:middle}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<table class="tg">
<tr>
<th class="tg-cly1">
<span style="font-weight:bold">Level (Treatment)</span>
</th>
<th class="tg-yla0" colspan="4">
Replicates (Observations)
</th>
</tr>
<tr>
<td class="tg-cly1">
1
</td>
<td class="tg-cly1">
<span class="math inline">\(y_{11}\)</span>
</td>
<td class="tg-cly1">
<span class="math inline">\(y_{12}\)</span>
</td>
<td class="tg-cly1">
…
</td>
<td class="tg-cly1">
<span class="math inline">\(y_{1n}\)</span>
</td>
</tr>
<tr>
<td class="tg-cly1">
2
</td>
<td class="tg-cly1">
<span class="math inline">\(y_{21}\)</span>
</td>
<td class="tg-cly1">
<span class="math inline">\(y_{22}\)</span>
</td>
<td class="tg-cly1">
…
</td>
<td class="tg-cly1">
<span class="math inline">\(y_{1n}\)</span>
</td>
</tr>
<tr>
<td class="tg-cly1">
…
</td>
<td class="tg-cly1">
…
</td>
<td class="tg-cly1">
…
</td>
<td class="tg-cly1">
…
</td>
<td class="tg-cly1">
…
</td>
</tr>
<tr>
<td class="tg-0lax">
a
</td>
<td class="tg-0lax">
<span class="math inline">\(y_{a1}\)</span>
</td>
<td class="tg-0lax">
<span class="math inline">\(y_{a2}\)</span>
</td>
<td class="tg-0lax">
…
</td>
<td class="tg-0lax">
<span class="math inline">\(y_{an}\)</span>
</td>
</tr>
</table>
</center>
<p><br></p>
<p>We want to be able to say something about the <strong>effect</strong> of the treatment. We can do that by <em>modeling</em> the data.</p>
<p>One possible model is:</p>
<center>
<span class="math inline">\(y_{ij} = \mu + \tau_i + \epsilon_{ij}\)</span>
</center>
<p>In this model:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the mean of all the observations from all of the treatments (In the IDF example above, the mean is (486/20)=24.3. Note that there are 20 <em>total</em> observations, 486 happens to be the sum of the kills of armored vehicles).</li>
<li><span class="math inline">\(\tau_i\)</span> is the (treatment) effect<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> of the <span class="math inline">\(i^{th}\)</span> level.</li>
<li><span class="math inline">\(\epsilon_{ij}\)</span> is the error associated with the <span class="math inline">\(ij^{th}\)</span> observation. Note that <span class="math inline">\(\epsilon_{ij} = y_{ij} - (\mu + \tau_i)\)</span> by the model above.</li>
</ul>
<p>The idea of the <strong>treatment effect</strong> is that by applying a specific level of a factor (i.e., a treatment), there is an overall change to the mean for observations where this treatment. More concretely, consider this toy example:</p>
<p>Imagine you have selected two people each from two “treatments.”<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> The first treatment is that the person is a professional basketball player. The second treatment is that the person is an elite gymnast. You measure the height of each of the people and get the following heights:</p>
<ul>
<li>Basketball Player 1: 7’2&quot;</li>
<li>Basketball Player 2: 6’10&quot;</li>
<li>Gymnast 1: 5’2&quot;</li>
<li>Gymnast 2: 4’10&quot;</li>
</ul>
<p>We can see the overall mean of these four people is 6’0“. The treatment effect of being a professional basketball player is to add an additional foot of height (i.e., <span class="math inline">\(\tau_{basketball} = +1&#39;\)</span>). The treatment effect of being an elite gymnast is to substract a foot of height (i.e., <span class="math inline">\(\tau_{gymnastics} = -1&#39;\)</span>). The errors associated for each athlete are +/- 2”. For example, for basketball player 1, we can say: <span class="math inline">\(\mu = 6&#39;0&quot;\)</span>, <span class="math inline">\(\tau_{basketball} = +1&#39;\)</span>, and <span class="math inline">\(\epsilon_{basketball,1}=+2&quot;\)</span>.</p>
<p>The above example is a merely a toy problem and generally impractical to calculate by hand. However, it is the simply the result of a linear statistical model. For ANOVA, however, we are not attempting to calculate specific <span class="math inline">\(\tau_{i}\)</span>, rather the question is: <strong>Are any of the <span class="math inline">\(\tau_i\)</span> non-zero?</strong> That is, do any of the treatments have an effect?</p>
<p>At this point, we have a hypothesis test, where:</p>
<center>
<p><span class="math inline">\(H_0: \tau_1=\tau_2=...=\tau_a=0\)</span></p>
<p><span class="math inline">\(H_A: \tau_i\neq0\)</span> for at least one <span class="math inline">\(i\in{1, 2, ... a}\)</span></p>
</center>
<p>To do this, we must satisfy several assumptions:</p>
</div>
<div id="single-factor-anova-assumptions" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Single Factor ANOVA Assumptions</h3>
<ol style="list-style-type: decimal">
<li>You are only testing a single factor with <span class="math inline">\(a&gt;2\)</span> treatments. You <em>can</em> run an ANOVA with 2 factors, but you really should choose a more explicit hypothesis test (e.g., a t-test).</li>
<li>The experiments were performed in a random order to minimize the effect of environmental factors. In simulation, this is largely a moot point as one can fix the environmental conditions and the stochasticity comes not from changing time (i.e., order) and associated changes to the environment, rather it comes from the selection of random variables. That stated, be aware of this requirement and ensure the simulation meets the intent. This is called a <strong>completely randomzied design</strong>.</li>
<li>The model errors, <span class="math inline">\(\epsilon_{ij}\)</span> are assumed to be normally and independently distributed with a mean of 0 and constant variance.</li>
<li>The observations are assumed to be mutually independent, i.e., there is no connection between the outcome of one simulation run and the next one.</li>
<li>The levels are <strong>fixed</strong>. By this, we mean we (the researcher) have identified specific levels for the factor and are only attempting to make inferences on the observed levels. Using the IDF example, we are only making inferences about the four round types and not attempting to learn anything about an untested round. Similarly, with the athlete example, we are only attempting to hypothesize about being a basketball player or gymnast, not being an athlete in general. This is called the <strong>fixed effects model</strong>. In a future section, we’ll address the <strong>random effects model</strong> where we assess a random sample of levels from a larger population of levels.</li>
</ol>
</div>
<div id="conducting-single-factor-fixed-effects-anova" class="section level3">
<h3><span class="header-section-number">4.3.4</span> Conducting Single Factor (Fixed Effects) ANOVA</h3>
<p>There is a significant amount of math and explanation as to exactly how the ANOVA test works. For a more detailed understanding, please see any of the following:</p>
<ul>
<li><a href = 'https://www.khanacademy.org/math/statistics-probability/analysis-of-variance-anova-library'> The set of Khan Academy videos (linked earlier in the chapter) provide a good overview.</a></li>
<li><a href = 'https://en.wikipedia.org/wiki/One-way_analysis_of_variance'>The wikipedia article has a good overview and example of the actual math </a><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>.</li>
<li>Most standard statistics texts explain the calculations, e.g.:<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>
<ul>
<li>Montgomery’s <em>Design and Analysis of Experiments, 8th Edition</em> Section 3.3.</li>
<li>Devore’s <em>Probability and Statistics for Engineering and the Sciences, 7th Edition</em> Section 10.1.</li>
<li>Hayter’s <em>Probability and Statistics for Engineers and Scientists, 4th Edition</em> Section 11.1.</li>
</ul></li>
<li>Many <em>R</em> books will cover the discussion as well, e.g. Crawley’s <em>The R Book, 2nd Edition</em> Section 11.1.</li>
</ul>
<p>Given this wealth of resources, we will only discuss how to actually conduct and interpret the single factor, fixed effects ANOVA in <em>R</em> here.</p>
<div id="single-factor-fixed-effects-anova-step-0---assumptions" class="section level4">
<h4><span class="header-section-number">4.3.4.1</span> Single Factor, Fixed Effects ANOVA: Step 0 - Assumptions</h4>
<p>Ensure you have met the required assumptions as listed above. At this point, we won’t worry about the normality and constant variance assumption, we’ll assess for it after the fact.</p>
</div>
<div id="single-factor-fixed-effects-anova-step-1---prepare-the-data." class="section level4">
<h4><span class="header-section-number">4.3.4.2</span> Single Factor, Fixed Effects ANOVA: Step 1 - Prepare the data.</h4>
<p>Often data is provided in a variety of formats, particularly the format seen in the tables above, where the levels are the rows and the columns are the replicates. <em>R</em>, however needs the data in the form of 2 vectors. This typically looks like a table (i.e., a data frame) where one column is the level and one column is the observation value. The data should look like:</p>
<pre><code>##    Replicate Round Kills
## 1          1 DPICM    23
## 2          5   PGM    19
## 3          5 DPICM    27
## 4          2   PGM    32
## 5          5   HTK    30
## 6          5  HEAT    13
## 7          3   PGM    27
## 8          3   HTK    34
## 9          2  HEAT    17
## 10         4 DPICM    27</code></pre>
<p>Note three things:</p>
<ul>
<li>This is only a sample of the data from our IDF example, obviously you need all of the data to actually conduct the ANOVA.</li>
<li>We have three columns, the replicate number (not really necessary for this analysis, but maybe for good record keeping), the round (i.e., the level), and the kills (i.e., the response). In <em>R</em>, the levels can be identified as characters or numbers, but the response must be numeric.</li>
<li>There is no requirement to order the data in some way. The analysis occurs the same regardless of order.</li>
</ul>
<p>If your data is formatted correctly, you can proceed to the next step. If not, you will have to do some data cleaning. This is a classic example of why the Tidyverse functions <code>pivot_wider()</code> and <code>pivot_longer()</code> (formerly <code>spread()</code> and <code>gather()</code>) exist. Please read about them in <a href = 'https://r4ds.had.co.nz/tidy-data.html'> <em>R For Data Scince Chapter 12, Tidy Data</em> </a>. Below is an example:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb404-1" data-line-number="1"><span class="co"># Suppose your orignal data looks like this:</span></a>
<a class="sourceLine" id="cb404-2" data-line-number="2">Original.Data</a></code></pre></div>
<pre><code>##   Round  1  2  3  4  5
## 1 DPICM 23 10 13 27 27
## 2  HEAT 19 17 31 15 13
## 3   HTK 28 28 34 38 30
## 4   PGM 29 32 27 26 19</code></pre>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb406-1" data-line-number="1"><span class="co"># To convert this to a data frame in a manner you need, use pivot_longer()</span></a>
<a class="sourceLine" id="cb406-2" data-line-number="2"></a>
<a class="sourceLine" id="cb406-3" data-line-number="3">Formatted.Data &lt;-<span class="st"> </span>Original.Data <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># We will save our new data in &#39;Formatted.Data&#39;</span></a>
<a class="sourceLine" id="cb406-4" data-line-number="4"><span class="st">                                    </span><span class="co"># We sart with &#39;Original.Data&#39; and pipe it to &#39;pivot_longer&#39;</span></a>
<a class="sourceLine" id="cb406-5" data-line-number="5"><span class="st">    </span><span class="kw">pivot_longer</span>(<span class="dt">cols =</span> <span class="kw">c</span>(<span class="st">&#39;1&#39;</span>, <span class="st">&#39;2&#39;</span>, <span class="st">&#39;3&#39;</span>, <span class="st">&#39;4&#39;</span>, <span class="st">&#39;5&#39;</span>), </a>
<a class="sourceLine" id="cb406-6" data-line-number="6">                 <span class="co"># The first argument is what columns are you gathering together</span></a>
<a class="sourceLine" id="cb406-7" data-line-number="7">                 <span class="co"># Note that the names of the columns are 1, 2, ..., but column names are characters</span></a>
<a class="sourceLine" id="cb406-8" data-line-number="8">                 <span class="co"># so you have to put the names in quotes or else R will think you are referring to a </span></a>
<a class="sourceLine" id="cb406-9" data-line-number="9">                 <span class="co"># column number</span></a>
<a class="sourceLine" id="cb406-10" data-line-number="10">                 <span class="dt">names_to =</span> <span class="st">&#39;Replicate&#39;</span>, </a>
<a class="sourceLine" id="cb406-11" data-line-number="11">                 <span class="co"># The second argument &#39;names_to&#39; is asking what do you want to call the column that</span></a>
<a class="sourceLine" id="cb406-12" data-line-number="12">                 <span class="co"># will hold the names of the former columns.  We chose &#39;Replicate&#39;</span></a>
<a class="sourceLine" id="cb406-13" data-line-number="13">                 <span class="dt">values_to =</span> <span class="st">&#39;Kills&#39;</span></a>
<a class="sourceLine" id="cb406-14" data-line-number="14">                 <span class="co"># The third argument asks for the name of the new column that will hold the values</span></a>
<a class="sourceLine" id="cb406-15" data-line-number="15">                 <span class="co"># We chose Kills as that is what the values are in each of columns 1, 2, ... 5</span></a>
<a class="sourceLine" id="cb406-16" data-line-number="16">                 <span class="co"># Finally, there are more arguments in pivot_longer that are optional.  </span></a>
<a class="sourceLine" id="cb406-17" data-line-number="17">                 <span class="co"># Please read the help `?pivot_longer` for more information</span></a>
<a class="sourceLine" id="cb406-18" data-line-number="18">                 )</a>
<a class="sourceLine" id="cb406-19" data-line-number="19"></a>
<a class="sourceLine" id="cb406-20" data-line-number="20"><span class="co"># View how our Formatted.Data turned out</span></a>
<a class="sourceLine" id="cb406-21" data-line-number="21">Formatted.Data</a></code></pre></div>
<pre><code>## # A tibble: 20 x 3
##    Round Replicate Kills
##    &lt;fct&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1 DPICM 1            23
##  2 DPICM 2            10
##  3 DPICM 3            13
##  4 DPICM 4            27
##  5 DPICM 5            27
##  6 HEAT  1            19
##  7 HEAT  2            17
##  8 HEAT  3            31
##  9 HEAT  4            15
## 10 HEAT  5            13
## 11 HTK   1            28
## 12 HTK   2            28
## 13 HTK   3            34
## 14 HTK   4            38
## 15 HTK   5            30
## 16 PGM   1            29
## 17 PGM   2            32
## 18 PGM   3            27
## 19 PGM   4            26
## 20 PGM   5            19</code></pre>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb408-1" data-line-number="1"><span class="co"># This looks good, so we can progress to the next step.</span></a></code></pre></div>
</div>
<div id="single-factor-fixed-effects-anova-step-2---conduct-the-anova" class="section level4">
<h4><span class="header-section-number">4.3.4.3</span> Single Factor, Fixed Effects ANOVA: Step 2 - Conduct the ANOVA</h4>
<p>In <em>R</em>, the function <code>aov()</code> is built to calculate a wide variety of ANOVA situations. We’ll use it for our single factor, fixed effects model. In <code>aov()</code>, <em>R</em> uses a format the will become quite familiar to you as you progress through the course. This format is:</p>
<center>
<code>Response ~ Input</code>
</center>
<p>In this, we are saying we want to assess something about the response as a function of (or an effect of) the given input (in our case, levels). It’s best to see this with a concrete example:</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb409-1" data-line-number="1"><span class="co"># Using our IDF data, we want to conduct a single factor, fixed effects ANOVA.</span></a>
<a class="sourceLine" id="cb409-2" data-line-number="2"><span class="co"># We have identified Kills as the response and Round as the factor.</span></a>
<a class="sourceLine" id="cb409-3" data-line-number="3"><span class="co"># Round has 4 levels, DPICM, HEAT, HTK, PGM.</span></a>
<a class="sourceLine" id="cb409-4" data-line-number="4"></a>
<a class="sourceLine" id="cb409-5" data-line-number="5"><span class="co"># R generally need the factor to be of type &#39;factor&#39;.  While on the surface a character string</span></a>
<a class="sourceLine" id="cb409-6" data-line-number="6"><span class="co"># and factor look similar, R treats them differently.  Sometimes you will still get results</span></a>
<a class="sourceLine" id="cb409-7" data-line-number="7"><span class="co"># if you don&#39;t change your variable to a factor, but sometimes they won&#39;t be fully accurate.</span></a>
<a class="sourceLine" id="cb409-8" data-line-number="8"><span class="co"># You can change the variable type as follows:</span></a>
<a class="sourceLine" id="cb409-9" data-line-number="9"></a>
<a class="sourceLine" id="cb409-10" data-line-number="10">Formatted.Data<span class="op">$</span>Round &lt;-<span class="st"> </span><span class="kw">as.factor</span>(Formatted.Data<span class="op">$</span>Round)</a>
<a class="sourceLine" id="cb409-11" data-line-number="11"><span class="co"># This takes the column &#39;Round&#39; in the data frame Formatted.Data and stores the values for the </span></a>
<a class="sourceLine" id="cb409-12" data-line-number="12"><span class="co"># vector as.factor(Formatted.Data$Round)</span></a>
<a class="sourceLine" id="cb409-13" data-line-number="13"></a>
<a class="sourceLine" id="cb409-14" data-line-number="14"><span class="co"># We assess the ANOVA as:</span></a>
<a class="sourceLine" id="cb409-15" data-line-number="15"><span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>Round, <span class="dt">data =</span> Formatted.Data)</a></code></pre></div>
<pre><code>## Call:
##    aov(formula = Kills ~ Round, data = Formatted.Data)
## 
## Terms:
##                 Round Residuals
## Sum of Squares  525.8     624.4
## Deg. of Freedom     3        16
## 
## Residual standard error: 6.246999
## Estimated effects may be unbalanced</code></pre>
<p>Note two things:</p>
<ol style="list-style-type: decimal">
<li>For convenience, we just use the column names in the formula, but then have to identify the data we want for the column names. We could have done the call <code>aov(Formatted.Data$Kills ~ Formatted.Data$Round)</code> but that becomes cumbersome.</li>
<li>The output does not look that useful (yet).</li>
</ol>
<p>The reason the output is not that useful is because <code>aov()</code> actually outputs quite a bit of information, but you actually have to save the analysis to a new variable to access the information. We do this as follows:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb411-1" data-line-number="1">myAOV &lt;-<span class="st"> </span><span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>Round, <span class="dt">data =</span> Formatted.Data)</a></code></pre></div>
<p>At this point, we’re done <em>doing</em> the ANOVA, we can move on to the analysis.</p>
</div>
<div id="single-factor-fixed-effects-anova-step-3---assess-the-ouput." class="section level4">
<h4><span class="header-section-number">4.3.4.4</span> Single Factor, Fixed Effects ANOVA: Step 3 - Assess the Ouput.</h4>
<p>The first thing we want to look at is something called the ANOVA table. We can access this with the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb412-1" data-line-number="1"><span class="kw">summary</span>(myAOV)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Round        3  525.8  175.27   4.491 0.0181 *
## Residuals   16  624.4   39.02                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This table has six columns:</p>
<ul>
<li>The first column (unnamed in <em>R</em>) identifies the factor in the model. In our case we have <code>Round</code> as that is the factor we assessed, the residuals (i.e., the <span class="math inline">\(\epsilon_{ij}\)</span>) as there is always some error. In some texts, you may see an ANOVA table with <code>total</code> as the final row. <em>R</em> does not do this, but it is easy enough to calculate as the total in the DF, Sum Sq, and Mean Sq columns is just the sum of the other rows.</li>
<li>The second column, <code>Df</code>, is the Degrees of Freedom column. It tells you how many degrees of freedom are associated with that factor.</li>
<li>The third column, <code>Sum Sq</code>, is your “Sum of Squares”. See the Khan Academy videos or external text for an explanation.</li>
<li>The fourth column, <code>Mean Sq</code>, is your “Mean Sum of Squares”. See the same resources for a more thorough explanation.</li>
<li>The fifth column, <code>F value</code>, and the sixth column, <code>Pr(&gt;F)</code> is what we are ultimately after. These are your test statistic and p-value respectively.</li>
<li>Finally note, there are relationships among the degrees of freedom, sum of squares, mean sum of squares, and F statistic. Please see any standard text if you care to calculate these by hand.</li>
</ul>
<p>Recall that, ultimately, ANOVA is conducting a special kind of hypothesis test that compares the ratio of variation seen in the data across the entire data set vs. internally to each level. If the assumptions are met, this can be modeled according to the F distribution with the appropriate parameters. Recall, then, our original hypothesis:</p>
<center>
<p><span class="math inline">\(H_0: \tau_1=\tau_2=...=\tau_a=0\)</span></p>
<p><span class="math inline">\(H_A: \tau_i\neq0\)</span> for at least one <span class="math inline">\(i\in{1, 2, ... a}\)</span></p>
</center>
<p>If the F-value is below your chosen <span class="math inline">\(\alpha\)</span> (generally either .01 or .05), we can reject the null hypothesis and say that at least one of the effects is non-zero. That is, we can say that the factor actually matters in our outcomes. In our case, if we set <span class="math inline">\(\alpha = .05\)</span>, we reject <span class="math inline">\(H_0\)</span> and do say that the choice of round matters in the number of kills achieved.</p>
<p>Before we get too excited, we want to check our assumptions. Fortunately, <code>aov()</code> helps us with that by enabling us to plot several things.</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb414-1" data-line-number="1"><span class="co"># Plot results of model to check ANOVA assumptions</span></a>
<a class="sourceLine" id="cb414-2" data-line-number="2"><span class="co"># Set plotting parameters</span></a>
<a class="sourceLine" id="cb414-3" data-line-number="3"><span class="co"># This is a plotting parameter that tells R to plot the next several plots on a 2 x 2 grid</span></a>
<a class="sourceLine" id="cb414-4" data-line-number="4"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) </a>
<a class="sourceLine" id="cb414-5" data-line-number="5"><span class="co"># Plot the standard ANOVA assessment graphs</span></a>
<a class="sourceLine" id="cb414-6" data-line-number="6"><span class="kw">plot</span>(myAOV)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>These four graphs will come up rather frequently both in ANOVA and linear regression. <a href = 'https://data.library.virginia.edu/diagnostic-plots/'> The University of Virginia has a good explanation of these graphs </a>. It is in the context of linear regression, but the assessment is the same.</p>
<p>The first (top-left) is the “Residuals vs. Fitted” plot. It helps us check the assumption that our observations are <strong>independent</strong>.We should see no major pattern in the data and indeed we don’t.</p>
<p>The second (top-right) is the “Normal Q-Q” plot. This plots the residuals (i.e., the <span class="math inline">\(\epsilon_{ij}\)</span>) against a normal curve (the residual values are normalized to the standard normal distribution). If the residuals were froma perfectly normal distribution, they would all fall exactly on the straight line indicated. Our data looks very well behaved in this case, so we can say we satisfy the assumption of <strong>normally distributed residuals</strong>.</p>
<p>The third (bottom-left) is the “Scale-Location” plot. It is very similar to the first, except the y-axis is the square root of the standardized residuals (standardized to a normal distribution) vs. the actual residual values. This allows us to check for <strong>constant variance</strong> (homoskedasticity). We look to meet that assumption.</p>
<p>The fourth (bottom-right) is the “Residuals vs. Levels Plot” that helps us identify influential points that significantly skew our analysis. We do not see any significant issues so we can continue.</p>
<p>Finally, though this should not be a factor in most simulation experiments, it is often useful to plot the residuals vs. run order or time. This allows one to identify potential dependence among the runs (this often occurs with physical experiments where test subjects’ skills either improve or degrade) or violations to the requirements of constant variance. The plots above do not show this, but they are easy enough to produce. The vector <code>myAOV$residuals</code> is ordered in the same manner as the initial input. If one has the time or order in which each response was calculated, one can plot this. For example:</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb415-1" data-line-number="1"><span class="co"># In our example above, assume that the order of `Formatted.Data` is the order </span></a>
<a class="sourceLine" id="cb415-2" data-line-number="2"><span class="co"># in which we collected the data.  I.e. Formatted.Data$Kills[1] was </span></a>
<a class="sourceLine" id="cb415-3" data-line-number="3"><span class="co"># the first observation, Formatted.Data$Kills[2] was the second, etc...</span></a>
<a class="sourceLine" id="cb415-4" data-line-number="4"></a>
<a class="sourceLine" id="cb415-5" data-line-number="5"><span class="co"># We then create a vector, run order that is simply 1, 2, 3.... 20 and plot that as &quot;time&quot;</span></a>
<a class="sourceLine" id="cb415-6" data-line-number="6"><span class="co"># Against the residuals.</span></a>
<a class="sourceLine" id="cb415-7" data-line-number="7"></a>
<a class="sourceLine" id="cb415-8" data-line-number="8"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb415-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">y =</span> myAOV<span class="op">$</span>residuals)) <span class="op">+</span><span class="st"> </span><span class="co"># Plot the residuals</span></a>
<a class="sourceLine" id="cb415-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="co"># Note that your residuals are centered on 0</span></a>
<a class="sourceLine" id="cb415-11" data-line-number="11"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;&#39;Observation Order&#39;&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Residual&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb415-12" data-line-number="12"><span class="st">  </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>There does not appear to be any significant patter of residual vs. time, so this appears to meet our assumption.</p>
<p>In addition to the graphic checks, we can check the assumptions mathematically:</p>
<p><em>Normality of Residuals</em></p>
<p>To assess if the residuals are normally distributed, we can use the Shapiro Wilk test:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb416-1" data-line-number="1"><span class="kw">shapiro.test</span>(myAOV<span class="op">$</span>residuals)</a></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  myAOV$residuals
## W = 0.98153, p-value = 0.9523</code></pre>
<p>Since our p-value is larger than 0.10, we fail-to-reject our null hypothesis that the residuals are normally distributed.</p>
<p>To assess if the residuals have constant variance, we can use the <a href = 'https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm'> Bartlett test </a>:<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb418-1" data-line-number="1"><span class="co"># we use `bartlett.test()</span></a>
<a class="sourceLine" id="cb418-2" data-line-number="2"><span class="co"># You can equivalently check the Kills as a function of Round from your</span></a>
<a class="sourceLine" id="cb418-3" data-line-number="3"><span class="co"># original data as follows:</span></a>
<a class="sourceLine" id="cb418-4" data-line-number="4"><span class="kw">bartlett.test</span>(Kills <span class="op">~</span><span class="st"> </span>Round, <span class="dt">data =</span> Formatted.Data)</a></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Kills by Round
## Bartlett&#39;s K-squared = 1.8243, df = 3, p-value = 0.6097</code></pre>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb420-1" data-line-number="1"><span class="co"># Or you can check the residuals vs. their associated level</span></a>
<a class="sourceLine" id="cb420-2" data-line-number="2"><span class="kw">bartlett.test</span>(myAOV<span class="op">$</span>residuals, Formatted.Data<span class="op">$</span>Round)</a></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  myAOV$residuals and Formatted.Data$Round
## Bartlett&#39;s K-squared = 1.8243, df = 3, p-value = 0.6097</code></pre>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb422-1" data-line-number="1"><span class="co"># Or check the residuals vs. their fitted values</span></a>
<a class="sourceLine" id="cb422-2" data-line-number="2"><span class="kw">bartlett.test</span>(myAOV<span class="op">$</span>residuals, myAOV<span class="op">$</span>fitted.values)</a></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  myAOV$residuals and myAOV$fitted.values
## Bartlett&#39;s K-squared = 1.8243, df = 3, p-value = 0.6097</code></pre>
<p>The null hypothesis in the Bartlett test is that the variance among groups is constant. In the above case, we fail to reject the null and conclude that we have met our assumption.</p>
<p>Finally, we can test for independence of the residuals from time or collection order in a number of ways. One way is to check for a correlation using <code>cor()</code>. Recall that <a href = 'https://en.wikipedia.org/wiki/Correlation_and_dependence'> correlation </a> measures vary between -1 and 1, where 1 means a perfect correlation and -1 means a completely inverse correlation. A correlation close to 0 means there is very little correlation. We can test this as follows:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb424-1" data-line-number="1"><span class="co"># Recall we assumed that our data is listed in the order in which the observations were made</span></a>
<a class="sourceLine" id="cb424-2" data-line-number="2"><span class="kw">cor</span>(myAOV<span class="op">$</span>residuals, <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>)</a></code></pre></div>
<pre><code>## [1] -0.001551879</code></pre>
<p>It appears there is no order dependence.</p>
<p>Having met our assumptions, we can safely conclude two things:</p>
<ol style="list-style-type: decimal">
<li>Single Factor, Fixed Effects ANOVA was the right sort of analysis for our data.</li>
<li>We can reject the null hypothesis and say that the choice of round does have an effect on kills achieved.</li>
</ol>
<p>We cannot, at this point, say what the effect is, or which round type it was, etc.</p>
</div>
</div>
<div id="single-factor-fixed-effects-anova-problem-set" class="section level3">
<h3><span class="header-section-number">4.3.5</span> Single Factor, Fixed Effects ANOVA Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter3_1_ProblemSets/Single_Factor_ANOVA_ProblemSet_Questions.html'> here </a>. Note that there are two data sets used in the problem set, tank.csv and soldier.csv. The links to the data set are in the problem set.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter3_1_ProblemSets/Single_Factor_ANOVA_ProblemSet_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter3_1_ProblemSets/Single_Factor_ANOVA_ProblemSet_Answers.html'> here </a>.</p>
</div>
</div>
<div id="single-factor-random-effects-model" class="section level2">
<h2><span class="header-section-number">4.4</span> Single Factor, Random Effects Model</h2>
<p>In the previous section, we assumed that the experimenter had defined set levels for the factor of interest. For example, in the IDF example above, there were four fixed levels of round type: DPICM, HEAT, HTK, PGM. Accordingly, our model: <span class="math inline">\(y_{ij} = \mu + \tau_i + \epsilon_{ij}\)</span> only had one random variable, <span class="math inline">\(\epsilon_{ij}\)</span>. In some cases, we have too many possible levels to assess all of them, but we still want to know if the factor has an effect on our response. In this case, we use the single factor, <strong>random effects</strong> model.</p>
<p>The random effects model looks the same as the fixed effects model:</p>
<center>
<span class="math inline">\(y_{ij} = \mu + \tau_i + \epsilon_{ij}\)</span>
</center>
<p>The difference here is that in the random effects model, we are taking both <span class="math inline">\(\epsilon_{ij}\)</span> <em>and</em> <span class="math inline">\(\tau_i\)</span> to be random variables (both normally and independently distributed with mean of 0 and constant variances <span class="math inline">\(\sigma_{\tau}^2\)</span> and <span class="math inline">\(\sigma_{\epsilon}^2\)</span> respectively). This has a few implications:</p>
<ol style="list-style-type: decimal">
<li>Unlike the fixed effects model, the sum of the effects is not necessarily zero.</li>
<li>The distribution of the response <span class="math inline">\(y_{ij}\)</span> is normal as it is the sum of two normal distributions.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></li>
<li>The observations are independent except when drawn from the same level as they have a covariance equal to the variance of <span class="math inline">\(\tau\)</span>. This largely doesn’t affect the analysis, however.</li>
<li><strong>The hypothesis test you are conducting is different</strong> relative to the hypothesis test for single factor, fixed effect ANOVA.</li>
</ol>
<p>This last point is the most important. Recall that in a fixed effect model, recall your null hypothesis is: <span class="math inline">\(H_0: \tau_1 = \tau_2 = ... = \tau_a = 0\)</span>. We were looking to see if at least one of the levels had a (non-zero) effect. Our question now is, does the population of the levels have an effect. We address this with the following hypotheses:</p>
<center>
<p><span class="math inline">\(H_0: \sigma_{\tau}^2 = 0\)</span></p>
<p><span class="math inline">\(H_A: \sigma_{\tau}^2 &gt; 0\)</span></p>
</center>
<p>Specifically, what we are asking is: are the treatment effects all the same (i.e., is there no variability)?<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> Alternatively, is there some variation meaning that there is an effect from the treatment. Somewhat surprisingly, the computational procedures for the random effects model are the same as for the fixed effects model, but do not forget that the conclusions are different! Let’s do an example:</p>
<p>Consider the IDF situation again as above, but this time, let’s consider what happens when we vary the range of the projectile (and fix the choice of munition and all other inputs to the simulation). Assume we have been told that the range of potential ranges is between 15km and 50km. Clearly, even if we fixed the levels at every kilometer we’d have 36 levels to check so <span class="math inline">\(36n\)</span> simulations to run if we did <span class="math inline">\(n\)</span> replicates per simulation. At some point, detailed analysis may be important, but if we simply want to know if range matters, it’s superior to randomly sample a few levels from the population of possible treatments. Let’s choose four random ranges in the 15km to 50km range:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb426-1" data-line-number="1"><span class="co"># Randomly choose ranges from 15 to 50 using a uniform distribution.</span></a>
<a class="sourceLine" id="cb426-2" data-line-number="2"><span class="co"># We can round these to an appropriate level of precision for our simulation</span></a>
<a class="sourceLine" id="cb426-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">8474623</span>)</a>
<a class="sourceLine" id="cb426-4" data-line-number="4">km.levels &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">runif</span>(<span class="dv">4</span>, <span class="dv">15</span>, <span class="dv">50</span>), <span class="dv">0</span>)  </a>
<a class="sourceLine" id="cb426-5" data-line-number="5">km.levels</a></code></pre></div>
<pre><code>## [1] 33 15 20 34</code></pre>
<p>We can now simulate our results replicating each run five times and get output as follows:</p>
<div id="htmlwidget-b4cf0cb6ab5bfc0325ee" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-b4cf0cb6ab5bfc0325ee">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4"],["15","20","33","34"],[23,25,26,21],[23,25,24,25],[23,25,27,25],[26,23,27,25],[22,23,27,25]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Range<\/th>\n      <th>1<\/th>\n      <th>2<\/th>\n      <th>3<\/th>\n      <th>4<\/th>\n      <th>5<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,4,5,6]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>We can then conduct our ANOVA as normal and get an ANOVA table:</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb428-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>Range, <span class="dt">data =</span> myDF))</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Range        3   21.4   7.133   3.397 0.0437 *
## Residuals   16   33.6   2.100                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb430-1" data-line-number="1"><span class="co"># Note the data in myDF is formatted as the same way as seen in the previous section</span></a></code></pre></div>
<p>From this, if we take <span class="math inline">\(\alpha = .05\)</span> we have a significant p-value and can reject our null hypothesis that says <span class="math inline">\(H_0: \sigma_{\tau}^2=0\)</span> meaning there is variation in the effects, meaning the factor of range does have an impact on kills.</p>
<p>You can of course then check your assumptions as previously indicated.</p>
<div id="single-factor-random-effects-problem-set" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Single Factor, Random Effects Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter3_1_ProblemSets/Single_Factor_RE_ANOVA_ProblemSet_Questions.html'> here </a>. Note that there is one data set used in the problem set, commo.csv. The link to the data set is in the problem set.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter3_1_ProblemSets/Single_Factor_RE_ANOVA_ProblemSet_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter3_1_ProblemSets/Single_Factor_RE_ANOVA_ProblemSet_Answers.html'> here </a>.</p>
</div>
</div>
<div id="two-factor-fixed-effects-anova" class="section level2">
<h2><span class="header-section-number">4.5</span> Two Factor, Fixed Effects ANOVA</h2>
<p>Having done one factor ANOVA, the natural question is, “What if I have multiple factors?” The answer is, we can still do ANOVA, we just extend our model for the additional factor.</p>
<p>First, consider our original model:</p>
<center>
<span class="math inline">\(y_{ij} = \mu + \tau_i + \epsilon_{ij}\)</span>
</center>
<p>If we have two factors, A and B, we can extend this with an effect for each factor:</p>
<center>
<span class="math inline">\(y_{ijk} = \mu + \tau_i + \beta_j + \epsilon_{ijk}\)</span>
</center>
<p>Where:</p>
<ul>
<li><span class="math inline">\(y_{ijk}\)</span> is the <span class="math inline">\(k^{th}\)</span> observation of <span class="math inline">\(y\)</span> at the <span class="math inline">\(i^{th}\)</span> level of Factor A and <span class="math inline">\(j^{th}\)</span> level of Factor B; <span class="math inline">\(\epsilon_{ijk}\)</span> is the corresponding error.</li>
<li><span class="math inline">\(\mu\)</span> is the mean of all observations.</li>
<li><span class="math inline">\(\tau_i\)</span> is the effect for the <span class="math inline">\(i^{th}\)</span> level of factor A, where <span class="math inline">\(i \in {1, 2, ...a}\)</span></li>
<li><span class="math inline">\(\beta_j\)</span> is the effect for the <span class="math inline">\(j^{th}\)</span> level of factor B, where <span class="math inline">\(j \in {1, 2, ...b}\)</span></li>
</ul>
<p>We make a few assumptions about this model:</p>
<ul>
<li>The levels of the factors A and B are fixed.</li>
<li><span class="math inline">\(\sum_1^a \tau_i = \sum_1^b \beta_j = 0\)</span>, that is, the sum of the effects is 0 in both cases.</li>
<li><span class="math inline">\(\epsilon_{ijk}\)</span> are Normally, Independently Distributed with a <span class="math inline">\(\mu = 0\)</span> and a constant variance <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p>Let’s look at an example:</p>
<p>Consider our IDF example where our response is the number of kills achieved, but now we have two factors: the round used and the maximum range. We will fix our levels as:</p>
<ul>
<li>Factor A: Round with levels DPICM, HEAT, HTK, and PGM as defined above. This implies that <span class="math inline">\(a = 4\)</span> as there are four levels.</li>
<li>Factor B: Range with levels: 15km, 30km, 50km. This implies that <span class="math inline">\(b = 3\)</span>. Note, in this case we have fixed our levels.</li>
</ul>
<p>If we do <span class="math inline">\(n\)</span> replicates of each combination of level from Factor A and Factor B, we will have <span class="math inline">\(nab\)</span> observations. Assume we run 5 replicates of each combination of the two factors and have the following output:</p>
<div id="htmlwidget-641ef5d5b1987d4affef" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-641ef5d5b1987d4affef">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60"],[1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],["DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM"],["15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km"],[11.24983105041852,12.33887023050679,10.93797345278701,12.34792351083315,10.30204850589829,17.73557248343453,20.86238519069308,16.50061953062279,18.11731742381735,16.70470330093911,20.57080505079227,21.34674071924472,21.21769893760298,22.71118776125287,20.77942480224742,17.51712326777098,17.11231364417038,16.42815697214942,16.39739293871664,20.08135258346172,23.76212994582905,23.87291693029189,24.0585823143933,19.80330049381267,24.26087683406583,29.16792919955477,25.3255219620382,24.94563004220853,25.95752666762709,28.56836957701444,28.55686685072776,30.03218547334807,23.30747833164396,25.19692727799227,29.97514589500275,29.10702908762441,31.25163057077817,31.82578500164688,30.53920879588543,33.00196391352047,36.77653946435184,40.8273460803057,38.68919720861919,34.03336437180621,34.4442316745893,24.87079467614861,22.2256565877545,24.51782495494739,26.5344821559483,27.20898504075688,29.53898491762534,31.83122414212031,30.44393556209819,28.40042080956957,26.42151260660589,32.48741838428882,34.27881199779814,33.15399405075357,33.14645240696252,29.74553248248771]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Replicate<\/th>\n      <th>Round<\/th>\n      <th>Range<\/th>\n      <th>Kills<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>First, let’s plot this. Note that we either have to look at these points three dimensionally (which gets confusing) or the values against a factor at a time.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb431-1" data-line-number="1"><span class="kw">ggplot</span>(<span class="dt">data =</span> IDF2) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb431-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Round, <span class="dt">y =</span> Kills)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb431-3" data-line-number="3"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Kills vs. Round Type in 2-Factor ANOVA&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb432-1" data-line-number="1"><span class="kw">ggplot</span>(<span class="dt">data =</span> IDF2) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb432-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Range, <span class="dt">y =</span> Kills)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb432-3" data-line-number="3"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Kills vs. Range in 2-Factor ANOVA&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-18-2.png" width="672" /></p>
<p>With these box plots, we can clearly see that that there is some variation caused by each factor, but it’s not exactly clear how much variation is caused by the each factor. One way to view this is with trace plots (also called interaction plots). A trace plot is simply a line plot that has one factor on the X axis, the mean of the response on the Y axis, and a different line or color for each of the second factors. It looks like:</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb433-1" data-line-number="1"><span class="kw">ggplot</span>(</a>
<a class="sourceLine" id="cb433-2" data-line-number="2">  <span class="co"># We mutate our data to give us a table of mean responses</span></a>
<a class="sourceLine" id="cb433-3" data-line-number="3">  IDF2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Round, Range) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Mean.Response =</span> <span class="kw">mean</span>(Kills)), </a>
<a class="sourceLine" id="cb433-4" data-line-number="4">  <span class="co"># We then set our aesthetic for all plots.  </span></a>
<a class="sourceLine" id="cb433-5" data-line-number="5">  <span class="co"># Note we have to use the aesthetic &#39;group&#39; with a value of range for geom_line to work</span></a>
<a class="sourceLine" id="cb433-6" data-line-number="6">  <span class="kw">aes</span>(<span class="dt">x =</span> Round, <span class="dt">y =</span> Mean.Response, <span class="dt">color =</span> Range, <span class="dt">group =</span> Range)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb433-7" data-line-number="7"><span class="st">  </span><span class="co"># We can then plot the mean observations as points of size 3</span></a>
<a class="sourceLine" id="cb433-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb433-9" data-line-number="9"><span class="st">  </span><span class="co"># We can plot lines between each observation to aid in understanding</span></a>
<a class="sourceLine" id="cb433-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb433-11" data-line-number="11"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Two Factor ANOVA Trace Plot</span><span class="ch">\n</span><span class="st">Factor A on X Axis&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb434-1" data-line-number="1"><span class="co"># This plot is set up the same, except we are now using the Range on the x-axis</span></a>
<a class="sourceLine" id="cb434-2" data-line-number="2"><span class="kw">ggplot</span>(IDF2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Round, Range) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Mean.Response =</span> <span class="kw">mean</span>(Kills)), </a>
<a class="sourceLine" id="cb434-3" data-line-number="3">       <span class="kw">aes</span>(<span class="dt">x =</span> Range, <span class="dt">y =</span> Mean.Response, <span class="dt">color =</span> Round, <span class="dt">group =</span> Round)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb434-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb434-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb434-6" data-line-number="6"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Two Factor ANOVA Trace Plot</span><span class="ch">\n</span><span class="st">Factor B on X Axis&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-19-2.png" width="672" /></p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb435-1" data-line-number="1"><span class="co"># There are at least two other ways to produces these plots</span></a>
<a class="sourceLine" id="cb435-2" data-line-number="2"></a>
<a class="sourceLine" id="cb435-3" data-line-number="3"><span class="co">## ggplot using stat_summary:</span></a>
<a class="sourceLine" id="cb435-4" data-line-number="4"><span class="co"># ggplot(data = IDF2, aes(x = Round, y = Kills, color = Range, group = Range)) +</span></a>
<a class="sourceLine" id="cb435-5" data-line-number="5"><span class="co">#   stat_summary(fun = &#39;mean&#39;, geom = &#39;point&#39;) +</span></a>
<a class="sourceLine" id="cb435-6" data-line-number="6"><span class="co">#   stat_summary(fun = &#39;mean&#39;, geom = &#39;line&#39;)</span></a>
<a class="sourceLine" id="cb435-7" data-line-number="7"></a>
<a class="sourceLine" id="cb435-8" data-line-number="8"><span class="co">## The stats package interaction.plot also does this</span></a>
<a class="sourceLine" id="cb435-9" data-line-number="9"><span class="co"># stats::interaction.plot(x.factor = IDF2$Round, trace.factor = IDF2$Range, response = IDF2$Kills)</span></a></code></pre></div>
<p>One thing you may immediately notice from these two plots is that the trace lines never cross. This is indicative of the fact that two factors are independent and do not interact. If the lines crossed (on either plot), it would indicate that you have an interaction.</p>
<p>We can now compute the actual ANOVA table in the same way we did for single factor ANOVA. The actual computations are analogous to single factor ANOVA but will not be covered here. For more in depth treatment, please refer to any standard probability and statistics text (e.g., Devore’s <em>Probability and Statistics for Engineering and the Sciences</em> Chapter 11 (7th Edition) or the <a href = 'https://www.itl.nist.gov/div898/handbook/prc/section4/prc427.htm'><em>NIST Engineering Statistics Handbook</em> </a>).</p>
<p>The <em>R</em> computations are as follows:</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb436-1" data-line-number="1"><span class="co"># Note the Response ~ FactorA + FactorB format.  </span></a>
<a class="sourceLine" id="cb436-2" data-line-number="2"><span class="co"># This is a common format in ANOVA, Regression, and other statistical </span></a>
<a class="sourceLine" id="cb436-3" data-line-number="3"><span class="co"># functions in R.  </span></a>
<a class="sourceLine" id="cb436-4" data-line-number="4">my<span class="fl">.2</span>Factor.ANOVA &lt;-<span class="st"> </span><span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>Round <span class="op">+</span><span class="st"> </span>Range, <span class="dt">data =</span> IDF2)</a>
<a class="sourceLine" id="cb436-5" data-line-number="5"><span class="kw">summary</span>(my<span class="fl">.2</span>Factor.ANOVA)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## Round        3 2015.1   671.7   181.9 &lt;2e-16 ***
## Range        2  822.9   411.5   111.4 &lt;2e-16 ***
## Residuals   54  199.4     3.7                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>You’ll note this looks very similar to the single factor, fixed effects ANOVA, and it is! The only major difference is we now have two factors listed as rows in the table, <code>Round</code> and <code>Range</code>. This is indicative of the fact that we now have two hypothesis tests occuring. They are:</p>
<ul>
<li>Factor A: <span class="math inline">\(H_{0-A}: \tau_1 = \tau_2 = ... \tau_a = 0\)</span> and its corresponding alternate.</li>
<li>Factor B: <span class="math inline">\(H_{0-B}: \beta_1 = \beta_2 = ... \beta_b = 0\)</span> and its corresponding alternate.</li>
</ul>
<p>If we have p-values for either of these that are below our desired <span class="math inline">\(\alpha\)</span> generally <span class="math inline">\(&lt;.05\)</span> or <span class="math inline">\(&lt;.01\)</span>, we can reject the null and conclude that the relevant does have an effect. In our case, in the table above, we can safely reject the null for both factors and say that it is plausible that at least one level of each factor has an effect on the response.</p>
<p>We still have to check our assumptions. We can do this in the same manner as single factor ANOVA:</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb438-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb438-2" data-line-number="2"><span class="kw">plot</span>(my<span class="fl">.2</span>Factor.ANOVA)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>We can see that our residuals are normally and independently distributed with a mean of 0 and constant variance. We can further check the residuals vs. order to check for time dependence (assuming our data set is written in order of the observations we gathered).</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb439-1" data-line-number="1"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb439-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">60</span>, <span class="dt">y =</span> my<span class="fl">.2</span>Factor.ANOVA<span class="op">$</span>residuals)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb439-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span><span class="st">&#39;red&#39;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>There does not appear to be any time dependence to our observations, so we further validate our independence assumption.</p>
<div id="including-interaction-effects" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Including Interaction Effects</h3>
<p>We can extend this sort of analysis arbitrarily, to include the potential for interaction effects. Let’s assume we have the same IDF simulation scenario, but now we’ve got a different set of data:</p>
<div id="htmlwidget-06a61acfff7e31cd2d7a" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-06a61acfff7e31cd2d7a">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60"],[1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],["DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM"],["15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km"],[12.06517235220101,15.40866878218906,14.03116522369201,13.50176763459989,14.3861301932103,21.08895331488005,17.5809496445142,15.76815923684487,13.68223365220703,18.52921713977181,23.29729957420163,17.16741717780355,23.67044438487138,21.84877771886546,21.16815493394079,28.51830099383,26.71045518563145,28.94517046713431,25.45401258195736,28.00320568335438,19.4564995042399,17.75529702605085,21.11311651792704,20.94713703874831,23.12703180973472,25.97009987178092,24.71251117596578,23.47634547126901,26.62770803819308,23.80450967442454,27.54385507938652,26.16987739666781,26.9946787212988,27.32977427064359,23.7018323210466,28.94241095821996,30.98774976245273,30.56072531585965,30.90572715074706,27.84025329887707,31.8577050660973,37.29428779198447,34.4776837624896,37.54967701653548,34.26155345742224,23.80993099901728,28.83088917521826,24.77686286766208,24.38324779457895,27.83598942785652,28.10174994600359,30.61349744581565,29.03210113988945,27.65145539925063,28.56984184744865,34.43068208227044,33.92705782575359,32.86743062865825,34.18875308682844,28.22617392394043]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Replicate<\/th>\n      <th>Round<\/th>\n      <th>Range<\/th>\n      <th>Kills<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>We can initially plot our data, first as boxplots, and then as trace plots as we did earlier:</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb440-1" data-line-number="1"><span class="kw">ggplot</span>(<span class="dt">data =</span> IDF2.Interaction) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb440-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Round, <span class="dt">y =</span> Kills)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb440-3" data-line-number="3"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Kills vs. Round Type in 2-Factor ANOVA</span><span class="ch">\n</span><span class="st">Interaction Effect&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb441-1" data-line-number="1"><span class="kw">ggplot</span>(<span class="dt">data =</span> IDF2.Interaction) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb441-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Range, <span class="dt">y =</span> Kills)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb441-3" data-line-number="3"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Kills vs. Range in 2-Factor ANOVA</span><span class="ch">\n</span><span class="st">Interaction Effect&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
<p>As you can see, it is challenging to identify an interaction effect with boxplots, but it becomes much more apparent in trace plots:</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb442-1" data-line-number="1"><span class="kw">ggplot</span>(IDF2.Interaction <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Round, Range) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Mean.Response =</span> <span class="kw">mean</span>(Kills)), </a>
<a class="sourceLine" id="cb442-2" data-line-number="2">       <span class="kw">aes</span>(<span class="dt">x =</span> Round, <span class="dt">y =</span> Mean.Response, <span class="dt">color =</span> Range, <span class="dt">group =</span> Range)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb442-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb442-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb442-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Two Factor ANOVA Trace Plot (Interaction)</span><span class="ch">\n</span><span class="st">Factor A on X Axis&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb443-1" data-line-number="1"><span class="kw">ggplot</span>(IDF2.Interaction <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Round, Range) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Mean.Response =</span> <span class="kw">mean</span>(Kills)), </a>
<a class="sourceLine" id="cb443-2" data-line-number="2">       <span class="kw">aes</span>(<span class="dt">x =</span> Range, <span class="dt">y =</span> Mean.Response, <span class="dt">color =</span> Round, <span class="dt">group =</span> Round)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb443-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb443-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb443-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Two Factor ANOVA Trace Plot (Interaction)</span><span class="ch">\n</span><span class="st">Factor B on X Axis&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<p>The interaction effect is much more apparent as indicated by the crossing lines. This is because the shape of the traces is not solely dependent on the each individual Factor, but their interaction. Our model now becomes:</p>
<center>
<span class="math inline">\(y_{ijk} = \mu + \tau_i + \beta_j + (\tau \beta)_{ij} + \epsilon_{ijk}\)</span>
</center>
<p>In this case, all the terms have the same meanings and bounds as in the previous model and we have simply added a new term, <span class="math inline">\((\tau \beta)_{ij}\)</span>, that indicates the interaction of the <span class="math inline">\(i^{th}\)</span> level of Factor A with the <span class="math inline">\(j^{th}\)</span> level of Factor B. We calculate the ANOVA in <em>R</em> as follows:</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb444-1" data-line-number="1">my<span class="fl">.2</span>Factor.Interaction.ANOVA &lt;-<span class="st"> </span><span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>Round <span class="op">+</span><span class="st"> </span>Range <span class="op">+</span><span class="st"> </span>Round<span class="op">:</span>Range, <span class="dt">data =</span> IDF2.Interaction)</a>
<a class="sourceLine" id="cb444-2" data-line-number="2"><span class="kw">summary</span>(my<span class="fl">.2</span>Factor.Interaction.ANOVA)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Round        3 1533.1   511.0  130.28  &lt; 2e-16 ***
## Range        2  308.8   154.4   39.36 7.61e-11 ***
## Round:Range  6  271.1    45.2   11.52 6.03e-08 ***
## Residuals   48  188.3     3.9                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>You’ll note the formula format here is <code>Response ~ FactorA + FactorB + FactorA:FactorB</code>. The <code>A:B</code> format in R is how we indicate the interaction effect.</p>
<p>We can interpret these results in the same way as before, noting that there are now three hypothesis tests, one for if Factor A has a non-zero effect, one for Factor B, and one for the interaction.</p>
<p>As a helpful note, in <em>R</em>, if your data frame is set up such that you have a single column as the response, and the rest of the columns indicate factors (i.e., no extraneous columns), you can indicate you want to use all of the non-response columns as factors by indicating a single <code>.</code> and every pair of interactions by <code>.:.</code>. You can see this here (note it produces the same result as above):</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb446-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>.<span class="op">:</span>., <span class="dt">data =</span> <span class="kw">select</span>(IDF2.Interaction, <span class="kw">c</span>(Kills, Round, Range))))</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Round        3 1533.1   511.0  130.28  &lt; 2e-16 ***
## Range        2  308.8   154.4   39.36 7.61e-11 ***
## Round:Range  6  271.1    45.2   11.52 6.03e-08 ***
## Residuals   48  188.3     3.9                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Finally, we still should do our standard tests to check our assumptions:</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb448-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb448-2" data-line-number="2"><span class="kw">plot</span>(my<span class="fl">.2</span>Factor.Interaction.ANOVA)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb449-1" data-line-number="1"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb449-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">60</span>, <span class="dt">y =</span> my<span class="fl">.2</span>Factor.Interaction.ANOVA<span class="op">$</span>residuals)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb449-3" data-line-number="3"><span class="st">  </span><span class="co">#Recall here, we are making an assumption that the data order is </span></a>
<a class="sourceLine" id="cb449-4" data-line-number="4"><span class="st">  </span><span class="co"># equivalent to the run order; really we should have some sort of time data</span></a>
<a class="sourceLine" id="cb449-5" data-line-number="5"><span class="st">  </span><span class="co"># to plot this</span></a>
<a class="sourceLine" id="cb449-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-28-2.png" width="672" /></p>
<p>As these plots look reasonable, we can safely use our analysis.</p>
<p>In both the example with no interaction effects and the example with interaction effects, we assumed the levels for the factors were fixed. If, on the other hand, they were randomly selected from a larger population of possible levels, our hypothesis test would change in the same manner as indicated in single factor ANOVA. If all factors’ levels are chosen randomly, the ANVOA becomes a random-effects model. If some factors are fixed and some are random, we call the model a “mixed-effects” model.</p>
</div>
<div id="two-factor-anova-problem-set" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Two Factor ANOVA Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter3_1_ProblemSets/Two_Factor_ANOVA_ProblemSet_Questions.html'> here </a>. Note that there is one data set used in the problem set, commo.csv. The link to the data set is in the problem set.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter3_1_ProblemSets/Two_Factor_ANOVA_ProblemSet_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter3_1_ProblemSets/Two_Factor_ANOVA_ProblemSet_Answers.html'> here </a>.</p>
</div>
</div>
<div id="anova-for-more-than-two-factors" class="section level2">
<h2><span class="header-section-number">4.6</span> ANOVA For More Than Two Factors</h2>
<p>In some cases, we will have 3+ factors along with 2nd, 3rd, and even higher order interactions. We can continue to do ANOVA by simply extending our model and method in the same manner as before. For example, consider the same IDF experiment, but with a third factor: the color of the artillery piece with the levels ‘Blue’ or ‘Green’.</p>
<p>Let’s assume our data is as follows:</p>
<div id="htmlwidget-3122f64f8cc833451606" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-3122f64f8cc833451606">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120"],[1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5,1,2,3,4,5],["DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","DPICM","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HEAT","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","HTK","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM","PGM"],["15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km","15km","15km","15km","15km","15km","30km","30km","30km","30km","30km","50km","50km","50km","50km","50km"],["Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Blue","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green","Green"],[18.04008886820858,10.9321693295539,12.77162410087599,17.13570072535698,13.61343400709251,15.79137512723215,19.3993406998379,20.75526226081117,18.86561948758692,19.11814054773539,18.82148023101235,23.23741666497305,19.92232591347164,20.9694600855999,21.25028476843069,25.69070922067548,27.39315446524764,27.74274510286909,25.56448424578475,25.48769140358614,23.02254052632879,22.47722047846791,20.22781011793366,22.042088751365,22.79614493143544,27.75511738287027,27.30924228573689,24.55917426124974,29.72934603447649,22.67251054358598,27.30339459489408,30.14934377700439,24.13907370146385,26.47829523192281,27.28902750701745,30.88784822203915,30.96943142455807,32.51773452893761,27.73164288527921,28.71896782923788,37.20717403543701,35.30604606982539,35.00211390515079,33.15866897991464,35.98271820514364,24.86644558212853,24.56421430723136,24.90721857070747,26.8603659665849,23.77271395673538,31.54930229197497,27.55747202465519,31.0755436605901,31.50820773191815,26.96165510048593,30.45422018738716,33.9307084500721,32.59653588944686,31.59980028008498,32.3555773494279,15.03675423391088,13.86572259897635,12.99088483666118,13.39247797135839,14.64005568035587,17.53747178826239,16.54756295162194,19.44763016509727,17.03889441174525,18.874851332556,21.20222978674068,23.40184462050536,20.51420642926995,22.4684099798784,19.29033904447229,26.61944014426243,25.19727319135535,25.39684523067237,26.82822941737117,23.54487634920768,21.42836874608954,20.20018505505087,19.83215235953459,17.31460957783492,20.39613273392199,24.58117341271237,26.40645241995009,26.13793919258159,25.90849070249667,26.38069074492391,28.03744583813029,28.79093575358639,23.43669093983279,26.89139527593282,28.34073741304124,31.59947435821424,29.67459222208134,32.47563090977309,33.78810236609993,32.11058387030592,35.06749720871598,30.1797635492003,34.08876427558354,33.24312722264582,38.04734049687335,24.98298691110564,23.23454246275196,23.29100856496826,25.17748953766322,25.83223505502897,30.92755758698488,26.157548083391,24.7303573095921,26.91363738412814,29.84542898531935,31.88878642598737,29.42619870007495,32.39127128286431,33.649992837802,33.06394575246267]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Replicate<\/th>\n      <th>Round<\/th>\n      <th>Range<\/th>\n      <th>Color<\/th>\n      <th>Kills<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,5]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>We can then do our analysis in the typical manner:</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb450-1" data-line-number="1">my<span class="fl">.3</span>Factor.ANOVA &lt;-<span class="st"> </span><span class="kw">aov</span>(Kills <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>.<span class="op">:</span>. <span class="op">+</span><span class="st"> </span>.<span class="op">:</span>.<span class="op">:</span>., <span class="dt">data =</span> <span class="kw">select</span>(IDF3, <span class="kw">c</span>(Kills, Round, Range, Color)))</a>
<a class="sourceLine" id="cb450-2" data-line-number="2"><span class="kw">summary</span>(my<span class="fl">.3</span>Factor.ANOVA)</a></code></pre></div>
<pre><code>##                   Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Round              3 2942.4   980.8 297.318  &lt; 2e-16 ***
## Range              2  636.6   318.3  96.494  &lt; 2e-16 ***
## Color              1    9.0     9.0   2.716    0.103    
## Round:Range        6  339.2    56.5  17.138 2.26e-13 ***
## Round:Color        3    8.8     2.9   0.889    0.450    
## Range:Color        2    1.5     0.8   0.232    0.793    
## Round:Range:Color  6   21.8     3.6   1.102    0.367    
## Residuals         96  316.7     3.3                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>From this we can see a few things:</p>
<ol style="list-style-type: decimal">
<li>We still see that Round and Range are significant. Color is not (as one would expect).</li>
<li>We see the interaction between Round and Range is significant, but the interactions between Round and Color and Range and Color is not significant.</li>
<li>The third order interaction is not significant.<br />
</li>
<li>With increasing numbers of factors, the number of interactions increases significantly.</li>
</ol>
<p>To this last point, the number of combinations of first and higher order interactions scales as <span class="math inline">\(2^K - 1\)</span> where <span class="math inline">\(K\)</span> is the number of factors. It is generally untenable to test this number of hypotheses and interpret that many. Fortunately, a common heuristic is that very high order interactions can generally be considered insignificant unless one has good reason to believe otherwise.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<p>Of course, we need to check our assumptions, though for the sake of space, we will ignore that for this portion of the tutorial. We check our assumptions in the same manner as in previous sections.</p>
<div id="multi-factor-anova-problem-set" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Multi-Factor ANOVA Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter3_1_ProblemSets/Multi_Factor_ANOVA_ProblemSet_Questions.html'> here </a>. Note that there is one data set used in the problem set, commo.csv. The link to the data set is in the problem set.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter3_1_ProblemSets/Multi_Factor_ANOVA_ProblemSet_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter3_1_ProblemSets/Multi_Factor_ANOVA_ProblemSet_Answers.html'> here </a>.</p>
</div>
</div>
<div id="multiple-comparisons" class="section level2">
<h2><span class="header-section-number">4.7</span> Multiple Comparisons</h2>
<p>We have now done ANOVA in many ways, and, if we have found at least one factor significant, we may want to understand which levels of that factor are different from each other.</p>
<p>If we have just two levels, this problem simply resolves to a T-Test for the comparison of two means as previously done. If we have <span class="math inline">\(a &gt; 3\)</span> levels, however, we have <span class="math inline">\(a\choose{2}\)</span> possible pairings. Given that, for the T-Test, we have a <span class="math inline">\(1 - \alpha\)</span> confidence, if we do <span class="math inline">\(a\choose2\)</span> tests, our confidence in not making an error in all of these these tests scales like <span class="math inline">\((1 - \alpha)^{a\choose2}\)</span>, which decreases rather rapidly.</p>
<p>To do avoid this problem, statisticians have come up with multiple methods depending on the situation. You can read more about this in some different situations <a href = 'http://www.biostathandbook.com/multiplecomparisons.html'> here </a>. For our current situation, we will use a test called “Tukey’s Test” You can read more about it <a href = 'https://en.wikipedia.org/wiki/Tukey%27s_range_test'> here </a>. A very nice thing about this test is that it holds the same assumptions as ANOVA, so if you’ve met those assumptions, you can use the test.</p>
<div id="tukey-test-example" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Tukey Test Example</h3>
<p>Let’s look at our original problem, the single factor, fixed effects ANOVA, where the factor was the Round and it had four levels:</p>
<pre><code>##   Round  1  2  3  4  5
## 1 DPICM 23 10 13 27 27
## 2  HEAT 19 17 31 15 13
## 3   HTK 28 28 34 38 30
## 4   PGM 29 32 27 26 19</code></pre>
<p>We did our ANOVA and got the following result:</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb453-1" data-line-number="1"><span class="kw">summary</span>(myAOV)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Round        3  525.8  175.27   4.491 0.0181 *
## Residuals   16  624.4   39.02                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>From this, we concluded that at least one of the levels of Round has a non-zero effect.</p>
<p>Let’s calculate this by hand, first to get an idea of what we are doing:</p>
<p>First, let’s plot the mean of each level:</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb455-1" data-line-number="1"><span class="co"># Note we&#39;re getting the means of the data and arranging it by the mean</span></a>
<a class="sourceLine" id="cb455-2" data-line-number="2"><span class="kw">ggplot</span>(Formatted.Data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Round) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mu =</span> <span class="kw">mean</span>(Kills)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(mu)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb455-3" data-line-number="3"><span class="st">  </span><span class="co"># The y = 1 is just for convenience to plot on a graph.  It has no meaning</span></a>
<a class="sourceLine" id="cb455-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">y =</span> <span class="dv">1</span>, <span class="dt">color =</span> Round)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb455-5" data-line-number="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Mean Kills&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb455-6" data-line-number="6"><span class="st">  </span><span class="co"># There is no y value</span></a>
<a class="sourceLine" id="cb455-7" data-line-number="7"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb455-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb455-9" data-line-number="9"><span class="st">  </span><span class="co"># We remove the y axis text as it is not meaningful and leaving it could cause confusion</span></a>
<a class="sourceLine" id="cb455-10" data-line-number="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>Now we’ll want to find a range, <code>w</code> that is defined as: <span class="math inline">\(w = Q_{\alpha, a, a(n-1)}\sqrt{\frac{MS_E}{n}}\)</span> where:</p>
<ul>
<li><span class="math inline">\(Q_{\alpha, a, a(n-1)}\)</span> is the Studentized Range Distribution with <span class="math inline">\(alpha\)</span> as normal, <span class="math inline">\(a\)</span> indicating the number of levels, and <span class="math inline">\(n\)</span> indicating the number of replicates.</li>
<li><span class="math inline">\(MS_E\)</span> is our Mean Square Error derived from our ANOVA table.</li>
</ul>
<p>We can calculate this w as follows:</p>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb456-1" data-line-number="1"><span class="co"># First, `qtukey()` is the command to look up the critical value</span></a>
<a class="sourceLine" id="cb456-2" data-line-number="2"><span class="co"># It takes a probability, p as its first argument.  </span></a>
<a class="sourceLine" id="cb456-3" data-line-number="3"><span class="co"># If you provide the alpha you will need to set lower.tail to F</span></a>
<a class="sourceLine" id="cb456-4" data-line-number="4"><span class="co"># If you provide 1 - alpha you will need to set lower.tail to T (the default)</span></a>
<a class="sourceLine" id="cb456-5" data-line-number="5"><span class="co"># nmeans is the number of levels you have (i.e., a)</span></a>
<a class="sourceLine" id="cb456-6" data-line-number="6"><span class="co"># and df is the degrees of freedom, this is defined as a(n-1)</span></a>
<a class="sourceLine" id="cb456-7" data-line-number="7"></a>
<a class="sourceLine" id="cb456-8" data-line-number="8"><span class="co"># our nmeans (a) is 4 as we have four levels:  DPICM, HEAT, HTK, PGM</span></a>
<a class="sourceLine" id="cb456-9" data-line-number="9"><span class="co"># our df is 16 as we have a = 4 and n = 5, so 4*(5-1) = 16</span></a>
<a class="sourceLine" id="cb456-10" data-line-number="10"><span class="co"># we&#39;ll choose alpha = .05</span></a>
<a class="sourceLine" id="cb456-11" data-line-number="11"></a>
<a class="sourceLine" id="cb456-12" data-line-number="12">q<span class="fl">.1</span>Factor &lt;-<span class="st"> </span><span class="kw">qtukey</span>(.<span class="dv">05</span>, <span class="dv">4</span>, <span class="dv">16</span>, <span class="dt">lower.tail =</span> F)</a>
<a class="sourceLine" id="cb456-13" data-line-number="13"></a>
<a class="sourceLine" id="cb456-14" data-line-number="14"><span class="co"># We can look at the ANOVA table above and find our MSE = 39.03</span></a>
<a class="sourceLine" id="cb456-15" data-line-number="15"></a>
<a class="sourceLine" id="cb456-16" data-line-number="16">w<span class="fl">.1</span>Factor &lt;-<span class="st"> </span>q<span class="fl">.1</span>Factor <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="fl">39.03</span><span class="op">/</span><span class="dv">5</span>)</a></code></pre></div>
<p>This gives us a range akin to a confidence interval. If the difference of any two means is less than this <span class="math inline">\(w\)</span>, we cannot, statistically, say that they are different (i.e., it is plausible they are drawn from the same population with the same true mean). We can see this graphically:</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb457-1" data-line-number="1"><span class="co"># This first part is the same as the original plot</span></a>
<a class="sourceLine" id="cb457-2" data-line-number="2"><span class="kw">ggplot</span>(Formatted.Data <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Round) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">mu =</span> <span class="kw">mean</span>(Kills)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(mu)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-3" data-line-number="3"><span class="st">  </span><span class="co"># We plot each level on its own value so we can avoid overlaps</span></a>
<a class="sourceLine" id="cb457-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">y =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">color =</span> Round), <span class="dt">size =</span> <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-5" data-line-number="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;Mean Kills&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-6" data-line-number="6"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-7" data-line-number="7"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_blank</span>()) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-9" data-line-number="9"><span class="st">  </span><span class="co"># We now add a segment that extends from the mean observation to the mean +/- our W</span></a>
<a class="sourceLine" id="cb457-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">xend =</span> mu <span class="op">+</span><span class="st"> </span>w<span class="fl">.1</span>Factor, <span class="dt">y =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">yend =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">color =</span> Round)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">xend =</span> mu <span class="op">-</span><span class="st"> </span>w<span class="fl">.1</span>Factor, <span class="dt">y =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">yend =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">color =</span> Round)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb457-12" data-line-number="12"><span class="st">  </span><span class="co"># The vertical lines help us clearly see the mean value for each level</span></a>
<a class="sourceLine" id="cb457-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> mu, <span class="dt">color =</span> Round), <span class="dt">lty =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb457-14" data-line-number="14"><span class="st">  </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">7</span>)) </a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>This is in initially a somewhat confusing graph, but it shows us a few things:</p>
<ul>
<li>The sample mean for each level is plotted with the large circle and its corresponding color.</li>
<li>The dashed vertical lines are simply there for clearly seeing the sample mean of each round type.</li>
<li>The solid horizontal lines are the mean of each level plus or minus the <span class="math inline">\(w\)</span> value we calculated.</li>
</ul>
<p>What the Tukey test tells us, is that if two means are within <span class="math inline">\(w\)</span> of each other (i.e. <span class="math inline">\(|\mu_i - \mu_j| &lt;= w\)</span>), we cannot tell if their difference is do to an effect of the level or simply due to random variation. We can see this graphically in the plot above. For example:</p>
<p>The HEAT round (in green) cannot be said to have an effect different than the DPICM (in red) or PGM (in purple), but definitely is different than the HTK (in teal). Note that this is not a binary distinction, it’s not that all of HEAT, DPICM, and PGM are potentially the same, but HTK is different, rather its a grouping per level. For example, in our case above, PGM is utterly ambiguous as the mean of every other level falls within <span class="math inline">\(w\)</span> of it.</p>
</div>
<div id="tukey-test-in-r" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Tukey Test in R</h3>
<p>While the above was certainly do-able, it was somewhat annoying. Fortunately, <em>R</em> has a built in Tukey test, <code>TukeyHSD()</code>. We can use it as follows:</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb458-1" data-line-number="1"><span class="co"># TukeyHSD has several arguments:</span></a>
<a class="sourceLine" id="cb458-2" data-line-number="2"><span class="co"># x: this is your ANOVA model</span></a>
<a class="sourceLine" id="cb458-3" data-line-number="3"><span class="co"># which: this is the factor you want to consider</span></a>
<a class="sourceLine" id="cb458-4" data-line-number="4"><span class="co"># conf.level: this is the confidence level you want (1 - alpha)</span></a>
<a class="sourceLine" id="cb458-5" data-line-number="5"><span class="co"># you can store it as a variable</span></a>
<a class="sourceLine" id="cb458-6" data-line-number="6">tukey<span class="fl">.1</span>Factor &lt;-<span class="st"> </span><span class="kw">TukeyHSD</span>(myAOV, <span class="dt">which =</span> <span class="st">&#39;Round&#39;</span>, <span class="dt">conf.level =</span> <span class="fl">.95</span>)</a></code></pre></div>
<p>The output of <code>TukeyHSD</code> is a little bit harder to interpret than as described above, but it is doable:</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb459-1" data-line-number="1">tukey<span class="fl">.1</span>Factor</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Kills ~ Round, data = Formatted.Data)
## 
## $Round
##            diff         lwr       upr     p adj
## HEAT-DPICM -1.0 -12.3037441 10.303744 0.9940787
## HTK-DPICM  11.6   0.2962559 22.903744 0.0432762
## PGM-DPICM   6.6  -4.7037441 17.903744 0.3701994
## HTK-HEAT   12.6   1.2962559 23.903744 0.0263523
## PGM-HEAT    7.6  -3.7037441 18.903744 0.2574848
## PGM-HTK    -5.0 -16.3037441  6.303744 0.5965234</code></pre>
<p>What we are saying here is:</p>
<ul>
<li><code>95% family-wise confidence level</code> just says you’re using a 95% confidence level.</li>
<li><code>Fit: aov ...</code> just repeats what your original ANOVA calculated</li>
<li><code>$Round</code> indicates we are looking at the Factor Round</li>
<li>Each of the combinations in the left hand column are the various pairings between the different levels of the factor</li>
<li>The <code>diff</code> column is the difference in means of the observed values of the two levels.</li>
<li>The <code>lwr</code> and <code>upr</code> are the ranges for the possible value of the differences.</li>
<li>The <code>p adj</code> is the p-value for the hypothesis: the difference in means is 0.</li>
</ul>
<p>For example, consider the first row (HEAT-DPICM):</p>
<ul>
<li>We are comparing the mean kills when the Round is HEAT vs. when the Round is DPICM.</li>
<li>The mean kills are (not depicted in this) 19 and 20 respectively.</li>
<li>The difference is 19-20 = -1.</li>
<li>The 95% confidence interval on the difference of the means is -12.3 to 10.3; which includes 0.</li>
<li>This has a p-value of .994, meaning we fail-to-reject the null that the difference of the means is 0 (for those two levels).</li>
</ul>
<p>Now consider the fourth row (HTK-HEAT):</p>
<ul>
<li>We are comparing the means when the Round is at HTK and when it is at HEAT.</li>
<li>The mean kills are: 31.6 and 19 respectively (again, not shown).</li>
<li>The difference is 31.6 - 19 = 12.6.</li>
<li>The 95% confidence interval on this difference is 1.30 to 23.90; which does not include 0.</li>
<li>This has a p-value of .026, meaning, for <span class="math inline">\(\alpha = .05\)</span>, we reject the null that the difference is 0, and conclude the treatment effect of the HTK and HEAT rounds is different.</li>
</ul>
<p>We can also plot these results:</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb461-1" data-line-number="1"><span class="co"># the par function sets parameters for a base R plot</span></a>
<a class="sourceLine" id="cb461-2" data-line-number="2"><span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">4</span>,<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="fl">.1</span>)</a>
<a class="sourceLine" id="cb461-3" data-line-number="3"><span class="co"># the las = 1 option ensures we plot the value for each level:level combination</span></a>
<a class="sourceLine" id="cb461-4" data-line-number="4"><span class="kw">plot</span>(tukey<span class="fl">.1</span>Factor, <span class="dt">las =</span> <span class="dv">1</span>)</a></code></pre></div>
<p><img src="031-ANOVA_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>This says a very similar thing as the plot we made above, but in a slightly different way. It shows the difference between the means for each of the level:level pairs. Having a confidence interval that does not include 0 indicates that there is a difference between the effects of those two levels (at the provided confidence level).</p>
</div>
<div id="tukey-test-multiple-factors" class="section level3">
<h3><span class="header-section-number">4.7.3</span> Tukey Test, Multiple Factors</h3>
<p>If we have a problem with multiple factors, to include interactions, we can run the test in the same manner. Using the 2-Factor, with Interactions example from above, we can run the <code>TukeyHSD</code> test:</p>
<div class="sourceCode" id="cb462"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb462-1" data-line-number="1"><span class="kw">TukeyHSD</span>(my<span class="fl">.2</span>Factor.Interaction.ANOVA, <span class="dt">conf.level =</span> <span class="fl">.95</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Kills ~ Round + Range + Round:Range, data = IDF2.Interaction)
## 
## $Round
##                 diff       lwr        upr     p adj
## HEAT-DPICM  6.761793  4.837093  8.6864926 0.0000000
## HTK-DPICM  12.881552 10.956852 14.8062519 0.0000000
## PGM-DPICM  11.603410  9.678710 13.5281101 0.0000000
## HTK-HEAT    6.119759  4.195059  8.0444593 0.0000000
## PGM-HEAT    4.841618  2.916918  6.7663174 0.0000001
## PGM-HTK    -1.278142 -3.202842  0.6465581 0.3014139
## 
## $Range
##               diff        lwr      upr     p adj
## 30km-15km 0.692656 -0.8220624 2.207374 0.5151298
## 50km-15km 5.121164  3.6064459 6.635883 0.0000000
## 50km-30km 4.428508  2.9137899 5.943227 0.0000000
## 
## $`Round:Range`
##                              diff         lwr        upr     p adj
## HEAT:15km-DPICM:15km   13.6476481   9.3465008 17.9487955 0.0000000
## HTK:15km-DPICM:15km    12.4694227   8.1682753 16.7705701 0.0000000
## PGM:15km-DPICM:15km    12.0488032   7.7476558 16.3499506 0.0000000
## DPICM:30km-DPICM:15km   3.4513218  -0.8498256  7.7524692 0.2319147
## HEAT:30km-DPICM:15km    6.6012355   2.3000882 10.9023829 0.0001861
## HTK:30km-DPICM:15km    15.9687925  11.6676451 20.2699399 0.0000000
## PGM:30km-DPICM:15km    14.9151483  10.6140009 19.2162957 0.0000000
## DPICM:50km-DPICM:15km   7.5518379   3.2506905 11.8529853 0.0000138
## HEAT:50km-DPICM:15km   11.0396540   6.7385066 15.3408014 0.0000000
## HTK:50km-DPICM:15km    21.2096006  16.9084532 25.5107480 0.0000000
## PGM:50km-DPICM:15km    18.8494387  14.5482913 23.1505861 0.0000000
## HTK:15km-HEAT:15km     -1.1782254  -5.4793728  3.1229220 0.9982467
## PGM:15km-HEAT:15km     -1.5988449  -5.8999923  2.7023025 0.9783288
## DPICM:30km-HEAT:15km  -10.1963264 -14.4974738 -5.8951790 0.0000000
## HEAT:30km-HEAT:15km    -7.0464126 -11.3475600 -2.7452652 0.0000556
## HTK:30km-HEAT:15km      2.3211443  -1.9800031  6.6222917 0.7806976
## PGM:30km-HEAT:15km      1.2675002  -3.0336472  5.5686476 0.9966740
## DPICM:50km-HEAT:15km   -6.0958102 -10.3969576 -1.7946628 0.0007097
## HEAT:50km-HEAT:15km    -2.6079941  -6.9091415  1.6931533 0.6371633
## HTK:50km-HEAT:15km      7.5619524   3.2608050 11.8630998 0.0000134
## PGM:50km-HEAT:15km      5.2017905   0.9006431  9.5029379 0.0066943
## PGM:15km-HTK:15km      -0.4206195  -4.7217669  3.8805279 0.9999999
## DPICM:30km-HTK:15km    -9.0181010 -13.3192484 -4.7169536 0.0000002
## HEAT:30km-HTK:15km     -5.8681872 -10.1693346 -1.5670398 0.0012786
## HTK:30km-HTK:15km       3.4993697  -0.8017777  7.8005171 0.2152565
## PGM:30km-HTK:15km       2.4457256  -1.8554218  6.7468730 0.7212162
## DPICM:50km-HTK:15km    -4.9175848  -9.2187322 -0.6164374 0.0130503
## HEAT:50km-HTK:15km     -1.4297687  -5.7309161  2.8713787 0.9909058
## HTK:50km-HTK:15km       8.7401779   4.4390305 13.0413253 0.0000005
## PGM:50km-HTK:15km       6.3800160   2.0788686 10.6811633 0.0003359
## DPICM:30km-PGM:15km    -8.5974815 -12.8986288 -4.2963341 0.0000007
## HEAT:30km-PGM:15km     -5.4475677  -9.7487151 -1.1464203 0.0036839
## HTK:30km-PGM:15km       3.9199892  -0.3811581  8.2211366 0.1049285
## PGM:30km-PGM:15km       2.8663451  -1.4348023  7.1674925 0.4982802
## DPICM:50km-PGM:15km    -4.4969653  -8.7981127 -0.1958179 0.0332096
## HEAT:50km-PGM:15km     -1.0091492  -5.3102966  3.2919982 0.9995769
## HTK:50km-PGM:15km       9.1607974   4.8596500 13.4619448 0.0000002
## PGM:50km-PGM:15km       6.8006355   2.4994881 11.1017828 0.0001086
## HEAT:30km-DPICM:30km    3.1499138  -1.1512336  7.4510612 0.3559315
## HTK:30km-DPICM:30km    12.5174707   8.2163233 16.8186181 0.0000000
## PGM:30km-DPICM:30km    11.4638266   7.1626792 15.7649739 0.0000000
## DPICM:50km-DPICM:30km   4.1005162  -0.2006312  8.4016636 0.0745816
## HEAT:50km-DPICM:30km    7.5883322   3.2871849 11.8894796 0.0000125
## HTK:50km-DPICM:30km    17.7582788  13.4571314 22.0594262 0.0000000
## PGM:50km-DPICM:30km    15.3981169  11.0969695 19.6992643 0.0000000
## HTK:30km-HEAT:30km      9.3675569   5.0664095 13.6687043 0.0000001
## PGM:30km-HEAT:30km      8.3139128   4.0127654 12.6150602 0.0000017
## DPICM:50km-HEAT:30km    0.9506024  -3.3505450  5.2517498 0.9997603
## HEAT:50km-HEAT:30km     4.4384185   0.1372711  8.7395659 0.0376009
## HTK:50km-HEAT:30km     14.6083650  10.3072176 18.9095124 0.0000000
## PGM:50km-HEAT:30km     12.2482031   7.9470557 16.5493505 0.0000000
## PGM:30km-HTK:30km      -1.0536441  -5.3547915  3.2475032 0.9993664
## DPICM:50km-HTK:30km    -8.4169545 -12.7181019 -4.1158071 0.0000012
## HEAT:50km-HTK:30km     -4.9291385  -9.2302858 -0.6279911 0.0127076
## HTK:50km-HTK:30km       5.2408081   0.9396607  9.5419555 0.0060958
## PGM:50km-HTK:30km       2.8806462  -1.4205012  7.1817936 0.4906997
## DPICM:50km-PGM:30km    -7.3633104 -11.6644578 -3.0621630 0.0000233
## HEAT:50km-PGM:30km     -3.8754943  -8.1766417  0.4256531 0.1138126
## HTK:50km-PGM:30km       6.2944523   1.9933049 10.5955997 0.0004213
## PGM:50km-PGM:30km       3.9342904  -0.3668570  8.2354377 0.1021977
## HEAT:50km-DPICM:50km    3.4878161  -0.8133313  7.7889635 0.2191824
## HTK:50km-DPICM:50km    13.6577627   9.3566153 17.9589101 0.0000000
## PGM:50km-DPICM:50km    11.2976008   6.9964534 15.5987481 0.0000000
## HTK:50km-HEAT:50km     10.1699466   5.8687992 14.4710940 0.0000000
## PGM:50km-HEAT:50km      7.8097847   3.5086373 12.1109321 0.0000068
## PGM:50km-HTK:50km      -2.3601619  -6.6613093  1.9409855 0.7626748</code></pre>
<p>You’ll note two things:</p>
<ol style="list-style-type: decimal">
<li>This does the test across all factors.</li>
<li>This quickly becomes cumbersome as the numbers of levels increase, which is particularly true for interactions.</li>
</ol>
<p>If you have multiple factors, but only want to see the results for one or some smaller subset of the number of factors, you can use the argument <code>which</code> in <code>TukeyHSD</code> as follows:</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb464-1" data-line-number="1"><span class="co"># Note the argument which takes a string with the name of the factor.</span></a>
<a class="sourceLine" id="cb464-2" data-line-number="2"><span class="co"># If you are looking for an interaction, the string is of the form: &#39;FactorA:FactorB&#39;</span></a>
<a class="sourceLine" id="cb464-3" data-line-number="3"><span class="kw">TukeyHSD</span>(my<span class="fl">.2</span>Factor.Interaction.ANOVA, <span class="dt">which =</span> <span class="st">&#39;Range&#39;</span>, <span class="dt">conf.level =</span> <span class="fl">.95</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Kills ~ Round + Range + Round:Range, data = IDF2.Interaction)
## 
## $Range
##               diff        lwr      upr     p adj
## 30km-15km 0.692656 -0.8220624 2.207374 0.5151298
## 50km-15km 5.121164  3.6064459 6.635883 0.0000000
## 50km-30km 4.428508  2.9137899 5.943227 0.0000000</code></pre>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb466-1" data-line-number="1"><span class="co"># Alternatively, if you want multiple factors, but not all of them,</span></a>
<a class="sourceLine" id="cb466-2" data-line-number="2"><span class="co"># you can pass a character vector with the selected Factors:</span></a>
<a class="sourceLine" id="cb466-3" data-line-number="3"><span class="kw">TukeyHSD</span>(my<span class="fl">.2</span>Factor.Interaction.ANOVA, <span class="dt">which =</span> <span class="kw">c</span>(<span class="st">&#39;Range&#39;</span>, <span class="st">&#39;Round&#39;</span>), <span class="dt">conf.level =</span> <span class="fl">.95</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Kills ~ Round + Range + Round:Range, data = IDF2.Interaction)
## 
## $Range
##               diff        lwr      upr     p adj
## 30km-15km 0.692656 -0.8220624 2.207374 0.5151298
## 50km-15km 5.121164  3.6064459 6.635883 0.0000000
## 50km-30km 4.428508  2.9137899 5.943227 0.0000000
## 
## $Round
##                 diff       lwr        upr     p adj
## HEAT-DPICM  6.761793  4.837093  8.6864926 0.0000000
## HTK-DPICM  12.881552 10.956852 14.8062519 0.0000000
## PGM-DPICM  11.603410  9.678710 13.5281101 0.0000000
## HTK-HEAT    6.119759  4.195059  8.0444593 0.0000000
## PGM-HEAT    4.841618  2.916918  6.7663174 0.0000001
## PGM-HTK    -1.278142 -3.202842  0.6465581 0.3014139</code></pre>
</div>
<div id="multiple-comparisons-problem-set" class="section level3">
<h3><span class="header-section-number">4.7.4</span> Multiple Comparisons Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter3_1_ProblemSets/Multi_Comparison_ProblemSet_Questions.html'> here </a>. Note that there is one data set used in the problem set, commo.csv. The link to the data set is in the problem set.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter3_1_ProblemSets/Multi_Comparison_ProblemSet_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter3_1_ProblemSets/Multi_Comparison_ProblemSet_Answers.html'> here </a>.</p>
</div>
</div>
<div id="anova-summary" class="section level2">
<h2><span class="header-section-number">4.8</span> ANOVA Summary</h2>
<p>In this section we covered ANOVA. Recall that ANOVA is a means of assessing if there is a difference in means of observations where the observations are grouped together by their corresponding levels of a factor. ANOVA assesses this difference by comparing the variability within the groups relative to the total variability. We did not spend much time to understand the theoretical basis or manual methods of calculating an ANOVA table as, for simulation, it is most important to understand how to use a tool (e.g., <em>R</em>) to calculate the ANOVA, understand the assumptions we must check, and how to interpret the results.</p>
<div id="how-to-calculate-anova" class="section level3">
<h3><span class="header-section-number">4.8.1</span> How to Calculate ANOVA</h3>
<p>We can calculate ANOVA using the <code>aov</code> function in <em>R</em>. This is a fairly robust function. It accounts for unbalanced observations (i.e., data where the various treatment combinations have differing numbers of replicates), and other similar challenges that become tricky when calculating and ANOVA by hand.</p>
</div>
<div id="anova-hypothesis-tests" class="section level3">
<h3><span class="header-section-number">4.8.2</span> ANOVA Hypothesis Test(s)</h3>
<p>In a fixed effects model, for any factor, or interaction, whose effect is represented as <span class="math inline">\(\tau_i\)</span>, where <span class="math inline">\(i \in {1, 2, ... a}\)</span> represents the level of the factor, the hypothesis test is:</p>
<p><span class="math inline">\(H_0: \tau_1 = \tau_2 = ... = \tau_a = 0\)</span></p>
<p><span class="math inline">\(H_A: \tau_i \neq 0\)</span> for at least one <span class="math inline">\(i \in {1, 2, ... a}\)</span></p>
<p>In a random effects model, for any factor whose effect is represented by <span class="math inline">\(\tau_i\)</span>, where <span class="math inline">\(i \in A\)</span>, where A is some large population of levels (it may be continuous or discrete), we say the variance in the random variable <span class="math inline">\(\tau\)</span> is zero, i.e.:</p>
<p><span class="math inline">\(H_0: \sigma^2(\tau) = 0\)</span></p>
<p><span class="math inline">\(H_A: \sigma^2(\tau) &gt; 0\)</span></p>
</div>
<div id="anova-assumptions" class="section level3">
<h3><span class="header-section-number">4.8.3</span> ANOVA Assumptions</h3>
<p>For ANOVA, we must make the following assumption: The residuals in our model are normally, and independently distributed, with a mean of 0 and a constant variance. We check this by:</p>
<ol style="list-style-type: decimal">
<li>Assessing if the residuals are normally distributed (QQ Plots, Shapiro Wilk Test).</li>
<li>Assessing if the residuals are homoscedastic (constant variance), we assess this with residuals vs. fitted values or residuals vs. levels plots. We can also check this with a hypothesis test such as the <a href = 'https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm'> Bartlett Test </a> or <a href = 'https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm'> Levene Test </a>.</li>
<li>Assessing the independence of the sample. We can see this graphically if we note patterns in our data on any of our standard plots. We can also plot our residuals vs. other potential explanatory variables, e.g., the time each observation was made or the collection order.</li>
</ol>
</div>
<div id="multiple-comparisons-1" class="section level3">
<h3><span class="header-section-number">4.8.4</span> Multiple Comparisons</h3>
<p>Having done ANOVA, and identified significant factors, we can compare means using the Tukey Test. This helps us avoid the problem of increasing likelihood of making a Type-I error with multiple T-Tests.</p>
</div>
<div id="further-extensions-of-anova" class="section level3">
<h3><span class="header-section-number">4.8.5</span> Further Extensions of ANOVA</h3>
<p>This section did not cover non-parametric ANOVA (the Kruskal-Wallis Test), randomized, complete block designs, transforming variables, or estimating the effects. These are further extensions on ANOVA that will be discussed at a future point in the course as required.</p>
<!--chapter:end:031-ANOVA.Rmd-->
</div>
</div>
</div>
<div id="fundamentals-of-design-of-experiments" class="section level1">
<h1><span class="header-section-number">5</span> Fundamentals of Design of Experiments</h1>
<!-- SEG Colinearity, vif,  & fractional, blocking, aliasing confounding, replication-->
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<blockquote>
<p>All experiments are designed experiments. The important issue is whether they are well designed or not.</p>
</blockquote>
<p style="text-align: right;">
Douglas C. Montgomery <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>
</p>
<p><br></p>
<p>This chapter introduces the fundamentals of Design of Experiments (DOE). An experiment, as we shall discuss, is simply the configuration of one or more tests that we conduct with the intention to learn something. Tests are discrete events where we supply inputs and measure outputs in some manner. These tests take many forms, including the physical (e.g., mixing some quantities of chemicals and measuring the properties of the resulting solution) and the virtual (e.g., providing some inputs to a computer simulation and recording the outputs). As noted by Montgomery in the quote above, any time we conduct an experiment<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> we, by definition, have designed it. The quality of the experiment is whether it 1) can answer our question(s) and 2) do so in an economical manner. The statistical design of experiments helps us with both.</p>
<div id="admin-1" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Admin</h3>
<ul>
<li><strong>POC:</strong> For any comments or identified errors, please contact Steve Gillespie at <a href="mailto:stephen.e.gillespie.mil@mail.mil" class="email">stephen.e.gillespie.mil@mail.mil</a> or Emma Schlagenhauff at <a href="mailto:emma.schlagenhauff.civ@mail.mil" class="email">emma.schlagenhauff.civ@mail.mil</a>.</li>
<li>This section was rendered using R version 3.6.0 (2019-04-26) on 18 Aug 2023.</li>
<li>The chapter is organized into sections that each include a description, a tutorial, and a problem set.</li>
</ul>
</div>
</div>
<div id="doe-overview" class="section level2">
<h2><span class="header-section-number">5.2</span> DOE Overview</h2>
<div id="what-is-design-of-experiments" class="section level3">
<h3><span class="header-section-number">5.2.1</span> What is Design of Experiments?</h3>
<p>The (statistical) design of experiments is the choice of tests for an experiment such that the resulting data may be analyzed using statistical methods in a valid, objective way. A well designed experiment can:</p>
<ul>
<li>Help researchers distinguish between causation and correlation.</li>
<li>Help researchers ensure they have covered an appropriate area of the “experimental space.”</li>
<li>Help researchers minimize the number of tests they need to run.</li>
<li>Help researchers model the nature of the relationship between their inputs and their outputs.</li>
</ul>
<p>To discuss DOE, we must introduce a few terms:</p>
<ul>
<li>Experiment: An experiment is a set of tests that are intended to answer some question about the relationship between inputs (i.e., factors) and outputs (i.e., responses).<br />
</li>
<li>Test: A test is an activity that one conducts to measure a response for some set of inputs. This may be physical (e.g., a chemical experiment), or in our case, a simulation. A test can be done with multiple replicates.</li>
<li>Factor: An input variable that may take two or more values (i.e., levels).</li>
<li>Level: The value a factor takes.</li>
<li>Treatment Combination: This is the set of inputs (i.e., factors) and their values (i.e., levels) that a test takes.</li>
<li>(Experimental or Design) Space: A theoretical space that is the set of all possible treatment combinations. This may be considered either within only the scope of the studied factors or the set of all theoretical factors. <font color = 'red'> <a href = ''> Read more about design and trade spaces here (TBP). </a> </font></li>
<li>Controllable or Uncontrollable: Factors may be controllable if their level may be varied at will by the experimenter. They are uncontrollable if they cannot be varied at will by the experimenter.</li>
<li>Nuisance Factor: A factor that has an impact on the outcome of a test, but is not something the experimenter is directly concerned with.</li>
</ul>
<p>This <a href = 'https://www.youtube.com/watch?v=-3ZBjmL_fME'> short video provides a nice overview on DOE.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<!--
Embed the EMS DOE Cartoon Video directly in site.
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-3ZBjmL_fME" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center><br>


Stuart Hunter video 1 of 2
<iframe width="560" height="315" src="https://www.youtube.com/embed/NoVlRAq0Uxs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Stuart Hunter video 2 of 2 
<iframe width="560" height="315" src="https://www.youtube.com/embed/hTviHGsl5ag" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

-->
<p>JMP<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> has two older videos of J. Stuart Hunter<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> introducing design of experiments: <a href = 'https://www.youtube.com/watch?v=NoVlRAq0Uxs'> Part I </a>, <a href = 'https://www.youtube.com/watch?v=hTviHGsl5ag'> Part II </a>. They are about 30 minutes total, but well worth watching.<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></p>
</div>
<div id="why-design-experiments" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Why Design Experiments?</h3>
<p>When discussing DOE, a natural question arises: why? There are at least three answers to this question:</p>
<p><strong>Analysis:</strong> Data and information do not equal knowledge. While all experiments will produce data, the question of whether or not that data can be transformed into knowledge is not a given. As one of the most common and powerful techniques for turning data into knowledge is statistics, data that has been acquired and structured such that it can be used by statistical tests and models is of much greater value than data that has not been.</p>
<p><strong>Breadth:</strong> Good experimental design helps one from inadvertently missing a significant portion of the experimental space and finding local extremes.</p>
<p><strong>Economy:</strong> Experiments are, among other things, expensive. They cost resources, time, and money. All other things being equal, the experiment that uses less, is done faster, and costs less but delivers the same, or a very close approximation to the same knowledge is better than a more resource-intensive, time consuming, and expensive one.</p>
<p><strong>Fun:</strong> Finally, designing experiments is fun! I’m not sure I can think of a better reason than that!</p>
<hr>
<p>Finally, one may say all of the above is well and good, but I’m doing computer simulation and computer simulations are fast and cheap. I should simply design an experiment to test all possibilities. Consider the following situation:</p>
<p>Imagine you are an analyst designing a system that has 100 parameters, e.g., the length of the system, or the system’s maximum range, etc. Further imagine that for each one of these parameters you have only two values, a high and a low. The set of all possibilities is therefore: <span class="math inline">\(2^{100} \approx 1.3 \times 10^{30}\)</span>.</p>
<p><span class="math inline">\(10^{30}\)</span> is a fantastically large number. Consider the age of the universe in seconds by comparison. The universe is approximately: 13.8 Billion years old.</p>
<p><span class="math display">\[13.8 \times 10^{9} years * 365 \frac{days}{year} * 24 \frac{hours}{day} * 60 \frac{minutes}{hour} * 60 \frac{seconds}{minute} \approx 4.4 \times 10^{17} seconds\]</span></p>
<p>Even if your computer simulation could run in a single second, you would still need <span class="math inline">\(\approx 2.9^{12}\)</span> simultaneous processes running to calculate all the possibilities for this system of the course of the universe’s lifespan. This of course assumes you have room for all of that data!</p>
<p>While this is an obviously extreme example to make a point, situations like this can easily exist, and we need strategies to deal with them appropriately. DOE provides us with a way.</p>
</div>
<div id="strategies-for-experimental-design" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Strategies for Experimental Design</h3>
<p>There are a number of strategies an analyst may take in designing experiments. Some have more merit than others.</p>
<ul>
<li><strong>Subject Matter Experts</strong>: One may rely on subject matter experts (SMEs) to choose the appropriate tests for an experiment. While one should always employ non-statistical knowledge in designing an experiment (this is a foremost principle), solely using SME judgment is generally a flawed approach. First, it assumes that one has the most appropriate expert for the study.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>. Of course, this is never quite true as one is generally conducting experiments to gain new knowledge and an SME has expertise in existing knowledge. Second, it assumes that the selected SME is without bias or other limitations.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>.</li>
<li><strong>One Factor at a Time</strong>: Another approach is to vary one factor at a time (OFAT). This is a more systematic approach than SME judgment, but it has several flaws. The most notable flaw is that it ignores the potential for interaction effects between two or more factors. Second, its success depends heavily on the initial fixed levels of the non-varying factors. J. Stuart Hunter covered the challenges well in his <a href = 'https://youtu.be/hTviHGsl5ag?t=364'>video (note this is the same as the video linked above, but starting at his discussion of OFAT)</a>. Of course, in good experimental design, we do need to vary the levels, so we will carry this forward.</li>
<li><strong>Random Design</strong>: Another strategy for experimentation may be to randomly choose the treatment combinations. This of course has the advantage that it reduces the potential for bias and allows for interactions. It has the problem, however, that it can introduce colinearity and does not guarantee an appropriate coverage of the experimental space. Of course, randomization is necessary for many statistical tests, so we will carry this forward.</li>
<li><strong>Statistical DOE</strong> Finally, we can look at statisitcal DOE as a strategy. In this strategy, we begin with the end in mind. That is, we design the experiment such that the results can be subject to appropriate analysis and maximize objectivity.</li>
</ul>
</div>
<div id="history-and-applications-of-experimental-design" class="section level3">
<h3><span class="header-section-number">5.2.4</span> History and Applications of Experimental Design</h3>
<p>Statistical experimental design traces its roots to <a href = 'https://en.wikipedia.org/wiki/Ronald_Fisher'> Sir Ronald Fisher </a> in the first half of the 20th century. This work focused primarily on applications to agriculture. It has subsequently been expanded on and developed by a many statisticians including George E.P. Box<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> among <a href = 'https://en.wikipedia.org/wiki/Design_of_experiments#Experimental_designs_after_Fisher'> others </a>.</p>
<p>Applications of DOE include:<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a></p>
<ul>
<li>Agriculture.</li>
<li>Biology.</li>
<li>Medicine.</li>
<li>Psychology.</li>
<li>Manufacturing.</li>
<li>Quality control.</li>
<li>Requirements and capability engineering.</li>
</ul>
<!-- may want to write more on this -->
</div>
<div id="principles" class="section level3">
<h3><span class="header-section-number">5.2.5</span> Principles</h3>
<p>Montgomery <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> (§ 1.3) offers three principles for experimental design: randomization, replication, and blocking. We will treat each in turn:</p>
<p><strong>Randomization:</strong> Randomization is generally necessary to avoid the introduction of dependency among the data. This is most often considered within the context of test order. For example, consider an experiment where the test is boiling temperature of various solutions. Boiling temperature is affected by the air pressure, and air pressure can vary even at a static location according to the weather. If one were conducting tests while the weather system changed, the tests would be affected. Randomizing helps us mitigate that variation when we cannot otherwise control for it. In the context of computer simulations we are in a fortunate situation in that we control this type of noise and so things like run order are not generally consequential for simulations.</p>
<p><strong>Replication:</strong> We typically need to replicate our tests, that is conduct the same test multiple times, so that we can get an estimate of the variability that occurs for a single level of the test such that we can estimate if differences observed are a function of a true distinction between two or more levels or simply a function of experimental error (note this is the same concept as discussed in the ANOVA chapter).</p>
<p><strong>Blocking:</strong> Finally, we can block to account for controllable, but undesired factors. That is, we can set groups of tests into relatively similar experimental conditions, so that we can focus on the effects of the factors we care about. Similar to the consideration of randomization, blocking is relatively easy for computer simulation. That stated, we may want to block in a computer simulation for factors that may arise in reality. For example, if we are designing a system, we may want to block on the scenario in which we place the system, as we can never fully know what scenario it may be used in.</p>
</div>
<div id="guidelines" class="section level3">
<h3><span class="header-section-number">5.2.6</span> Guidelines</h3>
<p>This course was purposefully titled, “The Design <em>and</em> Analysis of Experiments for Simulation” as we consider both the design of the experiment and the subsequent analysis equally important. We will attempt to follow a set of guidelines in designing experiments. These follow Montgomery’s <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> (§1.4) guidelines, though they are similar to many other problem defining / solving techniques, for example the Army’s TRAC’s Measurement Space methodology closely aligns to the first three steps of the guidelines. We will only cover a brief review of these guidelines, but recommend analysts read the full treatment in <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>.</p>
<p>There are seven guidelines for designing an experiment:</p>
<ol style="list-style-type: decimal">
<li>Recognition and statement of the problem.</li>
<li>Selection of the response variable.</li>
<li>Choice of factors, levels, and ranges.</li>
<li>Choice of experimental design.</li>
<li>Performing the experiment.</li>
<li>Statistical analysis of the data.</li>
<li>Conclusions and recommendations.</li>
</ol>
<p><strong>Steps 1-3:</strong> The first three steps can variously be called measurement space analysis, problem definition and scoping, or simply good critical thinking. In any event, they require a combination of subject matter expertise in 1) the nature and domain of the problem itself, 2) the nature and domain of the experiment. The actual statistical knowledge required for these steps is relatively minimal; however, it can help one categorize variables and the nature of what is possible within experimental design. In particular, one must consider design factors, held constant factors, nuissance factors (both controllable and uncontrollable), and response variables. Statistical knowledge also helps in determining the purpose of the study, whether it is to screen factors for effects or to help build detailed models for optimization. <strong>While these steps are vitally important, conducting them is situation, domain, and organization dependent. We will not cover them in great detail in this course.</strong></p>
<p><strong>Step 4:</strong> The world of experimental designs is not homogeneous. The choice of design is dependent on the nature of the varying factors (e.g., quantitative vs. qualitative), the desired response model, and the resources available to conduct the experiment. Similar to knowing a wide variety of hypothesis tests, understanding the set of possible designs and their various attributes is important such that analysts may choose the most appropriate design for their problem.</p>
<p><strong>Step 5:</strong> Actually performing the experiment is highly important. One must ensure it is conducted correctly and that the measured responses are both appropriate and measured correctly. Of course, performing the tests is highly domain dependent; accordingly, we will not cover how to build simulations in this course or conduct other tests. That stated, recall that it is important to validate that the tests were conducted correctly and that the data is accurate before moving on to subsequent steps.</p>
<p><strong>Steps 6-7:</strong> Finally, one must actually analyze the data, interpret the results, and provide recommendations. This analysis and its associated interpretation and recommendations are covered in later sections of this course. One important note, however, is that experimentation and the development of knowledge is iterative. The results of one experiment generally can and should inform future experiments.</p>
<p>Finally, recall the purpose of any study is generally to develop knowledge and inform a decision. As such, remember, <strong>do not let the math cloud your judgment.</strong> By that, we mean: ensure you bring your or your team’s non-statistical knowledge of the problem to bear; distinguish between statistical and practical significance; opt for a simplest design and analysis that sufficiently answers the question; recall that you are almost assuredly going to have to 1) explain your results to a non-statistician (or even non-quantitative person) and 2) defend your results as reasonable.</p>
</div>
<div id="problem-set-1" class="section level3">
<h3><span class="header-section-number">5.2.7</span> Problem Set</h3>
<p>There is no formal problem set for this section. That stated, think of a problem on which you have worked on or may work on and consider how the problem can be related to experimental design. Be prepared to discuss this in a group setting.</p>
<!--------------------------------------------------------------------------------------------------------------------------->
</div>
</div>
<div id="factorial-designs" class="section level2">
<h2><span class="header-section-number">5.3</span> Factorial Designs</h2>
<div id="introduction-3" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Introduction</h3>
<p>Factorial designs are some of the most common experimental designs out there and highly useful. In a sense we have already seen these with our discussions on ANOVA, so if this feels familiar that’s a good thing. The basic idea of a factorial design is as follows:</p>
<p>A researcher has identified two or more factors that can each take two or more levels (where the definition of factor and level are the same as in ANOVA). These factors and levels can be of any variety, quantitative, ordinal, qualitative, etc. We then take the Cartesian product of the sets of levels to produce all possible “treatment combinations.” A treatment combination is simply the set of levels for each factor for a given test. The cardinality of the set of treatment combinations for a factorial experiment is then simply the product of the cardinality of the set of levels for each factor.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></p>
<p>We can see this more concretely with an example. Consider a researcher who is designing a tank main gun and is considering two factors: the caliber, which may be set to either 105mm or 120m and the type of round used, which may be set to High Explosive (HE) or Armor Piercing (AP). In this case, we have:</p>
<ul>
<li>Two factors: Caliber (A) and Round (B).</li>
<li>Each factor has two levels:
<ul>
<li>A: 105mm or 120mm.</li>
<li>B: HE or AP.</li>
</ul></li>
<li>We have four treatment combinations:
<ul>
<li>105mm and HE ((1)).</li>
<li>120mm and HE (a).</li>
<li>105m and AP (b).</li>
<li>120mm and HE (ab).</li>
</ul></li>
<li>Note that by convention we typically indicate factors with capital letters and treatment combinations with lower case letters (more to follow on exactly how we do this).</li>
</ul>
<p>Often times, it is helpful to see this geometrically:</p>
<center>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
</center>
<p>This, of course, should familiar from the discussion of two factor ANOVA. Moreover we can generalize these concepts to any number of factors with any number of levels; however for the next several sections, we will limit our discussion to experiments where there are only two levels per factor, and, in the next section, to experiments with only two factors.</p>
<p>There are a few other concepts to recall (from our ANOVA discussion) before we move forward:</p>
<ul>
<li>Effect: A change in the response (i.e., your output) based on a change in the level of a factor.
<ul>
<li>Main Effect: This is the change in the response based on changing a single factor.</li>
<li>Interaction Effect: This is the change in the response based on changing two or more factors.</li>
</ul></li>
<li>Interaction: An interaction occurs when “the effect of one factor on the response depends on the levels of the others”. That is, the combined effects of two factors are not additive <span class="citation">Law (<a href="#ref-law2015">2015</a>)</span>.
<ul>
<li>Recall we can see this interaction effect visually. Consider the following plots that use the same scenario as above. Assume we have measured some response as indicated by the numbers in the geometric view:</li>
</ul></li>
</ul>
<center>
<!--
Personally, I [John] prefer this definition of interaction effects from Law (2015): interaction effects occur when "the effect of one factor on the response depends on the levels of the others". That is, the combined effects of two factors are not additive.

Steve's definition:  An interaction between two or more factors occurs when their interaction effect is non-zero.
-->
<p>Examle <strong>Without</strong> Interaction:</p>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Example <strong>With</strong> Interaction</p>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</center>
<p>As we have seen before, interaction is generally indicated through a change in the slope of the trace lines (i.e., the lines intersect). More concretely, we see this interaction being “non-additive” in the following sense:</p>
<ul>
<li>In the first example, we have two factors: Caliber and Round Type.
<ul>
<li>When we increase the caliber from 105mm to 120mm (and hold round constant) we have an effect of ~20, going from 20 to 40.</li>
<li>When we change the round from HE to AP (and hold caliber constant) we have an effect of ~10, going from 20 to 30.</li>
<li>When we change both the caliber and round, we have an effect of 32, going from 20 to 52.
<ul>
<li>We see very little interaction because we can explain the change in response of 32 by the change of each factor independently as 32 ~ 10 + 20.</li>
<li>We might say there is an interaction effect of 2 to explain the difference, but in reality, that is so small and subject to experimental error that we generally do not consider such small effects (we’ll make this more precise later).</li>
</ul></li>
</ul></li>
<li>In the second example, we have the same two factors:
<ul>
<li>When we increase the caliber from 105mm to 120mm (and hold round constant) we have an effect of ~30, going from 20 to 50.</li>
<li>When we change the round from HE to AP (and hold caliber constant) we have an effect of ~20, going from 20 to 40.</li>
<li>When we change both the caliber and round, we have an effect of ~-8 going from 20 to 12.
<ul>
<li>We cannot explain this change based solely on the effects of each individual factor, as we would assume, if there were no interaction effect between the round and caliber, we would assume a 120mm with AP would be our base level + the effect of caliber + the effect of round or 20 + 30 + 20 = 70.<br />
</li>
<li>Instead we see a large distinction between what we would expect and what we observed and that is the interaction effect of round and caliber at the levels 120mm and AP, of 70 - 12 = 58. We apparently have a large interaction effect.</li>
</ul></li>
</ul></li>
<li>Finally, note all the above numbers are indicated to get an intuitive understanding of interaction effects, we’ll make estimating effects more precise in a future section.</li>
</ul>
<p><strong>Coding Variables:</strong> There is a new concept to consider: coding variables.</p>
<p>We often find ourselves in situations where the levels of a factor can either not be described quantitatively or it is inconvenient to do so. In these cases, we often provide levels a coded, quantitative scale. Very commonly, we have experiments where we have a “low” and “high” level for each factor and we can code the levels as either:
* Low = -1 and High = 1.
* Low = 0 and High = 1.</p>
<p>This coding allows us to model non-quantitative levels and often makes the math easier for levels with quantitative, but unruly<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> levels.</p>
<p>We will discuss in future sections how we use this coding to model effects and understand different aspects of our designs.</p>
<p><strong>Advantages of Factorial Designs:</strong> Finally, it is important to consider why factorial designs are advantageous. There are at least two reasons:</p>
<ol style="list-style-type: decimal">
<li><strong>Breadth:</strong> A factorial experiment ensures that you test every combination. This ensures that you do not miss out on interaction effects as you may in an OFAT type strategy.</li>
<li><strong>Efficiency:</strong> While it might sound odd given that factorial experiments test every treatment combination exhaustively, one can gain some efficiency compared to other possible designs, e.g. an OFAT type design. This occurs from the need for replication:
<ul>
<li>Recall that to test the mean effect of a factor and account for experimental error, one must do at least two replicates for each level.<br />
</li>
<li>What is useful in a factorial experiment is that one does not necessarily have to test each treatment combination with multiple replicates, as one gets multiple data points for each level of a given factor across all the treatment combinations of which it is a member. For example, in the above scenario, one tests the effect of having a 120mm caliber main gun in both the ‘a’ and the ‘ab’ treatment combination.</li>
<li>There are further in depth arguments on this, but we will stop at this point. For further reading, see, e.g. <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> §5.2.</li>
</ul></li>
</ol>
<!--
### Estimating Effects

Up until this point in the course we have not discussed actually estimating the effects of a given factor.  Consider the example above where we were varying a tank main gun caliber and round type and had some results without interaction:

| A | B | Response | TC | TC |
|---|---|---|---|
|105mm|HE|20| $A^- B^-}$ | (1) |
|120mm|HE|40| $A^+ B^-}$ | a |
|105mm|AP|30| $A^- B^+$ | b | 
|120mm|AP|52| $A^+ B^+$ | ab |

Note that we have indicated the treatment combination by two different names, but they say the same thing.  One is in the format $Factor^{Level}$, where '-' for the level indicates the low level and '+' the high. The other is in the lower case letter format previously discussed.  They are equivalent, though the former format makes things more concrete.

We can estimate the effects of each factor by taking the average result whenever the factor is at its high level and subtracting that from the average result when the factor is at its low level.  For example:

* The effect of moving from $A^-$ to $A^+$ is:  $\frac{52 + 40}{2} - \frac{30 + 20}{2} = 21$
* The effect of moving from $B^-$ to $B^+$ is: $\frac{52 + 30}{2} - \frac{40 + 20}{2} = 11$
* The interaction effect is 52 - 20 + 21 + 11
-->
</div>
<div id="assessing-and-estimating-effects" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Assessing and Estimating Effects</h3>
<p>If much of the discussion has looked familiar, it should, as in our ANOVA section, we covered analyzing the output of factorial designs (even though we didn’t explicitly say that). Recall, for example, our two factor, fixed effects ANOVA effects model:</p>
<p><span class="math display">\[y_{ijk} = \mu + \tau_i + \beta_j + (\tau\beta)_{ij} + \epsilon_{ijk}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(y_{ijk}\)</span> is the response for the <span class="math inline">\(k^{th}\)</span> replicate of the <span class="math inline">\(i^{th}\)</span> level of Factor A and <span class="math inline">\(j^{th}\)</span> level of Factor B.</li>
<li><span class="math inline">\(\mu\)</span> is the overall mean.</li>
<li><span class="math inline">\(\tau_i\)</span> is the effect of Factor A at the <span class="math inline">\(i^{th}\)</span> level.</li>
<li><span class="math inline">\(\beta_j\)</span> is the effect of Factor B at the <span class="math inline">\(j^{th}\)</span> level.</li>
<li><span class="math inline">\((\tau\beta)_{ij}\)</span> is the interaction effect of Factors A and B at their respective levels.</li>
<li><span class="math inline">\(\epsilon_{ijk}\)</span> is the error associated with that response.</li>
</ul>
<p>Further recall that the sum of the treatments effects is 0 for all factors or interactions.</p>
<p>We can then conduct an ANOVA and multiple comparisons test (e.g., Tukey HSD) as conducted in the ANOVA section of this course. We may further extimate these effects using the following equations:</p>
<ul>
<li><span class="math inline">\(\hat{\mu} = \bar{y_{...}}\)</span>, i.e., the estimate for the mean effect is the mean of all observations.</li>
<li><span class="math inline">\(\hat{\tau_i} = \bar{y_{i..}} - \bar{y_{...}}\)</span>, i.e., the estimate for the effect of the <span class="math inline">\(i^{th}\)</span> level of Factor A is the mean for all observations at that level less the mean of all observations.</li>
<li><span class="math inline">\(\hat{\beta_j} = \bar{y_{.j.}} - \bar{y_{...}}\)</span>, i.e., the same as above but for Factor B.</li>
<li><span class="math inline">\(\hat{(\tau\beta)_{ij}} = \bar{y_{ij.}} - \bar{y_{i..}} - \bar{y_{.j.}} + \bar{y_{...}}\)</span>, i.e., the estimate for the interaction effect at the <span class="math inline">\(ij^{th}\)</span> level is the mean at that level less the means at only the <span class="math inline">\(i^{th}\)</span> and <span class="math inline">\(j^{th}\)</span> levels respectively plus the grand mean.</li>
<li>These derivations are shown in <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>.</li>
</ul>
<p>Note that the <span class="math inline">\(\hat{}\)</span> symbol indicates an estimated parameter, the <span class="math inline">\(\bar{}\)</span> indicates the mean of a set and <span class="math inline">\(y_{...}\)</span> indicates the observed value at the indicated levels where the first dot is for Factor A, the second for Factor B, and the third for the replicate. If there is a dot, it indicates across all levels of the factor or replicates. For example, <span class="math inline">\(\bar{y_{...}}\)</span> is the mean of all observations and <span class="math inline">\(\bar{y_{1..}}\)</span> is the mean for all observations where Factor A is on the first level.</p>
<p>We can do this more concretely with an example:</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb468-1" data-line-number="1"><span class="co"># We will use the weapon range data set from a previous two factor ANOVA homework</span></a>
<a class="sourceLine" id="cb468-2" data-line-number="2"><span class="co"># Recall there were two factors:</span></a>
<a class="sourceLine" id="cb468-3" data-line-number="3"><span class="co">#  Factor A was Weapon which could be 1, 2, or 3</span></a>
<a class="sourceLine" id="cb468-4" data-line-number="4"><span class="co">#  Factor B was range which could be 50, 150, or 200m</span></a>
<a class="sourceLine" id="cb468-5" data-line-number="5"><span class="co">#  The response was number of targets engaged</span></a>
<a class="sourceLine" id="cb468-6" data-line-number="6"><span class="co">#  There were 6 replciates for each combination</span></a>
<a class="sourceLine" id="cb468-7" data-line-number="7"></a>
<a class="sourceLine" id="cb468-8" data-line-number="8">weapon_range &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;../docsArchive/_Chapter3_1_ProblemSets/weapon_range.csv&#39;</span>)</a>
<a class="sourceLine" id="cb468-9" data-line-number="9">weapon_range<span class="op">$</span>Range &lt;-<span class="st"> </span><span class="kw">as.factor</span>(weapon_range<span class="op">$</span>Range)</a>
<a class="sourceLine" id="cb468-10" data-line-number="10">weapon_range<span class="op">$</span>Weapon &lt;-<span class="st"> </span><span class="kw">as.factor</span>(weapon_range<span class="op">$</span>Weapon)</a>
<a class="sourceLine" id="cb468-11" data-line-number="11"></a>
<a class="sourceLine" id="cb468-12" data-line-number="12"><span class="co"># In the previous homework, we had found that weapon, range, and their interaction were significant.</span></a>
<a class="sourceLine" id="cb468-13" data-line-number="13"><span class="co"># We can now estimate their parameters</span></a>
<a class="sourceLine" id="cb468-14" data-line-number="14"></a>
<a class="sourceLine" id="cb468-15" data-line-number="15"><span class="co"># this gives us our y_{...}</span></a>
<a class="sourceLine" id="cb468-16" data-line-number="16">grand.mean &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets)</a>
<a class="sourceLine" id="cb468-17" data-line-number="17"></a>
<a class="sourceLine" id="cb468-18" data-line-number="18"><span class="co"># We can calculate our means by subsetting the data frame to the levels we desire and following</span></a>
<a class="sourceLine" id="cb468-19" data-line-number="19"><span class="co"># the above equations</span></a>
<a class="sourceLine" id="cb468-20" data-line-number="20">tau<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets[weapon_range<span class="op">$</span>Weapon <span class="op">==</span><span class="st"> &#39;1&#39;</span>]) <span class="op">-</span><span class="st"> </span>grand.mean</a>
<a class="sourceLine" id="cb468-21" data-line-number="21">tau<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets[weapon_range<span class="op">$</span>Weapon <span class="op">==</span><span class="st"> &#39;2&#39;</span>]) <span class="op">-</span><span class="st"> </span>grand.mean</a>
<a class="sourceLine" id="cb468-22" data-line-number="22">tau<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets[weapon_range<span class="op">$</span>Weapon <span class="op">==</span><span class="st"> &#39;3&#39;</span>]) <span class="op">-</span><span class="st"> </span>grand.mean</a>
<a class="sourceLine" id="cb468-23" data-line-number="23">beta<span class="fl">.50</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets[weapon_range<span class="op">$</span>Range <span class="op">==</span><span class="st"> &#39;50&#39;</span>]) <span class="op">-</span><span class="st"> </span>grand.mean</a>
<a class="sourceLine" id="cb468-24" data-line-number="24">beta<span class="fl">.150</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets[weapon_range<span class="op">$</span>Range <span class="op">==</span><span class="st"> &#39;150&#39;</span>]) <span class="op">-</span><span class="st"> </span>grand.mean</a>
<a class="sourceLine" id="cb468-25" data-line-number="25">beta<span class="fl">.200</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(weapon_range<span class="op">$</span>Targets[weapon_range<span class="op">$</span>Range <span class="op">==</span><span class="st"> &#39;200&#39;</span>]) <span class="op">-</span><span class="st"> </span>grand.mean</a>
<a class="sourceLine" id="cb468-26" data-line-number="26"></a>
<a class="sourceLine" id="cb468-27" data-line-number="27"><span class="co"># There are 9 interaction levels, these are left as an exercise to the reader to calculate</span></a></code></pre></div>
<p>We then see:</p>
<ul>
<li><span class="math inline">\(\mu \approx 31.9\)</span></li>
<li><span class="math inline">\(\tau_1 \approx = -2.8\)</span></li>
<li><span class="math inline">\(\tau_2 \approx = 3.2\)</span></li>
<li><span class="math inline">\(\tau_3 \approx = -0.3\)</span></li>
<li><span class="math inline">\(\beta_{50} \approx = -1.4\)</span></li>
<li><span class="math inline">\(\beta_{150} \approx = 3.6\)</span></li>
<li><span class="math inline">\(\beta_{200} \approx = -2.2\)</span></li>
</ul>
<p>This of course, can extend to any number of factors, both in terms of the ANOVA and the estimation of effects.</p>
<p>We can also (and perhaps more commonly) model effects using regression, though we will reserve that discussion for our regression modeling chapter. This is generally called modeling a <strong>“response surface.”</strong> This is particularly useful when the levels are quantitative.</p>
</div>
<div id="blocking" class="section level3">
<h3><span class="header-section-number">5.3.3</span> Blocking</h3>
<p>We are now going to introduce the concept of a <strong>block.</strong> Recall that a factor is a variable input to one’s experiment, e.g., the choice of caliber or round in the example of the experiment for a main tank gun. These are factors of interest for us as experimenters. In some cases, there are what we call <strong>nuissance factors</strong>. These are factors that affect the outcome of a test, but are not of interest to us. Nuissance factors can be either <strong>uncontrollable</strong> or <strong>controllable.</strong></p>
<p><strong>Uncontrollable factors</strong> generally occur in physical experiments and are simply the vagaries of life - e.g. the exact amount of wind present or the exact level of humidity, etc. These are often very hard to control precisely. We attempt to avoid issues associated with this by randomly choosing the order for our experiments. We have encountered this in our ANOVA examples. Recall, for example, the single factor, fixed effects ANOVA problem where we considered the effect of soldier’s load on ruck march times. We randomized their starting order to account for the uncontrollable factors that may occur on a ruck march such as wind, temperature, etc.</p>
<p><strong>Controllable factors</strong> also occur in physical experiments, but are ones where we can choose the level of the nuissance factor. For example, if we had been testing soldier ruck march times over several days, we could have blocked by the day that a soldier conducted the experiment.</p>
<p>When we block, we assign replicates to a specific level of the controllable nuissance factor. For example, assume we were doing a physical test of shooting a new tank main gun at a physical target and we had two factors: caliber at either 105mm or 120mm and round at HE or AP. Further assume we had 3 rounds each type of material and we were testing the penetration by shooting at steel plates and had three steel plates that we could shoot at. We could cut each plate into 4 parts, randomly assign one of those parts to each of the treatment combinations, then shoot it and measure our result. We would then be blocking by metal sheet.</p>
<p>Generally when we block, we make an assumption that there is no interaction between the levels of the block and the factors of interest<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> We then do our analysis in a similar manner to everything we have done before, simply treating the block as a separate factor in our ANOVA and estimation fo the effects.</p>
<p><strong>Fortunately for simulation:</strong><a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> we can largely control everything. This is a great advantage of simulation when it comes to experimental design: many of the issues such as run order and blocking become moot. It is imporant to consider blocking and nuissance factors (e.g., scenarios), but the subsequent analysis ultimately becomes the same.</p>
<!-- I think this is important, but I don't know enough about it... Need to ask John 
### Number of Replications

The last question in a general factorial experiment is, "How many replicates should I do."  A snarky answer would be, do as many as you can afford.  That is, however, generally unuseful and uneconomical.  The more correct answer is dependent upon the required confidence in one's estimates.  

-->
</div>
<div id="problem-set-2" class="section level3">
<h3><span class="header-section-number">5.3.4</span> Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter4_ProblemSets/Factorial_Design_PS_Questions.html'> here </a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter4_ProblemSets/Factorial_Design_PS_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter4_ProblemSets/Factorial_Design_PS_Answer.html'> here </a>.</p>
</div>
</div>
<div id="k-factorial-design" class="section level2">
<h2><span class="header-section-number">5.4</span> <span class="math inline">\(2^K\)</span> Factorial Design</h2>
<div id="introduction-4" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Introduction</h3>
<p>Very often, we find ourselves working with a particular class of factorial designs we call <span class="math inline">\(2^K\)</span> Factorial designs. These are designs where we have <span class="math inline">\(K\)</span> factors, and each factor has two levels, typically called the low and the high level. As there are only two levels for each of the <span class="math inline">\(K\)</span> factors, there are <span class="math inline">\(2\times 2 \times 2 \times ... \times 2 = 2^K\)</span> treatment combinations in this design.</p>
<p><strong>Factors and Levels:</strong> In a <span class="math inline">\(2^K\)</span> design, we generally assume that the levels of each factor are fixed. Moreoever, we generally code the values as either <span class="math inline">\(\langle 0, 1 \rangle\)</span> or <span class="math inline">\(\langle -1, +1 \rangle\)</span>. This allows us to consider both purely quantitative measures (e.g., weapon caliber), qualitative measures (e.g., camoglauge color), or even groups of changes (e.g. scenario or entire units).</p>
<p><strong>Assumptions:</strong> We both assume and design the experiment such that the tests are independent and randomized (up to any blocking we choose) and that we meet the usual normality assumptions (as we have required for ANOVA). We further assume that the response to a factor is approximately linear (if it exists), as when we do our analysis, we can only interpolate in a linear manner between two points.</p>
<p><strong>Applications:</strong> Often <span class="math inline">\(2^K\)</span> designs are used in <strong>screening experiments</strong>. A screening experiment is an experiment in which one is attempting to simply understand which factors or combination of factors have an effect on the response in any fashion. Often times, experimenters do not know this <em>a priori</em> and simply being able to identify an effect without over-concern on the precision of its estimate allows one to select the most significant factors and then use a more fine-grained approach (i.e., a different design) to understanding the experimental space.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></p>
<p><strong>Limitations:</strong> Beyond any limitations associated with the assumptions, the major limitation to a <span class="math inline">\(2^K\)</span> design is that it is resource intensive and the requisite numbers of tests scales exponentially by <span class="math inline">\(K\)</span>. This means the number of factors you can consider scales logarithmically as a function of your maximum number of tests, i.e., if your maximum number of tests is <span class="math inline">\(N\)</span>, your maximum number of factors is of order <span class="math inline">\(log_2(N)\)</span>.</p>
</div>
<div id="coding-variables-and-effects-signs" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Coding Variables and Effects Signs</h3>
<p>As discussed in the section on general factorial designs, we often find it convenient to code variables to help us 1) understand something about the design itself, 2) represent categorical levels, and 3) “normalize” the values associated with the effects so that we can understand relative effects size. For the time being, we will represent our <span class="math inline">\(2^K\)</span> designs using <strong>orthogonal coding</strong> which is representing the low level as <code>-1</code> and the high level as <code>1</code>. First, consider how we can represent our <span class="math inline">\(2^K\)</span> design with this coding:</p>
<p>Consider a <span class="math inline">\(2^2\)</span> design. First, we build a table where the factors are listed as the columns. We then list the treatment combinations as the rows. The level for each factor is then shown as a +/- as we can see here:</p>
<center>
<table>
<thead>
<tr class="header">
<th>TC</th>
<th>A</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(1)</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>a</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>b</td>
<td>-1</td>
<td>1</td>
</tr>
<tr class="even">
<td>ab</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</center>
<p>This should look familiar from the previous section. Note that we adopt two conventions. The first is that we permute the levels of the factors in increasing order.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> That is, for our first factor, we vary the level every single time; i.e., the levels of A go -1, 1, -1, 1. For our second level, we vary the level every second time, i.e., the levels of B go -1, -1, 1, 1. If we had a third factor, we would vary the levels every 4th time, and so forth. The second convention is that we name the treatment combinations by the “product” of the lower case letter associated with the Factor in that treatment combination that is at the high level. That is, if we have A = -1 and B = 1, we name that treatment combination b. There is nothing sacrosanct about these conventions, but it is typical. The most important thing, of course, is to ensure that we capture every treatment combination correctly.</p>
<p>The next thing we often see is an additional column for the interaction effects. In our above example, this would mean we include the AB interaction as follows:</p>
<center>
<table>
<thead>
<tr class="header">
<th>TC</th>
<th>A</th>
<th>B</th>
<th>AB</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(1)</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
</tr>
<tr class="even">
<td>a</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>b</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>ab</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</center>
<p>You’ll note two things here. First, this does not add any additional treatment combinations, it merely adds a column for the interaction effect. Second, the value for the interaction effect is the product of the values for the factors that are interacting. For example: for treatment combination <span class="math inline">\((1)\)</span>, <span class="math inline">\(A = -1\)</span> and <span class="math inline">\(B = -1\)</span>, so <span class="math inline">\(AB = -1*-1 = 1\)</span>. Similarly, for treatment combination <span class="math inline">\(a\)</span>, <span class="math inline">\(A = 1\)</span> and <span class="math inline">\(B = -1\)</span>, so <span class="math inline">\(AB = 1*-1 = -1\)</span>. This helps us later in understanding ideas about orthoginality and contrast.</p>
<p>We can expand this concept to arbitrarily large <span class="math inline">\(K\)</span>. For example, consider <span class="math inline">\(K = 3\)</span>:</p>
<center>
<table>
<thead>
<tr class="header">
<th>TC</th>
<th>A</th>
<th>B</th>
<th>AB</th>
<th>C</th>
<th>AC</th>
<th>BC</th>
<th>ABC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(1)</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>a</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td>b</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>1</td>
</tr>
<tr class="even">
<td>ab</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>c</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
</tr>
<tr class="even">
<td>ac</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td>bc</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="even">
<td>abc</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</center>
<p>A note on <strong>orthogonality</strong>: an astute observer may notice something about the columns in these matrices. That is, the columns are <a href = 'https://en.wikipedia.org/wiki/Orthogonality'> orthogonal </a>. <a href = 'https://mathworld.wolfram.com/Orthogonal.html'> Orthoginality </a> is a general mathematical and physical concept that, in elementary geometry, orthoginality can be equated to perpendicularity. More generally, if we have two vectors of the same length, we say they are orthogonial if their dot product is 0. For example, in the above table, we see column ‘A’ as: $ A = -1, 1, -1, 1, -1, 1, -1, 1 $ and column ‘B’ as <span class="math inline">\(B = \langle -1, -1, 1, 1, -1, -1, 1, 1 \rangle\)</span>. Their dot product can be calculated either manually or in <em>R</em>:</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb469-1" data-line-number="1"><span class="co"># Define our two vectors</span></a>
<a class="sourceLine" id="cb469-2" data-line-number="2">A &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb469-3" data-line-number="3">B &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb469-4" data-line-number="4"></a>
<a class="sourceLine" id="cb469-5" data-line-number="5"><span class="co"># You can get the dot product in R in any number of ways.  Here are two:</span></a>
<a class="sourceLine" id="cb469-6" data-line-number="6"></a>
<a class="sourceLine" id="cb469-7" data-line-number="7"><span class="co"># You can sum the product of each vector multiplied element by element.</span></a>
<a class="sourceLine" id="cb469-8" data-line-number="8"><span class="kw">sum</span>(A<span class="op">*</span>B)</a></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb471-1" data-line-number="1"><span class="co"># You can use the matrix multiplication in base R of `%*%`.</span></a>
<a class="sourceLine" id="cb471-2" data-line-number="2">A<span class="op">%*%</span>B</a></code></pre></div>
<pre><code>##      [,1]
## [1,]    0</code></pre>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb473-1" data-line-number="1"><span class="co"># There are various packages that have a built in dot product function.</span></a>
<a class="sourceLine" id="cb473-2" data-line-number="2"><span class="co"># Of course, you can always define your own!</span></a></code></pre></div>
<p><a href = 'https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/doe/supporting-topics/basics/orthogonal-designs/'> Orthoginality is important in experimental design </a><a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> as it tells us something about the independence of the effects we are measuring. That is, if two factors or interaction of factors are orthogonal, we can estimate their effects independently. If they are not, we cannot estimate their effects as such. In a <span class="math inline">\(2^K\)</span> design, all of our factors and their interactions are orthogonal, so, if we have sufficient tests, we can estimate the effects independently.</p>
<p>Finally, note that these tables have several interesting properties:</p>
<ol style="list-style-type: decimal">
<li>The sum of any factor column is zero (e.g., in the above table, <span class="math inline">\(A = \langle -1, 1, -1, 1, -1, 1, -1, 1 \rangle\)</span>. One can easily verify that the sum of this column is 0.)</li>
<li>The element-by-element product of any two columns results in another column in the table. Specifically, it yields the column that is the product of the two factors where the exponent of each factor is assessed modulo 2. This is best seen with an example.
<ul>
<li>Consider <span class="math inline">\(A \times AB\)</span>. One “multiplies” the two names to get: <span class="math inline">\(A^2B^1\)</span>. We then take the exponent of A modulo 2 and see <span class="math inline">\(2 mod 2 = 0\)</span> and the exponent of B modulo 2 and see <span class="math inline">\(1 mod 2 = 1\)</span>, so we have: <span class="math inline">\(A^2B^1 = A^0B^1 = 1 \cdot B = B\)</span>.</li>
<li>We can confirm this: <span class="math inline">\(A = \langle -1, 1, -1, 1, -1, 1, -1, 1 \rangle\)</span>, <span class="math inline">\(AB = \langle 1, -1, -1, 1, 1, -1, -1, 1 \rangle\)</span> and the pairwise product of these two is: <span class="math inline">\(\langle -1*1, 1*-1, -1*-1, 1*1, -1*1, 1*-1, -1*-1, 1*1 \rangle = \langle -1, -1, 1, 1, -1, -1, 1, 1 \rangle = B\)</span>.</li>
</ul></li>
<li>We will sometimes include an identity column, <span class="math inline">\(I = \langle 1, 1, ... 1 \rangle\)</span> (i.e., all positives) that is not a factor, but allows for consistent multiplication.</li>
</ol>
</div>
<div id="estimating-effects-and-contrasts" class="section level3">
<h3><span class="header-section-number">5.4.3</span> Estimating Effects and Contrasts</h3>
<p>The point of an experimental design, of course, is to identify the effects of a factor <!--or?--> some interaction. We introduced a means to estimate effects in the general factorial design for two factors at any number of levels, we can generalize that here for <span class="math inline">\(K\)</span> factors at two levels. We will do this through the idea of contrasts. Let us consider an example:</p>
<p>Recall our tank main gun example from the previous section. We had Factor A as the round type, either HE or AP and Factor B as the caliber, either 105mm or 120mm. This is a <span class="math inline">\(2^2\)</span> design. Let HE and 105mm be the low levels and AP and 120mm be the high levels. We can visualize it as follows:</p>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Further assume we have been able conduct the experiment and run each test 3 times (i.e., <span class="math inline">\(n = 3\)</span> replicates) and we had the following results:</p>
<div id="htmlwidget-0745cf7bf4ee7f2147b9" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-0745cf7bf4ee7f2147b9">{"x":{"filter":"none","vertical":false,"data":[["(1)","(1)","(1)","a","a","a","ab","ab","ab","b","b","b"],["run.1","run.2","run.3","run.1","run.2","run.3","run.1","run.2","run.3","run.1","run.2","run.3"],["-1: HE","-1: HE","-1: HE","1: AP","1: AP","1: AP","1: AP","1: AP","1: AP","-1: HE","-1: HE","-1: HE"],["-1: 105mm","-1: 105mm","-1: 105mm","-1: 105mm","-1: 105mm","-1: 105mm","1: 120mm","1: 120mm","1: 120mm","1: 120mm","1: 120mm","1: 120mm"],[20,18,21,40,37,42,52,53,48,30,31,28]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>tc<\/th>\n      <th>Replicate<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>Response<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":4}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>We can visualize these results geometrically:</p>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We will take the convention here that (for a balanced design, i.e., we have the same number of replicates per treatment combination), the value of a treatment combination is the sum of the response of the treatment combination as assessed in each replicate. That is, for example, (1) = 59 because we assessed the response of (1) as 20, 18, and 21. We then say that the effect of a factor is the difference between the average response when the factor is at its high level and the average response when the factor is at its low level. This becomes very apparent in our notation, as we can say, for example the effect of is: <span class="math inline">\(A = \frac{ab + a}{2n} - \frac{b + (1)}{2n} = \frac{1}{2n}[ab + a - b - (1)]\)</span> where <span class="math inline">\(n\)</span> is the number of replicates and the values of <span class="math inline">\((1), a, b, and ab\)</span> are as indicated above.</p>
<p>In our example, we can then say that <span class="math inline">\(A = \frac{1}{2\cdot3} [153 + 119 - 89 - 59] \approx 20.7\)</span>. Similarly, we can say that <span class="math inline">\(B = \frac{1}{2\cdot3} [153 + 89 - 119 - 59] \approx 10.7\)</span> and $  [153 + 59 - 119 - 89] 0.7$.</p>
<p>You may notice two things about these equations:</p>
<ol style="list-style-type: decimal">
<li>The form (for a <span class="math inline">\(2&amp;K\)</span> design) of these factor effects is <span class="math inline">\(\frac{1}{2^{K-1} \cdot n} \times [Something]\)</span></li>
<li>That <span class="math inline">\([Something]\)</span> has a generally common form. Two things on this:
<ul>
<li>This is called the <strong>contrast</strong> for a given factor.</li>
<li>The value of the contrast is: <span class="math inline">\(\bf{tc} \cdot \bf{factor}\)</span>. Where, <span class="math inline">\(\bf{tc}\)</span> is the vector of values for the treatment combinations, e.g. <span class="math inline">\(\bf{tc} = \langle (1), a, b, ab \rangle = \langle 59, 119, 89, 153 \rangle\)</span> (in the above example) and <span class="math inline">\(\bf{factor}\)</span> is the vector of +/-1 associated with that factor’s treatment combinations, e.g., <span class="math inline">\(A = \langle -1, 1 -1, 1 \rangle\)</span> in the above example. We generally call this <span class="math inline">\(Contrast_{Factor}\)</span>, e.g. <span class="math inline">\(Contrast_A = -1 \cdot 59 + 1 \cdot 119 + -1 \cdot 89 + 1 \cdot 153 = 124\)</span>.</li>
</ul></li>
</ol>
<p>Given this set up, it’s relatively easy to calculate contrasts using a data frame, for example:</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb474-1" data-line-number="1"><span class="co"># Define our data frame</span></a>
<a class="sourceLine" id="cb474-2" data-line-number="2">myDF  &lt;-<span class="st"> </span>myDF &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">A =</span> (<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>)), <span class="dt">B =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>), <span class="dt">tc =</span> <span class="kw">c</span>(<span class="st">&#39;(1)&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;a&#39;</span>, <span class="st">&#39;ab&#39;</span>), <span class="dt">run.1 =</span> <span class="kw">c</span>(<span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">52</span>), <span class="dt">run.2 =</span> <span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">31</span>, <span class="dv">37</span>, <span class="dv">53</span>), <span class="dt">run.3 =</span> <span class="kw">c</span>(<span class="dv">21</span>, <span class="dv">28</span>, <span class="dv">42</span>, <span class="dv">48</span>))</a>
<a class="sourceLine" id="cb474-3" data-line-number="3"></a>
<a class="sourceLine" id="cb474-4" data-line-number="4"><span class="co"># Modify the data to add the AB column and sum the runs; drop unnecessary additional info and order the data</span></a>
<a class="sourceLine" id="cb474-5" data-line-number="5">myDF &lt;-<span class="st"> </span>myDF <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Run.Total =</span> run<span class="fl">.1</span> <span class="op">+</span><span class="st"> </span>run<span class="fl">.2</span> <span class="op">+</span><span class="st"> </span>run<span class="fl">.3</span>, <span class="dt">AB =</span> A<span class="op">*</span>B) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(tc, A, B, AB, Run.Total)</a>
<a class="sourceLine" id="cb474-6" data-line-number="6">myDF</a></code></pre></div>
<pre><code>##    tc  A  B AB Run.Total
## 1 (1) -1 -1  1        59
## 2   b -1  1 -1        89
## 3   a  1 -1 -1       119
## 4  ab  1  1  1       153</code></pre>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb476-1" data-line-number="1"><span class="co"># We can then calculate the contrasts:</span></a>
<a class="sourceLine" id="cb476-2" data-line-number="2">Contrast.A =<span class="st"> </span><span class="kw">sum</span>(myDF<span class="op">$</span>A <span class="op">*</span><span class="st"> </span>myDF<span class="op">$</span>Run.Total)</a>
<a class="sourceLine" id="cb476-3" data-line-number="3">Contrast.B =<span class="st"> </span><span class="kw">sum</span>(myDF<span class="op">$</span>B <span class="op">*</span><span class="st"> </span>myDF<span class="op">$</span>Run.Total)</a>
<a class="sourceLine" id="cb476-4" data-line-number="4">Contrast.AB =<span class="st"> </span><span class="kw">sum</span>(myDF<span class="op">$</span>AB <span class="op">*</span><span class="st"> </span>myDF<span class="op">$</span>Run.Total)</a>
<a class="sourceLine" id="cb476-5" data-line-number="5"></a>
<a class="sourceLine" id="cb476-6" data-line-number="6">Contrast.A</a></code></pre></div>
<pre><code>## [1] 124</code></pre>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb478-1" data-line-number="1">Contrast.B</a></code></pre></div>
<pre><code>## [1] 64</code></pre>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb480-1" data-line-number="1">Contrast.AB</a></code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb482-1" data-line-number="1"><span class="co"># Further, we can then show the effects:</span></a>
<a class="sourceLine" id="cb482-2" data-line-number="2">Contrast.A <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span><span class="op">*</span><span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 20.66667</code></pre>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb484-1" data-line-number="1">Contrast.B <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span><span class="op">*</span><span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 10.66667</code></pre>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb486-1" data-line-number="1">Contrast.AB <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span><span class="op">*</span><span class="dv">3</span>)</a></code></pre></div>
<pre><code>## [1] 0.6666667</code></pre>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb488-1" data-line-number="1"><span class="co"># This of course matches what we showed above</span></a></code></pre></div>
<p>There is further a nice relationship between these contrasts and the Sum of Squares that you see on an ANOVA table. That is, the sum of squares for a factor F is: <span class="math inline">\(SS_F = \frac{Contrast_F^2}{2^K \cdot n}\)</span>. We can see this explicitly with our above example</p>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## A            1 1281.3  1281.3 284.741 1.54e-07 ***
## B            1  341.3   341.3  75.852 2.36e-05 ***
## A:B          1    1.3     1.3   0.296    0.601    
## Residuals    8   36.0     4.5                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>And using the contrasts we see:</p>
<ul>
<li><span class="math inline">\(SS_A = \frac{Contrast_A^2}{2^2 \cdot 3} = 1281.3333333\)</span></li>
<li><span class="math inline">\(SS_B = \frac{Contrast_B^2}{2^2 \cdot 3} = 341.3333333\)</span></li>
<li><span class="math inline">\(SS_{AB} = \frac{Contrast_{AB}^2}{2^2 \cdot 3} = 1.3333333\)</span></li>
</ul>
<p>These numbers of course match the numbers we see in our ANOVA table. In our ANOVA discussion, we did not dive deeply into the discussion of sum of squares, but in general its useful to note that, all things being equal, if one has a larger sum of squares, one will have a relatively larger F Value which implies a lower p-value which implies the factor is more significant. This is a long way of saying a larger contrast implies greater statistical significance.</p>
<p>While both contrast and the sum of squares gives one an idea on the magnitude of the effect, contrast also provides an idea of the direction of the effect that sum of squares does not (as it is always positive). If a contrast is positive, the effect of moving from the low level to the high level is positive; conversely, if it is negative, the effect of moving from the low level to the high level is negative.</p>
</div>
<div id="unreplicated-2k-designs" class="section level3">
<h3><span class="header-section-number">5.4.4</span> Unreplicated <span class="math inline">\(2^K\)</span> Designs</h3>
<p>Often we find that we only have the ability to conduct a single replicate of a <span class="math inline">\(2^K\)</span> design (especially as <span class="math inline">\(K\)</span> grows). As has been noted before, there are two major challenges to an unreplicated design. First, it does not provide us enough degrees of freedom to assess the residual standard error and thus insufficient degrees of freedom to conduct an ANOVA against every factor and every interaction. Second, there is a possibility that we may erroneously assess a factor as significant or not due to the noise inherent in each test. We can address these problems in several ways.</p>
<p><strong>Choice of levels</strong>: Montgomery <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> recommends an “aggressive” spacing in levels. That is, we are less likely to make errors due to response variation if the levels are far apart. This is best seen graphically (recreated from <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>):</p>
<center>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</center>
<p>As we can see, in both cases, the measured response was slightly greater than the true response at the low level and slightly lower than the true response at the higher level. However, in the left graph, with a distance between the levels less than our response error, we can see that it is possible to get test results that indicate no effect of the factor (i.e., a response with zero slope) as indicated by the purple line. Conversely, with a larger distance between the levels, while we will not perfectly model the effect, we will be significantly more accurate and less likely to make an error.</p>
<p><strong>Sparsity of Effects Principle</strong>: Another approach to assessing unreplicated designs is to make a (generally reasonable) assumption that higher order (e.g., third+ level) interactions are negligible. This, in effect, provides more degrees of freedom for estimating error and thus the significance of main and lower order interaction effects. While there is no mathematical reason why higher order interactions may be insignficant, this is a commonly used heuristic that has been found to hold up in a variety of situations.</p>
<p><strong>Normal Probability Plot:</strong> Normal probability plots have been used to identify factors that are significant, with the idea that the points that are off of the “normal line” likely have non-zero effect. <a href = 'http://www.stat.yale.edu/Conferences/Stats2009/GOSLIDES.pdf'> This presentation </a> discusses in greater detail this methodology. You can also read more about this in <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> §6.5.</p>
<p><strong>Projection of Design:</strong> In an unreplicated design, it is likely that after some initial analysis, you may identify one or more factors that have approximately zero effect. If you do find this, you can disregard the factor with no effect and subsequently “gain replicates.” For example, consider an unreplicated <span class="math inline">\(2^3\)</span> design with Factors A, B, and C. You initially have the following design:</p>
<table>
<thead>
<tr class="header">
<th>A</th>
<th>B</th>
<th>C</th>
<th>TC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>(1)</td>
</tr>
<tr class="even">
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>a</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>b</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>-1</td>
<td>ab</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>c</td>
</tr>
<tr class="even">
<td>1</td>
<td>-1</td>
<td>1</td>
<td>ac</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>1</td>
<td>1</td>
<td>bc</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>1</td>
<td>abc</td>
</tr>
</tbody>
</table>
<p>Now imagine you have identified C as not having an effect. You can then consider that any treatment combination with a c as an additional replicate for that “residual treatment combination.” For example, ac can now be considered as a replicate of a.</p>
<table>
<thead>
<tr class="header">
<th>A</th>
<th>B</th>
<th>C</th>
<th>TC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>(1)</td>
</tr>
<tr class="even">
<td>1</td>
<td>-1</td>
<td>-1</td>
<td>a</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>1</td>
<td>-1</td>
<td>b</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>-1</td>
<td>ab</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>c</td>
</tr>
<tr class="even">
<td>1</td>
<td>-1</td>
<td>1</td>
<td>ac</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>1</td>
<td>1</td>
<td>bc</td>
</tr>
<tr class="even">
<td>1</td>
<td>1</td>
<td>1</td>
<td>abc</td>
</tr>
</tbody>
</table>
<p>You now have an additional replicate to do more thorough analysis.</p>
<p><strong>Normal Probability Plots</strong>: In unreplicated designs, it is possible that we may see significant effects from higher order interactions. One way to identify these is through the use of normal probability plots. We have seen these when analyzing residuals in an ANOVA; you can read more about them <a href = 'https://www.itl.nist.gov/div898/handbook/eda/section3/normprpl.htm'> here (NIST Engineering Statistics Handbook) </a>. The key difference here is that we are plotting the effects we have observed from an experiment, not residuals. The assumption we are making with this analysis is that if effects are non-signfiicant, they are generally small, average to zero, and any variation is due to random, normal variation. Therefore, any effects that fall outside of what would be expected with this distribution are significant. That is, any points on the plot that fall off of the straight line. We can see this using <em>R</em>:</p>
<p>Consider a <span class="math inline">\(2^4\)</span> experiment that had the following effects (data taken from <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>, Example 6.2):</p>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb490-1" data-line-number="1">myDF &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Factor =</span> <span class="kw">c</span>(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>, <span class="st">&#39;C&#39;</span>, <span class="st">&#39;D&#39;</span>, <span class="st">&#39;AB&#39;</span>, <span class="st">&#39;AC&#39;</span>, <span class="st">&#39;AD&#39;</span>, <span class="st">&#39;BC&#39;</span>, <span class="st">&#39;BD&#39;</span>, <span class="st">&#39;CD&#39;</span>, <span class="st">&#39;ABC&#39;</span>, <span class="st">&#39;ABD&#39;</span>, <span class="st">&#39;ACD&#39;</span>, <span class="st">&#39;BCD&#39;</span>, <span class="st">&#39;ABCD&#39;</span>),</a>
<a class="sourceLine" id="cb490-2" data-line-number="2">                   <span class="dt">Effect =</span> <span class="kw">c</span>(<span class="fl">21.625</span>, <span class="fl">3.125</span>, <span class="fl">9.875</span>, <span class="fl">14.625</span>, <span class="fl">0.125</span>, <span class="fl">-18.125</span>, <span class="fl">16.625</span>, <span class="fl">2.375</span>, <span class="fl">-.375</span>, <span class="fl">1.125</span>, <span class="fl">1.875</span>, <span class="fl">4.125</span>, <span class="fl">-1.625</span>, <span class="fl">-2.625</span>, <span class="fl">1.375</span>))</a>
<a class="sourceLine" id="cb490-3" data-line-number="3">DT<span class="op">::</span><span class="kw">datatable</span>(myDF, <span class="dt">rownames =</span> F, <span class="dt">options =</span> <span class="kw">list</span>(<span class="dt">pageLength =</span> <span class="dv">16</span>))</a></code></pre></div>
<div id="htmlwidget-d1c9c5fa7747be886055" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-d1c9c5fa7747be886055">{"x":{"filter":"none","vertical":false,"data":[["A","B","C","D","AB","AC","AD","BC","BD","CD","ABC","ABD","ACD","BCD","ABCD"],[21.625,3.125,9.875,14.625,0.125,-18.125,16.625,2.375,-0.375,1.125,1.875,4.125,-1.625,-2.625,1.375]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Factor<\/th>\n      <th>Effect<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":16,"columnDefs":[{"className":"dt-right","targets":1}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[10,16,25,50,100]},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>We can look at this and certainly say some of the effects are significant, for example, <span class="math inline">\(A\)</span> has the largest effect and is signficantly larger than most (in absolute value). Conversely, <span class="math inline">\(AB\)</span> has an effect that is almost 0 and is almost certainly not significant. The question is where is the cut off for significant. For example, one would certainly include <span class="math inline">\(AD\)</span> and <span class="math inline">\(D\)</span> as significant, but then, what about <span class="math inline">\(C\)</span>, or do we continue to <span class="math inline">\(ABD\)</span>? It is easier to visualize this data with a normal probability plot. One way we can do this is with <code>qqnorm</code>:</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb491-1" data-line-number="1"><span class="co"># Use the functions qqnorm and qqline to produce a normal probability plot</span></a>
<a class="sourceLine" id="cb491-2" data-line-number="2"><span class="co"># Note, various texts will use differing forms of this plot, but the results</span></a>
<a class="sourceLine" id="cb491-3" data-line-number="3"><span class="co"># are functionally the same</span></a>
<a class="sourceLine" id="cb491-4" data-line-number="4"><span class="kw">qqnorm</span>(myDF<span class="op">$</span>Effect)</a>
<a class="sourceLine" id="cb491-5" data-line-number="5"><span class="kw">qqline</span>(myDF<span class="op">$</span>Effect)</a></code></pre></div>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<div class="sourceCode" id="cb492"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb492-1" data-line-number="1"><span class="co"># This shows us there are several points that are significant</span></a>
<a class="sourceLine" id="cb492-2" data-line-number="2"><span class="co"># Unfortunately, this does not actually label the points for us</span></a>
<a class="sourceLine" id="cb492-3" data-line-number="3"></a>
<a class="sourceLine" id="cb492-4" data-line-number="4"><span class="co"># We can add labels (in probably many ways, this is just one):</span></a>
<a class="sourceLine" id="cb492-5" data-line-number="5"></a>
<a class="sourceLine" id="cb492-6" data-line-number="6"><span class="co"># First, calculate the qqnorm x and y coordinates and save as &quot;points&quot;</span></a>
<a class="sourceLine" id="cb492-7" data-line-number="7"><span class="co"># The argument plot.it = F, prevents the qqnorm from plotting an additional plot</span></a>
<a class="sourceLine" id="cb492-8" data-line-number="8">points &lt;-<span class="st"> </span><span class="kw">qqnorm</span>(myDF<span class="op">$</span>Effect, <span class="dt">plot.it =</span> F)</a>
<a class="sourceLine" id="cb492-9" data-line-number="9"></a>
<a class="sourceLine" id="cb492-10" data-line-number="10"><span class="co"># Next plot the same plot as before</span></a>
<a class="sourceLine" id="cb492-11" data-line-number="11"><span class="kw">qqnorm</span>(myDF<span class="op">$</span>Effect, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">20</span>, <span class="dv">25</span>)) <span class="co"># modify the y limit to see all labels</span></a>
<a class="sourceLine" id="cb492-12" data-line-number="12"><span class="kw">qqline</span>(myDF<span class="op">$</span>Effect)</a>
<a class="sourceLine" id="cb492-13" data-line-number="13"><span class="co"># add text where the labels are plotted at the corresponding points</span></a>
<a class="sourceLine" id="cb492-14" data-line-number="14"><span class="co"># of the qqnorm.  Note, qqnorm preserves the order of the orginal data</span></a>
<a class="sourceLine" id="cb492-15" data-line-number="15"><span class="co"># to avoid some overlap, add a small delta to the y coordinate</span></a>
<a class="sourceLine" id="cb492-16" data-line-number="16"><span class="kw">text</span>(points<span class="op">$</span>x, points<span class="op">$</span>y <span class="op">+</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">labels =</span> myDF<span class="op">$</span>Factor)</a></code></pre></div>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb493-1" data-line-number="1"><span class="co"># This lets us clearly see that A, AD, D, C, and AC are significant factors </span></a>
<a class="sourceLine" id="cb493-2" data-line-number="2"></a>
<a class="sourceLine" id="cb493-3" data-line-number="3"></a>
<a class="sourceLine" id="cb493-4" data-line-number="4"><span class="co"># Sometimes people prefer to flip the axes so that the effect is seen on the x axis</span></a>
<a class="sourceLine" id="cb493-5" data-line-number="5"><span class="co"># you can simply use the datax = T argument for qqnorm and qqline</span></a>
<a class="sourceLine" id="cb493-6" data-line-number="6"><span class="co"># Note that you can also change labels, and so forth using various arguments</span></a>
<a class="sourceLine" id="cb493-7" data-line-number="7"><span class="co"># but this is functionally the same sort of plotting as above</span></a>
<a class="sourceLine" id="cb493-8" data-line-number="8">points &lt;-<span class="st"> </span><span class="kw">qqnorm</span>(myDF<span class="op">$</span>Effect, <span class="dt">datax =</span> T, <span class="dt">plot.it =</span> F)</a>
<a class="sourceLine" id="cb493-9" data-line-number="9"><span class="kw">qqnorm</span>(myDF<span class="op">$</span>Effect, <span class="dt">datax =</span> T, <span class="dt">ylab =</span> <span class="st">&#39;Effect&#39;</span>) <span class="co"># Note the labeling on this does not presume the flipped axis</span></a>
<a class="sourceLine" id="cb493-10" data-line-number="10"><span class="kw">qqline</span>(myDF<span class="op">$</span>Effect, <span class="dt">datax =</span> T)</a>
<a class="sourceLine" id="cb493-11" data-line-number="11"><span class="kw">text</span>(points<span class="op">$</span>x, points<span class="op">$</span>y <span class="op">+</span><span class="st"> </span><span class="fl">.15</span>, <span class="dt">labels =</span> myDF<span class="op">$</span>Factor)</a></code></pre></div>
<p><img src="04-DOE_Fundamentals_files/figure-html/unnamed-chunk-13-3.png" width="672" /></p>
<div class="sourceCode" id="cb494"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb494-1" data-line-number="1"><span class="co"># If one prefers to have more control over the graph, one can do this in ggplot either by making a dataframe out of the </span></a>
<a class="sourceLine" id="cb494-2" data-line-number="2"><span class="co"># given data or using stat_qq</span></a>
<a class="sourceLine" id="cb494-3" data-line-number="3"><span class="co"># This stack exachange discussion is highly useful:</span></a>
<a class="sourceLine" id="cb494-4" data-line-number="4"><span class="co"># https://stackoverflow.com/questions/14958814/how-can-i-label-the-points-of-a-quantile-quantile-plot-composed-with-ggplot2</span></a></code></pre></div>
<p>One can also do a half-normal probability plot in a similar manner. One can read about it <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section5/pri598.htm'> here </a>. The main difference is that we are plotting the absolute values of effects.</p>
</div>
<div id="problem-set-3" class="section level3">
<h3><span class="header-section-number">5.4.5</span> Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter4_ProblemSets/2K_Factorial_Design_PS_Question.html'> here </a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter4_ProblemSets/2K_Factorial_Design_PS_Question.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter4_ProblemSets/2K_Factorial_Design_PS_Answer.html'> here </a>.</p>
<!--chapter:end:04-DOE_Fundamentals.Rmd-->
</div>
</div>
</div>
<div id="fractional-factorial-designs" class="section level1">
<h1><span class="header-section-number">6</span> Fractional Factorial Designs</h1>
<!-- SEG Colinearity, vif,  & fractional, blocking, aliasing confounding, replication-->
<div id="introduction-5" class="section level2">
<h2><span class="header-section-number">6.1</span> Introduction</h2>
<div id="admin-2" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Admin</h3>
<p>For any errors associated with this section, please contact Steve Gillespie at <a href="mailto:stephen.e.gillespie.mil@mail.mil" class="email">stephen.e.gillespie.mil@mail.mil</a> or Emma Schlagenhauff at <a href="mailto:emma.schlagenhauff.civ@mail.mil" class="email">emma.schlagenhauff.civ@mail.mil</a>.</p>
<p>This chapter was published using the following software:</p>
<ul>
<li>R version 3.6.0 (2019-04-26).</li>
<li>On x86_64-pc-linux-gnu (64-bit) running Ubuntu 18.04.2 LTS.</li>
<li>Packages are explicitly shown in the code snippets with the exception of the <code>tidyverse</code> version 1.3.0.</li>
</ul>
</div>
<div id="overview" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Overview</h3>
<p>Often, doing a full factorial design, even a <span class="math inline">\(2^K\)</span> design is too resource intensive making that choice of an experimental design either impractical or impossible. However, at the trade-off of a slight loss of fidelity in our understanding of the nature of the effects<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a>, we can learn much about our system (i.e., the relationship between factors and responses) with significantly fewer tests by choosing to test only certain treatment combinations in a smart way (i.e., a way that allows for good subsequent statistical analysis). The way we make and analyze these designs, their appropriate use, and their relative merits is how we will spend much of the remainder of this course.</p>
<p>One common and powerful class of designs are “fractional factorial” designs. These are designs where we only take some portion of all the treatment combinations available for a full factorial design. In particular, we are going to look at <span class="math inline">\(2^{K-P}\)</span> designs, where we consider some <span class="math inline">\(\frac{1}{2^P}\)</span> fraction of a <span class="math inline">\(2^K\)</span> design. These types of designs are highly useful for screening experiments with a large number of factors.</p>
</div>
</div>
<div id="frac12-fractional-factorial-design-2k-1" class="section level2">
<h2><span class="header-section-number">6.2</span> <span class="math inline">\(\frac{1}{2}\)</span> Fractional Factorial Design (<span class="math inline">\(2^{K-1}\)</span>)</h2>
<p>Note, this section may be accompanied by reading from Montgomery’s §8.2 <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> or the <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section3/pri3.htm'> NIST Engineering Statistics Handbook §3.4 </a>.</p>
<div id="motivation-and-example" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Motivation and Example</h3>
<p>Assume you are running a high fidelity, physics based simulation to assess a tank’s survivability. You are varying three factors, the armor thickness (A), the material (B), and the slope of the armor (C). You have assigned each two levels, a high and a low. You had initially planned to do a full factorial design and assess all eight treatment combinations. Unfortunately, high fidelity, physics based simulations are resource intensive and your boss cut your budget and timeline in half. You can now only run four tests. The question is, which four do you choose.</p>
<p>Recall your original run matrix and the table of effects and interaction effects:</p>
<div id="htmlwidget-8f51fd287df49d77a7f8" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-8f51fd287df49d77a7f8">{"x":{"filter":"none","vertical":false,"data":[["(1)","a","b","ab","c","ac","bc","abc"],[1,1,1,1,1,1,1,1],[-1,1,-1,1,-1,1,-1,1],[-1,-1,1,1,-1,-1,1,1],[1,-1,-1,1,1,-1,-1,1],[-1,-1,-1,-1,1,1,1,1],[1,-1,1,-1,-1,1,-1,1],[1,1,-1,-1,-1,-1,1,1],[-1,1,1,-1,1,-1,-1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>Note that:</p>
<ol style="list-style-type: decimal">
<li>Every factor effect or interaction effect is distinct from every other. Specifically, they are orthogonal to eachother.</li>
<li>We are including every treatment combination.</li>
</ol>
<p>Unfortunately, as we can only run four tests, we must choose only four of the treatment combinations. The question is which ones. One option might be to just choose the first four:</p>
<div id="htmlwidget-cc6b06d0eaf25f8eefd2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-cc6b06d0eaf25f8eefd2">{"x":{"filter":"none","vertical":false,"data":[["(1)","a","b","ab"],[1,1,1,1],[-1,1,-1,1],[-1,-1,1,1],[1,-1,-1,1],[-1,-1,-1,-1],[1,-1,1,-1],[1,1,-1,-1],[-1,1,1,-1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>This is not a good choice. As we can see by inspection, we never assess C at its high level, so we cannot learn anything about what happens as we vary C.</p>
<p>Alternatively, we might choose the tests randomly, for example, we might get:</p>
<div id="htmlwidget-bc3b604e7efc4711666e" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-bc3b604e7efc4711666e">{"x":{"filter":"none","vertical":false,"data":[["(1)","abc","c","ab"],[1,1,1,1],[-1,1,-1,1],[-1,1,-1,1],[1,1,1,1],[-1,1,1,-1],[1,1,-1,-1],[1,1,-1,-1],[-1,1,1,-1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>It is perhaps a little less clear, but we might note that we never vary the AB interaction as we see all “+1” in that column. This is because we can see that A and B are always set to the same level for each treatment combination. The implication of this is that we won’t know if an observed effect is caused by a or caused by B.</p>
<p>To an extent, the challenges we see are inherent in this type of problem. By limiting ourselves to some fraction of the full factorial set of treatment combinations, we <em>are</em> going to lose some information, but losing all information about C or information about A and B independently of each other is not generally a good choice. To choose the fraction of treatment combinations smartly, we rely on design <em>generators</em>.</p>
</div>
<div id="design-generator" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Design Generator</h3>
<p>Consider the option where we choose only those treatment combinations where ABC = +1:</p>
<div id="htmlwidget-d21dede461e700c774b4" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-d21dede461e700c774b4">{"x":{"filter":"none","vertical":false,"data":[["a","b","c","abc"],[1,1,1,1],[1,-1,-1,1],[-1,1,-1,1],[-1,-1,1,1],[-1,-1,1,1],[-1,1,-1,1],[1,-1,-1,1],[1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>Now, as we look at this, we can note a few things:</p>
<ul>
<li>With the exception of ABC and I, every column has exactly two +1 and two -1.</li>
<li>Columns A, B, and C are orthogonal to each other (proof left to the reader).</li>
<li>Some of the columns are identical to each other. Specifically:
<ul>
<li>A = BC</li>
<li>B = AC</li>
<li>C = AB</li>
<li>I = ABC</li>
</ul></li>
</ul>
<p>We can make this explicit with some color:</p>
<div id="htmlwidget-a765aa2ce38f7dae043a" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-a765aa2ce38f7dae043a">{"x":{"filter":"none","vertical":false,"data":[["a","b","c","abc"],[1,1,1,1],[1,-1,-1,1],[-1,1,-1,1],[-1,-1,1,1],[-1,-1,1,1],[-1,1,-1,1],[1,-1,-1,1],[1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data, displayNum, displayIndex, dataIndex) {\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background-color':'red'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'background-color':'red'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'background-color':'blue'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'background-color':'blue'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'background-color':'green'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'background-color':'green'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'background-color':'yellow'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'background-color':'yellow'});\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-weight':'bold'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-weight':'bold'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'font-weight':'bold'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'font-weight':'bold'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'font-weight':'bold'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'font-weight':'bold'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'font-weight':'bold'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'font-weight':'bold'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'font-weight':'bold'});\n}"},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<p>What we have done now, is not avoided the problems shown above, but mitigated them. Specifically, we have done a few things:</p>
<ul>
<li>We have chosen <span class="math inline">\(ABC\)</span> as the <strong>generator</strong> for our design.<br />
</li>
<li>This is equivalent to saying that <span class="math inline">\(I = ABC\)</span> is the <strong>defining relation</strong>.</li>
<li>We have further <strong>aliased</strong> a number of main and interaction effects. Specifically, the following pairs are aliases of each other:
<ul>
<li>A and BC.</li>
<li>B and AC.</li>
<li>C and AB.</li>
<li>I and ABC.</li>
<li>An <strong>alias</strong>, is therefore, two factors whose effects cannot be distinguished from eachother, and whose levels are equivalent in every treatment combination.</li>
</ul></li>
<li>We chose this structure: the design generator, defining relation, and set of aliases based on the heuristic known as the <strong>sparsity of effects</strong>. This is the idea that higher order interactions generally have smaller or negligible effects such that we can assume that the observed effect is a result of the main or lower order effect.</li>
</ul>
<p>There are a few points to note here:</p>
<p>“<strong>Alias Multiplication</strong>”: As discussed in the previous chapter, we can “multiply” factor columns together to get the values of another column. This remains true. One useful aspect of this is that we can multiply columns together to identify the alias structure. Recall we have stated that <span class="math inline">\(I = ABC\)</span> and that <span class="math inline">\(I\)</span> is the identity column. We can use that fact to say that any two columns that are aliased, when multiplied are equivalent to the identity column, or, more simply, a column multiplied by the identity column identifies its alias. This is best seen as an example:</p>
<p><span class="math display">\[A = I \cdot A = ABC \cdot A = A^2BC = BC\]</span></p>
<p>This shows us that <span class="math inline">\(A\)</span> and <span class="math inline">\(BC\)</span> are aliased in this design. The reader can use this to validate the other aliases seen above.</p>
<p><strong>Principle and Alternate Fraction</strong>: In the above example, we chose all of the treatment combinations where <span class="math inline">\(ABC = +1\)</span>. This is called the principle fraction. We could have alternatively chosen <span class="math inline">\(ABC = -1\)</span>. This is called the alternative (or complementary) fraction. We could see this here:</p>
<div id="htmlwidget-82c64cf1fd83d006974b" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-82c64cf1fd83d006974b">{"x":{"filter":"none","vertical":false,"data":[["(1)","ab","ac","bc"],[1,1,1,1],[-1,1,1,-1],[-1,1,-1,1],[1,1,-1,-1],[-1,-1,1,1],[1,-1,1,-1],[1,-1,-1,1],[-1,-1,-1,-1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data, displayNum, displayIndex, dataIndex) {\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background-color':'red'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'background-color':'red'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'background-color':'blue'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'background-color':'blue'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'background-color':'green'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'background-color':'green'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'background-color':'yellow'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'background-color':'yellow'});\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-weight':'bold'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-weight':'bold'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'font-weight':'bold'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'font-weight':'bold'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'font-weight':'bold'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'font-weight':'bold'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'font-weight':'bold'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'font-weight':'bold'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'font-weight':'bold'});\n}"},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<p>Here we see that our alias structure is not exactly the same, rather our aliases are inverses of each other. For example, <span class="math inline">\(A = -BC\)</span>. We can calculate these in the same manner as before, e.g.:</p>
<p><span class="math display">\[ A = I \cdot A = -ABC \cdot A = -A^2BC = -BC\]</span></p>
<p>When we are estimating the effects in this case, we are going to see that our estimation includes the difference between the effect of A and BC, for example (the next section covers estimating effects).</p>
<p><strong>Choice of Generator</strong>: We are not bound to choose ABC or -ABC as our generator. This is a common choice based on the principle of sparsity of effects, but sometimes alternative generators make sense if we know something about our system. For example, consider a system where we strongly believe that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> alone have negligible effects, but we believe that the interactions <span class="math inline">\(AB\)</span> and <span class="math inline">\(BC\)</span> likely do, we might choose <span class="math inline">\(I = A\)</span> as our defining relation and see a design matrix and alias structure like this:</p>
<div id="htmlwidget-2a737ddeed8abab6980c" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2a737ddeed8abab6980c">{"x":{"filter":"none","vertical":false,"data":[["a","ab","ac","abc"],[1,1,1,1],[1,1,1,1],[-1,1,-1,1],[-1,1,-1,1],[-1,-1,1,1],[-1,-1,1,1],[1,-1,-1,1],[1,-1,-1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data, displayNum, displayIndex, dataIndex) {\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'background-color':'red'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'background-color':'red'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'background-color':'blue'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'background-color':'blue'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'background-color':'green'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'background-color':'green'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'background-color':'yellow'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background-color':'yellow'});\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-weight':'bold'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-weight':'bold'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'font-weight':'bold'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'font-weight':'bold'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'font-weight':'bold'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'font-weight':'bold'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'font-weight':'bold'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'font-weight':'bold'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'font-weight':'bold'});\n}"},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<p>To make this choice is unconventional and requires some reasonable knowledge of the system at hand, but it <em>can</em> be a good choice under the right circumstances.</p>
</div>
<div id="estimating-effects" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Estimating Effects</h3>
<p>As in full factorial designs, the point of designing an experiment and doing testing is such that we can estimate effects. In the case of a half fractional factorial design, we can estimate the effects in a manner similar to how we estimated with a full factorial design, with the use of contrasts. Recall that we use the name of the treatment combination to represent the sum of the responses for that given treatment combination. We then take the dot product of the treatment combination column and the effect column to get the contrast and multiply by $.</p>
<p>For example, if we have <span class="math inline">\(I = ABC\)</span>, we have the following design:</p>
<div id="htmlwidget-7177bd1a0e7a380eb82f" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7177bd1a0e7a380eb82f">{"x":{"filter":"none","vertical":false,"data":[["a","b","c","abc"],[1,1,1,1],[1,-1,-1,1],[-1,1,-1,1],[-1,-1,1,1],[-1,-1,1,1],[-1,1,-1,1],[1,-1,-1,1],[1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>AB<\/th>\n      <th>C<\/th>\n      <th>AC<\/th>\n      <th>BC<\/th>\n      <th>ABC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8]}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data, displayNum, displayIndex, dataIndex) {\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background-color':'red'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'background-color':'red'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'background-color':'blue'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'background-color':'blue'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'background-color':'green'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'background-color':'green'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'background-color':'yellow'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'background-color':'yellow'});\nvar value=data[0]; $(this.api().cell(row, 0).node()).css({'font-weight':'bold'});\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-weight':'bold'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'font-weight':'bold'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'font-weight':'bold'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'font-weight':'bold'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'font-weight':'bold'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'font-weight':'bold'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'font-weight':'bold'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'font-weight':'bold'});\n}"},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<p>We then see:</p>
<ul>
<li><span class="math inline">\([A] = [BC] = \frac{1}{2}(a - b - c + abc)\)</span></li>
<li><span class="math inline">\([B] = [AC] = \frac{1}{2}(-a + b - c + abc)\)</span></li>
<li><span class="math inline">\([C] = [AB] = \frac{1}{2}(-a - b + c + abc)\)</span></li>
<li>We cannot estimate the effect of ABC as it never varies in value (i.e., it is all 1s).</li>
<li>Note the notation [effect] is used to indicate that linear combination as indicated above.</li>
</ul>
<p>Further, what we are really estimating with each of these linear combinations is the sum of the effect of the two aliases. That is <span class="math inline">\([A] = [BC] \to A + BC\)</span>, meaning this value is really the effect of A plus the effect of BC. Of course, if we assume <span class="math inline">\(BC \approx 0\)</span>, we can reduce this to say, <span class="math inline">\([A] \to A + BC \approx A + 0 = A\)</span> or that the effect of <span class="math inline">\(A\)</span> is about <span class="math inline">\([A]\)</span>.</p>
<p>Similarly, when we take the alternate fraction, where <span class="math inline">\(I = -ABC\)</span>, we are saying <span class="math inline">\([A]&#39; = [BC]&#39; \to A - BC\)</span>, where the <span class="math inline">\([effect]&#39;\)</span> indicates the inverse of <span class="math inline">\([A]\)</span>. For example, <span class="math inline">\([A] = \frac{1}{2}(a - b - c + abc)\)</span> and <span class="math inline">\([A]&#39; = \frac{1}{2}(-(1) + ab + ac - bc)\)</span></p>
</div>
<div id="geometric-view" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Geometric View</h3>
<p>As with a full factorial design, one can view a fractional factorial design geometrically. Consider a <span class="math inline">\(2^{3-1}\)</span> design with <span class="math inline">\(ABC\)</span> as the generator. We can view this in at least two ways:</p>
<p>We can look at multiple 2D Perspectives as such:</p>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Note that the Principle Fraction (represented in red) includes: (1), ab, ac, and bc, and the Alternate Fraction (repreented in blue) includes: a, b, c, and abc. We can further see that the choices on each “plane” of C the choices of treatment combinations are opposite of each other.</p>
<p>We can also view these in a 3D manner as such:<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a></p>
<div id="htmlwidget-d1ace380fa4100121a9c" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-d1ace380fa4100121a9c">{"x":{"visdat":{"86b29eb4d3a":["function () ","plotlyVisDat"]},"cur_data":"86b29eb4d3a","attrs":{"86b29eb4d3a":{"x":{},"y":{},"z":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"text":{},"type":"scatter3d","mode":"text","inherit":true},"86b29eb4d3a.1":{"x":{},"y":{},"z":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","color":{},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"A"},"yaxis":{"title":"B"},"zaxis":{"title":"C"}},"xaxis":{"type":"category","categoryorder":"array","categoryarray":["-1","1"]},"yaxis":{"type":"category","categoryorder":"array","categoryarray":["-1","1"]},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":["-1","1","-1","1","-1","1","-1","1"],"y":["-1","-1","1","1","-1","-1","1","1"],"z":["-1","-1","-1","-1","1","1","1","1"],"text":["(1)","a","b","ab","c","ac","bc","abc"],"type":"scatter3d","mode":"text","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"x":["-1","1","1","-1"],"y":["-1","1","-1","1"],"z":["-1","-1","1","1"],"type":"scatter3d","mode":"markers","name":"Alternate","marker":{"color":"rgba(102,194,165,1)","line":{"color":"rgba(102,194,165,1)"}},"textfont":{"color":"rgba(102,194,165,1)"},"error_y":{"color":"rgba(102,194,165,1)"},"error_x":{"color":"rgba(102,194,165,1)"},"line":{"color":"rgba(102,194,165,1)"},"frame":null},{"x":["1","-1","-1","1"],"y":["-1","1","-1","1"],"z":["-1","-1","1","1"],"type":"scatter3d","mode":"markers","name":"Principle","marker":{"color":"rgba(141,160,203,1)","line":{"color":"rgba(141,160,203,1)"}},"textfont":{"color":"rgba(141,160,203,1)"},"error_y":{"color":"rgba(141,160,203,1)"},"error_x":{"color":"rgba(141,160,203,1)"},"line":{"color":"rgba(141,160,203,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Again, we see the nice symmetry in the choice of treatment combinations for each fraction.</p>
</div>
<div id="example-24-1-design" class="section level3">
<h3><span class="header-section-number">6.2.5</span> Example <span class="math inline">\(2^{4-1}\)</span> Design</h3>
<p><em>Note this example has been modified from Example 8.1 in §8.2 of <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>.</em></p>
<p>Consider an experiment with four factors: A, B, C, and D that each take a high and low level and return a response. A full factorial experiement would require: <span class="math inline">\(2^4 = 16\)</span> tests minimum to test all treatment combinations. Unfortunately, we only have the resources to conduct 8 tests. Accordingly, we have opted to conduct a half fractional factorial (<span class="math inline">\(2^{4-1}\)</span>) experiment. We take <span class="math inline">\(ABCD = I\)</span> as the defining relation (with <span class="math inline">\(ABCD\)</span> as the generator); we will choose the principle fraction (i.e., where <span class="math inline">\(ABCD = 1\)</span>).</p>
<p>First, let us identify the appropriate treatment combinations. We can do this in at least two ways. The first is manually:</p>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb495-1" data-line-number="1"><span class="co"># First let us create a full factorial design</span></a>
<a class="sourceLine" id="cb495-2" data-line-number="2"><span class="co"># This clearly gets very annoying beyond K = 3</span></a>
<a class="sourceLine" id="cb495-3" data-line-number="3">myExample &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb495-4" data-line-number="4">  <span class="dt">TC =</span> <span class="kw">c</span>(<span class="st">&#39;(1)&#39;</span>, <span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;ab&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;ac&#39;</span>, <span class="st">&#39;bc&#39;</span>, <span class="st">&#39;abc&#39;</span>, <span class="st">&#39;d&#39;</span>, <span class="st">&#39;ad&#39;</span>, <span class="st">&#39;bd&#39;</span>, <span class="st">&#39;abd&#39;</span>, <span class="st">&#39;cd&#39;</span>, <span class="st">&#39;acd&#39;</span>, <span class="st">&#39;bcd&#39;</span>, <span class="st">&#39;abcd&#39;</span>),</a>
<a class="sourceLine" id="cb495-5" data-line-number="5">  <span class="dt">I =</span> <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb495-6" data-line-number="6">  <span class="dt">A =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb495-7" data-line-number="7">  <span class="dt">B =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">4</span>),</a>
<a class="sourceLine" id="cb495-8" data-line-number="8">  <span class="dt">C =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">4</span>)), <span class="dv">2</span>), </a>
<a class="sourceLine" id="cb495-9" data-line-number="9">  <span class="dt">D =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">8</span>))</a>
<a class="sourceLine" id="cb495-10" data-line-number="10">)</a>
<a class="sourceLine" id="cb495-11" data-line-number="11"></a>
<a class="sourceLine" id="cb495-12" data-line-number="12">myExample</a></code></pre></div>
<pre><code>##      TC I  A  B  C  D
## 1   (1) 1 -1 -1 -1 -1
## 2     a 1  1 -1 -1 -1
## 3     b 1 -1  1 -1 -1
## 4    ab 1  1  1 -1 -1
## 5     c 1 -1 -1  1 -1
## 6    ac 1  1 -1  1 -1
## 7    bc 1 -1  1  1 -1
## 8   abc 1  1  1  1 -1
## 9     d 1 -1 -1 -1  1
## 10   ad 1  1 -1 -1  1
## 11   bd 1 -1  1 -1  1
## 12  abd 1  1  1 -1  1
## 13   cd 1 -1 -1  1  1
## 14  acd 1  1 -1  1  1
## 15  bcd 1 -1  1  1  1
## 16 abcd 1  1  1  1  1</code></pre>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb497-1" data-line-number="1"><span class="co"># Show interaction effects columns</span></a>
<a class="sourceLine" id="cb497-2" data-line-number="2">myExample &lt;-<span class="st"> </span>myExample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb497-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">AB =</span> A<span class="op">*</span>B,</a>
<a class="sourceLine" id="cb497-4" data-line-number="4">         <span class="dt">AC =</span> A<span class="op">*</span>C,</a>
<a class="sourceLine" id="cb497-5" data-line-number="5">         <span class="dt">AD =</span> A<span class="op">*</span>D,</a>
<a class="sourceLine" id="cb497-6" data-line-number="6">         <span class="dt">BC =</span> B<span class="op">*</span>C,</a>
<a class="sourceLine" id="cb497-7" data-line-number="7">         <span class="dt">BD =</span> B<span class="op">*</span>D,</a>
<a class="sourceLine" id="cb497-8" data-line-number="8">         <span class="dt">CD =</span> C<span class="op">*</span>D,</a>
<a class="sourceLine" id="cb497-9" data-line-number="9">         <span class="dt">ABC =</span> A<span class="op">*</span>B<span class="op">*</span>C,</a>
<a class="sourceLine" id="cb497-10" data-line-number="10">         <span class="dt">ABD =</span> A<span class="op">*</span>B<span class="op">*</span>D,</a>
<a class="sourceLine" id="cb497-11" data-line-number="11">         <span class="dt">ACD =</span> A<span class="op">*</span>C<span class="op">*</span>D,</a>
<a class="sourceLine" id="cb497-12" data-line-number="12">         <span class="dt">BCD =</span> B<span class="op">*</span>C<span class="op">*</span>D,</a>
<a class="sourceLine" id="cb497-13" data-line-number="13">         <span class="dt">ABCD =</span> A<span class="op">*</span>B<span class="op">*</span>C<span class="op">*</span>D)</a>
<a class="sourceLine" id="cb497-14" data-line-number="14"></a>
<a class="sourceLine" id="cb497-15" data-line-number="15"><span class="co"># We can see what a full factorial design would look like</span></a>
<a class="sourceLine" id="cb497-16" data-line-number="16"><span class="co"># note that datatable from the DT package is a nice way for outputting </span></a>
<a class="sourceLine" id="cb497-17" data-line-number="17"><span class="co"># tables.  It is quite extensible and you can format your tables in many </span></a>
<a class="sourceLine" id="cb497-18" data-line-number="18"><span class="co"># convenient ways.</span></a>
<a class="sourceLine" id="cb497-19" data-line-number="19"><span class="kw">datatable</span>(myExample, <span class="dt">rownames =</span> F, <span class="dt">options =</span> <span class="kw">list</span>(<span class="dt">pageLength =</span> <span class="dv">16</span>))</a></code></pre></div>
<div id="htmlwidget-ffd27d9ad9c180433166" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-ffd27d9ad9c180433166">{"x":{"filter":"none","vertical":false,"data":[["(1)","a","b","ab","c","ac","bc","abc","d","ad","bd","abd","cd","acd","bcd","abcd"],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,1],[-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1],[-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,1,1,1,1],[-1,-1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1,1],[1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1],[1,-1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1],[1,-1,1,-1,1,-1,1,-1,-1,1,-1,1,-1,1,-1,1],[1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,1,1],[1,1,-1,-1,1,1,-1,-1,-1,-1,1,1,-1,-1,1,1],[1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,1,1],[-1,1,1,-1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1],[-1,1,1,-1,-1,1,1,-1,1,-1,-1,1,1,-1,-1,1],[-1,1,-1,1,1,-1,1,-1,1,-1,1,-1,-1,1,-1,1],[-1,-1,1,1,1,1,-1,-1,1,1,-1,-1,-1,-1,1,1],[1,-1,-1,1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>C<\/th>\n      <th>D<\/th>\n      <th>AB<\/th>\n      <th>AC<\/th>\n      <th>AD<\/th>\n      <th>BC<\/th>\n      <th>BD<\/th>\n      <th>CD<\/th>\n      <th>ABC<\/th>\n      <th>ABD<\/th>\n      <th>ACD<\/th>\n      <th>BCD<\/th>\n      <th>ABCD<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":16,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[10,16,25,50,100]},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb498-1" data-line-number="1"><span class="co"># We can then select our principle freaction of ABCD = I by filtering for ABCD = 1 in the table</span></a>
<a class="sourceLine" id="cb498-2" data-line-number="2"><span class="kw">datatable</span>(myExample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(ABCD <span class="op">==</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">rownames =</span> F, <span class="dt">options =</span> <span class="kw">list</span>(<span class="dt">pageLength =</span> <span class="dv">8</span>))</a></code></pre></div>
<div id="htmlwidget-95c8091ab5ea06656922" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-95c8091ab5ea06656922">{"x":{"filter":"none","vertical":false,"data":[["(1)","ab","ac","bc","ad","bd","cd","abcd"],[1,1,1,1,1,1,1,1],[-1,1,1,-1,1,-1,-1,1],[-1,1,-1,1,-1,1,-1,1],[-1,-1,1,1,-1,-1,1,1],[-1,-1,-1,-1,1,1,1,1],[1,1,-1,-1,-1,-1,1,1],[1,-1,1,-1,-1,1,-1,1],[1,-1,-1,1,1,-1,-1,1],[1,-1,-1,1,1,-1,-1,1],[1,-1,1,-1,-1,1,-1,1],[1,1,-1,-1,-1,-1,1,1],[-1,-1,-1,-1,1,1,1,1],[-1,-1,1,1,-1,-1,1,1],[-1,1,-1,1,-1,1,-1,1],[-1,1,1,-1,1,-1,-1,1],[1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>C<\/th>\n      <th>D<\/th>\n      <th>AB<\/th>\n      <th>AC<\/th>\n      <th>AD<\/th>\n      <th>BC<\/th>\n      <th>BD<\/th>\n      <th>CD<\/th>\n      <th>ABC<\/th>\n      <th>ABD<\/th>\n      <th>ACD<\/th>\n      <th>BCD<\/th>\n      <th>ABCD<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":8,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100]},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>We can calculate our alias structure using effect multiplication:</p>
<ul>
<li><span class="math inline">\(A = A \cdot ABCD = BCD\)</span></li>
<li><span class="math inline">\(B = B \cdot ABCD = ACD\)</span></li>
<li><span class="math inline">\(C = C \cdot ABCD = ABD\)</span></li>
<li><span class="math inline">\(D = D \cdot ABCD = ABC\)</span></li>
<li><span class="math inline">\(AB = AB \cdot ABCD = CD\)</span></li>
<li><span class="math inline">\(AC = AC \cdot ABCD = BD\)</span></li>
<li><span class="math inline">\(AD = AD \cdot ABCD = BC\)</span></li>
</ul>
<p>With this, we see every main effect is aliased with a third-order interaction effect, and every second-order interaction effect is aliased with another second-order interaction effect.</p>
<p>We can see this on our run matrix by color coding the aliased columns:</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb499-1" data-line-number="1"><span class="kw">datatable</span>(myExample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(ABCD <span class="op">==</span><span class="st"> </span><span class="dv">1</span>), <span class="dt">rownames =</span> F, <span class="dt">options =</span> <span class="kw">list</span>(<span class="dt">pageLength =</span> <span class="dv">8</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-2" data-line-number="2"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;I&#39;</span>, <span class="st">&#39;ABCD&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;red&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-3" data-line-number="3"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;BCD&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;orange&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-4" data-line-number="4"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;B&#39;</span>, <span class="st">&#39;ACD&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;yellow&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-5" data-line-number="5"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;C&#39;</span>, <span class="st">&#39;ABD&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;green&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-6" data-line-number="6"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;D&#39;</span>, <span class="st">&#39;ABC&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;blue&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-7" data-line-number="7"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;AB&#39;</span>, <span class="st">&#39;CD&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;purple&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-8" data-line-number="8"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;AC&#39;</span>, <span class="st">&#39;BD&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;grey&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb499-9" data-line-number="9"><span class="st">  </span><span class="kw">formatStyle</span>(<span class="kw">c</span>(<span class="st">&#39;AD&#39;</span>, <span class="st">&#39;BC&#39;</span>), <span class="dt">backgroundColor =</span> <span class="st">&#39;white&#39;</span>)</a></code></pre></div>
<div id="htmlwidget-295c25f433bc14f3b903" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-295c25f433bc14f3b903">{"x":{"filter":"none","vertical":false,"data":[["(1)","ab","ac","bc","ad","bd","cd","abcd"],[1,1,1,1,1,1,1,1],[-1,1,1,-1,1,-1,-1,1],[-1,1,-1,1,-1,1,-1,1],[-1,-1,1,1,-1,-1,1,1],[-1,-1,-1,-1,1,1,1,1],[1,1,-1,-1,-1,-1,1,1],[1,-1,1,-1,-1,1,-1,1],[1,-1,-1,1,1,-1,-1,1],[1,-1,-1,1,1,-1,-1,1],[1,-1,1,-1,-1,1,-1,1],[1,1,-1,-1,-1,-1,1,1],[-1,-1,-1,-1,1,1,1,1],[-1,-1,1,1,-1,-1,1,1],[-1,1,-1,1,-1,1,-1,1],[-1,1,1,-1,1,-1,-1,1],[1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>TC<\/th>\n      <th>I<\/th>\n      <th>A<\/th>\n      <th>B<\/th>\n      <th>C<\/th>\n      <th>D<\/th>\n      <th>AB<\/th>\n      <th>AC<\/th>\n      <th>AD<\/th>\n      <th>BC<\/th>\n      <th>BD<\/th>\n      <th>CD<\/th>\n      <th>ABC<\/th>\n      <th>ABD<\/th>\n      <th>ACD<\/th>\n      <th>BCD<\/th>\n      <th>ABCD<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":8,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100],"rowCallback":"function(row, data, displayNum, displayIndex, dataIndex) {\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'background-color':'red'});\nvar value=data[16]; $(this.api().cell(row, 16).node()).css({'background-color':'red'});\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'background-color':'orange'});\nvar value=data[15]; $(this.api().cell(row, 15).node()).css({'background-color':'orange'});\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'background-color':'yellow'});\nvar value=data[14]; $(this.api().cell(row, 14).node()).css({'background-color':'yellow'});\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'background-color':'green'});\nvar value=data[13]; $(this.api().cell(row, 13).node()).css({'background-color':'green'});\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'background-color':'blue'});\nvar value=data[12]; $(this.api().cell(row, 12).node()).css({'background-color':'blue'});\nvar value=data[6]; $(this.api().cell(row, 6).node()).css({'background-color':'purple'});\nvar value=data[11]; $(this.api().cell(row, 11).node()).css({'background-color':'purple'});\nvar value=data[7]; $(this.api().cell(row, 7).node()).css({'background-color':'grey'});\nvar value=data[10]; $(this.api().cell(row, 10).node()).css({'background-color':'grey'});\nvar value=data[8]; $(this.api().cell(row, 8).node()).css({'background-color':'white'});\nvar value=data[9]; $(this.api().cell(row, 9).node()).css({'background-color':'white'});\n}"},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
<p>This of course becomes overwhelming as <span class="math inline">\(K\)</span> increases, both from a visualization perspective and from a practical recording the data perspective. There a variety of computer programs and packages that can do much of this for us. One is the <code>FrF2</code> package in <em>R</em>. We will demonstrate it here:</p>
<div class="sourceCode" id="cb500"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb500-1" data-line-number="1"><span class="co">#install.packages(&#39;FrF2&#39;) # Install the package if you have not already done so.</span></a>
<a class="sourceLine" id="cb500-2" data-line-number="2"><span class="kw">library</span>(FrF2)</a>
<a class="sourceLine" id="cb500-3" data-line-number="3"></a>
<a class="sourceLine" id="cb500-4" data-line-number="4"><span class="co"># The FrF2 function in FrF2 produces a data frame with some additional information:</span></a>
<a class="sourceLine" id="cb500-5" data-line-number="5"></a>
<a class="sourceLine" id="cb500-6" data-line-number="6">myDesign &lt;-<span class="st"> </span><span class="kw">FrF2</span>(</a>
<a class="sourceLine" id="cb500-7" data-line-number="7">  <span class="co"># Choose the total number of treatment combinations you desire.  Must be a power of 2</span></a>
<a class="sourceLine" id="cb500-8" data-line-number="8">  <span class="dt">nruns =</span> <span class="dv">8</span>, </a>
<a class="sourceLine" id="cb500-9" data-line-number="9">  <span class="co"># Choose the number of factors</span></a>
<a class="sourceLine" id="cb500-10" data-line-number="10">  <span class="dt">nfactors =</span> <span class="dv">4</span>, </a>
<a class="sourceLine" id="cb500-11" data-line-number="11">  <span class="co"># The default is to name factors A, B, C...; you can choose other names, however</span></a>
<a class="sourceLine" id="cb500-12" data-line-number="12">  <span class="co"># with a character vector of the same length as the number of factors</span></a>
<a class="sourceLine" id="cb500-13" data-line-number="13">  <span class="dt">factor.names =</span> LETTERS[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], </a>
<a class="sourceLine" id="cb500-14" data-line-number="14">  <span class="co"># There are a variety of options.  One is to include alias info up to aliases of 3rd order interactions</span></a>
<a class="sourceLine" id="cb500-15" data-line-number="15">  <span class="dt">alias.info =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb500-16" data-line-number="16"></a>
<a class="sourceLine" id="cb500-17" data-line-number="17"><span class="co"># We can view the design by calling it</span></a>
<a class="sourceLine" id="cb500-18" data-line-number="18">myDesign</a></code></pre></div>
<pre><code>##    A  B  C  D
## 1  1  1  1  1
## 2  1 -1 -1  1
## 3  1 -1  1 -1
## 4 -1 -1 -1 -1
## 5 -1  1  1 -1
## 6 -1 -1  1  1
## 7  1  1 -1 -1
## 8 -1  1 -1  1
## class=design, type= FrF2</code></pre>
<div class="sourceCode" id="cb502"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb502-1" data-line-number="1"><span class="co"># Note two things: </span></a>
<a class="sourceLine" id="cb502-2" data-line-number="2"><span class="co"># 1) the factors are a factor data type.  This is useful, though if you want to multiply columns, you&#39;ll have to convert</span></a>
<a class="sourceLine" id="cb502-3" data-line-number="3"><span class="co"># the data type</span></a>
<a class="sourceLine" id="cb502-4" data-line-number="4"><span class="co"># 2) This is not strictly a data frame, it is an object of class design</span></a>
<a class="sourceLine" id="cb502-5" data-line-number="5"><span class="co"># We can see this with its structure</span></a>
<a class="sourceLine" id="cb502-6" data-line-number="6"></a>
<a class="sourceLine" id="cb502-7" data-line-number="7"><span class="co"># If we call the structure of `myDesign` we can learn a lot about it</span></a>
<a class="sourceLine" id="cb502-8" data-line-number="8"><span class="kw">str</span>(myDesign)</a></code></pre></div>
<pre><code>## Classes &#39;design&#39; and &#39;data.frame&#39;:   8 obs. of  4 variables:
##  $ A: Factor w/ 2 levels &quot;-1&quot;,&quot;1&quot;: 2 2 2 1 1 1 2 1
##   ..- attr(*, &quot;contrasts&quot;)= num [1:2, 1] -1 1
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr  &quot;-1&quot; &quot;1&quot;
##   .. .. ..$ : NULL
##  $ B: Factor w/ 2 levels &quot;-1&quot;,&quot;1&quot;: 2 1 1 1 2 1 2 2
##   ..- attr(*, &quot;contrasts&quot;)= num [1:2, 1] -1 1
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr  &quot;-1&quot; &quot;1&quot;
##   .. .. ..$ : NULL
##  $ C: Factor w/ 2 levels &quot;-1&quot;,&quot;1&quot;: 2 1 2 1 2 2 1 1
##   ..- attr(*, &quot;contrasts&quot;)= num [1:2, 1] -1 1
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr  &quot;-1&quot; &quot;1&quot;
##   .. .. ..$ : NULL
##  $ D: Factor w/ 2 levels &quot;-1&quot;,&quot;1&quot;: 2 2 1 1 1 2 1 2
##   ..- attr(*, &quot;contrasts&quot;)= num [1:2, 1] -1 1
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr  &quot;-1&quot; &quot;1&quot;
##   .. .. ..$ : NULL
##  - attr(*, &quot;desnum&quot;)= num [1:8, 1:4] 1 1 1 -1 -1 -1 1 -1 1 -1 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr  &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr  &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot;
##  - attr(*, &quot;run.order&quot;)=&#39;data.frame&#39;:    8 obs. of  3 variables:
##   ..$ run.no.in.std.order: Factor w/ 8 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 8 2 6 1 7 5 4 3
##   ..$ run.no             : int  1 2 3 4 5 6 7 8
##   ..$ run.no.std.rp      : Factor w/ 8 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 8 2 6 1 7 5 4 3
##  - attr(*, &quot;design.info&quot;)=List of 13
##   ..$ type        : chr &quot;FrF2&quot;
##   ..$ nruns       : num 8
##   ..$ nfactors    : num 4
##   ..$ factor.names:List of 4
##   .. ..$ A: num  -1 1
##   .. ..$ B: num  -1 1
##   .. ..$ C: num  -1 1
##   .. ..$ D: num  -1 1
##   ..$ catlg.name  : chr &quot;catlg&quot;
##   ..$ catlg.entry :List of 1
##   .. ..$ 4-1.1:List of 9
##   .. .. ..$ res           : int 4
##   .. .. ..$ nfac          : num 4
##   .. .. ..$ nruns         : num 8
##   .. .. ..$ gen           : num 7
##   .. .. ..$ WLP           : num  0 0 0 1 0 0 0
##   .. .. ..$ nclear.2fis   : num 0
##   .. .. ..$ clear.2fis    : num 
##   .. .. ..$ all.2fis.clear: num 
##   .. .. ..$ dominating    : logi FALSE
##   .. ..- attr(*, &quot;class&quot;)= chr  &quot;catlg&quot; &quot;list&quot;
##   ..$ aliased     :List of 4
##   .. ..$ legend: chr  &quot;A=A&quot; &quot;B=B&quot; &quot;C=C&quot; &quot;D=D&quot;
##   .. ..$ main  : chr  &quot;A=BCD&quot; &quot;B=ACD&quot; &quot;C=ABD&quot; &quot;D=ABC&quot;
##   .. ..$ fi2   : chr  &quot;AB=CD&quot; &quot;AC=BD&quot; &quot;AD=BC&quot;
##   .. ..$ fi3   : chr 
##   ..$ FrF2.version: chr &quot;2.3-2&quot;
##   ..$ replications: num 1
##   ..$ repeat.only : logi FALSE
##   ..$ randomize   : logi TRUE
##   ..$ seed        : NULL
##   ..$ creator     : language FrF2(nruns = 8, nfactors = 4, factor.names = LETTERS[1:4], alias.info = 3)</code></pre>
<div class="sourceCode" id="cb504"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb504-1" data-line-number="1"><span class="co"># We see the main columns $A, $B, $C, $D</span></a>
<a class="sourceLine" id="cb504-2" data-line-number="2"><span class="co"># We can also see that the data frame has a number of attributes</span></a>
<a class="sourceLine" id="cb504-3" data-line-number="3"></a>
<a class="sourceLine" id="cb504-4" data-line-number="4"><span class="co"># We can call information about the attributes using the `attr` command</span></a>
<a class="sourceLine" id="cb504-5" data-line-number="5"><span class="co"># For example, we can call the attribute &#39;design.info&#39;  using the command below</span></a>
<a class="sourceLine" id="cb504-6" data-line-number="6"><span class="kw">attr</span>(myDesign, <span class="st">&#39;design.info&#39;</span>)</a></code></pre></div>
<pre><code>## $type
## [1] &quot;FrF2&quot;
## 
## $nruns
## [1] 8
## 
## $nfactors
## [1] 4
## 
## $factor.names
## $factor.names$A
## [1] -1  1
## 
## $factor.names$B
## [1] -1  1
## 
## $factor.names$C
## [1] -1  1
## 
## $factor.names$D
## [1] -1  1
## 
## 
## $catlg.name
## [1] &quot;catlg&quot;
## 
## $catlg.entry
## Design:  4-1.1 
##    8  runs,  4  factors,  
##    Resolution  IV 
##    Generating columns:  7 
##    WLP (3plus):  0 1 0 0 0 ,  0  clear 2fis
## 
## $aliased
## $aliased$legend
## [1] &quot;A=A&quot; &quot;B=B&quot; &quot;C=C&quot; &quot;D=D&quot;
## 
## $aliased$main
## [1] &quot;A=BCD&quot; &quot;B=ACD&quot; &quot;C=ABD&quot; &quot;D=ABC&quot;
## 
## $aliased$fi2
## [1] &quot;AB=CD&quot; &quot;AC=BD&quot; &quot;AD=BC&quot;
## 
## $aliased$fi3
## character(0)
## 
## 
## $FrF2.version
## [1] &quot;2.3-2&quot;
## 
## $replications
## [1] 1
## 
## $repeat.only
## [1] FALSE
## 
## $randomize
## [1] TRUE
## 
## $seed
## NULL
## 
## $creator
## FrF2(nruns = 8, nfactors = 4, factor.names = LETTERS[1:4], alias.info = 3)</code></pre>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb506-1" data-line-number="1"><span class="co"># We can &quot;dig into&quot; this in our normal indexing manner, for example, we can learn about our aliases and the gnerators</span></a>
<a class="sourceLine" id="cb506-2" data-line-number="2"><span class="kw">attr</span>(myDesign, <span class="st">&#39;design.info&#39;</span>)<span class="op">$</span>aliased</a></code></pre></div>
<pre><code>## $legend
## [1] &quot;A=A&quot; &quot;B=B&quot; &quot;C=C&quot; &quot;D=D&quot;
## 
## $main
## [1] &quot;A=BCD&quot; &quot;B=ACD&quot; &quot;C=ABD&quot; &quot;D=ABC&quot;
## 
## $fi2
## [1] &quot;AB=CD&quot; &quot;AC=BD&quot; &quot;AD=BC&quot;
## 
## $fi3
## character(0)</code></pre>
<div class="sourceCode" id="cb508"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb508-1" data-line-number="1"><span class="co"># This shows us the main effects aliases, the 2nd order interaction aliases, </span></a>
<a class="sourceLine" id="cb508-2" data-line-number="2"><span class="co"># and if there third order interactions aliased with higher order ones, you would see that here</span></a>
<a class="sourceLine" id="cb508-3" data-line-number="3"></a>
<a class="sourceLine" id="cb508-4" data-line-number="4"><span class="co"># If we want to really dig into this, we can call the elements of this list.</span></a>
<a class="sourceLine" id="cb508-5" data-line-number="5"><span class="co"># This would, for example, allow you to state the main interactions in a report</span></a>
<a class="sourceLine" id="cb508-6" data-line-number="6"><span class="kw">attr</span>(myDesign, <span class="st">&#39;design.info&#39;</span>)<span class="op">$</span>aliased<span class="op">$</span>main</a></code></pre></div>
<pre><code>## [1] &quot;A=BCD&quot; &quot;B=ACD&quot; &quot;C=ABD&quot; &quot;D=ABC&quot;</code></pre>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb510-1" data-line-number="1"><span class="co"># We can view the generators</span></a>
<a class="sourceLine" id="cb510-2" data-line-number="2"><span class="kw">attr</span>(myDesign, <span class="st">&#39;design.info&#39;</span>)<span class="op">$</span>catlg.entry</a></code></pre></div>
<pre><code>## Design:  4-1.1 
##    8  runs,  4  factors,  
##    Resolution  IV 
##    Generating columns:  7 
##    WLP (3plus):  0 1 0 0 0 ,  0  clear 2fis</code></pre>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb512-1" data-line-number="1"><span class="co"># We can dig even deeper into this to get the numeric vector of generators</span></a>
<a class="sourceLine" id="cb512-2" data-line-number="2"><span class="kw">attr</span>(myDesign, <span class="st">&#39;design.info&#39;</span>)<span class="op">$</span>catlg.entry[[<span class="dv">1</span>]]<span class="op">$</span>gen</a></code></pre></div>
<pre><code>## [1] 7</code></pre>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb514-1" data-line-number="1"><span class="co"># This is somewhat cryptic</span></a>
<a class="sourceLine" id="cb514-2" data-line-number="2"><span class="co"># FrF2 uses an internal vector of generator names that correspond to its vector &quot;Yates&quot;</span></a>
<a class="sourceLine" id="cb514-3" data-line-number="3"><span class="co"># We can see this by:</span></a>
<a class="sourceLine" id="cb514-4" data-line-number="4"><span class="kw">names</span>(Yates)[<span class="dv">7</span>]</a></code></pre></div>
<pre><code>## [1] &quot;ABC&quot;</code></pre>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb516-1" data-line-number="1"><span class="co"># We also have to remember that FrF2 does not provide generators in the form I = [My Generator]</span></a>
<a class="sourceLine" id="cb516-2" data-line-number="2"><span class="co"># They are in the form Factor = [My Generator]</span></a>
<a class="sourceLine" id="cb516-3" data-line-number="3"><span class="co"># Where the factor is identified by the order in the provided vector and the size of the fraction</span></a>
<a class="sourceLine" id="cb516-4" data-line-number="4"><span class="co"># For example, if you have P generators and K factors, the first value corresponds to the (K-P+1) letter</span></a>
<a class="sourceLine" id="cb516-5" data-line-number="5"><span class="co"># In our case we have four factors, A, B, C, and D</span></a>
<a class="sourceLine" id="cb516-6" data-line-number="6"><span class="co"># We have one generator, so we have ABC = D as ABC is our only generator and K - 1 + 1 = 4 and D is the 4th letter</span></a>
<a class="sourceLine" id="cb516-7" data-line-number="7"></a>
<a class="sourceLine" id="cb516-8" data-line-number="8"><span class="co"># Finally, if you wanted to write the design to a file, you can do this in the normal manner </span></a>
<a class="sourceLine" id="cb516-9" data-line-number="9"><span class="co"># and it will write what you see in the main data frame.  For example:</span></a>
<a class="sourceLine" id="cb516-10" data-line-number="10"><span class="kw">write.csv</span>(myDesign, <span class="st">&#39;../docsArchive/_Chapter4_ProblemSets/myDesign.csv&#39;</span>, <span class="dt">row.names =</span> F)</a></code></pre></div>
<p>Regardless of how you choose to build a design, once you have the design and the responses, you can use the information available to assess the effects. Consider the following results:</p>
<div class="sourceCode" id="cb517"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb517-1" data-line-number="1">exampleData &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb517-2" data-line-number="2">  <span class="dt">TC =</span> <span class="kw">c</span>(<span class="st">&#39;(1)&#39;</span>, <span class="st">&#39;ad&#39;</span>, <span class="st">&#39;bd&#39;</span>, <span class="st">&#39;ab&#39;</span>, <span class="st">&#39;cd&#39;</span>, <span class="st">&#39;ac&#39;</span>, <span class="st">&#39;bc&#39;</span>, <span class="st">&#39;abcd&#39;</span>),</a>
<a class="sourceLine" id="cb517-3" data-line-number="3">  <span class="dt">A =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">4</span>),</a>
<a class="sourceLine" id="cb517-4" data-line-number="4">  <span class="dt">B =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb517-5" data-line-number="5">  <span class="dt">C =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">4</span>)), </a>
<a class="sourceLine" id="cb517-6" data-line-number="6">  <span class="dt">D =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">-1</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb517-7" data-line-number="7">  <span class="dt">Response =</span> <span class="kw">c</span>(<span class="dv">45</span>, <span class="dv">100</span>, <span class="dv">45</span>, <span class="dv">65</span>, <span class="dv">75</span>, <span class="dv">60</span>, <span class="dv">80</span>, <span class="dv">96</span>)</a>
<a class="sourceLine" id="cb517-8" data-line-number="8">)</a>
<a class="sourceLine" id="cb517-9" data-line-number="9"></a>
<a class="sourceLine" id="cb517-10" data-line-number="10">exampleData &lt;-<span class="st"> </span>exampleData <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb517-11" data-line-number="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">AB =</span> A<span class="op">*</span>B, <span class="dt">AC =</span> A<span class="op">*</span>C, <span class="dt">AD =</span> A<span class="op">*</span>D, <span class="dt">BC =</span> B<span class="op">*</span>C, <span class="dt">BD =</span> B<span class="op">*</span>D, <span class="dt">CD =</span> C<span class="op">*</span>D)</a>
<a class="sourceLine" id="cb517-12" data-line-number="12"></a>
<a class="sourceLine" id="cb517-13" data-line-number="13">exampleData</a></code></pre></div>
<pre><code>##     TC  A  B  C  D Response AB AC AD BC BD CD
## 1  (1) -1 -1 -1 -1       45  1  1  1  1  1  1
## 2   ad  1 -1 -1  1      100 -1 -1  1  1 -1 -1
## 3   bd -1  1 -1  1       45 -1  1 -1 -1  1 -1
## 4   ab  1  1 -1 -1       65  1 -1 -1 -1 -1  1
## 5   cd -1 -1  1  1       75  1 -1 -1 -1 -1  1
## 6   ac  1 -1  1 -1       60 -1  1 -1 -1  1 -1
## 7   bc -1  1  1 -1       80 -1 -1  1  1 -1 -1
## 8 abcd  1  1  1  1       96  1  1  1  1  1  1</code></pre>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb519-1" data-line-number="1"><span class="co"># Note that in our data frame, the factors and response are listed as doubles (i.e., numeric)</span></a>
<a class="sourceLine" id="cb519-2" data-line-number="2"><span class="co"># This is advantageous to us to calculate the effects</span></a></code></pre></div>
<p><strong>Visualize the data</strong>: It is always a good practice to visualize the data. We can do that as follows:</p>
<p>Main effects visualization:</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb520-1" data-line-number="1">ggpubr<span class="op">::</span><span class="kw">ggarrange</span>(</a>
<a class="sourceLine" id="cb520-2" data-line-number="2">  <span class="kw">ggplot</span>(exampleData) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-3" data-line-number="3"><span class="st">    </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-4" data-line-number="4"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;Factor A&#39;</span>),</a>
<a class="sourceLine" id="cb520-5" data-line-number="5">  <span class="kw">ggplot</span>(exampleData) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-6" data-line-number="6"><span class="st">    </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(B), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-7" data-line-number="7"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;Factor B&#39;</span>),</a>
<a class="sourceLine" id="cb520-8" data-line-number="8">  <span class="kw">ggplot</span>(exampleData) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-9" data-line-number="9"><span class="st">    </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(C), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-10" data-line-number="10"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;Factor C&#39;</span>),</a>
<a class="sourceLine" id="cb520-11" data-line-number="11">  <span class="kw">ggplot</span>(exampleData) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-12" data-line-number="12"><span class="st">    </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(D), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb520-13" data-line-number="13"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&#39;Factor D&#39;</span>)</a>
<a class="sourceLine" id="cb520-14" data-line-number="14">)</a></code></pre></div>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>It appears that C and D are almost certainly significant, and probably A. It is unlikely that B is. It is also possible that these effects could be from the corresponding aliased third order interactions, though we assess that as unlikely given the sparsity of effects principle. Keep in mind, there are only four data points in each of the “boxes.”</p>
<p>Interaction effects:</p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb521-1" data-line-number="1">ggpubr<span class="op">::</span><span class="kw">ggarrange</span>(</a>
<a class="sourceLine" id="cb521-2" data-line-number="2">  <span class="co"># These plots are created in the same way as we have done other plots</span></a>
<a class="sourceLine" id="cb521-3" data-line-number="3">  <span class="co"># Just note it is convenient to convert the factors to factor types for visualization</span></a>
<a class="sourceLine" id="cb521-4" data-line-number="4">  <span class="kw">ggplot</span>(exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">B =</span> <span class="kw">as.factor</span>(B), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D)), </a>
<a class="sourceLine" id="cb521-5" data-line-number="5">         <span class="kw">aes</span>(<span class="dt">x =</span> A, <span class="dt">y =</span> Response, <span class="dt">group =</span> B, <span class="dt">color =</span> B)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-6" data-line-number="6"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-7" data-line-number="7"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-8" data-line-number="8"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;AB Interaction&#39;</span>), </a>
<a class="sourceLine" id="cb521-9" data-line-number="9"></a>
<a class="sourceLine" id="cb521-10" data-line-number="10">  <span class="kw">ggplot</span>(exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">B =</span> <span class="kw">as.factor</span>(B), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D)), </a>
<a class="sourceLine" id="cb521-11" data-line-number="11">         <span class="kw">aes</span>(<span class="dt">x =</span> A, <span class="dt">y =</span> Response, <span class="dt">group =</span> C, <span class="dt">color =</span> C)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-12" data-line-number="12"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-13" data-line-number="13"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-14" data-line-number="14"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;AC Interaction&#39;</span>),</a>
<a class="sourceLine" id="cb521-15" data-line-number="15">  </a>
<a class="sourceLine" id="cb521-16" data-line-number="16">  <span class="kw">ggplot</span>(exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">B =</span> <span class="kw">as.factor</span>(B), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D)), </a>
<a class="sourceLine" id="cb521-17" data-line-number="17">         <span class="kw">aes</span>(<span class="dt">x =</span> A, <span class="dt">y =</span> Response, <span class="dt">group =</span> D, <span class="dt">color =</span> D)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-18" data-line-number="18"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-19" data-line-number="19"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb521-20" data-line-number="20"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;AD Interaction&#39;</span>),</a>
<a class="sourceLine" id="cb521-21" data-line-number="21">  </a>
<a class="sourceLine" id="cb521-22" data-line-number="22">  <span class="kw">ggplot</span>(exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">B =</span> <span class="kw">as.factor</span>(B), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D)), </a>
<a class="sourceLine" id="cb521-23" data-line-number="23">         <span class="kw">aes</span>(<span class="dt">x =</span> B, <span class="dt">y =</span> Response, <span class="dt">group =</span> C, <span class="dt">color =</span> C)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-24" data-line-number="24"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-25" data-line-number="25"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-26" data-line-number="26"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;BC Interaction&#39;</span>),</a>
<a class="sourceLine" id="cb521-27" data-line-number="27"></a>
<a class="sourceLine" id="cb521-28" data-line-number="28">  <span class="kw">ggplot</span>(exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">B =</span> <span class="kw">as.factor</span>(B), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D)), </a>
<a class="sourceLine" id="cb521-29" data-line-number="29">         <span class="kw">aes</span>(<span class="dt">x =</span> B, <span class="dt">y =</span> Response, <span class="dt">group =</span> D, <span class="dt">color =</span> D)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-30" data-line-number="30"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-31" data-line-number="31"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-32" data-line-number="32"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;BD Interaction&#39;</span>),</a>
<a class="sourceLine" id="cb521-33" data-line-number="33">  </a>
<a class="sourceLine" id="cb521-34" data-line-number="34">  <span class="kw">ggplot</span>(exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">B =</span> <span class="kw">as.factor</span>(B), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D)), </a>
<a class="sourceLine" id="cb521-35" data-line-number="35">    <span class="kw">aes</span>(<span class="dt">x =</span> C, <span class="dt">y =</span> Response, <span class="dt">group =</span> D, <span class="dt">color =</span> D)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-36" data-line-number="36"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-37" data-line-number="37"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb521-38" data-line-number="38"><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&#39;CD Interaction&#39;</span>)</a>
<a class="sourceLine" id="cb521-39" data-line-number="39">)</a></code></pre></div>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>We can say from this that there is an interaction effect between either AC or BD (as they are aliased) and also between AD or BC (as they are aliased). It does not appear that there is much of an interaction occuring between AB or CD.</p>
<p><strong>Calculate the Effects</strong>: We can calculate the effects using our formula:</p>
<ul>
<li><span class="math inline">\([A] = [BCD] \to A + BCD =\)</span> 19.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$A * exampleData$Response)</code></li>
</ul></li>
<li><span class="math inline">\([B] = [ACD] \to B + ACD =\)</span> 1.5.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$B * exampleData$Response)</code></li>
</ul></li>
<li><span class="math inline">\([C] = [ABD] \to C + ABD =\)</span> 14.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$C * exampleData$Response)</code></li>
</ul></li>
<li><span class="math inline">\([D] = [ABC] \to D + ABC =\)</span> 16.5.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$D * exampleData$Response)</code></li>
</ul></li>
<li><span class="math inline">\([AB] = [CD] \to AB + CD =\)</span> -1.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$AB * exampleData$Response)</code></li>
</ul></li>
<li><span class="math inline">\([AC] = [BD] \to AC + BD =\)</span> -18.5.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$AC * exampleData$Response)</code></li>
</ul></li>
<li><span class="math inline">\([AD] = [BC] \to AD + BC =\)</span> 19.
<ul>
<li>We calculate this using the contrasts: <code>(2^-(4-1-1))*sum(exampleData$AD * exampleData$Response)</code></li>
</ul></li>
</ul>
<p>From this, we can generally conclude that, if we assume third order interaction effects are negligible, (i.e. <span class="math inline">\(ABC \approx ABD \approx ACD \approx BCD \approx 0\)</span>), we can conclude that <span class="math inline">\(A\)</span>, <span class="math inline">\(C\)</span>, and <span class="math inline">\(D\)</span> are significant. The second-order interaction effects require a somewhat more nuance approach:</p>
<ul>
<li>For the <span class="math inline">\(AB\)</span> / <span class="math inline">\(CD\)</span> interaction, we see the effect is close to zero. We can interpret this as <span class="math inline">\(AB \approx CD \approx 0\)</span>. Alternatively, it is possible that <span class="math inline">\(AB \approx -CD\)</span> and that both are significant but in opposite ways.</li>
<li>For the <span class="math inline">\(AC\)</span> / <span class="math inline">\(BD\)</span> and the <span class="math inline">\(AD\)</span> / <span class="math inline">\(BD\)</span> interactions we can interpret that either both have moderate effects or that a single one of the interactions has a large effect.<br />
</li>
<li>In both instances above, it is impossible to know for certain what the absolutely correct interpretation is without additional testing. However we may make some reasonable assumptions:
<ul>
<li>We have good reason to believe that <span class="math inline">\(B\)</span> is negligible. We can therefore, most simply assume that the interactions without <span class="math inline">\(B\)</span> are likely to be more significant. That is, if, for example, <span class="math inline">\(A\)</span> is significant, we can say an interaction with <span class="math inline">\(A\)</span>, e.g., <span class="math inline">\(AC\)</span>, is more likely to be significant as this is the most simple explanation.</li>
<li>This <strong>does not</strong> conclusively say that the above statements are true, it simply is a reasonable logic in absence of other information. One should use their system specific subject matter expertise and / or conduct additional testing if this is important.</li>
</ul></li>
</ul>
<p><strong>ANOVA:</strong> We can conduct an ANOVA to confirm mathematically what we have already observed. As we have already shown that <span class="math inline">\(B\)</span> is likely not signficant, we can gain some information by dropping it as a factor and effectively gaining design points to have an unreplicated <span class="math inline">\(2^3\)</span> design (i.e., projecting our design onto that design).</p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb522-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">aov</span>(Response <span class="op">~</span><span class="st"> </span>A <span class="op">+</span><span class="st"> </span>C <span class="op">+</span><span class="st"> </span>D <span class="op">+</span><span class="st"> </span>A<span class="op">:</span>C <span class="op">+</span><span class="st"> </span>A<span class="op">:</span>D <span class="op">+</span><span class="st"> </span>C<span class="op">:</span>D, <span class="dt">data =</span> exampleData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">A =</span> <span class="kw">as.factor</span>(A), <span class="dt">C =</span> <span class="kw">as.factor</span>(C), <span class="dt">D =</span> <span class="kw">as.factor</span>(D))))</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## A            1  722.0   722.0 160.444 0.0502 .
## C            1  392.0   392.0  87.111 0.0680 .
## D            1  544.5   544.5 121.000 0.0577 .
## A:C          1  684.5   684.5 152.111 0.0515 .
## A:D          1  722.0   722.0 160.444 0.0502 .
## C:D          1    2.0     2.0   0.444 0.6257  
## Residuals    1    4.5     4.5                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We see through this that what we stated in our effects analysis appears to be generally true. <span class="math inline">\(A\)</span>, <span class="math inline">\(C\)</span>, <span class="math inline">\(D\)</span>, <span class="math inline">\(AC\)</span>, and <span class="math inline">\(AD\)</span> all are potentially significant (though we get realitvely weak p-values given the lack of replication).</p>
<p>Finally, through this example, it is important to note a few things when doing statistics:</p>
<ul>
<li>Look at the results through multiple “lenses.” For example, here we used graphs, effects, and ANOVA to understand something about the problem.</li>
<li>Use logic to think through most likely results in absence of other information. We did this with the discussion of second-order effects. All things being equal, a simpler model is generally better than a more complex one.</li>
<li>Use non-statistical knowledge about the problem. We did this problem “in the blind” here, but the reality is that we should have subject matter experts help us to interpret the data in a meaningful way.</li>
<li>Use the knowledge gained in one experiment to inform future experiments. In this case, we could use the knowledge we have to conduct another experiment with more runs with perhaps just A, C, and D to gain more information.</li>
</ul>
</div>
<div id="frac12-fractional-factorial-design-2k-1-problem-set" class="section level3">
<h3><span class="header-section-number">6.2.6</span> <span class="math inline">\(\frac{1}{2}\)</span> Fractional Factorial Design (<span class="math inline">\(2^{K-1}\)</span>) Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter4_ProblemSets/Half_Fractional_Factorial_Design_PS_Questions.html'> here </a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter4_ProblemSets/Half_Fractional_Factorial_Design_PS_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter4_ProblemSets/Half_Fractional_Factorial_Design_PS_Answer.html'> here </a>.</p>
<!--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------->
</div>
</div>
<div id="general-2k-p-designs" class="section level2">
<h2><span class="header-section-number">6.3</span> General <span class="math inline">\(2^{K-P}\)</span> Designs</h2>
<div id="introduction-6" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Introduction</h3>
<p>Often even half fractional factorial designs do not sufficiently reduce the number of requiste tests relative to the resources available. Fortuntately, we can continue the concepts we introduced in a half fractional factorial design by considering fractions of the form <span class="math inline">\(\frac{1}{2^P}\)</span> - i.e., half, quarter, eighth, etc.</p>
</div>
<div id="quarter-fractional-design" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Quarter Fractional Design</h3>
<p>Consider an experiment with six factors (<span class="math inline">\(A, B, C, D, E, F\)</span>), each with a high <span class="math inline">\(+1\)</span> and low <span class="math inline">\(-1\)</span> level. If one executed this as a full factorial design, there would be <span class="math inline">\(2^6 = 64\)</span> treatment combinations to test. A <span class="math inline">\(2^{6-1}\)</span> design would have 32 treatment combinations. This may, however, even be too much. We can opt for even fewer runs, with a <span class="math inline">\(2^{6-2}\)</span> quarter fractional factorial design. To do this, we must identify two generators. Consider the choice of <span class="math inline">\(I = ABCE\)</span> and <span class="math inline">\(I = BCDF\)</span> as generators for this design. We can learn a few things:</p>
<ol style="list-style-type: decimal">
<li>With multiple generators, we have a generalized interaction. As <span class="math inline">\(I = ABCE = BCDF\)</span> and <span class="math inline">\(I \cdot I = I\)</span>, we can also say <span class="math inline">\(I = ABCE \cdot BCDF = AB^2C^2DEF = ADEF\)</span>.</li>
<li>We can then identify the alias structure by multiplying any factor or interaction by these generators. For example:
<ul>
<li><span class="math inline">\(A = A \cdot ABCE = BCE\)</span></li>
<li><span class="math inline">\(A = A \cdot BCDF = ABCDF\)</span></li>
<li><span class="math inline">\(A = A \cdot ADEF = DEF\)</span></li>
<li>Thus, when we are estimating the effect of <span class="math inline">\(A\)</span> with <span class="math inline">\([A]\)</span> we are really estimating <span class="math inline">\(A + BCE + ABCDF + DEF\)</span>.</li>
</ul></li>
<li>By inspection, we can see that every main effect is aliased with third or higher order interactions, and every 2nd order effect is aliased with either 2nd or higher order interactions.</li>
</ol>
<p>We can see the complete alias structure in the following table:</p>
<center>
<table>
<tbody>
<tr class="odd">
<td><span class="math inline">\(A = BCE = DEF = ABCDF\)</span></td>
<td>         </td>
<td><span class="math inline">\(AB = CE = ACDF = BDEF\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(B = ACE = CDF = ABDEF\)</span></td>
<td></td>
<td><span class="math inline">\(AC = BE = ABDF = CDEF\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(C = ABE = BDF = ACDEF\)</span></td>
<td></td>
<td><span class="math inline">\(AD = EF = BCDE = ABCF\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(D = BCF = AEF = ABCDE\)</span></td>
<td></td>
<td><span class="math inline">\(AE = BC = DF = ABCDEF\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(E = ABC = ADF = BCDEF\)</span></td>
<td></td>
<td><span class="math inline">\(AF = DE = BCEF = ABCD\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(F = BCD = ADE = ABCEF\)</span></td>
<td></td>
<td><span class="math inline">\(BD = CF = ACDE = ABEF\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td><span class="math inline">\(BF = CD = ACEF = ABDE\)</span></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(ABD = CDE = ACF = BEF\)</span></td>
<td></td>
<td><span class="math inline">\(ACD = BDE = ABF = CEF\)</span></td>
</tr>
</tbody>
</table>
</center>
<p>We can also see this in <em>R</em> as follows:</p>
<p>We can do it manually:</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb524-1" data-line-number="1"><span class="co"># ID the table</span></a>
<a class="sourceLine" id="cb524-2" data-line-number="2">myData &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb524-3" data-line-number="3">  <span class="dt">A =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="dv">32</span>),</a>
<a class="sourceLine" id="cb524-4" data-line-number="4">  <span class="dt">B =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb524-5" data-line-number="5">  <span class="dt">C =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">4</span>)), <span class="dv">8</span>),</a>
<a class="sourceLine" id="cb524-6" data-line-number="6">  <span class="dt">D =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">8</span>)), <span class="dv">4</span>),</a>
<a class="sourceLine" id="cb524-7" data-line-number="7">  <span class="dt">E =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">16</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">16</span>)), <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb524-8" data-line-number="8">  <span class="dt">F =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">32</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">32</span>))</a>
<a class="sourceLine" id="cb524-9" data-line-number="9">)</a>
<a class="sourceLine" id="cb524-10" data-line-number="10"></a>
<a class="sourceLine" id="cb524-11" data-line-number="11">myDesign &lt;-<span class="st"> </span>myData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(A<span class="op">*</span>B<span class="op">*</span>C<span class="op">*</span>E <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>B<span class="op">*</span>C<span class="op">*</span>D<span class="op">*</span>F <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>A<span class="op">*</span>D<span class="op">*</span>E<span class="op">*</span>F <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb524-12" data-line-number="12">myDesign</a></code></pre></div>
<pre><code>##     A  B  C  D  E  F
## 1  -1 -1 -1 -1 -1 -1
## 2  -1  1  1 -1 -1 -1
## 3   1  1 -1  1 -1 -1
## 4   1 -1  1  1 -1 -1
## 5   1 -1 -1 -1  1 -1
## 6   1  1  1 -1  1 -1
## 7  -1  1 -1  1  1 -1
## 8  -1 -1  1  1  1 -1
## 9   1  1 -1 -1 -1  1
## 10  1 -1  1 -1 -1  1
## 11 -1 -1 -1  1 -1  1
## 12 -1  1  1  1 -1  1
## 13 -1  1 -1 -1  1  1
## 14 -1 -1  1 -1  1  1
## 15  1 -1 -1  1  1  1
## 16  1  1  1  1  1  1</code></pre>
<p>This of course starts to become laborious and does not immediately show us the alias structure. Alternatively, we can use a package like <code>FrF2</code></p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb526-1" data-line-number="1"><span class="co"># To get a fractional factorial design using FrF2 we must specify a number of things:</span></a>
<a class="sourceLine" id="cb526-2" data-line-number="2"><span class="co"># First, we specify the number of factors: `nfactors`.  This is straight forward.</span></a>
<a class="sourceLine" id="cb526-3" data-line-number="3"><span class="co"># Second we specify the number of runs: `nruns`.  This must be some power of 2.  In particular, </span></a>
<a class="sourceLine" id="cb526-4" data-line-number="4"><span class="co">#   it is 2^(K-P)</span></a>
<a class="sourceLine" id="cb526-5" data-line-number="5"><span class="co"># Third we specify the generators.  This is (IMHO) not intuitive.  It works as follows (as best I can see):</span></a>
<a class="sourceLine" id="cb526-6" data-line-number="6"><span class="co"># you supply it with a a vector of P generators, where you are giving it the short hand for</span></a>
<a class="sourceLine" id="cb526-7" data-line-number="7"><span class="co"># a main factor is aliased with xyz... this is best seen through an example</span></a>
<a class="sourceLine" id="cb526-8" data-line-number="8"><span class="co"># In our example, we had I = ABCE and I = BCDF</span></a>
<a class="sourceLine" id="cb526-9" data-line-number="9"><span class="co"># FrF2 wants a vector that corresponds to: c(E = ..., F = ...)</span></a>
<a class="sourceLine" id="cb526-10" data-line-number="10"><span class="co"># We get that by saying: E*I = E*ABCE = ABC and</span></a>
<a class="sourceLine" id="cb526-11" data-line-number="11"><span class="co">#   F*I = F*BCDF = BCD</span></a>
<a class="sourceLine" id="cb526-12" data-line-number="12"><span class="co"># So we supply the function the vector as seen below</span></a>
<a class="sourceLine" id="cb526-13" data-line-number="13"></a>
<a class="sourceLine" id="cb526-14" data-line-number="14"><span class="co"># Finally, note that we opted for randomize as false, as we want to be able to directly compare our results</span></a>
<a class="sourceLine" id="cb526-15" data-line-number="15"><span class="co"># and we choose alias.info to go to third order interactions</span></a>
<a class="sourceLine" id="cb526-16" data-line-number="16">myDesign.FrF2 &lt;-<span class="st"> </span>FrF2<span class="op">::</span><span class="kw">FrF2</span>(<span class="dt">nfactors =</span> <span class="dv">6</span>, <span class="dt">nruns =</span> <span class="dv">16</span>, <span class="dt">generators =</span> <span class="kw">c</span>(<span class="st">&#39;ABC&#39;</span>, <span class="st">&#39;BCD&#39;</span>), <span class="dt">randomize =</span> F, <span class="dt">alias.info =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb526-17" data-line-number="17"></a>
<a class="sourceLine" id="cb526-18" data-line-number="18">myDesign.FrF2</a></code></pre></div>
<pre><code>##     A  B  C  D  E  F
## 1  -1 -1 -1 -1 -1 -1
## 2   1 -1 -1 -1  1 -1
## 3  -1  1 -1 -1  1  1
## 4   1  1 -1 -1 -1  1
## 5  -1 -1  1 -1  1  1
## 6   1 -1  1 -1 -1  1
## 7  -1  1  1 -1 -1 -1
## 8   1  1  1 -1  1 -1
## 9  -1 -1 -1  1 -1  1
## 10  1 -1 -1  1  1  1
## 11 -1  1 -1  1  1 -1
## 12  1  1 -1  1 -1 -1
## 13 -1 -1  1  1  1 -1
## 14  1 -1  1  1 -1 -1
## 15 -1  1  1  1 -1  1
## 16  1  1  1  1  1  1
## class=design, type= FrF2.generators</code></pre>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb528-1" data-line-number="1"><span class="co"># When we view this we can see that this is the same design as we produced manually, </span></a>
<a class="sourceLine" id="cb528-2" data-line-number="2"></a>
<a class="sourceLine" id="cb528-3" data-line-number="3"><span class="co"># We can further ascertain the alias structure from this design as shown in the previous section:</span></a>
<a class="sourceLine" id="cb528-4" data-line-number="4"><span class="kw">attr</span>(myDesign.FrF2, <span class="st">&quot;design.info&quot;</span>)</a></code></pre></div>
<pre><code>## $type
## [1] &quot;FrF2.generators&quot;
## 
## $nruns
## [1] 16
## 
## $nfactors
## [1] 6
## 
## $factor.names
## $factor.names$A
## [1] -1  1
## 
## $factor.names$B
## [1] -1  1
## 
## $factor.names$C
## [1] -1  1
## 
## $factor.names$D
## [1] -1  1
## 
## $factor.names$E
## [1] -1  1
## 
## $factor.names$F
## [1] -1  1
## 
## 
## $generators
## [1] &quot;E=ABC&quot; &quot;F=BCD&quot;
## 
## $aliased
## $aliased$legend
## [1] &quot;A=A&quot; &quot;B=B&quot; &quot;C=C&quot; &quot;D=D&quot; &quot;E=E&quot; &quot;F=F&quot;
## 
## $aliased$main
## [1] &quot;A=BCE=DEF&quot; &quot;B=ACE=CDF&quot; &quot;C=ABE=BDF&quot; &quot;D=AEF=BCF&quot; &quot;E=ABC=ADF&quot; &quot;F=ADE=BCD&quot;
## 
## $aliased$fi2
## [1] &quot;AB=CE&quot;    &quot;AC=BE&quot;    &quot;AD=EF&quot;    &quot;AE=BC=DF&quot; &quot;AF=DE&quot;    &quot;BD=CF&quot;    &quot;BF=CD&quot;   
## 
## $aliased$fi3
## [1] &quot;ABD=ACF=BEF=CDE&quot; &quot;ABF=ACD=BDE=CEF&quot;
## 
## 
## $FrF2.version
## [1] &quot;2.3-2&quot;
## 
## $replications
## [1] 1
## 
## $repeat.only
## [1] FALSE
## 
## $randomize
## [1] FALSE
## 
## $seed
## NULL
## 
## $creator
## FrF2::FrF2(nfactors = 6, nruns = 16, generators = c(&quot;ABC&quot;, &quot;BCD&quot;), 
##     randomize = F, alias.info = 3)</code></pre>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb530-1" data-line-number="1"><span class="co"># Again, we can compare this to our earlier results and see that our alias structure is the same</span></a>
<a class="sourceLine" id="cb530-2" data-line-number="2"><span class="co"># Though the function does not calculate fourth or higher interactions as they are assumed to be irrelevant</span></a>
<a class="sourceLine" id="cb530-3" data-line-number="3"><span class="co"># If necessary, you can clearly calculate these by hand</span></a></code></pre></div>
<p>With this information, we can analyze the results of an experiment in a manner similar to previous analyses. For example, we will use this same design and data from <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> Example 8.4.</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb531-1" data-line-number="1"><span class="co"># This is the response data from our experiment</span></a>
<a class="sourceLine" id="cb531-2" data-line-number="2">myDesign<span class="op">$</span>Response &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">26</span>, <span class="dv">60</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">60</span>, <span class="dv">34</span>, <span class="dv">16</span>, <span class="dv">60</span>, <span class="dv">15</span>, <span class="dv">8</span>, <span class="dv">37</span>, <span class="dv">32</span>, <span class="dv">4</span>, <span class="dv">12</span>, <span class="dv">52</span>)</a>
<a class="sourceLine" id="cb531-3" data-line-number="3"></a>
<a class="sourceLine" id="cb531-4" data-line-number="4"><span class="co"># We can visualize our data:</span></a>
<a class="sourceLine" id="cb531-5" data-line-number="5"></a>
<a class="sourceLine" id="cb531-6" data-line-number="6">ggpubr<span class="op">::</span><span class="kw">ggarrange</span>(</a>
<a class="sourceLine" id="cb531-7" data-line-number="7">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb531-8" data-line-number="8"><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;A&#39;</span>), </a>
<a class="sourceLine" id="cb531-9" data-line-number="9">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(B), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb531-10" data-line-number="10"><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;B&#39;</span>), </a>
<a class="sourceLine" id="cb531-11" data-line-number="11">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(C), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb531-12" data-line-number="12"><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;C&#39;</span>), </a>
<a class="sourceLine" id="cb531-13" data-line-number="13">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(D), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb531-14" data-line-number="14"><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;D&#39;</span>), </a>
<a class="sourceLine" id="cb531-15" data-line-number="15">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(E), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb531-16" data-line-number="16"><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;E&#39;</span>), </a>
<a class="sourceLine" id="cb531-17" data-line-number="17">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(F), <span class="dt">y =</span> Response)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb531-18" data-line-number="18"><span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;F&#39;</span>)</a>
<a class="sourceLine" id="cb531-19" data-line-number="19">)</a></code></pre></div>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb532-1" data-line-number="1"><span class="co"># We can see that its quite apparent that B has an effect, and also likely A</span></a>
<a class="sourceLine" id="cb532-2" data-line-number="2"></a>
<a class="sourceLine" id="cb532-3" data-line-number="3"><span class="co"># We can visualize 2-way interactions:</span></a>
<a class="sourceLine" id="cb532-4" data-line-number="4"><span class="co"># I broke these into two groups, b/c there are so many.  </span></a>
<a class="sourceLine" id="cb532-5" data-line-number="5"></a>
<a class="sourceLine" id="cb532-6" data-line-number="6">ggpubr<span class="op">::</span><span class="kw">ggarrange</span>(</a>
<a class="sourceLine" id="cb532-7" data-line-number="7">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(B), <span class="dt">group =</span> <span class="kw">as.factor</span>(B))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-8" data-line-number="8"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-9" data-line-number="9">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(C), <span class="dt">group =</span> <span class="kw">as.factor</span>(C))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-10" data-line-number="10"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-11" data-line-number="11">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(D), <span class="dt">group =</span> <span class="kw">as.factor</span>(D))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-12" data-line-number="12"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-13" data-line-number="13">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(E), <span class="dt">group =</span> <span class="kw">as.factor</span>(E))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-14" data-line-number="14"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-15" data-line-number="15">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(A), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(F), <span class="dt">group =</span> <span class="kw">as.factor</span>(F))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-16" data-line-number="16"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-17" data-line-number="17">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(B), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(C), <span class="dt">group =</span> <span class="kw">as.factor</span>(C))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-18" data-line-number="18"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-19" data-line-number="19">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(B), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(D), <span class="dt">group =</span> <span class="kw">as.factor</span>(D))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-20" data-line-number="20"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb532-21" data-line-number="21">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(B), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(E), <span class="dt">group =</span> <span class="kw">as.factor</span>(E))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb532-22" data-line-number="22"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>)</a>
<a class="sourceLine" id="cb532-23" data-line-number="23">)</a></code></pre></div>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb533-1" data-line-number="1">ggpubr<span class="op">::</span><span class="kw">ggarrange</span>(</a>
<a class="sourceLine" id="cb533-2" data-line-number="2">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(B), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(F), <span class="dt">group =</span> <span class="kw">as.factor</span>(F))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-3" data-line-number="3"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb533-4" data-line-number="4">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(C), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(D), <span class="dt">group =</span> <span class="kw">as.factor</span>(D))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-5" data-line-number="5"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb533-6" data-line-number="6">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(C), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(E), <span class="dt">group =</span> <span class="kw">as.factor</span>(E))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-7" data-line-number="7"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb533-8" data-line-number="8">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(C), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(F), <span class="dt">group =</span> <span class="kw">as.factor</span>(F))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-9" data-line-number="9"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb533-10" data-line-number="10">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(D), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(E), <span class="dt">group =</span> <span class="kw">as.factor</span>(E))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-11" data-line-number="11"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb533-12" data-line-number="12">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(D), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(F), <span class="dt">group =</span> <span class="kw">as.factor</span>(F))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-13" data-line-number="13"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>),</a>
<a class="sourceLine" id="cb533-14" data-line-number="14">  <span class="kw">ggplot</span>(myDesign, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">as.factor</span>(E), <span class="dt">y =</span> Response, <span class="dt">color =</span> <span class="kw">as.factor</span>(F), <span class="dt">group =</span> <span class="kw">as.factor</span>(F))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb533-15" data-line-number="15"><span class="st">    </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;line&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">stat_summary</span>(<span class="dt">fun =</span> <span class="st">&#39;mean&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;point&#39;</span>)</a>
<a class="sourceLine" id="cb533-16" data-line-number="16">)</a></code></pre></div>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-22-3.png" width="672" /></p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb534-1" data-line-number="1"><span class="co"># We see potential interactions among the following: AB, AD, CE, DE, DF, EF</span></a>
<a class="sourceLine" id="cb534-2" data-line-number="2"></a>
<a class="sourceLine" id="cb534-3" data-line-number="3"><span class="co"># We can estimate the effects in the same way we have been doing:</span></a>
<a class="sourceLine" id="cb534-4" data-line-number="4"><span class="co"># Recall we can estimate effects with the following formula (1/(n*2^(K-P-1)))([Factor Column]*[Column of response])</span></a>
<a class="sourceLine" id="cb534-5" data-line-number="5">Effect.A &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>A<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-6" data-line-number="6">Effect.B &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>B<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-7" data-line-number="7">Effect.C &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>C<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-8" data-line-number="8">Effect.D &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>D<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-9" data-line-number="9">Effect.E &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>E<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-10" data-line-number="10">Effect.F &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>F<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-11" data-line-number="11">Effect.AB.CE &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>A<span class="op">*</span>myDesign<span class="op">$</span>B<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-12" data-line-number="12">Effect.AC.BE &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>A<span class="op">*</span>myDesign<span class="op">$</span>C<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-13" data-line-number="13">Effect.AD.EF &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>A<span class="op">*</span>myDesign<span class="op">$</span>D<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-14" data-line-number="14">Effect.AE.BC.DF &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>A<span class="op">*</span>myDesign<span class="op">$</span>E<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-15" data-line-number="15">Effect.AF.DE &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>A<span class="op">*</span>myDesign<span class="op">$</span>F<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-16" data-line-number="16">Effect.BD.CF &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>B<span class="op">*</span>myDesign<span class="op">$</span>D<span class="op">*</span>myDesign<span class="op">$</span>Response)</a>
<a class="sourceLine" id="cb534-17" data-line-number="17">Effect.BF.CE &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">8</span>)<span class="op">*</span><span class="kw">sum</span>(myDesign<span class="op">$</span>B<span class="op">*</span>myDesign<span class="op">$</span>F<span class="op">*</span>myDesign<span class="op">$</span>Response)</a></code></pre></div>
<p>Recall that these estimates are really estimates of the sums of effects. For example <code>Effect.A</code> is really:</p>
<p><span class="math display">\[[A] = [BCE] = [DEF] = [ABCDF] = A + BCE + DEF + ABCDF\]</span></p>
<p>Which, if we assume higher order (3rd plus) effects are negligible (i.e., about 0), we can say:</p>
<p><span class="math display">\[[A] = A + BCE + DEF + ABCDF \approx A + 0 + 0 + 0 = A\]</span></p>
<p>Using our alias structure and analysis above, we can then say:</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb535-1" data-line-number="1"><span class="co"># This is not strictly necessary - we&#39;ve already identified the alias structure and should know this from that</span></a>
<a class="sourceLine" id="cb535-2" data-line-number="2"><span class="co"># In doing this, we are simply attempting to make it explict what the measured effects really are showing</span></a>
<a class="sourceLine" id="cb535-3" data-line-number="3"></a>
<a class="sourceLine" id="cb535-4" data-line-number="4">DT<span class="op">::</span><span class="kw">datatable</span>(</a>
<a class="sourceLine" id="cb535-5" data-line-number="5">  <span class="kw">data.frame</span>(<span class="dt">Effect.1 =</span> <span class="kw">c</span>(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>, <span class="st">&#39;C&#39;</span>, <span class="st">&#39;D&#39;</span>, <span class="st">&#39;E&#39;</span>, <span class="st">&#39;F&#39;</span>, <span class="st">&#39;AB&#39;</span>, <span class="st">&#39;AC&#39;</span>, <span class="st">&#39;AD&#39;</span>, <span class="st">&#39;AE&#39;</span>, <span class="st">&#39;AF&#39;</span>, <span class="st">&#39;BD&#39;</span>, <span class="st">&#39;BF&#39;</span>, <span class="st">&#39;ABD&#39;</span>, <span class="st">&#39;ACD&#39;</span> ),</a>
<a class="sourceLine" id="cb535-6" data-line-number="6">           <span class="dt">Effect.2 =</span> <span class="kw">c</span>(<span class="st">&#39;BCE&#39;</span>, <span class="st">&#39;ACE&#39;</span>, <span class="st">&#39;ABE&#39;</span>, <span class="st">&#39;BCF&#39;</span>, <span class="st">&#39;ABC&#39;</span>, <span class="st">&#39;BCD&#39;</span>, <span class="st">&#39;CE&#39;</span>, <span class="st">&#39;BE&#39;</span>, <span class="st">&#39;EF&#39;</span>, <span class="st">&#39;BC&#39;</span>, <span class="st">&#39;DE&#39;</span>, <span class="st">&#39;CF&#39;</span>, <span class="st">&#39;CD&#39;</span>, <span class="st">&#39;CDE&#39;</span>, <span class="st">&#39;BDE&#39;</span>),</a>
<a class="sourceLine" id="cb535-7" data-line-number="7">           <span class="dt">Effect.3 =</span> <span class="kw">c</span>(<span class="st">&#39;DEF&#39;</span>, <span class="st">&#39;CDF&#39;</span>, <span class="st">&#39;BDF&#39;</span>, <span class="st">&#39;AEF&#39;</span>, <span class="st">&#39;ADF&#39;</span>, <span class="st">&#39;ADE&#39;</span>, <span class="st">&#39;ACDF&#39;</span>, <span class="st">&#39;ABDF&#39;</span>, <span class="st">&#39;BCDE&#39;</span>, <span class="st">&#39;DF&#39;</span>, <span class="st">&#39;BCEF&#39;</span>, <span class="st">&#39;ACDE&#39;</span>, <span class="st">&#39;ACEF&#39;</span>, <span class="st">&#39;ACF&#39;</span>, <span class="st">&#39;ABF&#39;</span>),</a>
<a class="sourceLine" id="cb535-8" data-line-number="8">           <span class="dt">Effect.4 =</span> <span class="kw">c</span>(<span class="st">&#39;ABCDF&#39;</span>, <span class="st">&#39;ABDEF&#39;</span>, <span class="st">&#39;ACDEF&#39;</span>, <span class="st">&#39;ABCDE&#39;</span>, <span class="st">&#39;BCDEF&#39;</span>, <span class="st">&#39;ABCEF&#39;</span>, <span class="st">&#39;BDEF&#39;</span>, <span class="st">&#39;CDEF&#39;</span>, <span class="st">&#39;ABCF&#39;</span>, <span class="st">&#39;ABCDEF&#39;</span>, <span class="st">&#39;ABCD&#39;</span>, <span class="st">&#39;ABEF&#39;</span>, <span class="st">&#39;ABDE&#39;</span>, <span class="st">&#39;BEF&#39;</span>, <span class="st">&#39;CEF&#39;</span>),</a>
<a class="sourceLine" id="cb535-9" data-line-number="9">           <span class="dt">Effect =</span> <span class="kw">c</span>(Effect.A, Effect.B, Effect.C, Effect.D, Effect.E, Effect.F, Effect.AB.CE, Effect.AC.BE, Effect.AD.EF, Effect.AE.BC.DF, Effect.AF.DE, Effect.BD.CF, Effect.BF.CE, <span class="ot">NA</span>, <span class="ot">NA</span>)),</a>
<a class="sourceLine" id="cb535-10" data-line-number="10">  <span class="dt">rownames =</span> F, <span class="dt">options =</span> <span class="kw">list</span>(<span class="dt">pageLength =</span> <span class="dv">16</span>)) </a></code></pre></div>
<div id="htmlwidget-caa6848e77f8f7695084" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-caa6848e77f8f7695084">{"x":{"filter":"none","vertical":false,"data":[["A","B","C","D","E","F","AB","AC","AD","AE","AF","BD","BF","ABD","ACD"],["BCE","ACE","ABE","BCF","ABC","BCD","CE","BE","EF","BC","DE","CF","CD","CDE","BDE"],["DEF","CDF","BDF","AEF","ADF","ADE","ACDF","ABDF","BCDE","DF","BCEF","ACDE","ACEF","ACF","ABF"],["ABCDF","ABDEF","ACDEF","ABCDE","BCDEF","ABCEF","BDEF","CDEF","ABCF","ABCDEF","ABCD","ABEF","ABDE","BEF","CEF"],[13.875,35.625,-0.875,1.375,0.375,0.375,11.875,-1.625,-5.375,-1.875,0.625,-0.125,-0.125,null,null]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Effect.1<\/th>\n      <th>Effect.2<\/th>\n      <th>Effect.3<\/th>\n      <th>Effect.4<\/th>\n      <th>Effect<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":16,"columnDefs":[{"className":"dt-right","targets":4}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[10,16,25,50,100]},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<div class="sourceCode" id="cb536"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb536-1" data-line-number="1"><span class="co"># We can see from this that A, B and AB all have very apparent effects.  </span></a>
<a class="sourceLine" id="cb536-2" data-line-number="2"><span class="co"># We may also consider AD, though its effect is somewhat less</span></a>
<a class="sourceLine" id="cb536-3" data-line-number="3">    </a>
<a class="sourceLine" id="cb536-4" data-line-number="4"><span class="co"># We can also view this via an ANOVA</span></a>
<a class="sourceLine" id="cb536-5" data-line-number="5"><span class="co"># We can consider first the entire set of 2 factor interactions</span></a>
<a class="sourceLine" id="cb536-6" data-line-number="6"><span class="kw">summary</span>(<span class="kw">aov</span>(Response <span class="op">~</span><span class="st"> </span>(.)<span class="op">^</span><span class="dv">2</span>, <span class="dt">data =</span> myDesign))  </a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## A            1    770     770  16.191 0.05657 . 
## B            1   5077    5077 106.735 0.00924 **
## C            1      3       3   0.064 0.82339   
## D            1      8       8   0.159 0.72862   
## E            1      1       1   0.012 0.92333   
## F            1      1       1   0.012 0.92333   
## A:B          1    564     564  11.859 0.07496 . 
## A:C          1     11      11   0.222 0.68387   
## A:D          1    116     116   2.430 0.25939   
## A:E          1     14      14   0.296 0.64112   
## A:F          1      2       2   0.033 0.87288   
## B:D          1      0       0   0.001 0.97438   
## B:F          1      0       0   0.001 0.97438   
## Residuals    2     95      48                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb538-1" data-line-number="1"><span class="co"># We can also project this as a replicated design onto an experiment with just A and B as factors:</span></a>
<a class="sourceLine" id="cb538-2" data-line-number="2"><span class="kw">summary</span>(<span class="kw">aov</span>(Response <span class="op">~</span><span class="st"> </span>A <span class="op">+</span><span class="st"> </span>B <span class="op">+</span><span class="st"> </span>A<span class="op">:</span>B, <span class="dt">data =</span> myDesign))</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## A            1    770     770   37.15 5.38e-05 ***
## B            1   5077    5077  244.90 2.39e-09 ***
## A:B          1    564     564   27.21 0.000216 ***
## Residuals   12    249      21                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb540-1" data-line-number="1"><span class="co"># This makes it seem quite apparent that A, B and their interaction are significant</span></a></code></pre></div>
<p>At this point, we have done a fairly reasonably screening experiment. An analyst can then opt to do further experimentation with just varying A and B at different levels and building more detailed statistical models of the results.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a></p>
</div>
<div id="general-2k-p-design" class="section level3">
<h3><span class="header-section-number">6.3.3</span> General <span class="math inline">\(2^{K-P}\)</span> Design</h3>
<p>Of course, a quarter fraction is often not sufficient. Fortunately, we can continue the process we saw for half and quarter fractional factorial designs arbitrarily. We simply must have <span class="math inline">\(P\)</span> generators to to make a <span class="math inline">\(\frac{1}{2^P}\)</span> fractional design. These generators must be independent. That is, when the design is chosen, the generators cannot be aliased.</p>
<p>Doing this manually is certainly an option, however, it is more common to either look up a table of generators. These are typically contained in textbooks. There is alaso a useful example on the <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section3/pri3347.htm'> NIST Engineering Statistics Handbook </a>. Just note that various sources may use differing notations.</p>
<p>Further, you can use computer packages to generate designs. For example, we have used <code>FrF2</code>. In the previous example, we specified our generators; however, that is not required. For example, consider an experiment with 10 factors at two levels each. That would require 1024 treatment combinations in a full design. Consider the case where we might only be able to do <span class="math inline">\(2^6 = 64\)</span> tests. We would then want a <span class="math inline">\(2^{10-4}\)</span> design. We could use <code>FrF2</code> as follows:</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb541-1" data-line-number="1"><span class="co"># Note that we do not have to assign generators</span></a>
<a class="sourceLine" id="cb541-2" data-line-number="2">my.<span class="fl">10.</span>minus.<span class="fl">4.</span>design &lt;-<span class="st"> </span>FrF2<span class="op">::</span><span class="kw">FrF2</span>(<span class="dt">nfactors =</span> <span class="dv">10</span>, <span class="dt">nruns =</span> <span class="dv">64</span>, <span class="dt">randomize =</span> F, <span class="dt">alias.info =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb541-3" data-line-number="3"></a>
<a class="sourceLine" id="cb541-4" data-line-number="4"><span class="co"># We can view the design:</span></a>
<a class="sourceLine" id="cb541-5" data-line-number="5">my.<span class="fl">10.</span>minus.<span class="fl">4.</span>design</a></code></pre></div>
<pre><code>##     A  B  C  D  E  F  G  H  J  K
## 1  -1 -1 -1 -1 -1 -1 -1  1  1  1
## 2   1 -1 -1 -1 -1 -1  1 -1 -1 -1
## 3  -1  1 -1 -1 -1 -1  1 -1 -1  1
## 4   1  1 -1 -1 -1 -1 -1  1  1 -1
## 5  -1 -1  1 -1 -1 -1  1  1  1 -1
## 6   1 -1  1 -1 -1 -1 -1 -1 -1  1
## 7  -1  1  1 -1 -1 -1 -1 -1 -1 -1
## 8   1  1  1 -1 -1 -1  1  1  1  1
## 9  -1 -1 -1  1 -1 -1 -1 -1 -1  1
## 10  1 -1 -1  1 -1 -1  1  1  1 -1
## 11 -1  1 -1  1 -1 -1  1  1  1  1
## 12  1  1 -1  1 -1 -1 -1 -1 -1 -1
## 13 -1 -1  1  1 -1 -1  1 -1 -1 -1
## 14  1 -1  1  1 -1 -1 -1  1  1  1
## 15 -1  1  1  1 -1 -1 -1  1  1 -1
## 16  1  1  1  1 -1 -1  1 -1 -1  1
## 17 -1 -1 -1 -1  1 -1 -1 -1  1 -1
## 18  1 -1 -1 -1  1 -1  1  1 -1  1
## 19 -1  1 -1 -1  1 -1  1  1 -1 -1
## 20  1  1 -1 -1  1 -1 -1 -1  1  1
## 21 -1 -1  1 -1  1 -1  1 -1  1  1
## 22  1 -1  1 -1  1 -1 -1  1 -1 -1
## 23 -1  1  1 -1  1 -1 -1  1 -1  1
## 24  1  1  1 -1  1 -1  1 -1  1 -1
## 25 -1 -1 -1  1  1 -1 -1  1 -1 -1
## 26  1 -1 -1  1  1 -1  1 -1  1  1
## 27 -1  1 -1  1  1 -1  1 -1  1 -1
## 28  1  1 -1  1  1 -1 -1  1 -1  1
## 29 -1 -1  1  1  1 -1  1  1 -1  1
## 30  1 -1  1  1  1 -1 -1 -1  1 -1
## 31 -1  1  1  1  1 -1 -1 -1  1  1
## 32  1  1  1  1  1 -1  1  1 -1 -1
## 33 -1 -1 -1 -1 -1  1 -1  1 -1 -1
## 34  1 -1 -1 -1 -1  1  1 -1  1  1
## 35 -1  1 -1 -1 -1  1  1 -1  1 -1
## 36  1  1 -1 -1 -1  1 -1  1 -1  1
## 37 -1 -1  1 -1 -1  1  1  1 -1  1
## 38  1 -1  1 -1 -1  1 -1 -1  1 -1
## 39 -1  1  1 -1 -1  1 -1 -1  1  1
## 40  1  1  1 -1 -1  1  1  1 -1 -1
## 41 -1 -1 -1  1 -1  1 -1 -1  1 -1
## 42  1 -1 -1  1 -1  1  1  1 -1  1
## 43 -1  1 -1  1 -1  1  1  1 -1 -1
## 44  1  1 -1  1 -1  1 -1 -1  1  1
## 45 -1 -1  1  1 -1  1  1 -1  1  1
## 46  1 -1  1  1 -1  1 -1  1 -1 -1
## 47 -1  1  1  1 -1  1 -1  1 -1  1
## 48  1  1  1  1 -1  1  1 -1  1 -1
## 49 -1 -1 -1 -1  1  1 -1 -1 -1  1
## 50  1 -1 -1 -1  1  1  1  1  1 -1
## 51 -1  1 -1 -1  1  1  1  1  1  1
## 52  1  1 -1 -1  1  1 -1 -1 -1 -1
## 53 -1 -1  1 -1  1  1  1 -1 -1 -1
## 54  1 -1  1 -1  1  1 -1  1  1  1
## 55 -1  1  1 -1  1  1 -1  1  1 -1
## 56  1  1  1 -1  1  1  1 -1 -1  1
## 57 -1 -1 -1  1  1  1 -1  1  1  1
## 58  1 -1 -1  1  1  1  1 -1 -1 -1
## 59 -1  1 -1  1  1  1  1 -1 -1  1
## 60  1  1 -1  1  1  1 -1  1  1 -1
## 61 -1 -1  1  1  1  1  1  1  1 -1
## 62  1 -1  1  1  1  1 -1 -1 -1  1
## 63 -1  1  1  1  1  1 -1 -1 -1 -1
## 64  1  1  1  1  1  1  1  1  1  1
## class=design, type= FrF2</code></pre>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb543-1" data-line-number="1"><span class="co"># Further, we can look at some useful </span></a>
<a class="sourceLine" id="cb543-2" data-line-number="2"><span class="kw">attr</span>(my.<span class="fl">10.</span>minus.<span class="fl">4.</span>design, <span class="st">&quot;design.info&quot;</span>)</a></code></pre></div>
<pre><code>## $type
## [1] &quot;FrF2&quot;
## 
## $nruns
## [1] 64
## 
## $nfactors
## [1] 10
## 
## $factor.names
## $factor.names$A
## [1] -1  1
## 
## $factor.names$B
## [1] -1  1
## 
## $factor.names$C
## [1] -1  1
## 
## $factor.names$D
## [1] -1  1
## 
## $factor.names$E
## [1] -1  1
## 
## $factor.names$F
## [1] -1  1
## 
## $factor.names$G
## [1] -1  1
## 
## $factor.names$H
## [1] -1  1
## 
## $factor.names$J
## [1] -1  1
## 
## $factor.names$K
## [1] -1  1
## 
## 
## $catlg.name
## [1] &quot;catlg&quot;
## 
## $catlg.entry
## Design:  10-4.1 
##    64  runs,  10  factors,  
##    Resolution  IV 
##    Generating columns:  7 27 43 53 
##    WLP (3plus):  0 2 8 4 0 ,  33  clear 2fis
##  Factors with all 2fis clear:  D K
## 
## $aliased
## $aliased$legend
##  [1] &quot;A=A&quot; &quot;B=B&quot; &quot;C=C&quot; &quot;D=D&quot; &quot;E=E&quot; &quot;F=F&quot; &quot;G=G&quot; &quot;H=H&quot; &quot;J=J&quot; &quot;K=K&quot;
## 
## $aliased$main
## [1] &quot;A=BCG&quot; &quot;B=ACG&quot; &quot;C=ABG&quot; &quot;E=FHJ&quot; &quot;F=EHJ&quot; &quot;G=ABC&quot; &quot;H=EFJ&quot; &quot;J=EFH&quot;
## 
## $aliased$fi2
##  [1] &quot;AB=CG=DEH=DFJ&quot; &quot;AC=BG=EFK=HJK&quot; &quot;AD=BEH=BFJ&quot;    &quot;AE=BDH=CFK&quot;   
##  [5] &quot;AF=BDJ=CEK&quot;    &quot;AG=BC&quot;         &quot;AH=BDE=CJK&quot;    &quot;AJ=BDF=CHK&quot;   
##  [9] &quot;AK=CEF=CHJ&quot;    &quot;BD=AEH=AFJ&quot;    &quot;BE=ADH=FGK&quot;    &quot;BF=ADJ=EGK&quot;   
## [13] &quot;BH=ADE=GJK&quot;    &quot;BJ=ADF=GHK&quot;    &quot;BK=EFG=GHJ&quot;    &quot;CD=EGH=FGJ&quot;   
## [17] &quot;CE=AFK=DGH&quot;    &quot;CF=AEK=DGJ&quot;    &quot;CH=AJK=DEG&quot;    &quot;CJ=AHK=DFG&quot;   
## [21] &quot;CK=AEF=AHJ&quot;    &quot;DE=ABH=CGH&quot;    &quot;DF=ABJ=CGJ&quot;    &quot;DG=CEH=CFJ&quot;   
## [25] &quot;DH=ABE=CEG&quot;    &quot;DJ=ABF=CFG&quot;    &quot;EF=HJ=ACK=BGK&quot; &quot;EG=BFK=CDH&quot;   
## [29] &quot;EH=FJ=ABD=CDG&quot; &quot;EJ=FH&quot;         &quot;EK=ACF=BFG&quot;    &quot;FG=BEK=CDJ&quot;   
## [33] &quot;FK=ACE=BEG&quot;    &quot;GH=BJK=CDE&quot;    &quot;GJ=BHK=CDF&quot;    &quot;GK=BEF=BHJ&quot;   
## [37] &quot;HK=ACJ=BGJ&quot;    &quot;JK=ACH=BGH&quot;   
## 
## $aliased$fi3
##  [1] &quot;ABK=CGK&quot;         &quot;ACD=BDG&quot;         &quot;ADG=BCD=EJK=FHK&quot; &quot;ADK=EGJ=FGH&quot;    
##  [5] &quot;AEG=BCE=DJK&quot;     &quot;AEJ=AFH=DGK&quot;     &quot;AFG=BCF=DHK&quot;     &quot;AGH=BCH=DFK&quot;    
##  [9] &quot;AGJ=BCJ=DEK&quot;     &quot;AGK=BCK=DEJ=DFH&quot; &quot;BDK=CEJ=CFH&quot;     &quot;BEJ=BFH=CDK&quot;    
## [13] &quot;DEF=DHJ&quot;         &quot;EHK=FJK&quot;        
## 
## 
## $FrF2.version
## [1] &quot;2.3-2&quot;
## 
## $replications
## [1] 1
## 
## $repeat.only
## [1] FALSE
## 
## $randomize
## [1] FALSE
## 
## $seed
## NULL
## 
## $creator
## FrF2::FrF2(nfactors = 10, nruns = 64, randomize = F, alias.info = 3)</code></pre>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb545-1" data-line-number="1"><span class="co"># In particular, we get our alias structure which is useful</span></a></code></pre></div>
<p>We can, of course, then run our tests and do our analysis in the same manner as we have done previously.</p>
</div>
<div id="resolution" class="section level3">
<h3><span class="header-section-number">6.3.4</span> Resolution</h3>
<p>In the output of FrF2, you may have noticed that there is a reference to the “Resolution” of a design. The resolution of a design is a useful way of categorizing the alias structure of designs. In particular, we generally talk about Resolution III, IV, and V designs. They are defined as:</p>
<ul>
<li>Resolution III: No main factor is aliased with any other main factor, but may be aliased with 2nd order interactions.</li>
<li>Resolution IV: No main factor is aliased with any main or 2nd order interaction, but 2nd order interactions may be aliased with eachother.</li>
<li>Resolution V: No main factor or 2nd order interaction is aliased with any other main or 2nd order interaction.</li>
</ul>
<p>If we consider the design above, we can note that FrF2 said our <span class="math inline">\(2^{10-4}\)</span> design was “Resolution IV” and we can see that in the alias structure as:</p>
<ul>
<li>Main Factors: A=BCG, B=ACG, C=ABG, E=FHJ, F=EHJ, G=ABC, H=EFJ, J=EFH</li>
<li>2nd Order: AB=CG=DEH=DFJ, AC=BG=EFK=HJK, AD=BEH=BFJ, AE=BDH=CFK, AF=BDJ=CEK, AG=BC, AH=BDE=CJK, AJ=BDF=CHK, AK=CEF=CHJ, BD=AEH=AFJ, BE=ADH=FGK, BF=ADJ=EGK, BH=ADE=GJK, BJ=ADF=GHK, BK=EFG=GHJ, CD=EGH=FGJ, CE=AFK=DGH, CF=AEK=DGJ, CH=AJK=DEG, CJ=AHK=DFG, CK=AEF=AHJ, DE=ABH=CGH, DF=ABJ=CGJ, DG=CEH=CFJ, DH=ABE=CEG, DJ=ABF=CFG, EF=HJ=ACK=BGK, EG=BFK=CDH, EH=FJ=ABD=CDG, EJ=FH, EK=ACF=BFG, FG=BEK=CDJ, FK=ACE=BEG, GH=BJK=CDE, GJ=BHK=CDF, GK=BEF=BHJ, HK=ACJ=BGJ, JK=ACH=BGH</li>
</ul>
<p>We can see that there are no main factors aliased with anything less than a third order interaction. However, we see second order interactions aliased with eachother, for example, <code>AB = CG</code></p>
<p>We can also use packages to build designs of certain resolutions. For example, we could use <code>FrF2</code> to give us a Resolution V design for 10 factors as follows:</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb546-1" data-line-number="1">my.Res5<span class="fl">.10</span>Factor.Design &lt;-<span class="st"> </span>FrF2<span class="op">::</span><span class="kw">FrF2</span>(<span class="dt">nfactors =</span> <span class="dv">10</span>, <span class="dt">resolution =</span> <span class="dv">5</span>, <span class="dt">randomize =</span> F, <span class="dt">alias.info =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb546-2" data-line-number="2"></a>
<a class="sourceLine" id="cb546-3" data-line-number="3"><span class="co"># We can view the design:</span></a>
<a class="sourceLine" id="cb546-4" data-line-number="4">my.Res5<span class="fl">.10</span>Factor.Design</a></code></pre></div>
<pre><code>##      A  B  C  D  E  F  G  H  J  K
## 1   -1 -1 -1 -1 -1 -1 -1 -1 -1  1
## 2    1 -1 -1 -1 -1 -1 -1  1  1 -1
## 3   -1  1 -1 -1 -1 -1 -1  1  1 -1
## 4    1  1 -1 -1 -1 -1 -1 -1 -1  1
## 5   -1 -1  1 -1 -1 -1 -1  1  1  1
## 6    1 -1  1 -1 -1 -1 -1 -1 -1 -1
## 7   -1  1  1 -1 -1 -1 -1 -1 -1 -1
## 8    1  1  1 -1 -1 -1 -1  1  1  1
## 9   -1 -1 -1  1 -1 -1 -1  1 -1 -1
## 10   1 -1 -1  1 -1 -1 -1 -1  1  1
## 11  -1  1 -1  1 -1 -1 -1 -1  1  1
## 12   1  1 -1  1 -1 -1 -1  1 -1 -1
## 13  -1 -1  1  1 -1 -1 -1 -1  1 -1
## 14   1 -1  1  1 -1 -1 -1  1 -1  1
## 15  -1  1  1  1 -1 -1 -1  1 -1  1
## 16   1  1  1  1 -1 -1 -1 -1  1 -1
## 17  -1 -1 -1 -1  1 -1 -1  1 -1  1
## 18   1 -1 -1 -1  1 -1 -1 -1  1 -1
## 19  -1  1 -1 -1  1 -1 -1 -1  1 -1
## 20   1  1 -1 -1  1 -1 -1  1 -1  1
## 21  -1 -1  1 -1  1 -1 -1 -1  1  1
## 22   1 -1  1 -1  1 -1 -1  1 -1 -1
## 23  -1  1  1 -1  1 -1 -1  1 -1 -1
## 24   1  1  1 -1  1 -1 -1 -1  1  1
## 25  -1 -1 -1  1  1 -1 -1 -1 -1 -1
## 26   1 -1 -1  1  1 -1 -1  1  1  1
## 27  -1  1 -1  1  1 -1 -1  1  1  1
## 28   1  1 -1  1  1 -1 -1 -1 -1 -1
## 29  -1 -1  1  1  1 -1 -1  1  1 -1
## 30   1 -1  1  1  1 -1 -1 -1 -1  1
## 31  -1  1  1  1  1 -1 -1 -1 -1  1
## 32   1  1  1  1  1 -1 -1  1  1 -1
## 33  -1 -1 -1 -1 -1  1 -1 -1  1 -1
## 34   1 -1 -1 -1 -1  1 -1  1 -1  1
## 35  -1  1 -1 -1 -1  1 -1  1 -1  1
## 36   1  1 -1 -1 -1  1 -1 -1  1 -1
## 37  -1 -1  1 -1 -1  1 -1  1 -1 -1
## 38   1 -1  1 -1 -1  1 -1 -1  1  1
## 39  -1  1  1 -1 -1  1 -1 -1  1  1
## 40   1  1  1 -1 -1  1 -1  1 -1 -1
## 41  -1 -1 -1  1 -1  1 -1  1  1  1
## 42   1 -1 -1  1 -1  1 -1 -1 -1 -1
## 43  -1  1 -1  1 -1  1 -1 -1 -1 -1
## 44   1  1 -1  1 -1  1 -1  1  1  1
## 45  -1 -1  1  1 -1  1 -1 -1 -1  1
## 46   1 -1  1  1 -1  1 -1  1  1 -1
## 47  -1  1  1  1 -1  1 -1  1  1 -1
## 48   1  1  1  1 -1  1 -1 -1 -1  1
## 49  -1 -1 -1 -1  1  1 -1  1  1 -1
## 50   1 -1 -1 -1  1  1 -1 -1 -1  1
## 51  -1  1 -1 -1  1  1 -1 -1 -1  1
## 52   1  1 -1 -1  1  1 -1  1  1 -1
## 53  -1 -1  1 -1  1  1 -1 -1 -1 -1
## 54   1 -1  1 -1  1  1 -1  1  1  1
## 55  -1  1  1 -1  1  1 -1  1  1  1
## 56   1  1  1 -1  1  1 -1 -1 -1 -1
## 57  -1 -1 -1  1  1  1 -1 -1  1  1
## 58   1 -1 -1  1  1  1 -1  1 -1 -1
## 59  -1  1 -1  1  1  1 -1  1 -1 -1
## 60   1  1 -1  1  1  1 -1 -1  1  1
## 61  -1 -1  1  1  1  1 -1  1 -1  1
## 62   1 -1  1  1  1  1 -1 -1  1 -1
## 63  -1  1  1  1  1  1 -1 -1  1 -1
## 64   1  1  1  1  1  1 -1  1 -1  1
## 65  -1 -1 -1 -1 -1 -1  1 -1  1  1
## 66   1 -1 -1 -1 -1 -1  1  1 -1 -1
## 67  -1  1 -1 -1 -1 -1  1  1 -1 -1
## 68   1  1 -1 -1 -1 -1  1 -1  1  1
## 69  -1 -1  1 -1 -1 -1  1  1 -1  1
## 70   1 -1  1 -1 -1 -1  1 -1  1 -1
## 71  -1  1  1 -1 -1 -1  1 -1  1 -1
## 72   1  1  1 -1 -1 -1  1  1 -1  1
## 73  -1 -1 -1  1 -1 -1  1  1  1 -1
## 74   1 -1 -1  1 -1 -1  1 -1 -1  1
## 75  -1  1 -1  1 -1 -1  1 -1 -1  1
## 76   1  1 -1  1 -1 -1  1  1  1 -1
## 77  -1 -1  1  1 -1 -1  1 -1 -1 -1
## 78   1 -1  1  1 -1 -1  1  1  1  1
## 79  -1  1  1  1 -1 -1  1  1  1  1
## 80   1  1  1  1 -1 -1  1 -1 -1 -1
## 81  -1 -1 -1 -1  1 -1  1  1  1  1
## 82   1 -1 -1 -1  1 -1  1 -1 -1 -1
## 83  -1  1 -1 -1  1 -1  1 -1 -1 -1
## 84   1  1 -1 -1  1 -1  1  1  1  1
## 85  -1 -1  1 -1  1 -1  1 -1 -1  1
## 86   1 -1  1 -1  1 -1  1  1  1 -1
## 87  -1  1  1 -1  1 -1  1  1  1 -1
## 88   1  1  1 -1  1 -1  1 -1 -1  1
## 89  -1 -1 -1  1  1 -1  1 -1  1 -1
## 90   1 -1 -1  1  1 -1  1  1 -1  1
## 91  -1  1 -1  1  1 -1  1  1 -1  1
## 92   1  1 -1  1  1 -1  1 -1  1 -1
## 93  -1 -1  1  1  1 -1  1  1 -1 -1
## 94   1 -1  1  1  1 -1  1 -1  1  1
## 95  -1  1  1  1  1 -1  1 -1  1  1
## 96   1  1  1  1  1 -1  1  1 -1 -1
## 97  -1 -1 -1 -1 -1  1  1 -1 -1 -1
## 98   1 -1 -1 -1 -1  1  1  1  1  1
## 99  -1  1 -1 -1 -1  1  1  1  1  1
## 100  1  1 -1 -1 -1  1  1 -1 -1 -1
## 101 -1 -1  1 -1 -1  1  1  1  1 -1
## 102  1 -1  1 -1 -1  1  1 -1 -1  1
## 103 -1  1  1 -1 -1  1  1 -1 -1  1
## 104  1  1  1 -1 -1  1  1  1  1 -1
## 105 -1 -1 -1  1 -1  1  1  1 -1  1
## 106  1 -1 -1  1 -1  1  1 -1  1 -1
## 107 -1  1 -1  1 -1  1  1 -1  1 -1
## 108  1  1 -1  1 -1  1  1  1 -1  1
## 109 -1 -1  1  1 -1  1  1 -1  1  1
## 110  1 -1  1  1 -1  1  1  1 -1 -1
## 111 -1  1  1  1 -1  1  1  1 -1 -1
## 112  1  1  1  1 -1  1  1 -1  1  1
## 113 -1 -1 -1 -1  1  1  1  1 -1 -1
## 114  1 -1 -1 -1  1  1  1 -1  1  1
## 115 -1  1 -1 -1  1  1  1 -1  1  1
## 116  1  1 -1 -1  1  1  1  1 -1 -1
## 117 -1 -1  1 -1  1  1  1 -1  1 -1
## 118  1 -1  1 -1  1  1  1  1 -1  1
## 119 -1  1  1 -1  1  1  1  1 -1  1
## 120  1  1  1 -1  1  1  1 -1  1 -1
## 121 -1 -1 -1  1  1  1  1 -1 -1  1
## 122  1 -1 -1  1  1  1  1  1  1 -1
## 123 -1  1 -1  1  1  1  1  1  1 -1
## 124  1  1 -1  1  1  1  1 -1 -1  1
## 125 -1 -1  1  1  1  1  1  1  1  1
## 126  1 -1  1  1  1  1  1 -1 -1 -1
## 127 -1  1  1  1  1  1  1 -1 -1 -1
## 128  1  1  1  1  1  1  1  1  1  1
## class=design, type= FrF2</code></pre>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb548-1" data-line-number="1"><span class="co"># We can also view the info about the design:</span></a>
<a class="sourceLine" id="cb548-2" data-line-number="2"><span class="kw">attr</span>(my.Res5<span class="fl">.10</span>Factor.Design, <span class="st">&quot;design.info&quot;</span>)</a></code></pre></div>
<pre><code>## $type
## [1] &quot;FrF2&quot;
## 
## $nruns
## [1] 128
## 
## $nfactors
## [1] 10
## 
## $factor.names
## $factor.names$A
## [1] -1  1
## 
## $factor.names$B
## [1] -1  1
## 
## $factor.names$C
## [1] -1  1
## 
## $factor.names$D
## [1] -1  1
## 
## $factor.names$E
## [1] -1  1
## 
## $factor.names$F
## [1] -1  1
## 
## $factor.names$G
## [1] -1  1
## 
## $factor.names$H
## [1] -1  1
## 
## $factor.names$J
## [1] -1  1
## 
## $factor.names$K
## [1] -1  1
## 
## 
## $catlg.name
## [1] &quot;catlg&quot;
## 
## $catlg.entry
## Design:  10-3.1 
##    128  runs,  10  factors,  
##    Resolution  V 
##    Generating columns:  31 103 43 
##    WLP (3plus):  0 0 3 3 ,  45  clear 2fis
## 
## $aliased
## $aliased$legend
##  [1] &quot;A=A&quot; &quot;B=B&quot; &quot;C=C&quot; &quot;D=D&quot; &quot;E=E&quot; &quot;F=F&quot; &quot;G=G&quot; &quot;H=H&quot; &quot;J=J&quot; &quot;K=K&quot;
## 
## $aliased$main
## character(0)
## 
## $aliased$fi2
##  [1] &quot;AB=DFK&quot;     &quot;AD=BFK&quot;     &quot;AF=BDK&quot;     &quot;AK=BDF&quot;     &quot;BD=AFK&quot;    
##  [6] &quot;BF=ADK&quot;     &quot;BK=ADF&quot;     &quot;CD=GJK&quot;     &quot;CE=FHK&quot;     &quot;CF=EHK&quot;    
## [11] &quot;CG=DJK&quot;     &quot;CH=EFK&quot;     &quot;CJ=DGK&quot;     &quot;CK=DGJ=EFH&quot; &quot;DF=ABK&quot;    
## [16] &quot;DG=CJK&quot;     &quot;DJ=CGK&quot;     &quot;DK=ABF=CGJ&quot; &quot;EF=CHK&quot;     &quot;EH=CFK&quot;    
## [21] &quot;EK=CFH&quot;     &quot;FH=CEK&quot;     &quot;FK=ABD=CEH&quot; &quot;GJ=CDK&quot;     &quot;GK=CDJ&quot;    
## [26] &quot;HK=CEF&quot;     &quot;JK=CDG&quot;    
## 
## $aliased$fi3
##  [1] &quot;ABC=DEH=FGJ&quot; &quot;ABE=CDH&quot;     &quot;ABG=CFJ&quot;     &quot;ABH=CDE&quot;     &quot;ABJ=CFG&quot;    
##  [6] &quot;ACD=BEH&quot;     &quot;ACE=BDH&quot;     &quot;ACF=BGJ&quot;     &quot;ACG=BFJ&quot;     &quot;ACH=BDE&quot;    
## [11] &quot;ACJ=BFG&quot;     &quot;ADE=BCH&quot;     &quot;ADH=BCE&quot;     &quot;AEH=BCD&quot;     &quot;AFG=BCJ&quot;    
## [16] &quot;AFJ=BCG&quot;     &quot;AGJ=BCF&quot;     &quot;DEF=GHJ&quot;     &quot;DEG=FHJ&quot;     &quot;DEJ=FGH&quot;    
## [21] &quot;DFG=EHJ&quot;     &quot;DFH=EGJ&quot;     &quot;DFJ=EGH&quot;     &quot;DGH=EFJ&quot;     &quot;DHJ=EFG&quot;    
## 
## 
## $FrF2.version
## [1] &quot;2.3-2&quot;
## 
## $replications
## [1] 1
## 
## $repeat.only
## [1] FALSE
## 
## $randomize
## [1] FALSE
## 
## $seed
## NULL
## 
## $creator
## FrF2::FrF2(nfactors = 10, resolution = 5, randomize = F, alias.info = 3)</code></pre>
<p>We can see this is a <span class="math inline">\(2^{10-3}\)</span> design with 128 tests and the alias structure pretty clearly.</p>
<p>The general notation for discussing these types of designs is generally: <span class="math inline">\(2_{[Resolution]}^{K-P}\)</span>, where <span class="math inline">\(K\)</span> is the number of factors, <span class="math inline">\(P\)</span> is the fraction, and <span class="math inline">\([Resolution]\)</span> is the resolution number, typically in Roman numerals. For example, a quarter fractional factorial design that is resolution IV would be: <span class="math inline">\(2_{IV}^{6-2}\)</span>.</p>
<p><strong>Advantage of Fractional Factorials</strong> One thing that is quite amazing is that, as <span class="math inline">\(K\)</span> increases, how small of a fraction one needs to get a reasonable resolution. We can calculate the minimum number of runs required to get a design with a given resolution with <span class="math inline">\(K\)</span> factorsby the following formulas:</p>
<ul>
<li>Resolution III: <span class="math inline">\(1 + K\)</span></li>
<li>Resolution V: <span class="math inline">\(1 + K + {K\choose2}\)</span></li>
<li>Resolution VII: <span class="math inline">\(1 + K + {K\choose2} + {K\choose3}\)</span> (Note, a Resolution VII design is one in which none of the three-way interactions are aliased with any third or lower order interactions).</li>
<li>In general, to calculate the minimum number of requisite treatment combinations, the formula is 1 + the number of main effects (K) + the number of 2-way interactions (K choose 2) + ….</li>
<li>Unfortunately, there does not appear to be a closed form to find the exact number of tests to achieve a given resolution.</li>
</ul>
<p>We can see how advantageous this is for us in the following graphs (Note 1: The y scale is logarthmic; Note 2: This data was generated manually with the <code>FrF2</code> package):</p>
<p><img src="041-Fractional_Factorial_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>It is simply incredible how much information we can gain with such a relatively small sample of all the possible treatment combinations so long as we do it in a smart way!</p>
</div>
<div id="general-2k-p-designs-problem-set" class="section level3">
<h3><span class="header-section-number">6.3.5</span> General <span class="math inline">\(2^{K-P}\)</span> Designs Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter4_ProblemSets/2K_General_Fractional_ProblemSet_Questions.html'> here </a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = '/_Chapter4_ProblemSets/2K_General_Fractional_ProblemSet_Questions.Rmd'> here </a></p>
<p>The answers for this problem set are <a href = '/_Chapter4_ProblemSets/2K_General_Fractional_ProblemSet_Answers.html'> here </a>.</p>
</div>
</div>
<div id="additional-notes-on-2k-p-designs" class="section level2">
<h2><span class="header-section-number">6.4</span> Additional Notes on <span class="math inline">\(2^{K-P}\)</span> Designs</h2>
<div id="additional-topics" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Additional Topics</h3>
<p>The world of designing and analyzing two level factorial designs is rather large, and there are additional topics. For a more detailed treatment on additional topics, we can study:</p>
<ul>
<li><strong>Plackett-Burman Designs</strong>: These are a special class of 2-level designs that are highly efficient at screening for main effects. They are unique in how they are generated, with every main effect being “partially aliased” with every two-way interaction not including itself. You can read more about them at the <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section3/pri335.htm'> NIST Engineering Statistics Handbook </a>, <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> §8.6.3, <span class="citation">George Box (<a href="#ref-box2005">2005</a>)</span> §7.1, or their <a href = 'https://www.jstor.org/stable/pdf/2332195.pdf?casa_token=eoTdz8-vlOkAAAAA:91FVj0dWQZ5S-Md_QLBGJZsLKIDLQzUoS4PIPOZp2BBs9gcXeNWHWDYimF5fCxJLsI19Tp2ZmsmOe_RB81NI5abBj-gezEjyjak9lP3I24qycgGxwPuc'> original paper, <em>The Design of Optimum Multifactorial Experiments</em> </a>.</li>
<li><strong>Folding</strong>: Often we find that we need to increase our resolution for a given experiment after our initial results. We can do this smartly with the concept of <strong>folding</strong> or <strong>fold-over</strong>. We can read more about that at <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section3/pri338.htm'> the NIST Engineering Statistics Handbook </a>, <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> §8.6.2, 8.7.2, or <span class="citation">George Box (<a href="#ref-box2005">2005</a>)</span> §6.8.</li>
<li><strong>Projection</strong>: While we briefly touched on this concept, projection is the idea that in any <span class="math inline">\(2^{K-P}\)</span> design, one may have a higher resolution or full factorial design with some number of factors <span class="math inline">\(R &lt; K\)</span>. We can read more about this in <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> §8.2.3 or §8.4.2.</li>
<li><strong>Additional Levels</strong>: Often we need to consider more than two levels, we will discuss the addition of center points and <span class="math inline">\(3^K\)</span> designs in a future section of this course.</li>
</ul>
</div>
<div id="sequencing-experiments" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Sequencing Experiments</h3>
<p>As we have noted, factorial designs are often used as screening experiments. That is, they are purposefully used to gain additional information about the nature of the factors and their relationship with resopnses of interest such that one can conduct more informative experiments in an economical manner. <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> suggests that it is generally a mistake to design a single, large, comprehensive experiment as the potential for error and wasted resources (i.e., experimenting with inconsequential factors) is large. He suggests that as a general rule, one should devote no more than 25% of available resources to the first experiment (§1.4). Depending on the results of an initial experiment, one has several options. These include (paraphrased from <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span>):</p>
<ul>
<li>Perform confirmation runs to verify intial results and/or replicate some of the runs to improve precision.</li>
<li>Add additional runs to resolve aliasing or account for curvature (e.g., center point designs).</li>
<li>Change the scale on factors (for example, one may not see an effect if the difference between a low and high level is too small).</li>
<li>Drop or add factors (i.e., drop factors that are clearly inconsequential - this allows you to project your design to a higher resolution one with fewer factors).</li>
<li>Move to a new experimental design region.</li>
</ul>
<p>A method of moving to a new experimental design region is called the method of steepest ascents. It was described by Hunter in the <a href = 'https://youtu.be/hTviHGsl5ag?t=443'> introductory video of the previous section (link starts at discussion of steepest ascents)</a>. You can read more about it at the <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section5/pri5.htm'> NIST Engineering Statistics Handbook </a>, <span class="citation">Montgomery (<a href="#ref-montgomery2017">2017</a>)</span> §11.2, or <span class="citation">George Box (<a href="#ref-box2005">2005</a>)</span> §12. These methods require some discussion of response surface modeling that we have not yet covered.</p>
<p>As has been previously discussed, a significant concern for experimental design is the independence of the tests from eachother. In particular, in physical experiments, tests may vary with environmental conditions or subject adaptation that corresponds to time. Fortunately, with computer simulation, we mitigate that concern as we can precisely describe our conditions and keep tests independent from each other (presuming we use the same set of inputs, version of the simulation software, independent random seeds and so forth). This allows us to use simulation results conducted in an initial experiment to inform subsequent experiments (assuming we keep the computer simulation conditions constant).</p>
<p>Finally, the NIST Engineering Statistics Handbook has a <a href = 'https://www.itl.nist.gov/div898/handbook/pri/section4/pri41.htm'> nice flowchart </a> describing DOE analysis. There are some thing we have not yet done (e.g., transforming variables and regression), but this is a good overview and reminder. It is important, the authors of that flow chart note that this flowchart is <strong>not</strong> a “hard-and-fast-rule” for step by step analysis, rather it is a guideline. Recall that there is always a question of judgement and acceptance that must be made in any statistical process or analysis as one is 1) never fully certain and 2) trading off resources for information. The question is generally, have I done enough to answer my questions.</p>
</div>
<div id="fractional-factorial-design-simulation-problem-set" class="section level3">
<h3><span class="header-section-number">6.4.3</span> Fractional Factorial Design Simulation Problem Set</h3>
<p>The problem set for this section reviews using a fractional factorial design with a simulation. Each person’s work and resuls will be unique.</p>
<p>The problem set is located <a href = '/_Chapter4_ProblemSets/FF_Design_SimLab_PS.html'> here </a>.</p>
<p>The simulation is a shiny app (link in the problem set). Please note, it is a notional simulation and not reflective of any proprietary, Army, or DoD simualtion.</p>
</div>
</div>
<div id="screening-experiments-and-selecting-factors" class="section level2">
<h2><span class="header-section-number">6.5</span> Screening Experiments and Selecting Factors</h2>
<p><font color = 'red'> TBP </font></p>
<!--

Dangers of dropping factors
Benefits of dropping factors
Methods to choose what factors to drop
What to do in simulation with necessary input factors (fixed, etc..)

-->
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">6.6</span> Conclusion</h2>
<p>Hopefully, the reader can see the power of two level factorial designs by now, particularly fractional factorial designs. These designs are deceptively simple, but highly powerful, particularly when one is attempting to identify relevant factors for continued studies (with more detailed designs). Recall a few of the key points in our study of these designs:</p>
<ul>
<li>We have <span class="math inline">\(K\)</span> factors under study, each with 2 levels, a “low” and “high” that we code as <span class="math inline">\(-1\)</span> and <span class="math inline">\(+1\)</span> respectively.</li>
<li>The factors and their associated levels may be quantitative, but can also be categorical and include a number of related changes (e.g., one can choose two vehicles each with a number of attributes that vary by the choice of vehicle).</li>
<li>Our modeling assumption is that the relationship between a low and high level is approximately linear.</li>
<li>We choose our design points such that the factors and interactions are orthogonal to each other. This allows for the subsequent analysis of effects.</li>
<li>We can calculate the treatment effect for any factor or interaction by the formula: <span class="math inline">\(\frac{1}{n \cdot 2^{K-P-1}} [Contrast]\)</span>, where the contrast is the linear combination of the sum of the responses for each treatment combination and the value (+/- 1) for that factor in the treatment combination.</li>
<li>When we choose to use a fractional factorial design, we do so with the introduction of a design generator. This introduces an alias structure to our design. The alias structure shows us what we can estimate and what we cannot.<br />
</li>
<li>In general, we can make a reasonable assumption that higher order interactions (e.g., 3rd plus) are negligible (principle of sparsity of effects), and thus have an effect close to 0. Therefore, our estimation of a main or second-order factor is approximately what we calculate for the effect of the alias structure.</li>
<li><span class="math inline">\(2^{K-P}\)</span> designs for varying resolutions need not be calculated by hand (in general), but can be either looked up in references or generated by computer programs (e.g., <code>FrF2</code> in <em>R</em>).</li>
</ul>
<!--chapter:end:041-Fractional_Factorial.Rmd-->
</div>
</div>
<div id="fundamentals-of-regression" class="section level1">
<h1><span class="header-section-number">7</span> Fundamentals of Regression</h1>
<div id="admin-3" class="section level2">
<h2><span class="header-section-number">7.1</span> Admin</h2>
<p>For any errors associated with this section, please contact <a href="mailto:john.f.king1.mil@mail.mil">John King</a> or <a href="mailto:stephen.e.gillespie.mil@mail.mil">Steve Gillespie</a>.</p>
<p>This chapter was published using the following software:</p>
<ul>
<li>R version 3.6.0 (2019-04-26).</li>
<li>On x86_64-pc-linux-gnu (64-bit) running Ubuntu 18.04.2 LTS.</li>
<li>Packages used in this chapter are explicitly shown in the code snippets.</li>
</ul>
</div>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">7.2</span> Simple Linear Regression</h2>
<p>The purpose of regression is to describe a relationship that explains one variable (the <em>response</em>, or the “y” variable) based on one or more other variables (the <em>predictors</em>, or the “x” variables). The simplest deterministic mathematical relationship between two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is a linear relationship, which we define as:</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x + \varepsilon\]</span></p>
<p>where,</p>
<ul>
<li><span class="math inline">\(\beta_{0}\)</span> is the y-intercept</li>
<li><span class="math inline">\(\beta_{1}\)</span> is the slope</li>
<li><span class="math inline">\(\varepsilon\)</span> is the error in <span class="math inline">\(y\)</span> not explained by <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span>.</li>
</ul>
<p>If there is no error in the model and a linear relationship exists, we could predict the true value of y given any value of x. With error, however, we can only estimate y, which we annotate by <span class="math inline">\(\hat{y}\)</span>. The regression line itself is determined using the <em>least squares</em> method, which involves drawing a line through the centroid of the data, and adjusting the slope until the squared distance between the straight line and each observed value (the <em>residual</em>) is minimized. For example, assume we have the following observations of height in inches (predictor) and weight in pounds (response).</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb550-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb550-2" data-line-number="2"><span class="kw">library</span>(GGally)</a>
<a class="sourceLine" id="cb550-3" data-line-number="3"></a>
<a class="sourceLine" id="cb550-4" data-line-number="4">df =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb550-5" data-line-number="5">  <span class="dt">height =</span> <span class="kw">c</span>(<span class="dv">66</span>, <span class="dv">54</span>, <span class="dv">50</span>, <span class="dv">74</span>, <span class="dv">59</span>, <span class="dv">53</span>),</a>
<a class="sourceLine" id="cb550-6" data-line-number="6">  <span class="dt">weight =</span> <span class="kw">c</span>(<span class="dv">141</span>, <span class="dv">128</span>, <span class="dv">123</span>, <span class="dv">160</span>, <span class="dv">136</span>, <span class="dv">139</span>)</a>
<a class="sourceLine" id="cb550-7" data-line-number="7">)</a></code></pre></div>
<div id="least-squares-method-manually" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Least Squares Method Manually</h3>
<p>The centroid coordinates <span class="math inline">\((\bar{x},\bar{y})\)</span> are calculated simply by <span class="math inline">\(\bar{x}\)</span> = <code>mean(df$height)</code> = 59.33, and <span class="math inline">\(\bar{y}\)</span> = <code>mean(df$weight)</code> = 137.83. Plotting the data with the centroid, we get:</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>To find the slope, <span class="math inline">\(\beta_{1}\)</span>, we calculate how much each height and weight observation deviate from the centroid, multiply those paired deviations, sum them, and divide that by the sums of the squared height deviations. With the height and weight data, we find:</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb551-1" data-line-number="1">df =<span class="st"> </span>df <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb551-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb551-3" data-line-number="3">    <span class="dt">h_dev =</span> height <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(height),    <span class="co"># height deviation from centroid</span></a>
<a class="sourceLine" id="cb551-4" data-line-number="4">    <span class="dt">w_dev =</span> weight <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(weight),    <span class="co"># weight deviation from centroid</span></a>
<a class="sourceLine" id="cb551-5" data-line-number="5">    <span class="dt">dev_prod =</span> h_dev <span class="op">*</span><span class="st"> </span>w_dev,         <span class="co"># the product of the deviations</span></a>
<a class="sourceLine" id="cb551-6" data-line-number="6">    <span class="dt">h_dev_squared =</span> h_dev<span class="op">^</span><span class="dv">2</span>           <span class="co"># the squared products</span></a>
<a class="sourceLine" id="cb551-7" data-line-number="7">  )</a></code></pre></div>
<table>
<colgroup>
<col width="8%" />
<col width="8%" />
<col width="17%" />
<col width="17%" />
<col width="21%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th>height</th>
<th>weight</th>
<th>height deviance</th>
<th>weight deviance</th>
<th>deviation products</th>
<th>height deviance squared</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x</td>
<td>y</td>
<td><span class="math inline">\(x_{i}-\bar{x}\)</span></td>
<td><span class="math inline">\(y_{i}-\bar{y}\)</span></td>
<td><span class="math inline">\((x_{i}-\bar{x})(y_{i}-\bar{y})\)</span></td>
<td><span class="math inline">\((x_{i}-\bar{x})^{2}\)</span></td>
</tr>
<tr class="even">
<td>66</td>
<td>141</td>
<td>6.67</td>
<td>3.17</td>
<td>21.14</td>
<td>44.49</td>
</tr>
<tr class="odd">
<td>54</td>
<td>128</td>
<td>-5.33</td>
<td>-9.83</td>
<td>52.39</td>
<td>28.41</td>
</tr>
<tr class="even">
<td>50</td>
<td>123</td>
<td>-9.33</td>
<td>-14.83</td>
<td>138.36</td>
<td>87.05</td>
</tr>
<tr class="odd">
<td>74</td>
<td>160</td>
<td>14.67</td>
<td>22.17</td>
<td>325.23</td>
<td>215.21</td>
</tr>
<tr class="even">
<td>59</td>
<td>136</td>
<td>-0.33</td>
<td>-1.83</td>
<td>0.60</td>
<td>0.11</td>
</tr>
<tr class="odd">
<td>53</td>
<td>139</td>
<td>-6.33</td>
<td>1.17</td>
<td>-7.41</td>
<td>40.07</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\bar{x} = 59.33\)</span></td>
<td><span class="math inline">\(\bar{y} = 137.83\)</span></td>
<td>-</td>
<td>-</td>
<td><span class="math inline">\(\Sigma = 530.33\)</span></td>
<td><span class="math inline">\(\Sigma = 415.33\)</span></td>
</tr>
</tbody>
</table>
<p>The slope is found by <span class="math inline">\(\beta_{1} = \frac{\Sigma (x_{i}-\bar{x})(y_{i}-\bar{y})}{\Sigma (x_{i}-\bar{x})^{2}} = \frac{530.33}{415.33} = 1.28\)</span>. For our dataset in <em>R</em>, that translates to:</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb552-1" data-line-number="1">beta1 =<span class="st"> </span><span class="kw">sum</span>(df<span class="op">$</span>dev_prod) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(df<span class="op">$</span>h_dev_squared)</a>
<a class="sourceLine" id="cb552-2" data-line-number="2">beta1</a></code></pre></div>
<pre><code>## [1] 1.276886</code></pre>
<p>We have now have what we need to calculate the y-intercept, <span class="math inline">\(\beta_{0} =\bar{y}-\beta{_1}\bar{x}\)</span>. Equivalently in <em>R</em>:</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb554-1" data-line-number="1">beta0 =<span class="st"> </span><span class="kw">mean</span>(df<span class="op">$</span>weight) <span class="op">-</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(df<span class="op">$</span>height)</a>
<a class="sourceLine" id="cb554-2" data-line-number="2">beta0</a></code></pre></div>
<pre><code>## [1] 62.07143</code></pre>
<p>When we plot the line defined by our beta values, we find that it does, in fact, pass through the centroid and visually appears to fit the data.</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb556-1" data-line-number="1"><span class="kw">ggplot</span>(<span class="dt">data=</span>df, <span class="kw">aes</span>(<span class="dt">x=</span>height, <span class="dt">y=</span>weight)) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb556-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept=</span>beta0, <span class="dt">slope=</span>beta1, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># note the explicit use of our betas</span></a>
<a class="sourceLine" id="cb556-4" data-line-number="4"><span class="st">  </span><span class="co">#geom_smooth(formula=y~x, method=&quot;lm&quot;, se=FALSE) + # how it&#39;s normally done in practice</span></a>
<a class="sourceLine" id="cb556-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> centroid, <span class="kw">aes</span>(<span class="dt">x=</span>height, <span class="dt">y=</span>weight), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-6" data-line-number="6"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">61</span>, <span class="dt">y=</span><span class="dv">138</span>, <span class="dt">label=</span><span class="st">&quot;centroid&quot;</span>, <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-7" data-line-number="7"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="fl">67.5</span>, <span class="dt">y=</span><span class="fl">143.5</span>, <span class="dt">label=</span><span class="st">&quot;residual&quot;</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-8" data-line-number="8"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;segment&quot;</span>, <span class="dt">x=</span><span class="dv">50</span>, <span class="dt">xend=</span><span class="dv">50</span>, <span class="dt">y=</span><span class="dv">123</span>, <span class="dt">yend=</span><span class="fl">125.5</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-9" data-line-number="9"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;segment&quot;</span>, <span class="dt">x=</span><span class="dv">53</span>, <span class="dt">xend=</span><span class="dv">53</span>, <span class="dt">y=</span><span class="dv">139</span>, <span class="dt">yend=</span><span class="fl">129.5</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-10" data-line-number="10"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;segment&quot;</span>, <span class="dt">x=</span><span class="dv">54</span>, <span class="dt">xend=</span><span class="dv">54</span>, <span class="dt">y=</span><span class="dv">128</span>, <span class="dt">yend=</span><span class="fl">131.5</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-11" data-line-number="11"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;segment&quot;</span>, <span class="dt">x=</span><span class="dv">59</span>, <span class="dt">xend=</span><span class="dv">59</span>, <span class="dt">y=</span><span class="dv">136</span>, <span class="dt">yend=</span><span class="fl">137.5</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-12" data-line-number="12"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;segment&quot;</span>, <span class="dt">x=</span><span class="dv">66</span>, <span class="dt">xend=</span><span class="dv">66</span>, <span class="dt">y=</span><span class="dv">141</span>, <span class="dt">yend=</span><span class="fl">146.5</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-13" data-line-number="13"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;segment&quot;</span>, <span class="dt">x=</span><span class="dv">74</span>, <span class="dt">xend=</span><span class="dv">74</span>, <span class="dt">y=</span><span class="dv">160</span>, <span class="dt">yend=</span><span class="fl">156.5</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb556-14" data-line-number="14"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>This method minimizes the residual sum of squares (RSS), which is represented mathematically by:</p>
<p><span class="math display">\[RSS = \sum\limits_{i=1}^{n}{(y_{i} - \hat{y}_{i})^2} = \sum\limits_{i=1}^{n}{\hat\varepsilon_{i}^{2}}\]</span></p>
<p>and is calculated as follows.</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb557-1" data-line-number="1">df =<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb557-2" data-line-number="2">  <span class="dt">y_hat =</span> beta0 <span class="op">+</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span>height,</a>
<a class="sourceLine" id="cb557-3" data-line-number="3">  <span class="dt">error =</span> weight <span class="op">-</span><span class="st"> </span>y_hat,</a>
<a class="sourceLine" id="cb557-4" data-line-number="4">  <span class="dt">error_squared =</span> error<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb557-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb557-6" data-line-number="6"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;RSS =&quot;</span>, <span class="kw">round</span>(<span class="kw">sum</span>(df<span class="op">$</span>error_squared), <span class="dv">2</span>)))</a></code></pre></div>
<pre><code>## [1] &quot;RSS = 145.66&quot;</code></pre>
<table>
<thead>
<tr class="header">
<th>height</th>
<th>weight</th>
<th>predicted weight</th>
<th>error</th>
<th>squared error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x</td>
<td>y</td>
<td><span class="math inline">\(\hat{y}_{i}\)</span></td>
<td><span class="math inline">\(y-\hat{y}_{i}\)</span></td>
<td><span class="math inline">\((y-\hat{y}_{i})^2\)</span></td>
</tr>
<tr class="even">
<td>66</td>
<td>141</td>
<td>146.35</td>
<td>-5.35</td>
<td>28.58</td>
</tr>
<tr class="odd">
<td>54</td>
<td>128</td>
<td>131.02</td>
<td>-3.02</td>
<td>9.14</td>
</tr>
<tr class="even">
<td>50</td>
<td>123</td>
<td>125.92</td>
<td>-2.92</td>
<td>8.50</td>
</tr>
<tr class="odd">
<td>74</td>
<td>160</td>
<td>156.56</td>
<td>3.44</td>
<td>11.83</td>
</tr>
<tr class="even">
<td>59</td>
<td>136</td>
<td>137.41</td>
<td>-1.41</td>
<td>1.98</td>
</tr>
<tr class="odd">
<td>53</td>
<td>139</td>
<td>129.75</td>
<td>9.25</td>
<td>85.63</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\bar{x} = 59.33\)</span></td>
<td><span class="math inline">\(\bar{y} = 137.83\)</span></td>
<td>-</td>
<td>-</td>
<td><span class="math inline">\(RSS: \Sigma = 145.66\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="goodness-of-fit" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Goodness of Fit</h3>
<p>While RSS gives us an idea of how well the regression prediction (<span class="math inline">\(\hat{y}\)</span>) can approximate the response (<span class="math inline">\(y\)</span>), it does not tell us how well the model fits the data because it has the same units as <span class="math inline">\(y\)</span>. To obtain a unitless measure of fit, <span class="math inline">\(R^2\)</span> (also called the coefficient of determination), RSS is divided by the total sum of squares (TSS), and that ratio is substracted from 1.</p>
<p><span class="math display">\[R^2 = 1- \frac{RSS}{TSS} = 1 - \frac{\Sigma(y_{i} - \hat{y}_{i})^2}{\Sigma(y_{i} - \bar{y}_{i})^2}\]</span></p>
<p>We calculate <span class="math inline">\(R^2\)</span> for the height/weight data as follows:</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb559-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(df<span class="op">$</span>error_squared) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(df<span class="op">$</span>w_dev<span class="op">^</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.8229798</code></pre>
<p>We interpret <span class="math inline">\(R^2\)</span> as the proportion of weight variation explained by the linear model. As a proportion, <span class="math inline">\(R^2\)</span> varies from 0 to 1, and ideally we seek models with a high <span class="math inline">\(R^2\)</span>. A graphical depiction of RSS and TSS for one of the residuals illustrates their relationship.</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="least-squares-method-in-r" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Least Squares Method In <em>R</em></h3>
<p>That was a fair amount of work, and of course <em>R</em> simplifies the process. Fortunately, the syntax for creating a linear model is very similar to ANOVA.</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb561-1" data-line-number="1">df.lm =<span class="st"> </span><span class="kw">lm</span>(weight <span class="op">~</span><span class="st"> </span>height, <span class="dt">data=</span>df)</a>
<a class="sourceLine" id="cb561-2" data-line-number="2"><span class="kw">summary</span>(df.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = weight ~ height, data = df)
## 
## Residuals:
##      1      2      3      4      5      6 
## -5.346 -3.023 -2.916  3.439 -1.408  9.254 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  62.0714    17.7405   3.499   0.0249 *
## height        1.2769     0.2961   4.312   0.0125 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.034 on 4 degrees of freedom
## Multiple R-squared:  0.823,  Adjusted R-squared:  0.7787 
## F-statistic:  18.6 on 1 and 4 DF,  p-value: 0.01252</code></pre>
<p>Going through each section of the output from top to bottom:</p>
<p><strong>Call:</strong> This is simply the formula we gave the <code>lm()</code> function.</p>
<p><strong>Residuals:</strong> The residuals in order of observation.</p>
<p><strong>Coefficients:</strong></p>
<ul>
<li><code>Estimate</code> These are the <span class="math inline">\(\beta\)</span>s, and we see that they match our values calculated above.</li>
<li><code>Std. Error</code> is the standard deviation of each <code>Estimate</code> (or <span class="math inline">\(\beta\)</span>) and can be used to determine the 95% confidence interval (CI). For example, the 95% CI for <code>height</code> is <span class="math inline">\(1.28 \pm 1.96(0.296)\)</span>.</li>
<li><code>t value</code> is <code>Estimate</code> / <code>Std. Error</code>.</li>
<li><code>Pr(&gt;|t|)</code> is the probability of observing a value at least as extreme as <span class="math inline">\(\beta\)</span> using a t-distribution and <span class="math inline">\((n-p-1)\)</span> degrees of freedom. The null hypothesis is <span class="math inline">\(H_{o}: \beta_{i}=0\)</span>. Notice that this is a test of each individual predictor.</li>
</ul>
<!-- Steve comment:  If I'm not mistaken, R doesn't use a z test if you calculate CIs on your estimates.  I think it uses a t test (which, with enough observations is about the same).  It might be worth noting that this CI estimate is similar to what we did in chapter 2.  see confint section below-->
<p><strong>Residual standard error:</strong> The square root of RSS divided by the difference of number of observations and the number of predictors. Or, <span class="math inline">\(RSE = \sqrt{\frac{RSS}{n-p}}\)</span>. Degrees of freedom is <span class="math inline">\((n-p-1)\)</span>.</p>
<p><strong>Multiple R-squared:</strong> The <span class="math inline">\(R^2\)</span> we calculated above.</p>
<p><strong>Adjusted R-squared:</strong>Normalizes <span class="math inline">\(R^2\)</span> by accounting for the number of observations and predictors in the model. When conducting multiple linear regression, this is the appropriate method of measuring goodness of fit. Adjusted r-squared is calculated by: <span class="math inline">\(\bar{R}^{2} = 1 - (1 - R^{2}) \frac{n-1}{n-p-1}\)</span>.</p>
<p><strong>F-statistic:</strong> The global test of significance where we wish to determine if <em>at least one</em> predictor is sginificant. The null hypothesis is <span class="math inline">\(H_{o}: \beta_{1}=...=\beta_{p-1}=0\)</span> under the F-distribution with <span class="math inline">\(p-1\)</span> and <span class="math inline">\(n-p-1\)</span> degrees of freedom.</p>
<p>We interpret the linear model in the following manner: <strong>for every inch increase in height, we predict a person’s weight increases by 1.28 pounds</strong>.</p>
<p><em>R</em> allows us to do several things with a model. We can use <em>R</em> to give us a confidence interval on our coefficients using <code>confint</code>:</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb563-1" data-line-number="1"><span class="co"># Note confint has several options</span></a>
<a class="sourceLine" id="cb563-2" data-line-number="2"><span class="kw">confint</span>(df.lm)</a></code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) 12.8158877 111.326969
## height       0.4547796   2.098992</code></pre>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb565-1" data-line-number="1"><span class="co"># Note this is more precise than the Z estimation shown above as it accounts for our sample size and uses a t test</span></a></code></pre></div>
<p>We can also predict results using <code>predict</code> Predict can either give you a point estimate, or an interval based on either the mean predictions (using <code>'confidence'</code>) or a single point (using <code>'prediction'</code>). You can read more about these options <a href = 'http://www.sthda.com/english/articles/40-regression-analysis/166-predict-in-r-model-predictions-and-confidence-intervals/'>here</a>.</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb566-1" data-line-number="1"><span class="kw">predict</span>(df.lm, <span class="kw">list</span>(<span class="dt">height =</span> <span class="dv">66</span>))</a></code></pre></div>
<pre><code>##        1 
## 146.3459</code></pre>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb568-1" data-line-number="1"><span class="kw">predict</span>(df.lm, <span class="kw">list</span>(<span class="dt">height =</span> <span class="dv">66</span>), <span class="dt">interval =</span> <span class="st">&#39;confidence&#39;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 146.3459 137.5811 155.1108</code></pre>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb570-1" data-line-number="1"><span class="kw">predict</span>(df.lm, <span class="kw">list</span>(<span class="dt">height =</span> <span class="dv">66</span>), <span class="dt">interval =</span> <span class="st">&#39;prediction&#39;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 146.3459 127.4375 165.2544</code></pre>
<p>Note, <em>R</em> will not prevent one from extrapolating beyond the data. Predicting a result on values outside the observed data is bad practice and should generally be avoided.</p>
<p>Finally, one can plot the results and a regression quite simply with <code>ggplot</code> using <code>stat_smooth</code>:</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb572-1" data-line-number="1"><span class="kw">ggplot</span>(<span class="dt">data =</span> df, <span class="kw">aes</span>(<span class="dt">x =</span> height, <span class="dt">y =</span> weight)) <span class="op">+</span><span class="st"> </span><span class="co"># Provide your data and aesthetics as usual</span></a>
<a class="sourceLine" id="cb572-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st">  </span><span class="co"># plot the observations</span></a>
<a class="sourceLine" id="cb572-3" data-line-number="3"><span class="st">  </span><span class="co"># stat_smooth creates a linear regression based on your given x and y values (i.e. lm(y~x))</span></a>
<a class="sourceLine" id="cb572-4" data-line-number="4"><span class="st">  </span><span class="co"># you can also plot the standard error</span></a>
<a class="sourceLine" id="cb572-5" data-line-number="5"><span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&#39;lm&#39;</span>, <span class="dt">se =</span> T) </a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="simple-linear-regression-problem-set" class="section level3">
<h3><span class="header-section-number">7.2.4</span> Simple Linear Regression Problem Set</h3>
<p><strong>For this problem set, you will have to read the next section on assumptions and diagnostics if you are not familiar with the assumptions necessary for simple linear regression.</strong></p>
<p>The problem set for this section is located <a href = '/_Chapter6_ProblemSets/Simple_Linear_Regression_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter6_ProblemSets/Simple_Linear_Regression_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter6_ProblemSets/Simple_Linear_Regression_PS_Answers.html'>here</a>.</p>
</div>
</div>
<div id="assumptions-and-diagnostics" class="section level2">
<h2><span class="header-section-number">7.3</span> Assumptions and Diagnostics</h2>
<p>There are four assumptions fundamental to linear regression:</p>
<ol style="list-style-type: decimal">
<li><strong>Linearity:</strong> The relationship between x and the mean of y is linear.</li>
<li><strong>Homoscedasticity:</strong> The variance of residual is the same for any value of x (i.e, constant variance).</li>
<li><strong>Independence:</strong> Independence of the prediction error from every one of the predictor variables.</li>
<li><strong>Normality:</strong> The prediction error is normally distributed.</li>
</ol>
<p>When conducting linear regression, we need to always perform diagnostic check to ensure we are not violating any of the inherent assumptions.</p>
<div id="linearity" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Linearity</h3>
<p>The assumption is that the relationship between x and the mean of y is linear, but what does that mean exactly? A regression model is linear if <span class="math inline">\(E[Y|X =x]\)</span> is a linear function <strong>of the <span class="math inline">\(\beta\)</span> parameters</strong>, not of <span class="math inline">\(x\)</span>. That means each of the following is a linear model:</p>
<ul>
<li><span class="math inline">\(\beta_{0} + \beta_{1}x\)</span> (note<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>)</li>
<li><span class="math inline">\(\beta_{0} + \beta_{1}x + \beta_{2}x^{2} + \beta_{3}x^{3}\)</span></li>
<li><span class="math inline">\(\beta_{0} + \beta_{1}log(x) + \beta_{2}sin(x)\)</span></li>
</ul>
<p>These are <em>not</em> linear models:</p>
<ul>
<li><span class="math inline">\(\beta_{0} + x^{\beta_{1}}\)</span>
<p>
 
</p></li>
<li><span class="math inline">\(\frac{1}{\beta_{0} + \beta_{1}x}\)</span>
<p>
 
</p></li>
<li><span class="math inline">\(\frac{e^{\beta_{0}+\beta_{1}x_{1}}}{1+e^{\beta_{0}+\beta_{1}x_{1}}}\)</span> (note<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>)</li>
</ul>
<p>As with ANOVA, <em>R</em> produces diagnostic plots for objects created by the <code>lm()</code> function. The first plot may be used to evaluate both linearity and homoscedasticity. A linear relationship will be indicated by a (relatively) horizontal red line on the plot. Since our height-weight data is so simple, we’ll switch to the <code>teengamb</code> dataset from the <code>faraway</code> package. This dataset consists of four predictor variables and one response (<code>gamble</code>). Read the help for <code>teengamb</code> to familiarize youself with the data. Since one of the predictors is binary (<code>sex</code>), we’ll exclude it for this example.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a> A summary of the resulting linear model is as follows.</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb574-1" data-line-number="1"><span class="kw">library</span>(faraway)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;faraway&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:GGally&#39;:
## 
##     happy</code></pre>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb577-1" data-line-number="1">tg.lm =<span class="st"> </span><span class="kw">lm</span>(gamble <span class="op">~</span><span class="st"> </span>. <span class="op">-</span>sex, <span class="dt">data=</span>teengamb)</a>
<a class="sourceLine" id="cb577-2" data-line-number="2"><span class="kw">summary</span>(tg.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gamble ~ . - sex, data = teengamb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -49.649 -12.008  -1.242   8.239 103.390 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -1.3044    15.7760  -0.083   0.9345    
## status        0.4701     0.2509   1.873   0.0678 .  
## income        5.7707     1.0494   5.499 1.95e-06 ***
## verbal       -4.1211     2.2785  -1.809   0.0775 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 24.28 on 43 degrees of freedom
## Multiple R-squared:  0.445,  Adjusted R-squared:  0.4062 
## F-statistic: 11.49 on 3 and 43 DF,  p-value: 1.161e-05</code></pre>
<p>The diagnostic plot to check the linearity assumption is the first plot returned, and we see a slight “U” shape to the red line. Notice that there are only three observations on the far right which appear to be heavily influencing the results. The conical spread of the data also strongly suggests heteroscedasticity might be an issue.</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb579-1" data-line-number="1"><span class="kw">plot</span>(tg.lm, <span class="dt">which =</span> <span class="dv">1</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Another screening method is with a paris plot, which we can quickly produce in base <em>R</em> with <code>pairs()</code>. This is a great way to do a quick check potential nonlinear relationships between pairs of variables. This is a screening method only, however, because we’re projecting onto two dimensions, so we may be missing things lurking in higher dimensions.</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb580-1" data-line-number="1"><span class="kw">pairs</span>(teengamb[, <span class="dv">2</span><span class="op">:</span><span class="dv">5</span>], <span class="dt">upper.panel=</span><span class="ot">NULL</span>, <span class="dt">lower.panel=</span>panel.smooth)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>If evidence of a nonlinear relationship exists, a linear model can still be used; however, either the response variable or one or more of the predictors must be transformed. This topic is covered in detail in the Advanced Designs chapter.</p>
</div>
<div id="homoscedasticity" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Homoscedasticity</h3>
<p>The procedure for testing constant variance in residuals in a linear model is similar to ANOVA. A plot of residuals versus fitted values is shown two plots ago, and we can look at the square root of standardized residuals versus fitted values. Both plots show strong evidence of heteroscedasticity.</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb581-1" data-line-number="1"><span class="kw">plot</span>(tg.lm, <span class="dt">which =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>There is no doubt some subjectivity to visual inspections. As a guide, consider the next three sets of plots that show constance variance, mild heteroscedasticity, and strong heteroscedasticity.</p>
<p>Constant variance:</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb582-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">oma =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>, <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb582-2" data-line-number="2"></a>
<a class="sourceLine" id="cb582-3" data-line-number="3">n &lt;-<span class="st"> </span><span class="dv">50</span> </a>
<a class="sourceLine" id="cb582-4" data-line-number="4"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>) {x &lt;-<span class="st"> </span><span class="kw">runif</span>(n); <span class="kw">plot</span>(x,<span class="kw">rnorm</span>(n))} </a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Mild heteroscedasticity:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb583-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">oma =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>, <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb583-2" data-line-number="2"></a>
<a class="sourceLine" id="cb583-3" data-line-number="3"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>) {x &lt;-<span class="st"> </span><span class="kw">runif</span>(n); <span class="kw">plot</span>(x,<span class="kw">sqrt</span>((x))<span class="op">*</span><span class="kw">rnorm</span>(n))} </a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Strong heteroscedasticity:</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb584-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">oma =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>, <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb584-2" data-line-number="2"></a>
<a class="sourceLine" id="cb584-3" data-line-number="3"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>) {x &lt;-<span class="st"> </span><span class="kw">runif</span>(n); <span class="kw">plot</span>(x,x<span class="op">*</span><span class="kw">rnorm</span>(n))}</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>The linear model analog to the Levene test is the Breusch-Pagan test. The null hypothesis is that the residuals have constant variance, and the alternative is that the error variance changes with the level of the response or with a linear combination of predictors. The <code>ncvTest()</code> from the <code>car</code> (companion to applied regression) package performs the test, and when applied to the <code>tg.lm</code> object confirms our suspicion of non-constant variance based on our visual inspection.</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb585-1" data-line-number="1">car<span class="op">::</span><span class="kw">ncvTest</span>(tg.lm)</a></code></pre></div>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 26.18623, Df = 1, p = 3.1003e-07</code></pre>
</div>
<div id="independence" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Independence</h3>
<p>The concept of indepedent (and identically distributed) data was covered in the statistics review and ANOVA chapters. It is no different when conducting linear regression and so will not be repeated here.</p>
</div>
<div id="normality" class="section level3">
<h3><span class="header-section-number">7.3.4</span> Normality</h3>
<p>Again, checking whether the residuals are normally distributed is the same for linear regression as for ANOVA. Create a Q-Q plot and apply the Shapiro-Wilk test as shown below.</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb587-1" data-line-number="1"><span class="kw">plot</span>(tg.lm, <span class="dt">which=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb588-1" data-line-number="1"><span class="kw">shapiro.test</span>(<span class="kw">residuals</span>(tg.lm))</a></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(tg.lm)
## W = 0.8651, p-value = 6.604e-05</code></pre>
</div>
<div id="unusual-observations" class="section level3">
<h3><span class="header-section-number">7.3.5</span> Unusual Observations</h3>
<p>Although not an assumption inherent to a linear model, it’s good practice to also check for unusual observations when performing diagnostic checks. There are two types of unusual observations: outliers and influential. An <em>outlier</em> is an observation with a large residual - it plots substantially above or below the regression line. An <em>influential observation</em> is one that substantially changes the model fit. Keep in mind that it is possible for an observation to have both characteristics. Examples Both types of observations are shown on the following plot (note that I rigged observations 11 and 12 to be unsual observations).</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>It’s not necessarily bad to have unusual observations, but it’s good practice to check for them, and, if found, decide what to do about them. A point with high <em>leverage</em> falls within the predictor space but is significantly separated from the other points. It has the potential to influence the fit but may not actually do so.</p>
<div id="leverage-points" class="section level4">
<h4><span class="header-section-number">7.3.5.1</span> Leverage Points</h4>
<p>The amount of leverage associated with each observation is called the <em>hat value</em> and are the diagonal elements of the <em>hat matrix</em>, which you can read more about <a href="https://www.sciencedirect.com/topics/mathematics/hat-matrix">here</a>, if you’re interested (or just really like linear algebra). The gist of it is that the sum of the hat values equals the number of observations. If every observation has exactly the same leverage, then the hat values will all equal <span class="math inline">\(p/n\)</span>, where p is the number of parameters and n is the number of observations (in our example we just have two parameters, so it’s <span class="math inline">\(2/n\)</span>). Increasing the hat value of one observation necessitates decreasing the hat values of the others, so we’re essentially looking for hat values significantly greater than this theoretical average. The generally accepted rule of thumb is that hat values greater than ~ <span class="math inline">\(2p/n\)</span> times the averages should be looked at more carefully. Extracting hat values from a linear model in <em>R</em> is done using the <code>hatvalues()</code> or <code>influence()</code> functions.</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb590-1" data-line-number="1">df.lm =<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data=</span>df)</a>
<a class="sourceLine" id="cb590-2" data-line-number="2">hatv =<span class="st"> </span><span class="kw">hatvalues</span>(df.lm)</a>
<a class="sourceLine" id="cb590-3" data-line-number="3"><span class="kw">print</span>(hatv)</a></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
## 0.14483261 0.12736536 0.11280932 0.10116448 0.09243086 0.08660844 0.08369723 
##          8          9         10         11         12 
## 0.08369723 0.08660844 0.09243086 0.10116448 0.88719068</code></pre>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb592-1" data-line-number="1"><span class="kw">influence</span>(df.lm)<span class="op">$</span>hat</a></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
## 0.14483261 0.12736536 0.11280932 0.10116448 0.09243086 0.08660844 0.08369723 
##          8          9         10         11         12 
## 0.08369723 0.08660844 0.09243086 0.10116448 0.88719068</code></pre>
<p>Verify that the sum of the hat values equals the number of parameters (2):</p>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb594-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;Sum of hat values:&quot;</span>, <span class="kw">sum</span>(hatv)))</a></code></pre></div>
<pre><code>## [1] &quot;Sum of hat values: 2&quot;</code></pre>
<p>Are any hat values &gt; <span class="math inline">\(2p/n\)</span> (recall I rigged observation 12)?</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb596-1" data-line-number="1">hatv <span class="op">&gt;</span><span class="st"> </span><span class="dv">4</span><span class="op">/</span><span class="kw">length</span>(df<span class="op">$</span>x)</a></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9    10    11    12 
## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE</code></pre>
<p>A graphical way of looking at leverage is with the <code>halfnorm()</code> function in the <code>faraway</code> package, which plots leverage against the positive normal quantiles. I added a red line to indicate the rule of thumb threshold.</p>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb598-1" data-line-number="1">faraway<span class="op">::</span><span class="kw">halfnorm</span>(hatv,<span class="dt">ylab=</span><span class="st">&quot;Leverages&quot;</span>)</a>
<a class="sourceLine" id="cb598-2" data-line-number="2"><span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">2</span><span class="op">*</span><span class="kw">mean</span>(hatv), <span class="dt">col=</span><span class="st">&#39;red&#39;</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Another measure of leaverage is <em>Cook’s Distance</em>, defined as:</p>
<p><span class="math display">\[D_{i}=\frac{r^{2}_{i}}{p}\left(\frac{h_{i}}{1-h_{i}}\right)\]</span></p>
<p>The rule of thumb for Cook’s Distance is an observation with <span class="math inline">\(D&gt;1\)</span>, and we can get these values in <em>R</em> with <code>cooks.distance()</code>.</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb599-1" data-line-number="1"><span class="kw">cooks.distance</span>(df.lm)</a></code></pre></div>
<pre><code>##            1            2            3            4            5            6 
## 6.193970e-02 4.398193e-05 6.553697e-04 4.789149e-10 3.736810e-03 1.917568e-02 
##            7            8            9           10           11           12 
## 3.490432e-03 4.701066e-02 1.130421e-02 9.893220e-02 3.409595e-01 1.703556e+01</code></pre>
<p>The fourth linear model plot also contains Cook’s Distance.</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb601-1" data-line-number="1"><span class="kw">plot</span>(df.lm, <span class="dt">which=</span><span class="dv">4</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
</div>
<div id="outliers" class="section level4">
<h4><span class="header-section-number">7.3.5.2</span> Outliers</h4>
<p>The hat values from the previous section are also used to calculate <em>standardized residuals</em>, <span class="math inline">\(r_{i}\)</span>.</p>
<p><span class="math display">\[r_{i}=\frac{\hat{\varepsilon}_{i} }{\hat{\sigma}\sqrt{1-h_{i}}}, i=1,...,n \]</span></p>
<p>where <span class="math inline">\(\hat{\varepsilon}\)</span> are the residuals, <span class="math inline">\(\hat{\sigma}\)</span> is the estimated residual standard error, and <span class="math inline">\(h\)</span> is the leverage. The rule of thumb for identifying unusually large standardised residuals is if <span class="math inline">\(|r_{i}| &gt; 2\)</span>. We can get standardized residuals in <em>R</em> with <code>rstandard()</code>.</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb602-1" data-line-number="1"><span class="kw">rstandard</span>(df.lm)</a></code></pre></div>
<pre><code>##             1             2             3             4             5 
##  8.552478e-01 -2.454950e-02  1.015300e-01 -9.225082e-05 -2.708924e-01 
##             6             7             8             9            10 
## -6.359731e-01 -2.764512e-01 -1.014559e+00 -4.882963e-01 -1.393847e+00 
##            11            12 
##  2.461458e+00  2.081408e+00</code></pre>
<p>Here we see that observation 11 is a potential outlier, and the observation 12 is both a high leverage point and a potential outlier.</p>
<p>We can also look at <em>studentized residuals</em>, which are defined as:</p>
<p><span class="math display">\[t_{i} = r_{i}\sqrt{\frac{n-p-1}{n-p-r^{2}_{i}}}\]</span></p>
<p>In <em>R</em>, we can use <code>rstudent()</code>:</p>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb604-1" data-line-number="1"><span class="kw">rstudent</span>(df.lm)</a></code></pre></div>
<pre><code>##             1             2             3             4             5 
##  8.427665e-01 -2.329041e-02  9.636946e-02 -8.751682e-05 -2.579393e-01 
##             6             7             8             9            10 
## -6.159215e-01 -2.632726e-01 -1.016216e+00 -4.688619e-01 -1.473142e+00 
##            11            12 
##  3.719616e+00  2.622850e+00</code></pre>
<p>It may be useful to view all of these measures together and apply some conditional formatting.</p>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb606-1" data-line-number="1"><span class="kw">library</span>(kableExtra)</a>
<a class="sourceLine" id="cb606-2" data-line-number="2"></a>
<a class="sourceLine" id="cb606-3" data-line-number="3">df <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb606-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb606-5" data-line-number="5">    <span class="dt">obs =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(df),</a>
<a class="sourceLine" id="cb606-6" data-line-number="6">    <span class="dt">r.standard =</span> <span class="kw">round</span>(<span class="kw">rstandard</span>(df.lm), <span class="dv">3</span>),</a>
<a class="sourceLine" id="cb606-7" data-line-number="7">    <span class="dt">r.student =</span> <span class="kw">round</span>(<span class="kw">rstudent</span>(df.lm), <span class="dv">3</span>), </a>
<a class="sourceLine" id="cb606-8" data-line-number="8">    <span class="dt">i.hatv =</span> <span class="kw">round</span>(<span class="kw">hatvalues</span>(df.lm), <span class="dv">3</span>),</a>
<a class="sourceLine" id="cb606-9" data-line-number="9">    <span class="dt">i.cook =</span> <span class="kw">round</span>(<span class="kw">cooks.distance</span>(df.lm), <span class="dv">3</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb606-10" data-line-number="10"><span class="st">  </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb606-11" data-line-number="11">    <span class="dt">r.standard =</span> <span class="kw">cell_spec</span>(r.standard, <span class="st">&quot;html&quot;</span>, <span class="dt">color=</span><span class="kw">ifelse</span>(<span class="kw">abs</span>(r.standard)<span class="op">&gt;</span><span class="dv">2</span>,<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>)),</a>
<a class="sourceLine" id="cb606-12" data-line-number="12">    <span class="dt">r.student =</span> <span class="kw">cell_spec</span>(r.student, <span class="st">&quot;html&quot;</span>, <span class="dt">color=</span><span class="kw">ifelse</span>(<span class="kw">abs</span>(r.student)<span class="op">&gt;</span><span class="dv">2</span>,<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>)),</a>
<a class="sourceLine" id="cb606-13" data-line-number="13">    <span class="dt">i.hatv =</span> <span class="kw">cell_spec</span>(i.hatv, <span class="st">&quot;html&quot;</span>, <span class="dt">color=</span><span class="kw">ifelse</span>(i.hatv<span class="op">&gt;</span><span class="dv">4</span><span class="op">/</span><span class="kw">nrow</span>(df),<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>)),</a>
<a class="sourceLine" id="cb606-14" data-line-number="14">    <span class="dt">i.cook =</span> <span class="kw">cell_spec</span>(i.cook, <span class="st">&quot;html&quot;</span>, <span class="dt">color=</span><span class="kw">ifelse</span>(i.cook<span class="op">&gt;</span><span class="dv">1</span>,<span class="st">&quot;red&quot;</span>, <span class="st">&quot;black&quot;</span>))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb606-15" data-line-number="15"><span class="st">  </span><span class="kw">kable</span>(<span class="dt">format =</span> <span class="st">&quot;html&quot;</span>, <span class="dt">escape =</span> F) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb606-16" data-line-number="16"><span class="st">  </span><span class="kw">kable_styling</span>(<span class="st">&quot;striped&quot;</span>, <span class="dt">full_width =</span> F)</a></code></pre></div>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
x
</th>
<th style="text-align:right;">
y
</th>
<th style="text-align:right;">
obs
</th>
<th style="text-align:left;">
r.standard
</th>
<th style="text-align:left;">
r.student
</th>
<th style="text-align:left;">
i.hatv
</th>
<th style="text-align:left;">
i.cook
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.0000000
</td>
<td style="text-align:right;">
1.6854792
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.855</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.843</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.145</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.062</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
0.3333333
</td>
<td style="text-align:right;">
0.7509842
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.025</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.023</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.127</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
0.6666667
</td>
<td style="text-align:right;">
1.2482309
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.102</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.096</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.113</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.001</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
1.0000000
</td>
<td style="text-align:right;">
1.4164313
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.101</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
1.3333333
</td>
<td style="text-align:right;">
1.3354675
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.271</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.258</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.092</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.004</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
1.6666667
</td>
<td style="text-align:right;">
1.1136044
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.636</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.616</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.087</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.019</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
2.0000000
</td>
<td style="text-align:right;">
1.9557610
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.276</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.263</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.084</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.003</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
2.3333333
</td>
<td style="text-align:right;">
1.1860038
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-1.015</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-1.016</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.084</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.047</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
2.6666667
</td>
<td style="text-align:right;">
2.2758785
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.488</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-0.469</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.087</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.011</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
3.0000000
</td>
<td style="text-align:right;">
1.2686430
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-1.394</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">-1.473</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.092</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.099</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
1.0000000
</td>
<td style="text-align:right;">
5.0000000
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:left;">
<span style="     color: red !important;">2.461</span>
</td>
<td style="text-align:left;">
<span style="     color: red !important;">3.72</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.101</span>
</td>
<td style="text-align:left;">
<span style="     color: black !important;">0.341</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
10.0000000
</td>
<td style="text-align:right;">
11.0000000
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:left;">
<span style="     color: red !important;">2.081</span>
</td>
<td style="text-align:left;">
<span style="     color: red !important;">2.623</span>
</td>
<td style="text-align:left;">
<span style="     color: red !important;">0.887</span>
</td>
<td style="text-align:left;">
<span style="     color: red !important;">17.036</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="what-to-do-about-unusual-observations" class="section level4">
<h4><span class="header-section-number">7.3.5.3</span> What To Do About Unusual Observations</h4>
<p>In the book, Linear Models With R, <span class="citation">Faraway (<a href="#ref-faraway2014">2014</a>)</span> gives advice on this topic that I’ll paraphrase.</p>
<ol style="list-style-type: decimal">
<li>Check for data entry errors and correct any that are found.</li>
<li>Consider the context. An unusual observation may be the single most important observation in the study.</li>
<li>Exclude the observation from the dataset and refit a model. If it makes little to no difference in your analysis, then it’s usually best to leave it in.</li>
<li>Do not automate the process of excluding outliers (see #2 above).</li>
<li>If you exclude an observation, document it in your report and explain your rationale so that your analytic integrety is not questioned.</li>
</ol>
</div>
</div>
<div id="linear-regression-assumptions-and-diagnostics-problem-set" class="section level3">
<h3><span class="header-section-number">7.3.6</span> Linear Regression Assumptions and Diagnostics Problem Set</h3>
<p>There is no problem set associated with this section. We check our assumptions and do diagnostic checks in all our analyses.</p>
</div>
</div>
<div id="multiple-linear-regression" class="section level2">
<h2><span class="header-section-number">7.4</span> Multiple Linear Regression</h2>
<p>In the previous section we considered just one predictor and one response. The linear model can be expanded to include multiple predictors by simply adding terms to the equation:</p>
<p><span class="math display">\[y = \beta_{0} + \beta_{1}x_{1}+ \beta_{2}x_{2} + ... + \beta_{(p-1)}x_{(p-1)} + \varepsilon\]</span></p>
<p>With one predictor, least squares regression produces a regression line. With two predictors, we get a regression plane (shown below), and so on up to a <span class="math inline">\((p-1)\)</span> dimensional hyperplane.</p>
<div id="htmlwidget-2a8e9539872343d5916c" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2a8e9539872343d5916c">{"x":{"visdat":{"8825f559861":["function () ","plotlyVisDat"],"8822298b30d":["function () ","data"],"88266a7fa20":["function () ","data"]},"cur_data":"88266a7fa20","attrs":{"8822298b30d":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"color":"black","size":7},"showlegend":false,"inherit":true},"88266a7fa20":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"mesh3d","facecolor":["blue","blue"],"opacity":0.75,"showlegend":false,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Best Fit Plane","showlegend":false,"scene":{"xaxis":{"range":[0,10],"title":"x1"},"yaxis":{"range":[0,10],"title":"x2"},"camera":{"eye":{"x":0,"y":-2,"z":0.29999999999999999}},"zaxis":{"title":"y"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[9.1480604349635541,9.3707541329786181,2.8613953478634357,8.3044762606732547,6.4174551889300346,5.1909594913013279,7.3658831464126706,1.3466659723781049,6.5699229040183127,7.0506478403694928],"y":[4.5774177624844015,7.1911225165240467,9.3467224715277553,2.5542882434092462,4.6229282254353166,9.4001452275551856,9.7822642838582397,1.1748736165463924,4.7499708156101406,5.6033274624496698],"z":[5.991143564095883,7.1147392251762405,3.2215451898572205,4.2641494583867541,4.4186978343246093,5.3655056340128997,4.5731544500974728,1.4696215585414492,2.1255277574059033,5.9528121108711503],"type":"scatter3d","mode":"markers","marker":{"color":"black","size":7,"line":{"color":"rgba(31,119,180,1)"}},"showlegend":false,"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"y<br />y","ticklen":2},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[0,10,0,10],"y":[0,0,10,10],"z":[0.16724376347106162,5.0760554882984916,2.1318105499343538,7.0406222747617839],"type":"mesh3d","facecolor":["blue","blue"],"opacity":0.75,"showlegend":false,"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>With two or more predictors, we can’t solve for the linear model coefficients the same way we did for the one predictor case. Solving for the coefficients (the <span class="math inline">\(\beta\)</span>s) requires some linear algebra. Given a data set with <span class="math inline">\(n\)</span> observations and one predictor, the <span class="math inline">\(y\)</span> (response), <span class="math inline">\(X\)</span> (predictor), and <span class="math inline">\(\beta\)</span> (coefficient) matrices are written as:</p>
<p><span class="math display">\[y= \begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix} , X= \begin{pmatrix} 1 &amp; x_1 \\ \vdots &amp; \vdots \\ 1 &amp; x_n \end{pmatrix}, \beta= \begin{pmatrix} \beta_0 \\ \beta_1 \end{pmatrix}\]</span></p>
<p>Incorporating the error term, we have:</p>
<p><span class="math display">\[\varepsilon= \begin{pmatrix} \varepsilon_1 \\ \vdots \\ \varepsilon_n \end{pmatrix} = \begin{pmatrix} y_1-\beta_0-\beta_1x_1 \\ \vdots \\ y_n-\beta_0-\beta_1x_n \end{pmatrix} = y-X\beta\]</span></p>
<p>Once we solve for the coefficients, multiplying them by the predictors gives the estimated response, <span class="math inline">\(\hat{y}\)</span>.</p>
<p><span class="math display">\[X\beta \equiv \hat{y}\]</span></p>
<p>With multiple linear regression, we expand the <span class="math inline">\(X\)</span> and <span class="math inline">\(\beta\)</span> matrices accordingly.</p>
<p><span class="math display">\[y= \begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix} , X= \begin{pmatrix} 1 &amp; x_{11} &amp; \ldots &amp; x_{1p-1} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_{n1} &amp; \ldots &amp; x_{np-1} \end{pmatrix}, \beta= \begin{pmatrix} \beta_0 \\ \vdots \\ \beta_{p-1} \end{pmatrix}\]</span></p>
<p>Incorporating error:</p>
<p><span class="math display">\[\varepsilon= \begin{pmatrix} \varepsilon_1 \\ \vdots \\ \varepsilon_n \end{pmatrix} = \begin{pmatrix} y_1-(\beta_0-\beta_1x_{11} + \ldots + \beta_{p-1}x_{1p-1}) \\ \vdots \\ y_n-(\beta_0-\beta_1x_{n1} + \ldots + \beta_{p-1}x_{np-1}) \end{pmatrix} = y-X\beta\]</span></p>
<p>However, notice that the final equation remains unchanged.</p>
<p><span class="math display">\[X\beta \equiv \hat{y}\]</span></p>
<p>The residual sum of squares (RSS) also remains unchanged, and so do the other equations that have RSS as a term, such as residual standard error and <span class="math inline">\(R^2\)</span>. The following is an example of solving the system of equations for a case with two predictors and no error. Given <span class="math inline">\(n=4\)</span> observations, we have the following system of equations:</p>
<p><span class="math display">\[x_0 = 10\]</span>
<span class="math display">\[x_0 + x_2 = 17\]</span>
<span class="math display">\[x_0 + x_1 = 15\]</span>
<span class="math display">\[x_0 + x_1 + x_2 = 22\]</span></p>
<p>In this example, we technically have all of the information we need to solve this system of equations without linear algebra, but we’ll apply it anyway to demonstrate the method. Rewriting the above system of equations into matrix form gives:</p>
<p><span class="math display">\[X= \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \end{pmatrix}, y= \begin{pmatrix} 10 \\ 17 \\ 15 \\ 22 \end{pmatrix}\]</span></p>
<p>One way to solve for the <span class="math inline">\(\beta\)</span> vector is to transpose the <span class="math inline">\(X\)</span> matrix and multiply it by the <span class="math inline">\(X|y\)</span> augmented matrix.</p>
<p><span class="math display">\[X^TX|y = \begin{pmatrix} 1&amp;1&amp;1&amp;1 \\ 0&amp;0&amp;1&amp;1 \\ 0&amp;1&amp;0&amp;1 \end{pmatrix} \begin{pmatrix} 1&amp;0&amp;0&amp;|&amp;10 \\ 1&amp;0&amp;1&amp;|&amp;17 \\ 1&amp;1&amp;0&amp;|&amp;15 \\ 1&amp;1&amp;1&amp;|&amp;22 \end{pmatrix} = \begin{pmatrix} 4&amp;2&amp;2&amp;|&amp;64 \\ 2&amp;2&amp;1&amp;|&amp;37 \\ 2&amp;1&amp;2&amp;|&amp;39 \end{pmatrix}\]</span></p>
<p>Use Gaussian elimination to reduce the resulting matrix by first multiplying the top row by <span class="math inline">\(-\frac{1}{2}\)</span> and adding those values to the second row.</p>
<p><span class="math display">\[\begin{pmatrix} 4&amp;2&amp;2&amp;|&amp;64 \\ 0&amp;1&amp;0&amp;|&amp;5 \\ 2&amp;1&amp;2&amp;|&amp;39 \end{pmatrix}\]</span></p>
<p>Reduce further using the same process on the third row.</p>
<p><span class="math display">\[\begin{pmatrix} 4&amp;2&amp;2&amp;|&amp;64 \\ 0&amp;1&amp;0&amp;|&amp;5 \\ 0&amp;0&amp;1&amp;|&amp;7 \end{pmatrix}\]</span></p>
<p>We find that</p>
<p><span class="math display">\[\beta_2 = 7\]</span>
and</p>
<p><span class="math display">\[\beta_1 = 5\]</span></p>
<p>and using back substitution we get</p>
<p><span class="math display">\[4\beta_0 + 2(5) + 2(7) = 64, \enspace so \enspace \beta_0 = 10\]</span></p>
<p>The resulting equation:</p>
<p><span class="math display">\[y=10+5x_1+7x_2\]</span></p>
<p>defines the best fit plane for this data, which is visualized below.</p>
<div id="htmlwidget-5bc403e1f7b162d7d6b0" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-5bc403e1f7b162d7d6b0">{"x":{"visdat":{"882562df27d":["function () ","plotlyVisDat"],"88225efa1f6":["function () ","data"],"88272bc863c":["function () ","data"]},"cur_data":"88272bc863c","attrs":{"88225efa1f6":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"color":"black","size":7},"showlegend":false,"inherit":true},"88272bc863c":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"mesh3d","facecolor":["blue","blue"],"showlegend":false,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Best Fit Plane","showlegend":false,"scene":{"camera":{"eye":{"x":-1.5,"y":-1.5,"z":0.29999999999999999}},"xaxis":{"title":"x1"},"yaxis":{"title":"x2"},"zaxis":{"title":"y"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[0,0,1,1],"y":[0,1,0,1],"z":[10,17,15,22],"type":"scatter3d","mode":"markers","marker":{"color":"black","size":7,"line":{"color":"rgba(31,119,180,1)"}},"showlegend":false,"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"y<br />y","ticklen":2},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[0,0,1,1],"y":[0,1,0,1],"z":[10,17,15,22],"type":"mesh3d","facecolor":["blue","blue"],"showlegend":false,"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Of course, <em>R</em> has linear algebra functions, so we don’t have to do all of that by hand. For example, we can solve for the <span class="math inline">\(\beta\)</span> vector by multiplying both sides of the equation <span class="math inline">\(X\beta \equiv \hat{y}\)</span> by <span class="math inline">\(X^T\)</span>.</p>
<p><span class="math display">\[X^TX\beta = X^Ty\]</span></p>
<p>Solving for <span class="math inline">\(\beta\)</span>, we get:</p>
<p><span class="math display">\[\beta=(X^TX)^{-1}X^Ty\]</span></p>
<p>Now use <code>solve()</code> function to calculate the <span class="math inline">\(\beta\)</span> vector (note that <code>solve()</code> inverts <span class="math inline">\(X^TX\)</span> automatically).</p>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb607-1" data-line-number="1">X =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,</a>
<a class="sourceLine" id="cb607-2" data-line-number="2">             <span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,</a>
<a class="sourceLine" id="cb607-3" data-line-number="3">             <span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,</a>
<a class="sourceLine" id="cb607-4" data-line-number="4">             <span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">byrow =</span> <span class="ot">TRUE</span>, <span class="dt">ncol=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb607-5" data-line-number="5"></a>
<a class="sourceLine" id="cb607-6" data-line-number="6">y =<span class="st"> </span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="dv">5</span><span class="op">*</span>X[, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="dv">7</span><span class="op">*</span>X[, <span class="dv">3</span>]</a>
<a class="sourceLine" id="cb607-7" data-line-number="7"></a>
<a class="sourceLine" id="cb607-8" data-line-number="8"><span class="kw">solve</span>(<span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X) <span class="op">%*%</span><span class="st"> </span>(<span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>y)</a></code></pre></div>
<pre><code>##      [,1]
## [1,]   10
## [2,]    5
## [3,]    7</code></pre>
<p>Fitting a linear model in <em>R</em> using the <code>lm()</code> function produces coefficients identical to the above results.</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb609-1" data-line-number="1"><span class="kw">coef</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>X[, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>X[, <span class="dv">3</span>]))</a></code></pre></div>
<pre><code>## (Intercept)      X[, 2]      X[, 3] 
##          10           5           7</code></pre>
<p>Technically, neither the <code>solve()</code> nor the <code>lm()</code> functions use Gaussian elimination when solving the system of equations. According to <a href="https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/lapack-routines/lapack-least-squares-and-eigenvalue-problem-routines.html">this site</a>, for overdetermined systems (where there are more equations than unknowns) like the example we’re working with, they use QR factorization instead. The details of QR factorization are beyond the scope of this course, but are explained well on <a href="http://www.seas.ucla.edu/~vandenbe/133A/lectures/ls.pdf">these slides</a> for a course at UCLA’s School of Engineering and Applied Sciences. In essence, the <span class="math inline">\(X\)</span> matrix is decomposed into <span class="math inline">\(Q\)</span> and <span class="math inline">\(R\)</span> matrices that are substituted for <span class="math inline">\(X\)</span> in the equation.</p>
<p><span class="math display">\[X^TX\beta = X^Ty\]</span></p>
<p><span class="math display">\[(QR)^T(QR)\beta = (QR)^Ty\]</span>
Skipping a lot of math, we end up with:</p>
<p><span class="math display">\[R\beta=Q^Ty\]</span></p>
<p>In <em>R</em>, use <code>qr(X)</code> to decompose <span class="math inline">\(X\)</span>, and then use <code>solve.qr()</code> to calculate the <span class="math inline">\(\beta\)</span> vector.</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb611-1" data-line-number="1">QR =<span class="st"> </span><span class="kw">qr</span>(X)</a>
<a class="sourceLine" id="cb611-2" data-line-number="2"><span class="kw">solve.qr</span>(QR, y)</a></code></pre></div>
<pre><code>## [1] 10  5  7</code></pre>
<p>Now we’ll make it a little more complicated by returning to the data set plotted at the beginning of this section. It consists of <span class="math inline">\(n=10\)</span> observations with random error.</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb613-1" data-line-number="1">mlr <span class="co"># multiple linear regression data set</span></a></code></pre></div>
<pre><code>## # A tibble: 10 x 3
##       x1    x2     y
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1  9.15  4.58  5.99
##  2  9.37  7.19  7.11
##  3  2.86  9.35  3.22
##  4  8.30  2.55  4.26
##  5  6.42  4.62  4.42
##  6  5.19  9.40  5.37
##  7  7.37  9.78  4.57
##  8  1.35  1.17  1.47
##  9  6.57  4.75  2.13
## 10  7.05  5.60  5.95</code></pre>
<p>Using QR decomposition, we get the following coefficients:</p>
<div class="sourceCode" id="cb615"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb615-1" data-line-number="1"><span class="co"># we need to add a column of 1&#39;s to get beta_0 for the intercept</span></a>
<a class="sourceLine" id="cb615-2" data-line-number="2">intercept =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb615-3" data-line-number="3">QR =<span class="st"> </span><span class="kw">qr</span>(<span class="kw">cbind</span>(intercept, mlr[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>])) </a>
<a class="sourceLine" id="cb615-4" data-line-number="4">betas =<span class="st"> </span><span class="kw">solve.qr</span>(QR, mlr<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb615-5" data-line-number="5">betas</a></code></pre></div>
<pre><code>## intercept        x1        x2 
## 0.1672438 0.4908812 0.1964567</code></pre>
<p>And we get the following coefficients in the linear model:</p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb617-1" data-line-number="1"><span class="kw">coef</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>mlr))</a></code></pre></div>
<pre><code>## (Intercept)          x1          x2 
##   0.1672438   0.4908812   0.1964567</code></pre>
<p>The following code chunk shows how the earlier interactive plot was generated. Note the following:</p>
<ul>
<li><p>The value of <code>y</code> defined by the plane at (<code>x1</code>, <code>x2</code>) = (0,0) is <span class="math inline">\(\beta_0\)</span> (shown by the red dot).</p></li>
<li><p>The slope of the line at the intersection of the plane with the <code>x1</code> axis is <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>The slope of the line at the intersection of the plane with the <code>x2</code> axis is <span class="math inline">\(\beta_2\)</span>,</p></li>
</ul>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb619-1" data-line-number="1"><span class="co"># define the bast fit plane using the betas from QR decomposition</span></a>
<a class="sourceLine" id="cb619-2" data-line-number="2">plane =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x1=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">10</span>),</a>
<a class="sourceLine" id="cb619-3" data-line-number="3">               <span class="dt">x2=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">10</span>),</a>
<a class="sourceLine" id="cb619-4" data-line-number="4">               <span class="dt">y=</span><span class="kw">c</span>(betas[<span class="dv">1</span>], betas[<span class="dv">1</span>]<span class="op">+</span><span class="dv">10</span><span class="op">*</span>betas[<span class="dv">2</span>], betas[<span class="dv">1</span>]<span class="op">+</span><span class="dv">10</span><span class="op">*</span>betas[<span class="dv">3</span>], betas[<span class="dv">1</span>]<span class="op">+</span><span class="kw">sum</span>(<span class="dv">10</span><span class="op">*</span>betas[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>])))</a>
<a class="sourceLine" id="cb619-5" data-line-number="5"></a>
<a class="sourceLine" id="cb619-6" data-line-number="6"><span class="co"># use plotly for interactive 3D graphs</span></a>
<a class="sourceLine" id="cb619-7" data-line-number="7"><span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb619-8" data-line-number="8"><span class="st">  </span><span class="co"># add the points to the graph</span></a>
<a class="sourceLine" id="cb619-9" data-line-number="9"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> mlr, <span class="dt">x=</span><span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>y, <span class="dt">type=</span><span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, </a>
<a class="sourceLine" id="cb619-10" data-line-number="10">            <span class="dt">marker=</span><span class="kw">list</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">size=</span><span class="dv">7</span>), <span class="dt">showlegend=</span><span class="ot">FALSE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb619-11" data-line-number="11"><span class="st">  </span><span class="co"># add the plane</span></a>
<a class="sourceLine" id="cb619-12" data-line-number="12"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> plane, <span class="dt">x=</span><span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>y, <span class="dt">type=</span><span class="st">&#39;mesh3d&#39;</span>, </a>
<a class="sourceLine" id="cb619-13" data-line-number="13">            <span class="dt">facecolor=</span><span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;blue&#39;</span>), <span class="dt">opacity =</span> <span class="fl">0.75</span>, <span class="dt">showlegend=</span><span class="ot">FALSE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb619-14" data-line-number="14"><span class="st">  </span><span class="co"># add the red dot</span></a>
<a class="sourceLine" id="cb619-15" data-line-number="15"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">x=</span><span class="dv">0</span>, <span class="dt">y=</span><span class="dv">0</span>, <span class="dt">z=</span>betas[<span class="dv">1</span>], <span class="dt">type=</span><span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>,</a>
<a class="sourceLine" id="cb619-16" data-line-number="16">            <span class="dt">marker=</span><span class="kw">list</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="dv">7</span>), <span class="dt">showlegend=</span><span class="ot">FALSE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb619-17" data-line-number="17"><span class="st">  </span><span class="co"># adjust the layout</span></a>
<a class="sourceLine" id="cb619-18" data-line-number="18"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&#39;Best Fit Plane&#39;</span>, <span class="dt">showlegend =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb619-19" data-line-number="19">         <span class="dt">scene =</span> <span class="kw">list</span>(<span class="dt">xaxis =</span> <span class="kw">list</span>(<span class="dt">range=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>)),</a>
<a class="sourceLine" id="cb619-20" data-line-number="20">                      <span class="dt">yaxis =</span> <span class="kw">list</span>(<span class="dt">range=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">10</span>)),</a>
<a class="sourceLine" id="cb619-21" data-line-number="21">                      <span class="dt">camera =</span> <span class="kw">list</span>(<span class="dt">eye =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="dv">0</span>, <span class="dt">y =</span> <span class="dv">-2</span>, <span class="dt">z =</span> <span class="fl">0.3</span>))))</a></code></pre></div>
<div id="htmlwidget-f4997105858173027594" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-f4997105858173027594">{"x":{"visdat":{"88212651923":["function () ","plotlyVisDat"],"8822bb091bc":["function () ","data"],"8827674d57a":["function () ","data"]},"cur_data":"8827674d57a","attrs":{"8822bb091bc":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"color":"black","size":7},"showlegend":false,"inherit":true},"8827674d57a":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"mesh3d","facecolor":["blue","blue"],"opacity":0.75,"showlegend":false,"inherit":true},"8827674d57a.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":0,"y":0,"z":0.16724376347106162,"type":"scatter3d","mode":"markers","marker":{"color":"red","size":7},"showlegend":false,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Best Fit Plane","showlegend":false,"scene":{"xaxis":{"range":[0,10],"title":"x1"},"yaxis":{"range":[0,10],"title":"x2"},"camera":{"eye":{"x":0,"y":-2,"z":0.29999999999999999}},"zaxis":{"title":"y"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[9.1480604349635541,9.3707541329786181,2.8613953478634357,8.3044762606732547,6.4174551889300346,5.1909594913013279,7.3658831464126706,1.3466659723781049,6.5699229040183127,7.0506478403694928],"y":[4.5774177624844015,7.1911225165240467,9.3467224715277553,2.5542882434092462,4.6229282254353166,9.4001452275551856,9.7822642838582397,1.1748736165463924,4.7499708156101406,5.6033274624496698],"z":[5.991143564095883,7.1147392251762405,3.2215451898572205,4.2641494583867541,4.4186978343246093,5.3655056340128997,4.5731544500974728,1.4696215585414492,2.1255277574059033,5.9528121108711503],"type":"scatter3d","mode":"markers","marker":{"color":"black","size":7,"line":{"color":"rgba(31,119,180,1)"}},"showlegend":false,"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"y<br />y","ticklen":2},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[0,10,0,10],"y":[0,0,10,10],"z":[0.16724376347106162,5.0760554882984916,2.1318105499343538,7.0406222747617839],"type":"mesh3d","facecolor":["blue","blue"],"opacity":0.75,"showlegend":false,"frame":null},{"x":[0],"y":[0],"z":[0.16724376347106162],"type":"scatter3d","mode":"markers","marker":{"color":"red","size":7,"line":{"color":"rgba(44,160,44,1)"}},"showlegend":false,"error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"line":{"color":"rgba(44,160,44,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<div id="r-example" class="section level3">
<h3><span class="header-section-number">7.4.1</span> <em>R</em> Example</h3>
<p>Below is a short example on doing multiple linear regression in <em>R</em>. This example uses a <a href = '/_Chapter6_ProblemSets/PatientSatData.csv'> data set </a> on patient satisfaction as a function of their age, illness severity, anxiety level, and a surgery variable (this is a binary variable, we will ignore for this exercise). We will attempt to model patient satisfaction as a function of age, illness severity, and anxiety level.</p>
<p>First, read the data and build the linear model.</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb620-1" data-line-number="1"><span class="co"># Read the data</span></a>
<a class="sourceLine" id="cb620-2" data-line-number="2">pt &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;../docsArchive/_Chapter6_ProblemSets/PatientSatData.csv&#39;</span>, <span class="dt">sep =</span> <span class="st">&#39;,&#39;</span>, <span class="dt">header =</span> T)</a>
<a class="sourceLine" id="cb620-3" data-line-number="3"><span class="co"># let&#39;s drop SurgMed as we&#39;re not going to use it</span></a>
<a class="sourceLine" id="cb620-4" data-line-number="4">pt &lt;-<span class="st"> </span>pt <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>SurgMed)</a>
<a class="sourceLine" id="cb620-5" data-line-number="5"><span class="co"># View the data</span></a>
<a class="sourceLine" id="cb620-6" data-line-number="6">pt</a></code></pre></div>
<pre><code>##    Age illSeverity Anxiety Satisfaction
## 1   55          50     2.1           68
## 2   46          24     2.8           77
## 3   30          46     3.3           96
## 4   35          48     4.5           80
## 5   59          58     2.0           43
## 6   61          60     5.1           44
## 7   74          65     5.5           26
## 8   38          42     3.2           88
## 9   27          42     3.1           75
## 10  51          50     2.4           57
## 11  53          38     2.2           56
## 12  41          30     2.1           88
## 13  37          31     1.9           88
## 14  24          34     3.1          102
## 15  42          30     3.0           88
## 16  50          48     4.2           70
## 17  58          61     4.6           52
## 18  60          71     5.3           43
## 19  62          62     7.2           46
## 20  68          38     7.8           56
## 21  70          41     7.0           59
## 22  79          66     6.2           26
## 23  63          31     4.1           52
## 24  39          42     3.5           83
## 25  49          40     2.1           75</code></pre>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb622-1" data-line-number="1"><span class="co"># Note that our data is formatted in numeric format, which is what we need for this sort of modeling.</span></a>
<a class="sourceLine" id="cb622-2" data-line-number="2"></a>
<a class="sourceLine" id="cb622-3" data-line-number="3"><span class="co"># we can look at our data.  In multiple regression, `pairs` is useful:</span></a>
<a class="sourceLine" id="cb622-4" data-line-number="4"><span class="kw">pairs</span>(pt)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb623-1" data-line-number="1"><span class="co"># We can see some useful things:</span></a>
<a class="sourceLine" id="cb623-2" data-line-number="2"><span class="co"># 1) Age and satisfaction appear to have a linear relationship (the bottom left corner)</span></a>
<a class="sourceLine" id="cb623-3" data-line-number="3"><span class="co"># 2) illness severity and satisfaction appear to have a linear relationship, thoguh not as strongly</span></a>
<a class="sourceLine" id="cb623-4" data-line-number="4"><span class="co"># 3) it&#39;s less clear for anxiety and satisfaction</span></a>
<a class="sourceLine" id="cb623-5" data-line-number="5"><span class="co"># 4) Age and illness severity do not appear to have a relationship</span></a>
<a class="sourceLine" id="cb623-6" data-line-number="6"><span class="co"># 5) Age and anxiety might have a relationship, but its not fully clear</span></a>
<a class="sourceLine" id="cb623-7" data-line-number="7"><span class="co"># 6) illness severity and anxiety do not appear to have a relationship</span></a>
<a class="sourceLine" id="cb623-8" data-line-number="8"></a>
<a class="sourceLine" id="cb623-9" data-line-number="9"><span class="co"># Model the data</span></a>
<a class="sourceLine" id="cb623-10" data-line-number="10"><span class="co"># Note how this format is analogous to ANOVA with multiple factors</span></a>
<a class="sourceLine" id="cb623-11" data-line-number="11"><span class="co"># and simple linear regression</span></a>
<a class="sourceLine" id="cb623-12" data-line-number="12">ptLM &lt;-<span class="st"> </span><span class="kw">lm</span>(Satisfaction <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>illSeverity <span class="op">+</span><span class="st"> </span>Anxiety, <span class="dt">data =</span> pt)</a></code></pre></div>
<p>We can now view our model results. We will use <span class="math inline">\(\alpha = .05\)</span> as our appropriate significance level.</p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb624-1" data-line-number="1"><span class="co"># we view the summary results</span></a>
<a class="sourceLine" id="cb624-2" data-line-number="2"><span class="kw">summary</span>(ptLM)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Satisfaction ~ Age + illSeverity + Anxiety, data = pt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.2812  -3.8635   0.6427   4.5324  11.8734 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 143.8952     5.8975  24.399  &lt; 2e-16 ***
## Age          -1.1135     0.1326  -8.398 3.75e-08 ***
## illSeverity  -0.5849     0.1320  -4.430 0.000232 ***
## Anxiety       1.2962     1.0560   1.227 0.233231    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.037 on 21 degrees of freedom
## Multiple R-squared:  0.9035, Adjusted R-squared:  0.8897 
## F-statistic: 65.55 on 3 and 21 DF,  p-value: 7.85e-11</code></pre>
<p>We see several things. First, we can say that the intercept, age, and illness severity are all statistically significant. Anxiety does not appear to be significant. As expected given our individual results, our F-statistic (sometimes called a model utility test) shows us that there is at least one predictor that is significant. Further we can see that our <span class="math inline">\(R^2\)</span> and <span class="math inline">\(R_{adj}^2\)</span> are both relatively high, which shows that these predictors explain much of the variability in the data. We can see our RSE is about 7, which is not too extreme given our the range on our outputs.</p>
<p>As we do not find anxiety significant, we can drop it as an independent variable (we discuss model selection in the next chapter). Our new model is then:</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb626-1" data-line-number="1">ptLM2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Satisfaction <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>illSeverity, <span class="dt">data =</span> pt)</a>
<a class="sourceLine" id="cb626-2" data-line-number="2"><span class="kw">summary</span>(ptLM2)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Satisfaction ~ Age + illSeverity, data = pt)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.2800  -5.0316   0.9276   4.2911  10.4993 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 143.4720     5.9548  24.093  &lt; 2e-16 ***
## Age          -1.0311     0.1156  -8.918 9.28e-09 ***
## illSeverity  -0.5560     0.1314  -4.231 0.000343 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.118 on 22 degrees of freedom
## Multiple R-squared:  0.8966, Adjusted R-squared:  0.8872 
## F-statistic: 95.38 on 2 and 22 DF,  p-value: 1.446e-11</code></pre>
<p>We get similar results. We can then build our linear model:</p>
<p><span class="math display">\[[Patient Satisfaction] = 143 + -1.03[Age] + -0.556[Illness Severity] + \epsilon\]</span></p>
<p>We can interpret this as saying that for every additional year of age, a patient’s satisfaction drops about a point and for every additional point of illness severity, a patient loses about half a point of satisfaction. That is, the older and sicker you are, the less likely you are to be satisfied. This generally seems to make sense.</p>
<p>Moreover, we can use the model to show our confidence intervals on our coefficients using <code>confint</code>.</p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb628-1" data-line-number="1"><span class="co"># Note that confint requires:</span></a>
<a class="sourceLine" id="cb628-2" data-line-number="2"><span class="co"># A model, called object in this case</span></a>
<a class="sourceLine" id="cb628-3" data-line-number="3"><span class="co"># You can also pass it your 1-alpha level (the default is alpha = .05, or .95 confidence)</span></a>
<a class="sourceLine" id="cb628-4" data-line-number="4"><span class="co"># You can also pass it specific parameters to check (useful if working with amodel with many parameters)</span></a>
<a class="sourceLine" id="cb628-5" data-line-number="5"><span class="kw">confint</span>(ptLM2, <span class="dt">level =</span> <span class="fl">.95</span>)</a></code></pre></div>
<pre><code>##                  2.5 %      97.5 %
## (Intercept) 131.122434 155.8215898
## Age          -1.270816  -0.7912905
## illSeverity  -0.828566  -0.2835096</code></pre>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb630-1" data-line-number="1"><span class="co"># We can then say, with 95% confidence that our intercept is in the interval ~ (131, 156)</span></a></code></pre></div>
<p>We can use our model to predict a patient’s satisfaction given their age and illness severity using <code>predict</code> in the same manner as simple linear regression.</p>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb631-1" data-line-number="1"><span class="co"># Point estimate</span></a>
<a class="sourceLine" id="cb631-2" data-line-number="2"><span class="kw">predict</span>(ptLM2, <span class="kw">list</span>(<span class="dt">Age =</span> <span class="dv">35</span>, <span class="dt">illSeverity=</span><span class="dv">50</span>))</a></code></pre></div>
<pre><code>##        1 
## 79.58325</code></pre>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb633-1" data-line-number="1"><span class="co"># An individual response will be in this interval</span></a>
<a class="sourceLine" id="cb633-2" data-line-number="2"><span class="kw">predict</span>(ptLM2,<span class="kw">list</span>(<span class="dt">Age=</span><span class="dv">35</span>, <span class="dt">illSeverity=</span><span class="dv">50</span>),<span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 79.58325 63.87546 95.29105</code></pre>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb635-1" data-line-number="1"><span class="co"># The mean response for someone with these inputs will be</span></a>
<a class="sourceLine" id="cb635-2" data-line-number="2"><span class="kw">predict</span>(ptLM2,<span class="kw">list</span>(<span class="dt">Age=</span><span class="dv">35</span>, <span class="dt">illSeverity=</span><span class="dv">50</span>),<span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 79.58325 74.21262 84.95388</code></pre>
<p>We can also plot these values. Note that our result with two predictors is a plane in this case. With 3+ predictors, it is a hyperplane. Often, we will plot either a contour map where each line corresponds to a fixed level of a predictor or just choose a single predictor.</p>
<p>We can produce a contour plot using <code>geom_contour</code> (one can also use <code>stat_contour</code>). Of course, this works for two predictors. As the number of independent variables increases, visualizing the data becomes somewhat more challenging and requires visualizing the solution only a few dimensions at a time.</p>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb637-1" data-line-number="1"><span class="co"># produce a contour plot</span></a>
<a class="sourceLine" id="cb637-2" data-line-number="2"></a>
<a class="sourceLine" id="cb637-3" data-line-number="3"><span class="co"># Requires a set of points with predictions:</span></a>
<a class="sourceLine" id="cb637-4" data-line-number="4">mySurface &lt;-<span class="st"> </span><span class="kw">expand_grid</span>( <span class="co"># produce a data frame that is every combination of the following vectors</span></a>
<a class="sourceLine" id="cb637-5" data-line-number="5">  <span class="dt">Age =</span> <span class="kw">seq</span>(<span class="kw">min</span>(pt<span class="op">$</span>Age), <span class="kw">max</span>(pt<span class="op">$</span>Age), <span class="dt">by =</span> <span class="dv">1</span>), <span class="co"># a sequence of ages from the min observation to the max by 1s</span></a>
<a class="sourceLine" id="cb637-6" data-line-number="6">  <span class="dt">illSeverity =</span> <span class="kw">seq</span>(<span class="kw">min</span>(pt<span class="op">$</span>illSeverity), <span class="kw">max</span>(pt<span class="op">$</span>illSeverity), <span class="dt">by =</span> <span class="dv">1</span>)) <span class="co"># a sequence of illness severity min to max observations</span></a>
<a class="sourceLine" id="cb637-7" data-line-number="7"></a>
<a class="sourceLine" id="cb637-8" data-line-number="8"><span class="co"># look at our data</span></a>
<a class="sourceLine" id="cb637-9" data-line-number="9"><span class="kw">head</span>(mySurface)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##     Age illSeverity
##   &lt;dbl&gt;       &lt;dbl&gt;
## 1    24          24
## 2    24          25
## 3    24          26
## 4    24          27
## 5    24          28
## 6    24          29</code></pre>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb639-1" data-line-number="1"><span class="co"># add in our predictions. Recall predict can take a data frame with </span></a>
<a class="sourceLine" id="cb639-2" data-line-number="2"><span class="co"># columns that have the same name as the variables in the model</span></a>
<a class="sourceLine" id="cb639-3" data-line-number="3">mySurface<span class="op">$</span>Satisfaction &lt;-<span class="st"> </span><span class="kw">predict</span>(ptLM2, mySurface) </a>
<a class="sourceLine" id="cb639-4" data-line-number="4"><span class="kw">head</span>(mySurface)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 3
##     Age illSeverity Satisfaction
##   &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;
## 1    24          24         105.
## 2    24          25         105.
## 3    24          26         104.
## 4    24          27         104.
## 5    24          28         103.
## 6    24          29         103.</code></pre>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb641-1" data-line-number="1"><span class="co"># Plot the contours for our response</span></a>
<a class="sourceLine" id="cb641-2" data-line-number="2"><span class="kw">ggplot</span>(<span class="dt">data =</span> mySurface, <span class="co"># requires a data frame with an x and y (your predictors), and z (your response)</span></a>
<a class="sourceLine" id="cb641-3" data-line-number="3">               <span class="kw">aes</span>(<span class="dt">x =</span> Age, <span class="dt">y =</span> illSeverity, <span class="dt">z =</span> Satisfaction)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb641-4" data-line-number="4"><span class="st">  </span><span class="co"># you can use a number of ways to do this.  geom_contour works</span></a>
<a class="sourceLine" id="cb641-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_contour</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="kw">after_stat</span>(level))) <span class="op">+</span><span class="st"> </span><span class="co"># This color argument varies the color of your contours by their level</span></a>
<a class="sourceLine" id="cb641-6" data-line-number="6"><span class="st">  </span><span class="kw">scale_color_distiller</span>(<span class="dt">palette =</span> <span class="st">&#39;Spectral&#39;</span>, <span class="dt">direction =</span> <span class="dv">-1</span>) <span class="op">+</span><span class="st"> </span><span class="co"># change the color from indecipherable blue</span></a>
<a class="sourceLine" id="cb641-7" data-line-number="7"><span class="st">  </span><span class="co"># clean up the plot</span></a>
<a class="sourceLine" id="cb641-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;Age&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Illness Severity&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&#39;Patient Satisfaction Response Surface&#39;</span>) </a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<p>With this plot, we can clearly see at least two things:</p>
<ul>
<li>Our mathematical interpretation holds true. The younger and less severely ill the patient, the more satisfied they are (in general, as based on our model).</li>
<li>Our model is a plane. We see this with the evenly spaced, linear contour lines.</li>
</ul>
<p>It is also useful to overlay the actual observations on the plot. We can do this as follows:</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb642-1" data-line-number="1"><span class="co"># This is our original contour plot as produced above, with one exception.  </span></a>
<a class="sourceLine" id="cb642-2" data-line-number="2"><span class="co"># We move the data for the contour to the geom_contour so we can also plot the observations</span></a>
<a class="sourceLine" id="cb642-3" data-line-number="3"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb642-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_contour</span>(<span class="dt">data =</span> mySurface, <span class="kw">aes</span>(<span class="dt">x =</span> Age, <span class="dt">y =</span> illSeverity, <span class="dt">z =</span> Satisfaction, <span class="dt">color =</span> <span class="kw">after_stat</span>(level))) <span class="op">+</span><span class="st"> </span><span class="co"># This color argument varies the color of your contours by their level</span></a>
<a class="sourceLine" id="cb642-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_color_distiller</span>(<span class="dt">palette =</span> <span class="st">&#39;Spectral&#39;</span>, <span class="dt">direction =</span> <span class="dv">-1</span>) <span class="op">+</span><span class="st"> </span><span class="co"># change the color from indecipherable blue</span></a>
<a class="sourceLine" id="cb642-6" data-line-number="6"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&#39;Age&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&#39;Illness Severity&#39;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&#39;Patient Satisfaction Response Surface&#39;</span>)  <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb642-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> pt, <span class="kw">aes</span>(<span class="dt">x =</span> Age, <span class="dt">y =</span> illSeverity, <span class="dt">color =</span> Satisfaction))</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<p>By plotting these points, we can compare our results (the contour lines) to the observations. The first thing this allows us to do is look for outliers. For example, there are two around the age 30 and a severity of illness; note how their colors are disjoint from what the contour colors predict. This, of course, is harder to interpret than a simple linear regression as it involves comparing colors. In general, it is easier to use the numbers for higher dimensional models. Second, we can get an idea of leverage or areas of our model that are not informed by data. For example, there are no observations in this region:</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>That means that any predictions in this region are ill-informed and extrapolations beyond the data. In an advanced design section, we will discuss how ensuring we get “coverage” or “space-filling” is an important property for good experimental designs so we can avoid this problem.</p>
<p>Finally, we can check our model to ensure that it is legitimate.</p>
<p>Check assumptions:</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb643-1" data-line-number="1"><span class="co"># Plot our standard diagnostic plots</span></a>
<a class="sourceLine" id="cb643-2" data-line-number="2"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb643-3" data-line-number="3"><span class="kw">plot</span>(ptLM2)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb644-1" data-line-number="1"><span class="co"># It appears that we meet our linearity, independence, normality and homoscedasticity assumptions.</span></a>
<a class="sourceLine" id="cb644-2" data-line-number="2"><span class="co"># There are no significant patterns, though we may have a few unusual observations</span></a>
<a class="sourceLine" id="cb644-3" data-line-number="3"></a>
<a class="sourceLine" id="cb644-4" data-line-number="4"><span class="co"># Check normality</span></a>
<a class="sourceLine" id="cb644-5" data-line-number="5"><span class="kw">shapiro.test</span>(ptLM2<span class="op">$</span>residuals)</a></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  ptLM2$residuals
## W = 0.95367, p-value = 0.3028</code></pre>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb646-1" data-line-number="1"><span class="co"># Check homosceasticity</span></a>
<a class="sourceLine" id="cb646-2" data-line-number="2">car<span class="op">::</span><span class="kw">ncvTest</span>(ptLM2)</a></code></pre></div>
<pre><code>## Non-constant Variance Score Test 
## Variance formula: ~ fitted.values 
## Chisquare = 1.380242, Df = 1, p = 0.24006</code></pre>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb648-1" data-line-number="1"><span class="co"># We meet our assumptions</span></a></code></pre></div>
<p>Unusual Observations</p>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb649-1" data-line-number="1"><span class="co"># Outliers</span></a>
<a class="sourceLine" id="cb649-2" data-line-number="2"><span class="co"># We can identify points that have residuals greater than 2 standard deviations away from our model&#39;s prediction</span></a>
<a class="sourceLine" id="cb649-3" data-line-number="3">ptLM2<span class="op">$</span>residuals[<span class="kw">abs</span>(ptLM2<span class="op">$</span>residuals) <span class="op">&gt;=</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span><span class="kw">sd</span>(ptLM2<span class="op">$</span>residuals)]</a></code></pre></div>
<pre><code>##         9 
## -17.27998</code></pre>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb651-1" data-line-number="1"><span class="co"># Point 9 is an outlier</span></a>
<a class="sourceLine" id="cb651-2" data-line-number="2"></a>
<a class="sourceLine" id="cb651-3" data-line-number="3"><span class="co"># We can check for leverage points with a number of ways.  We&#39;ll check using Cook&#39;s distance</span></a>
<a class="sourceLine" id="cb651-4" data-line-number="4"><span class="kw">plot</span>(ptLM2, <span class="dt">which =</span> <span class="dv">4</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb652-1" data-line-number="1"><span class="co"># Again point 9 is a point of significant leverage.  </span></a></code></pre></div>
<p>Based on these results, we may consider dropping point nine. Before doing so, we should check for data entry errors or anything unusual about that data point. If we do drop it, we should note that we did so in our analysis.</p>
<p>If we do conclude that point nine should be dropped, we can build a new linear model:</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb653-1" data-line-number="1"><span class="co"># Just check the summary of the model with Point 9 dropped</span></a>
<a class="sourceLine" id="cb653-2" data-line-number="2"><span class="kw">summary</span>(<span class="kw">lm</span>(Satisfaction <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>illSeverity, <span class="dt">data =</span> pt[<span class="op">-</span><span class="dv">9</span>,]))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Satisfaction ~ Age + illSeverity, data = pt[-9, 
##     ])
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -11.870  -3.700   0.834   3.595  12.169 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 147.9415     5.2186  28.349  &lt; 2e-16 ***
## Age          -1.1484     0.1044 -11.003 3.54e-10 ***
## illSeverity  -0.5054     0.1120  -4.513 0.000191 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.003 on 21 degrees of freedom
## Multiple R-squared:  0.9292, Adjusted R-squared:  0.9224 
## F-statistic: 137.8 on 2 and 21 DF,  p-value: 8.449e-13</code></pre>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb655-1" data-line-number="1"><span class="co"># Note that our standard errors decrease somewhat and our R^2 increases, indicating this is a better model</span></a>
<a class="sourceLine" id="cb655-2" data-line-number="2"><span class="co"># (though on a smaller subset of the data)</span></a></code></pre></div>
</div>
<div id="multiple-linear-regression-problem-set" class="section level3">
<h3><span class="header-section-number">7.4.2</span> Multiple Linear Regression Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter6_ProblemSets/Multi_Linear_Regression_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter6_ProblemSets/Multi_Linear_Regression_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter6_ProblemSets/Multi_Linear_Regression_PS_Answers.html'>here</a>.</p>
<!-------------------------------------------------------------------------------------------------------------------------->
</div>
</div>
<div id="categorical-variables" class="section level2">
<h2><span class="header-section-number">7.5</span> Categorical Variables</h2>
<p>In the ANOVA chapter, you were introduced to a method for evaluating differences in a response for three or more sample populations. In the dataset, each sample population was associated with a different level of a categorical variable. In linear regression, the categorical variable itself can be included as one of the predictors as long as we ensure that the categorical variable is a <code>factor</code> variable type in the formula we supply to the <code>lm()</code> function.</p>
<p>We’ll revisit the <code>ames</code> dataset from the ANOVA chapter. We’ll just consider one predictor, <code>Mo.Sold</code>, with <code>SalePrice</code> as the response. Recall that <code>Mo.Sold</code> is a discrete number between 1 and 12 that represents the month a house was sold. When we read the data into a tibble, <code>Mo.Sold</code> is a numeric data type since it consists of discrete numbers.</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb656-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb656-2" data-line-number="2"></a>
<a class="sourceLine" id="cb656-3" data-line-number="3">ames =<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_csv</span>(<span class="st">&#39;../docsArchive/_Chapter3_ProblemSets/ames.csv&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(Mo.Sold, SalePrice)</a>
<a class="sourceLine" id="cb656-4" data-line-number="4"></a>
<a class="sourceLine" id="cb656-5" data-line-number="5"><span class="kw">class</span>(ames<span class="op">$</span>Mo.Sold)</a></code></pre></div>
<pre><code>## [1] &quot;numeric&quot;</code></pre>
<p>We need to convert <code>Mo.Sold</code> to a factor to correctly perform ANOVA.</p>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb658-1" data-line-number="1">ames<span class="op">$</span>Mo.Sold =<span class="st"> </span><span class="kw">as.factor</span>(ames<span class="op">$</span>Mo.Sold)</a>
<a class="sourceLine" id="cb658-2" data-line-number="2"></a>
<a class="sourceLine" id="cb658-3" data-line-number="3">ames.aov =<span class="st"> </span><span class="kw">aov</span>(SalePrice <span class="op">~</span><span class="st"> </span>Mo.Sold, <span class="dt">data=</span>ames)</a>
<a class="sourceLine" id="cb658-4" data-line-number="4"><span class="kw">summary</span>(ames.aov)</a></code></pre></div>
<pre><code>##               Df    Sum Sq  Mean Sq F value Pr(&gt;F)  
## Mo.Sold       11 1.353e+11 1.23e+10   1.934  0.031 *
## Residuals   2918 1.856e+13 6.36e+09                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>And now we can also include <code>Mo.Sold</code> as a predictor in a linear model.</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb660-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">lm</span>(SalePrice <span class="op">~</span><span class="st"> </span>Mo.Sold, <span class="dt">data=</span>ames))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice ~ Mo.Sold, data = ames)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -168754  -51556  -19087   33297  560790 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   194210       7190  27.009  &lt; 2e-16 ***
## Mo.Sold2      -15846       9976  -1.588  0.11231    
## Mo.Sold3      -18080       8895  -2.033  0.04218 *  
## Mo.Sold4      -26498       8631  -3.070  0.00216 ** 
## Mo.Sold5      -20510       8234  -2.491  0.01280 *  
## Mo.Sold6      -12668       8018  -1.580  0.11427    
## Mo.Sold7       -9843       8116  -1.213  0.22529    
## Mo.Sold8       -7988       8888  -0.899  0.36890    
## Mo.Sold9       -2658       9550  -0.278  0.78080    
## Mo.Sold10     -14153       9406  -1.505  0.13250    
## Mo.Sold11      -6559       9807  -0.669  0.50368    
## Mo.Sold12      -9756      10623  -0.918  0.35851    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 79750 on 2918 degrees of freedom
## Multiple R-squared:  0.007239,   Adjusted R-squared:  0.003497 
## F-statistic: 1.934 on 11 and 2918 DF,  p-value: 0.03103</code></pre>
<p>Notice that the model F-statistic, degrees of freedom, and p-value of the linear model are identical to those of ANOVA. If we extract the coefficients from the ANOVA model, we see that they, too, are identical to the linear model coefficients.</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb662-1" data-line-number="1">ames.aov<span class="op">$</span>coefficients</a></code></pre></div>
<pre><code>## (Intercept)    Mo.Sold2    Mo.Sold3    Mo.Sold4    Mo.Sold5    Mo.Sold6 
##  194210.016  -15845.670  -18079.555  -26498.027  -20509.801  -12667.454 
##    Mo.Sold7    Mo.Sold8    Mo.Sold9   Mo.Sold10   Mo.Sold11   Mo.Sold12 
##   -9843.152   -7987.553   -2657.873  -14152.953   -6558.751   -9755.968</code></pre>
<p>The difference between ANOVA and linear regression is that in ANOVA, the categorical variable is effect coded, and in linear regression, the categorical variable is “dummy” coded. Effect coding means that each factor level is coded with 1s and -1s so that each category’s mean is compared to the overall mean. For example, the mean sale price for the month of January is:</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb664-1" data-line-number="1">ames <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Mo.Sold<span class="op">==</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">meanPrice =</span> <span class="kw">mean</span>(SalePrice))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   meanPrice
##       &lt;dbl&gt;
## 1   194210.</code></pre>
<p>Dummy coding means that factor levels are coded with 0s for all levels except the one of interest, which is coded with a 1.<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a> This creates dummy variables in the linear regression equation where each level is represented in the equation by its own variable. For the <code>ames</code> data, the regression equation becomes:</p>
<center>
<span class="math display">\[y=\beta_{0}+\beta_{1}x_{1}+...+\beta_{11}x_{11}+\varepsilon\]</span>
</center>
<p>Here, <span class="math inline">\(\beta_{0}\)</span> represents the coefficient for January, <span class="math inline">\(\beta_{1}\)</span> is the coefficient for February, and so on. If we want to find the mean sale price for January, we set <span class="math inline">\(x_{1}\)</span> through <span class="math inline">\(x_{11}\)</span> to 0, and we’re left with <span class="math inline">\(y=\beta_{0}\)</span>. In other words, the y-intercept is the mean sale price for January. We can do this explicitly by:</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb666-1" data-line-number="1">ames <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb666-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dummy =</span> <span class="kw">ifelse</span>(Mo.Sold<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>),  <span class="co"># one-hot encoding</span></a>
<a class="sourceLine" id="cb666-3" data-line-number="3">         <span class="dt">jan =</span> dummy <span class="op">*</span><span class="st"> </span>SalePrice) <span class="op">%&gt;%</span><span class="st">       </span><span class="co"># multiply dummy variable and sale price</span></a>
<a class="sourceLine" id="cb666-4" data-line-number="4"><span class="st">  </span><span class="kw">filter</span>(jan<span class="op">!=</span><span class="dv">0</span>) <span class="op">%&gt;%</span><span class="st">                        </span><span class="co"># don&#39;t include the zeros in the mean</span></a>
<a class="sourceLine" id="cb666-5" data-line-number="5"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">meanPrice =</span> <span class="kw">mean</span>(jan))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   meanPrice
##       &lt;dbl&gt;
## 1   194210.</code></pre>
<p>You can see that this is the same value as the intercept coefficient in the linear model summary. Fundamentally, these two coding techniques are just different ways of doing the same thing, and so in <em>R</em>, the <code>aov()</code> function is just a wrapper for the <code>lm()</code> function. For a more detailed discussion on effect versus dummy coding, please refer to <a href="https://stats.idre.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis/">this site</a> at the UCLA Institute for Digital Research and Education.</p>
<p>A nice feature of the <code>lm()</code> function is that we don’t have to manually create dummy variables for factor levels - it does it for us. The following code demonstrates. First the manual example with just the first three months.</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb668-1" data-line-number="1">ames =<span class="st"> </span>ames <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb668-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">feb=</span><span class="kw">ifelse</span>(Mo.Sold<span class="op">==</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb668-3" data-line-number="3">         <span class="dt">mar=</span><span class="kw">ifelse</span>(Mo.Sold<span class="op">==</span><span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb668-4" data-line-number="4"></a>
<a class="sourceLine" id="cb668-5" data-line-number="5"><span class="kw">summary</span>(<span class="kw">lm</span>(SalePrice <span class="op">~</span><span class="st"> </span>feb <span class="op">+</span><span class="st"> </span>mar, <span class="dt">data=</span>ames <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Mo.Sold <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>))))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice ~ feb + mar, data = ames %&gt;% filter(Mo.Sold %in% 
##     c(1, 2, 3)))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -165264  -53701  -17997   30319  560790 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   194210       7960  24.398   &lt;2e-16 ***
## feb           -15846      11044  -1.435    0.152    
## mar           -18080       9847  -1.836    0.067 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 88280 on 485 degrees of freedom
## Multiple R-squared:  0.007313,   Adjusted R-squared:  0.003219 
## F-statistic: 1.786 on 2 and 485 DF,  p-value: 0.1687</code></pre>
<p>Now let <code>lm()</code> do all the work.</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb670-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">lm</span>(SalePrice <span class="op">~</span><span class="st"> </span>Mo.Sold, <span class="dt">data=</span>ames <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Mo.Sold <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>))))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice ~ Mo.Sold, data = ames %&gt;% filter(Mo.Sold %in% 
##     c(1, 2, 3)))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -165264  -53701  -17997   30319  560790 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   194210       7960  24.398   &lt;2e-16 ***
## Mo.Sold2      -15846      11044  -1.435    0.152    
## Mo.Sold3      -18080       9847  -1.836    0.067 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 88280 on 485 degrees of freedom
## Multiple R-squared:  0.007313,   Adjusted R-squared:  0.003219 
## F-statistic: 1.786 on 2 and 485 DF,  p-value: 0.1687</code></pre>
<div id="categorical-linear-regression-problem-set" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Categorical Linear Regression Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter6_ProblemSets/Categorical_Linear_Regression_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter6_ProblemSets/Categorical_Linear_Regression_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter6_ProblemSets/Categorical_Linear_Regression_PS_Answers.html'>here</a>.</p>
</div>
</div>
<div id="transformation" class="section level2">
<h2><span class="header-section-number">7.6</span> Transformation</h2>
<p>Now that we have designs that include factors with more than two levels, we have the ability to evaluate non-linear relationships between predictor and response variables. Incorporating non-linear terms in a linear model is accomplished by transforming either the response or predictors. For an overview of transformation, read <a href = "http://fmwww.bc.edu/RePEc/bocode/t/transint.html">Transformations: an introduction</a> by Nicholas J. Cox at Durham University. Skip the section titled “How to do transformations in Stata”; we’ll replace that with “How to do transformations in <em>R</em>” below.</p>
<div id="identifying-non-linear-relationships" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Identifying Non-Linear Relationships</h3>
<p>I think the simplest way to screen your data for potential non-linear relationships is with a pairs plot that includes a smoother. To demonstrate, I’ll take the CCD we created earlier and add a response, y, that has a non-linear relationship with the speed and stealth factors. I also substracted 2 from the stealth factor to center it at 0.</p>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb672-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb672-2" data-line-number="2"></a>
<a class="sourceLine" id="cb672-3" data-line-number="3">ccdGrid =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb672-4" data-line-number="4">  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="dv">4</span>)),</a>
<a class="sourceLine" id="cb672-5" data-line-number="5">  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">3</span>), <span class="dt">each =</span> <span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb672-6" data-line-number="6">  <span class="dt">x3 =</span> <span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">4</span>), <span class="kw">rep</span>(<span class="dv">3</span>,<span class="dv">4</span>)),</a>
<a class="sourceLine" id="cb672-7" data-line-number="7">  <span class="dt">star =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;y&#39;</span>, <span class="dv">7</span>), <span class="kw">rep</span>(<span class="st">&#39;n&#39;</span>,<span class="dv">8</span>)),</a>
<a class="sourceLine" id="cb672-8" data-line-number="8">  <span class="dt">line =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;line1&#39;</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;line2&#39;</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;line3&#39;</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;none&#39;</span>,<span class="dv">9</span>))</a>
<a class="sourceLine" id="cb672-9" data-line-number="9">)</a>
<a class="sourceLine" id="cb672-10" data-line-number="10"></a>
<a class="sourceLine" id="cb672-11" data-line-number="11"></a>
<a class="sourceLine" id="cb672-12" data-line-number="12">ccd =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">speed =</span> ccdGrid<span class="op">$</span>x1, </a>
<a class="sourceLine" id="cb672-13" data-line-number="13">             <span class="dt">stealth =</span> ccdGrid<span class="op">$</span>x2 <span class="op">-</span><span class="st"> </span><span class="dv">2</span>, </a>
<a class="sourceLine" id="cb672-14" data-line-number="14">             <span class="dt">surv =</span> ccdGrid<span class="op">$</span>x3, </a>
<a class="sourceLine" id="cb672-15" data-line-number="15">             <span class="dt">y =</span> <span class="kw">log</span>(speed) <span class="op">-</span><span class="st"> </span>stealth<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>surv)</a>
<a class="sourceLine" id="cb672-16" data-line-number="16"></a>
<a class="sourceLine" id="cb672-17" data-line-number="17">smooth_fn &lt;-<span class="st"> </span><span class="cf">function</span>(data, mapping, ...){</a>
<a class="sourceLine" id="cb672-18" data-line-number="18">  <span class="kw">ggplot</span>(<span class="dt">data =</span> data, <span class="dt">mapping =</span> mapping) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb672-19" data-line-number="19"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb672-20" data-line-number="20"><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">formula =</span> y<span class="op">~</span>x, <span class="dt">method=</span>loess, <span class="dt">fill=</span><span class="st">&quot;red&quot;</span>, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, ...)</a>
<a class="sourceLine" id="cb672-21" data-line-number="21">}</a>
<a class="sourceLine" id="cb672-22" data-line-number="22"></a>
<a class="sourceLine" id="cb672-23" data-line-number="23"><span class="kw">ggpairs</span>(ccd, <span class="dt">lower=</span><span class="kw">list</span>(<span class="dt">continuous=</span>smooth_fn), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>A visual inspection of the last row of plots is enough to identify the non-linear relationships that speed and stealth have with the response. We can also look at the density plot for the response (the lower right curve) and see some skewness away from a normal distribution.</p>
</div>
<div id="checking-model-structure" class="section level3">
<h3><span class="header-section-number">7.6.2</span> Checking Model Structure</h3>
<p>Generating a pairs plot is a screening process only. For a more complete analysis, we need to check the model structure. Recall that one of the key assumptions of the linear regression model is that the regression errors are independent and identically distributed. If that assumption is not true, then the non-linear portion of the relationship between predictor and response will be contained in the (estimated) residuals, <span class="math inline">\(\hat{\varepsilon}\)</span>. Plotting the residuals versus the individual predictors is one method of checking model structure. In <em>R</em>, we can do this with <code>termplot</code>.</p>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb673-1" data-line-number="1"><span class="co"># first, we need a linear model</span></a>
<a class="sourceLine" id="cb673-2" data-line-number="2">ccd.lm =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>ccd)</a>
<a class="sourceLine" id="cb673-3" data-line-number="3"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb673-4" data-line-number="4"><span class="kw">termplot</span>(ccd.lm, <span class="dt">partial.resid =</span> <span class="ot">TRUE</span>, <span class="dt">col.res=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">main=</span><span class="st">&quot;Residuals vs. Predictor&quot;</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>In these plots, we’re checking for whether there is a non-linear shape to the data by looking for trends in the blue circles. The red lines are the coefficients from the linear model for reference. The non-linear shape to stealth is clearly visible, but we’re missing the non-linearity in speed. Unfortunately, partial residual plots only <em>suggest</em> transformations for the predictors because they are influenced by other predictor variables, and (if present) influential observations and multicollinearity. The process is done manually in <em>R</em>. First, since stealth appears to be an inverse square, we’ll transform that variable, then re-fit the model, and check the partial residuals again. Before we do that, we need to know how to transform variables.</p>
</div>
<div id="how-to-transform-variables-in-r" class="section level3">
<h3><span class="header-section-number">7.6.3</span> How To Transform Variables In <em>R</em></h3>
<p>To account for non-linear relationships in a linear model, we need to transform the variables in the <code>lm</code> function. From the partial residuals plot, we know we should try a quadratic term for stealth. Summaries of linear models without and then with the transformation are shown below for the <code>ccd</code> data.</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb674-1" data-line-number="1"><span class="co"># without transformation</span></a>
<a class="sourceLine" id="cb674-2" data-line-number="2">ccd.lm =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>speed <span class="op">+</span><span class="st"> </span>stealth <span class="op">+</span><span class="st"> </span>surv, <span class="dt">data =</span> ccd)</a>
<a class="sourceLine" id="cb674-3" data-line-number="3"><span class="kw">summary</span>(ccd.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ speed + stealth + surv, data = ccd)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.3813 -0.3813 -0.3813  0.6187  0.7626 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.168e+00  5.462e-01  -2.139  0.05574 .  
## speed        5.493e-01  1.855e-01   2.961  0.01295 *  
## stealth     -2.708e-18  1.855e-01   0.000  1.00000    
## surv         1.000e+00  1.855e-01   5.390  0.00022 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5867 on 11 degrees of freedom
## Multiple R-squared:  0.7747, Adjusted R-squared:  0.7132 
## F-statistic: 12.61 on 3 and 11 DF,  p-value: 0.0006996</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb676-1" data-line-number="1"><span class="co"># with transformation</span></a>
<a class="sourceLine" id="cb676-2" data-line-number="2">ccd_t.lm =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>speed <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(stealth<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>surv, <span class="dt">data =</span> ccd)</a>
<a class="sourceLine" id="cb676-3" data-line-number="3"><span class="kw">summary</span>(ccd_t.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ speed + I(stealth^2) + surv, data = ccd)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.08631 -0.02877 -0.02877  0.05754  0.11507 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -0.46300    0.07257   -6.38 5.22e-05 ***
## speed         0.54931    0.02295   23.94 7.72e-11 ***
## I(stealth^2) -1.05754    0.03975  -26.61 2.46e-11 ***
## surv          1.00000    0.02295   43.58 1.13e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.07257 on 11 degrees of freedom
## Multiple R-squared:  0.9966, Adjusted R-squared:  0.9956 
## F-statistic:  1060 on 3 and 11 DF,  p-value: 8.06e-14</code></pre>
<p>Notice in the call to <code>lm</code> with the transformed variables, the polynomial term is surrounded by <code>I()</code>. This is to avoid confusion between arithmetic and symbolic uses of <code>+</code> in the <code>formula</code> function (see <code>?formula</code> for more details). Let’s take another look at the partial residual plots with stealth transformed.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb678-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb678-2" data-line-number="2"><span class="kw">termplot</span>(ccd_t.lm, <span class="dt">partial.resid =</span> <span class="ot">TRUE</span>, <span class="dt">col.res=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">main=</span><span class="st">&quot;Residuals vs. Predictor&quot;</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>Stealth looks much better, and now we’re able to see the non-linear relationship with speed. Re-fit and plot again with a log transformation on speed.</p>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb679-1" data-line-number="1">ccd_t2.lm =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(speed) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(stealth<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>surv, <span class="dt">data =</span> ccd)</a>
<a class="sourceLine" id="cb679-2" data-line-number="2"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb679-3" data-line-number="3"><span class="kw">termplot</span>(ccd_t2.lm, <span class="dt">partial.resid =</span> <span class="ot">TRUE</span>, <span class="dt">col.res=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">main=</span><span class="st">&quot;Residuals vs. Predictor&quot;</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>I didn’t add any error to the data, so we now have a perfect fit. With real-world data, there will be noise, and the best transformation isn’t known in advance. The following chart from <a href="https://statswithcats.wordpress.com/2010/11/21/fifty-ways-to-fix-your-data/">Stats With Cats</a> is a useful guide when determining what transformations to try.</p>
<center>
<img src="https://statswithcats.files.wordpress.com/2010/11/independent-variable-transformations.jpg">
</center>
<p>Now consider results from the 17-point NOLH we created earlier. I added a response, y, with a non-linear relationship to one of the factors, and I added some noise to make this example more realistic. Plotting just these two variables with a linear regression line reveals a little curvature to the trend, but it’s not extreme.</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb680-1" data-line-number="1">nolh.lm1 =<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span>x, <span class="dt">data=</span>nolh)</a>
<a class="sourceLine" id="cb680-2" data-line-number="2"><span class="kw">termplot</span>(nolh.lm1, <span class="dt">partial.resid =</span> <span class="ot">TRUE</span>, <span class="dt">col.res=</span><span class="st">&#39;blue&#39;</span>)</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<p>We’ve picked up the non-linear shape, and it looks like we need some degree of polynomial as a transformation. For reference, let’s look at the linear model summary.</p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb681-1" data-line-number="1"><span class="kw">summary</span>(nolh.lm1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = nolh)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -665.4 -497.3 -108.8  364.6 1245.6 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -1193.3      314.6  -3.793  0.00177 ** 
## x              286.8       30.7   9.343 1.21e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 620.1 on 15 degrees of freedom
## Multiple R-squared:  0.8534, Adjusted R-squared:  0.8436 
## F-statistic: 87.29 on 1 and 15 DF,  p-value: 1.212e-07</code></pre>
<p>That’s not a bad fit, but we can probably improve it by trying a transformation. The curvature suggests a polynomial might be better, so let’s try a second degree polynomial fit. First the plot, then the linear model summary.</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<pre><code>## 
## Call:
## lm(formula = y ~ I(x^2), data = nolh)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -304.4 -243.1  -25.1  228.5  495.9 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -349.0775    97.0449  -3.597  0.00264 ** 
## I(x^2)        16.5459     0.6993  23.660 2.73e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 261.6 on 15 degrees of freedom
## Multiple R-squared:  0.9739, Adjusted R-squared:  0.9722 
## F-statistic: 559.8 on 1 and 15 DF,  p-value: 2.73e-13</code></pre>
<p>The plot looks better than the first one. This model also has a higher <span class="math inline">\(R^{2}\)</span> than the first one, so perhaps it is a better fit. What happens if we continue to add higher order polynomials? The <code>poly()</code> function is useful for this purpose.</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb684-1" data-line-number="1">nolh.poly =<span class="st"> </span><span class="kw">lm</span>(y<span class="op">~</span><span class="kw">poly</span>(x, <span class="dv">15</span>), <span class="dt">data =</span> nolh)</a>
<a class="sourceLine" id="cb684-2" data-line-number="2"><span class="kw">summary</span>(nolh.poly)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ poly(x, 15), data = nolh)
## 
## Residuals:
##          1          2          3          4          5          6          7 
##  0.0003231 -0.0051699  0.0387741 -0.1809457  0.5880735 -1.4113764  2.5875234 
##          8          9         10         11         12         13         14 
## -3.6964620  4.1585197 -3.6964620  2.5875234 -1.4113764  0.5880735 -0.1809457 
##         15         16         17 
##  0.0387741 -0.0051699  0.0003231 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1388.2398     1.9213 722.541 0.000881 ***
## poly(x, 15)1  5793.9598     7.9218 731.390 0.000870 ***
## poly(x, 15)2  2372.8190     7.9218 299.528 0.002125 ** 
## poly(x, 15)3   371.3985     7.9218  46.883 0.013577 *  
## poly(x, 15)4     6.3875     7.9218   0.806 0.568003    
## poly(x, 15)5    -1.2064     7.9218  -0.152 0.903787    
## poly(x, 15)6    -0.4781     7.9218  -0.060 0.961626    
## poly(x, 15)7    -8.2612     7.9218  -1.043 0.486653    
## poly(x, 15)8    -0.9076     7.9218  -0.115 0.927379    
## poly(x, 15)9    -2.6003     7.9218  -0.328 0.798087    
## poly(x, 15)10    4.4736     7.9218   0.565 0.672730    
## poly(x, 15)11    3.9691     7.9218   0.501 0.704304    
## poly(x, 15)12   -1.8700     7.9218  -0.236 0.852423    
## poly(x, 15)13   -5.3439     7.9218  -0.675 0.622195    
## poly(x, 15)14   -7.5554     7.9218  -0.954 0.515068    
## poly(x, 15)15   -6.5343     7.9218  -0.825 0.560919    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.922 on 1 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 4.179e+04 on 15 and 1 DF,  p-value: 0.003839</code></pre>
<p>With a 15th order polynomial we get an <span class="math inline">\(R^{2}\)</span> of 0.9999745, which is a nearly perfect fit. Notice the p-values, though. They indicate that the best model is actually the one with the second order term. Why is the best model not the one with the highest <span class="math inline">\(R^{2}\)</span>? What we’ve done is over-fit the model to the data. We can see this by plotting the two polynomial fits.</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<p>While the model with a 15th order polynomial perfectly fits these data, the model with the second order polynomial will generalize much better.</p>
</div>
<div id="transformed-regression-problem-set" class="section level3">
<h3><span class="header-section-number">7.6.4</span> Transformed Regression Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter6_ProblemSets/Transformed_Regression_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter6_ProblemSets/Transformed_Regression_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter6_ProblemSets/Transformed_Regression_PS_Answers.html'>here</a>.</p>
</div>
</div>
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">7.7</span> Logistic Regression</h2>
<p>So far, we’ve seen regression techniques for continuous and categorical response variables. There is a different form of regression called logistic regression for the case when the response is a binary variable. We could encounter this situation when analyzing AWARS results, if we were interested in something like whether a unit defeated a counterattack, reached an objective, or ended the simulation at some strength above a fixed threshold.</p>
<div id="motivating-example" class="section level3">
<h3><span class="header-section-number">7.7.1</span> Motivating Example</h3>
<p>The need for a different type of regression can be seen using an example. We’ll look at just one predictor (<code>age</code>) and the response (<code>chd</code>) in the <code>SAheart</code> dataset from the <code>bestglm</code> package. Here the response, <code>chd</code> is a binary variable indicating whether someone did (1) or did not (0) develop coronoary heart disease. For now, we’ll just look at the first 20 observations with a scatter plot.</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb686-1" data-line-number="1">SAheart =<span class="st"> </span>bestglm<span class="op">::</span>SAheart</a>
<a class="sourceLine" id="cb686-2" data-line-number="2"></a>
<a class="sourceLine" id="cb686-3" data-line-number="3"><span class="co"># look at the first 20 observations only and only age vs. chd</span></a>
<a class="sourceLine" id="cb686-4" data-line-number="4">saheart =<span class="st"> </span>SAheart[<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>, <span class="kw">c</span>(<span class="st">&#39;age&#39;</span>, <span class="st">&#39;chd&#39;</span>)]</a>
<a class="sourceLine" id="cb686-5" data-line-number="5"></a>
<a class="sourceLine" id="cb686-6" data-line-number="6"><span class="kw">ggplot</span>(saheart[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,], <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>chd)) <span class="op">+</span></a>
<a class="sourceLine" id="cb686-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb686-8" data-line-number="8"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb686-9" data-line-number="9"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<p>There’s a clear trend here - younger typically didn’t have heart disease while older people did - but what exactly is the nature of the relationship? We can also think about this relationship in terms of probability. People under 20 have a virtually 0 probability of heart disease, and people over 60 have a near 1.0 probability of heart disease. But how do we connect those two extremes? If we assume there is a linear relationship, we’d get the following plot.</p>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb687-1" data-line-number="1"><span class="kw">ggplot</span>(saheart[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,], <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>chd)) <span class="op">+</span></a>
<a class="sourceLine" id="cb687-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb687-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x, <span class="dt">method=</span>lm, <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb687-4" data-line-number="4"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb687-5" data-line-number="5"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<p>The 21st observation happens to be associated with a 20-year old who happened to have heart disease. If we include this new observation and re-fit the linear regression line, we get the following.</p>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb688-1" data-line-number="1"><span class="kw">ggplot</span>(saheart[<span class="dv">1</span><span class="op">:</span><span class="dv">21</span>,], <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>chd)) <span class="op">+</span></a>
<a class="sourceLine" id="cb688-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb688-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x, <span class="dt">method=</span>lm, <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb688-4" data-line-number="4"><span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb688-5" data-line-number="5"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>Adding the single observation didn’t give us any new information about the probability of heart disease for people in their 40s, 50, and 60s, but considerably changed the fit. Additionally, if we were to extend the regression line to the right to predict the probability of heart disease of an 80-year old, we’d get a probability &gt; 1. For these reasons, linear regression doesn’t model the relationship well, so we need to find something better.</p>
</div>
<div id="logit-function" class="section level3">
<h3><span class="header-section-number">7.7.2</span> Logit Function</h3>
<p>An alternative to linear regression is to use a <em>logit function</em>, <span class="math inline">\(\eta\)</span> to replace <span class="math inline">\(y\)</span> in the linear regression equation.</p>
<p><span class="math display">\[\eta = \beta_{0}+\beta_{1}x_{1}+...+\beta_{i}x_{i}+\varepsilon\]</span></p>
<p>where,</p>
<p><span class="math display">\[\eta = log\left\lgroup{\frac{p}{1-p}}\right\rgroup\]</span></p>
<p>and where <span class="math inline">\(p\)</span> is the probability of heart disease. In this form <span class="math inline">\(\eta\)</span> can also be thought of in terms of <span class="math inline">\(log(odds)\)</span>. To enforce <span class="math inline">\(0\le p \le 1\)</span>, we further define <span class="math inline">\(p\)</span> as:</p>
<p><span class="math display">\[p=\frac{e^{\eta}}{1+e^{\eta}}\]</span></p>
<p>With one predictor, as in our case, we can rewrite this to become:</p>
<p><span class="math display">\[p=\frac{e^{\beta_{0}+\beta_{1}x_{1}}}{1+e^{\beta_{0}+\beta_{1}x_{1}}}\]</span></p>
<p>If we now set <span class="math inline">\(\beta_{0}=0\)</span> and allow <span class="math inline">\(\beta_{1}\)</span> to vary, we can see the shape of the response for different coefficient values.</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p>Note that if <span class="math inline">\(\beta_{1}=0\)</span>, that is the equivalent of saying that <span class="math inline">\(p\)</span> is not a function of <span class="math inline">\(x\)</span>. The reverse (allowing <span class="math inline">\(\beta_{0}\)</span> to vary while holding <span class="math inline">\(\beta_{1}=1\)</span>), shifts the curve horizontally.</p>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
</div>
<div id="logistic-regression-in-r" class="section level3">
<h3><span class="header-section-number">7.7.3</span> Logistic Regression in <em>R</em></h3>
<p>To fit a logistic regression model in <em>R</em>, use <code>glm()</code> instead of <code>lm()</code> and specify <code>family=binomial</code>.</p>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb689-1" data-line-number="1">sa.glm =<span class="st"> </span><span class="kw">glm</span>(chd<span class="op">~</span>age, <span class="dt">family=</span>binomial, <span class="dt">data=</span>SAheart)</a>
<a class="sourceLine" id="cb689-2" data-line-number="2"><span class="kw">summary</span>(sa.glm)</a></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = chd ~ age, family = binomial, data = SAheart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.4321  -0.9215  -0.5392   1.0952   2.2433  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -3.521710   0.416031  -8.465  &lt; 2e-16 ***
## age          0.064108   0.008532   7.513 5.76e-14 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 596.11  on 461  degrees of freedom
## Residual deviance: 525.56  on 460  degrees of freedom
## AIC: 529.56
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>From the summary, we see that <span class="math inline">\(\beta_{0} = -3.522\)</span> and <span class="math inline">\(\beta_{1} = 0.064\)</span>, which gives us the equation for the estimated linear predictor:</p>
<p><span class="math display">\[\hat{\eta} = -3.522 + 0.064x\]</span></p>
<p>and the equation for the fitted probabilities.</p>
<p><span class="math display">\[\hat{p}=\frac{e^{-3.522 + 0.064x}}{1+e^{-3.522 + 0.064x}}\]</span></p>
<p>Given a 40-year old, we find <span class="math inline">\(\hat{\eta}=\)</span> -0.962 and <span class="math inline">\(\hat{p}=\)</span> 0.2764779. This highlights an important distinction when using <code>predict()</code> with a binomial response. To calculate <span class="math inline">\(\hat{\eta}\)</span>:</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb691-1" data-line-number="1"><span class="kw">predict</span>(sa.glm, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">age=</span><span class="dv">40</span>))</a></code></pre></div>
<pre><code>##         1 
## -0.957389</code></pre>
<p>but to calculate <span class="math inline">\(\hat{p}\)</span>, we need to specify <code>type = &quot;response&quot;</code>.</p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb693-1" data-line-number="1">p.hat =<span class="st"> </span><span class="kw">predict</span>(sa.glm, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">age=</span><span class="dv">40</span>), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb693-2" data-line-number="2">p.hat</a></code></pre></div>
<pre><code>##         1 
## 0.2774013</code></pre>
<p>We can see that this is a much lower estimate of the probability of heart disease than was estimated by the linear model produced by <code>lm()</code>. Since <span class="math inline">\(\beta_{0}\)</span> is negative, the regression curve will be shifted to the right of the mean age, and a low value for <span class="math inline">\(\beta_{1}\)</span> will stretch out the “s” curve. A plot of <span class="math inline">\(\hat{p}\)</span> versus age with the binomial regression curve and our estimated probability for a 40-year old is shown below.</p>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb695-1" data-line-number="1">ages =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">10</span>, <span class="dv">80</span>, <span class="dt">length.out =</span> <span class="kw">nrow</span>(SAheart))</a>
<a class="sourceLine" id="cb695-2" data-line-number="2">pred =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb695-3" data-line-number="3">  <span class="dt">p =</span> <span class="kw">predict</span>(sa.glm, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">age=</span>ages), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>),</a>
<a class="sourceLine" id="cb695-4" data-line-number="4">  <span class="dt">se =</span> <span class="kw">predict</span>(sa.glm, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">age=</span>ages), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>, <span class="dt">se=</span><span class="ot">TRUE</span>)<span class="op">$</span>se, <span class="co"># standard error</span></a>
<a class="sourceLine" id="cb695-5" data-line-number="5">  <span class="dt">age =</span> ages</a>
<a class="sourceLine" id="cb695-6" data-line-number="6">)</a>
<a class="sourceLine" id="cb695-7" data-line-number="7"></a>
<a class="sourceLine" id="cb695-8" data-line-number="8"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb695-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> pred, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>p), <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> pred, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>p<span class="op">+</span>se), <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">3</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> pred, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>p<span class="op">-</span>se), <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">linetype=</span><span class="dv">3</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">data =</span> SAheart, <span class="kw">aes</span>(<span class="dt">x=</span>age, <span class="dt">y=</span>chd), <span class="dt">shape=</span><span class="dv">124</span>, <span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">width=</span><span class="fl">0.2</span>, <span class="dt">height=</span><span class="dv">0</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">40</span>, <span class="dt">xend=</span><span class="dv">40</span>, <span class="dt">y=</span><span class="dv">0</span>, <span class="dt">yend=</span>p.hat), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-14" data-line-number="14"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">10</span>, <span class="dt">xend=</span><span class="dv">40</span>, <span class="dt">y=</span>p.hat, <span class="dt">yend=</span>p.hat), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">linetype=</span><span class="dv">2</span>, <span class="dt">size=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-15" data-line-number="15"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Age (years)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-16" data-line-number="16"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Heart Disease (1=yes, 0=no)</span><span class="ch">\n</span><span class="st"> p.hat&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb695-17" data-line-number="17"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb696-1" data-line-number="1"><span class="kw">rm</span>(ages, p.hat)</a></code></pre></div>
</div>
<div id="logistic-regression-diagnostics" class="section level3">
<h3><span class="header-section-number">7.7.4</span> Logistic Regression Diagnostics</h3>
<p>Diagnostics for logistic regression follows the same philosophy as linear regression: we will check the model assumptions and look for outliers and high leverage observations. First, we’ll look for violations of the equal variance assumption, but instead of using the raw residuals as we did in linear regression, we need to look at the <em>deviance residuals</em>. For logistic regression, we have the following definitions:</p>
<ul>
<li>Fitted values are <span class="math inline">\(\hat{\eta} = \hat{\beta_0} + \sum_{i=1}^n \hat{\beta_i}x_i\)</span></li>
<li>Raw residuals are <span class="math inline">\(e_{i} = y_{i} - \hat{p_{i}}\)</span></li>
<li>Deviance residuals are <span class="math inline">\(r_{i} = sign(y_{i}-\hat{p_{i}}) \sqrt{-2 \left\{y_{i} ln(\hat{p_{i}}) + (1-y_{i}) ln(1-\hat{p_{i}})\right\}}\)</span>
<ul>
<li>where <span class="math inline">\(y_{i}\)</span> is either 0 or 1, so if <span class="math inline">\(y_{i}=0\)</span>, then <span class="math inline">\(sign() = +\)</span></li>
</ul></li>
</ul>
<p>As with linear model diagnostics, we can plot fitted values and deviance residuals; however, the plot is not particularly useful. Note that the upper row of points correspond to <span class="math inline">\(y_{i}=1\)</span>, and the lower row to <span class="math inline">\(y_{i}=0\)</span>. With a sufficiently large dataset, we can generate a more useful diagnostic plot by binning the observations based on their predicted value, and calculating the mean deviance residual for each bin.</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb697-1" data-line-number="1">df =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb697-2" data-line-number="2">  <span class="dt">resid =</span> <span class="kw">residuals</span>(sa.glm), <span class="co"># for raw residuals, specify residuals(sa.glm, type = &quot;response&quot;)</span></a>
<a class="sourceLine" id="cb697-3" data-line-number="3">  <span class="dt">preds =</span> <span class="kw">predict</span>(sa.glm))</a>
<a class="sourceLine" id="cb697-4" data-line-number="4"></a>
<a class="sourceLine" id="cb697-5" data-line-number="5"><span class="kw">ggplot</span>(df) <span class="op">+</span></a>
<a class="sourceLine" id="cb697-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_rect</span>(<span class="kw">aes</span>(<span class="dt">xmin=</span><span class="op">-</span><span class="fl">2.2</span>, <span class="dt">xmax=</span><span class="op">-</span><span class="fl">1.8</span>, <span class="dt">ymin=</span><span class="op">-</span><span class="fl">0.8</span>, <span class="dt">ymax=</span><span class="fl">2.2</span>), <span class="dt">fill=</span><span class="st">&#39;lightgray&#39;</span>, <span class="dt">alpha=</span><span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb697-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>preds, <span class="dt">y=</span>resid)) <span class="op">+</span></a>
<a class="sourceLine" id="cb697-8" data-line-number="8"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="op">-</span><span class="dv">2</span>, <span class="dt">y=</span><span class="dv">1</span>, <span class="dt">label=</span><span class="st">&quot;Example</span><span class="ch">\n</span><span class="st">Bin&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb697-9" data-line-number="9"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Fitted Linear Predictor&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb697-10" data-line-number="10"><span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Deviance Residuals&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb697-11" data-line-number="11"><span class="st">    </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb698-1" data-line-number="1"><span class="co"># alternatively, plot(sa.glm, which=1)</span></a></code></pre></div>
<p>A general guideline is to create bins with at least 30 observations each, which for the <code>SAheart</code> dataset, means <code>462 %/% 30 = 15</code> bins. Now we have a much more useful diagnostic plot.</p>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb699-1" data-line-number="1">df =<span class="st"> </span>df <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb699-2" data-line-number="2"><span class="st">  </span><span class="kw">arrange</span>(preds) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb699-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">bin =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">15</span>, <span class="dt">each=</span><span class="dv">30</span>), <span class="kw">rep</span>(<span class="dv">15</span>, <span class="kw">nrow</span>(SAheart)<span class="op">-</span><span class="dv">15</span><span class="op">*</span><span class="dv">30</span>)))</a>
<a class="sourceLine" id="cb699-4" data-line-number="4"></a>
<a class="sourceLine" id="cb699-5" data-line-number="5">df <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb699-6" data-line-number="6"><span class="st">  </span><span class="kw">group_by</span>(bin) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb699-7" data-line-number="7"><span class="st">  </span><span class="kw">summarize</span>(</a>
<a class="sourceLine" id="cb699-8" data-line-number="8">    <span class="dt">meanResid =</span> <span class="kw">mean</span>(resid),</a>
<a class="sourceLine" id="cb699-9" data-line-number="9">    <span class="dt">meanPred =</span> <span class="kw">mean</span>(preds), <span class="dt">.groups =</span> <span class="st">&#39;drop&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb699-10" data-line-number="10"><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb699-11" data-line-number="11"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>meanPred, <span class="dt">y=</span>meanResid)) <span class="op">+</span></a>
<a class="sourceLine" id="cb699-12" data-line-number="12"><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Fitted Linear Predictor&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb699-13" data-line-number="13"><span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Deviance Residuals&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb699-14" data-line-number="14"><span class="st">    </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="05-Regression_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<p>We identify unusual observations in logistic regression the same way as we did with linear regression but with slightly different definitions for residuals. We already covered raw residuals and deviance residuals. If we now represent the deviance residuals as <span class="math inline">\(r_{D}\)</span>, then we have the following additional definitions:</p>
<table>
<colgroup>
<col width="19%" />
<col width="38%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th>Term</th>
<th align="center">Definition</th>
<th align="center"><em>R</em> Command</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Standardized deviance residuals</td>
<td align="center"><span class="math inline">\(r_{SD}=\frac{r_{D}}{\sqrt{1-h}}\)</span></td>
<td align="center"><code>rstandard(sa.glm)</code></td>
</tr>
<tr class="even">
<td>Pearson residuals</td>
<td align="center"><span class="math inline">\(r_{P}=\frac{y-\hat{p}}{\sqrt{\hat{p}(1-\hat{p})}}\)</span></td>
<td align="center"><code>residuals(sa.glm, type=&quot;pearson&quot;)</code></td>
</tr>
<tr class="odd">
<td>Pearson standardized residuals</td>
<td align="center"><span class="math inline">\(r_{SP}=\frac{r_{P}}{\sqrt{1-h}}\)</span></td>
<td align="center">none</td>
</tr>
<tr class="even">
<td>Cook’s Distance</td>
<td align="center"><span class="math inline">\(D=\frac{(r_{SP})^{2}}{q+1} \left({\frac{h}{1-h}} \right)\)</span></td>
<td align="center"><code>cooks.distance(sa.glm)</code></td>
</tr>
</tbody>
</table>
<p>Apply the same rules of thumb when identifying unusual observations as with linear regression.</p>
<p>Lastly, we can assess the goodness of fit for a model using several methods. A simple approximation akin to measuring <span class="math inline">\(R^2\)</span> is:</p>
<p><span class="math display">\[R^{2}=\frac{D_{NULL}-D}{D_{NULL}}\]</span></p>
<p>where <span class="math inline">\(D_{NULL}\)</span> is the null model devience (i.e., the total sum of squares) and <span class="math inline">\(D\)</span> is the logistic regression model deviance. From the calculation below, we find that approximately 12% of the variance in <code>chd</code> is explained by <code>age</code>.</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb700-1" data-line-number="1">(sa.glm<span class="op">$</span>null <span class="op">-</span><span class="st"> </span>sa.glm<span class="op">$</span>dev) <span class="op">/</span><span class="st"> </span>sa.glm<span class="op">$</span>null</a></code></pre></div>
<pre><code>## [1] 0.1183444</code></pre>
<p><span class="citation">Faraway (<a href="#ref-faraway2006">2006</a>)</span> proposes a more sophisticated measure:</p>
<p><span class="math display">\[R^{2}=\frac{1 - exp\left\{ (D-D_{NULL})/N \right\}} {1 - exp\left\{-D_{NULL}/N \right\}}\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the number of binary trials.</p>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb702-1" data-line-number="1">(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>( (sa.glm<span class="op">$</span>dev <span class="op">-</span><span class="st"> </span>sa.glm<span class="op">$</span>null)<span class="op">/</span><span class="kw">nrow</span>(SAheart))) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>( (<span class="op">-</span><span class="st"> </span>sa.glm<span class="op">$</span>null)<span class="op">/</span><span class="kw">nrow</span>(SAheart)))</a></code></pre></div>
<pre><code>## [1] 0.195377</code></pre>
<p>Lastly, there’s the Hosmer-Lemeshow goodness of fit test where the null hypothesis is the the model fit is “good”, and the alternative hypothesis is the the model is saturated (i.e, not a good fit). For our example, we fail to reject the null hypothesis at the 95% confidence level. For a detailed treatment of the test, read <a href="https://en.wikipedia.org/wiki/Hosmer%E2%80%93Lemeshow_test">this article</a>.</p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb704-1" data-line-number="1"><span class="kw">library</span>(ResourceSelection)</a>
<a class="sourceLine" id="cb704-2" data-line-number="2"></a>
<a class="sourceLine" id="cb704-3" data-line-number="3">p.hat =<span class="st"> </span><span class="kw">predict</span>(sa.glm, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb704-4" data-line-number="4"><span class="kw">hoslem.test</span>(SAheart<span class="op">$</span>chd, p.hat)</a></code></pre></div>
<pre><code>## 
##  Hosmer and Lemeshow goodness of fit (GOF) test
## 
## data:  SAheart$chd, p.hat
## X-squared = 9.6408, df = 8, p-value = 0.2911</code></pre>
</div>
<div id="logistic-regression-problem-set" class="section level3">
<h3><span class="header-section-number">7.7.5</span> Logistic Regression Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter6_ProblemSets/Logistic_Regression_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter6_ProblemSets/Logistic_Regression_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter6_ProblemSets/Logistic_Regression_PS_Answers.html'>here</a>.</p>
<!--chapter:end:05-Regression.Rmd-->
</div>
</div>
</div>
<div id="model-selection" class="section level1">
<h1><span class="header-section-number">8</span> Model Selection</h1>
<p>This chapter presents methods for finding a balance between under fitting and over fitting a model. Under fitting is when the model is a poor predictor of the response. With linear regression, this is largely addressed through diagnostic checks, which was covered in previous chapters. A linear model is over fitted when it includes more predictors than are needed to represent the relationship to the response variable. Appropriately reducing the complexity of the model improves its ability to make predictions based on new data, and it helps with interpretability.</p>
<div id="admin-4" class="section level2">
<h2><span class="header-section-number">8.1</span> Admin</h2>
<p>For any errors associated with this section, please contact <a href="mailto:john.f.king1.mil@mail.mil">John King</a>.</p>
<p>This chapter was published using the following software:</p>
<ul>
<li>R version 3.6.0 (2019-04-26).</li>
<li>On x86_64-pc-linux-gnu (64-bit) running Ubuntu 18.04.2 LTS.</li>
<li>Packages used in this chapter are explicitly shown in the code snippets.</li>
</ul>
</div>
<div id="introduction-7" class="section level2">
<h2><span class="header-section-number">8.2</span> Introduction</h2>
<p>There are three general approaches to reducing model complexity: dimension reduction, variable selection, and regularization. Dimension reduction is beyond the scope of this tutorial and will not be covered. This chapter presents two methods of variable selection (testing- and criterion-based methods) and regularization through lasso regression.</p>
</div>
<div id="testing-based-methods" class="section level2">
<h2><span class="header-section-number">8.3</span> Testing-Based Methods</h2>
<p>Testing-based methods are the easiest to implement but should only be considered when there are only a few predictors. The idea is simple. In <strong>forward elimination</strong>, we start with a linear model with no predictors, manually add them one at a time, and keep only those predictors with a low p-value. <strong>Backward elimination</strong> is just the opposite: we start with a linear model that contains all predictors (including interactions, if suspected), remove the predictor with the highest p-value, build a new linear model with the reduced set or predictors, and continue that process until only those predictors with low p-values remain.</p>
<p>We’ll use the <code>teengamb</code> dataset from the <code>faraway</code> package to demonstrate backward elimination. This dataset contains survey results from a study of teenage gambling in Britain. The response variable is <code>gamble</code>, which is the expenditure on gambling in pounds per year. The predictors are information regarding each survey respondent, such as gender and income.</p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb706-1" data-line-number="1"><span class="kw">library</span>(faraway)</a>
<a class="sourceLine" id="cb706-2" data-line-number="2"><span class="kw">data</span>(teengamb)</a>
<a class="sourceLine" id="cb706-3" data-line-number="3"><span class="kw">head</span>(teengamb)</a></code></pre></div>
<pre><code>##   sex status income verbal gamble
## 1   1     51   2.00      8    0.0
## 2   1     28   2.50      8    0.0
## 3   1     37   2.00      6    0.0
## 4   1     28   7.00      4    7.3
## 5   1     65   2.00      8   19.6
## 6   1     61   3.47      6    0.1</code></pre>
<p>A linear model with all predictors is as follows (we’ll assume this model passes all of the required diagnostic checks):</p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb708-1" data-line-number="1">tg =<span class="st"> </span><span class="kw">lm</span>(gamble<span class="op">~</span>., <span class="dt">data=</span>teengamb)</a>
<a class="sourceLine" id="cb708-2" data-line-number="2"><span class="kw">summary</span>(tg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gamble ~ ., data = teengamb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -51.082 -11.320  -1.451   9.452  94.252 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  22.55565   17.19680   1.312   0.1968    
## sex         -22.11833    8.21111  -2.694   0.0101 *  
## status        0.05223    0.28111   0.186   0.8535    
## income        4.96198    1.02539   4.839 1.79e-05 ***
## verbal       -2.95949    2.17215  -1.362   0.1803    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 22.69 on 42 degrees of freedom
## Multiple R-squared:  0.5267, Adjusted R-squared:  0.4816 
## F-statistic: 11.69 on 4 and 42 DF,  p-value: 1.815e-06</code></pre>
<p>Since the p-value for <code>status</code> is the highest, we remove it first.</p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb710-1" data-line-number="1">tg =<span class="st"> </span><span class="kw">update</span>(tg, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span>status) <span class="co"># remove status</span></a>
<a class="sourceLine" id="cb710-2" data-line-number="2"><span class="kw">summary</span>(tg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gamble ~ sex + income + verbal, data = teengamb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.639 -11.765  -1.594   9.305  93.867 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  24.1390    14.7686   1.634   0.1095    
## sex         -22.9602     6.7706  -3.391   0.0015 ** 
## income        4.8981     0.9551   5.128 6.64e-06 ***
## verbal       -2.7468     1.8253  -1.505   0.1397    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 22.43 on 43 degrees of freedom
## Multiple R-squared:  0.5263, Adjusted R-squared:  0.4933 
## F-statistic: 15.93 on 3 and 43 DF,  p-value: 4.148e-07</code></pre>
<p>Then we remove <code>verbal</code>.</p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb712-1" data-line-number="1">tg =<span class="st"> </span><span class="kw">update</span>(tg, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span>verbal) <span class="co"># remove verbal</span></a>
<a class="sourceLine" id="cb712-2" data-line-number="2"><span class="kw">summary</span>(tg)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gamble ~ sex + income, data = teengamb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -49.757 -11.649   0.844   8.659 100.243 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    4.041      6.394   0.632  0.53070    
## sex          -21.634      6.809  -3.177  0.00272 ** 
## income         5.172      0.951   5.438 2.24e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 22.75 on 44 degrees of freedom
## Multiple R-squared:  0.5014, Adjusted R-squared:  0.4787 
## F-statistic: 22.12 on 2 and 44 DF,  p-value: 2.243e-07</code></pre>
<p>Notice that even though we eliminated half of the predictors from the model, we only slightly reduced the adjusted <span class="math inline">\(R^{2}\)</span>. The simpler model explains almost as much variance in the response with only half the number of predictors. Something to keep in mind when conducting forward or backward elimination is that the predictor p-value does not necessarily have to be above 0.05 to eliminate the predictor from the model. You could also choose something higher - even up to around 0.15 to 0.20 if predictive performance is the goal. For example, note that the p-value for <code>verbal</code> in the second model was 0.14, and the adjusted <span class="math inline">\(R^{2}\)</span> for the model was the highest of the three. The coefficient for <code>verbal</code> was also negative, which is what we’d expect: teens with higher verbal scores spend less money on gambling. We should therefore consider keeping <code>verbal</code> in the model (there’s a little bit of an art to it).</p>
</div>
<div id="criterion-based-methods" class="section level2">
<h2><span class="header-section-number">8.4</span> Criterion-Based Methods</h2>
<p>As previously stated, testing-based procedures should only be considered when there are just a few factors to consider. The more potential factors in your model, the greater the chance that you’ll miss the optimal combination. We saw in the previous section that we had two competing goals: model simplicity versus model fit. <span class="citation">Akaike (<a href="#ref-akaike1974">1974</a>)</span> developed a method to measure this balance between simplicity and fit called the <strong>Akaike Information Criterion (AIC)</strong>, which takes the form of:</p>
<center>
<span class="math display">\[AIC = 2(p+1) - 2ln(\hat{L})\]</span>
</center>
<p>where,</p>
<ul>
<li><span class="math inline">\(p\)</span> is the number of predictors, and</li>
<li><span class="math inline">\(\hat{L}\)</span> is the maximized likelihood for the predictive model.</li>
</ul>
<p>We then choose the model with the lowest AIC. The <strong>Bayes Information Criterion (BIC)</strong> is an alternative to AIC and replaces <span class="math inline">\(2(p+1)\)</span> with <span class="math inline">\(ln(n)(p+1)\)</span>, where <span class="math inline">\(n\)</span> is the number of observations (design points). Adding <span class="math inline">\(ln(n)\)</span> increases the penalty for the number of factors in the model more for larger data sets. Which criterion you use can therefore depend on the dataset you’re working with.</p>
<p>Another common estimator of error is <strong>Mallow’s Cp</strong>, which is defined as:</p>
<center>
<span class="math display">\[C_{p}=\frac{1}{n}(RSS+2p\hat{\sigma}^{2})\]</span>
</center>
<p>where,</p>
<ul>
<li><span class="math inline">\(RSS\)</span> is the root sum of squares,</li>
<li><span class="math inline">\(p\)</span> is the number of predictor, and</li>
<li><span class="math inline">\(\hat{\sigma}^{2}\)</span> is an estimate of the variance of the error, <span class="math inline">\(\varepsilon\)</span>, in the linear regression equation.</li>
</ul>
<p>As with AIC and BIC, the penalty term (in this case <span class="math inline">\(2p\hat{\sigma}^{2}\)</span>) increases as the number of predictors in the model increases, which is intended to balance the corresponding decrease in <span class="math inline">\(RSS\)</span>. With each of these methods, as we vary <span class="math inline">\(p\)</span>, we get an associated criterion value from which we select the minimum as the best model. In <em>R</em>, we can calculate AIC and BIC with the <code>bestglm()</code> function from the <code>bestglm</code> package. Be aware that <code>bestglm()</code> expects the data to be in a dataframe with the response variable in the last column.</p>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb714-1" data-line-number="1"><span class="kw">library</span>(bestglm)</a>
<a class="sourceLine" id="cb714-2" data-line-number="2"><span class="co"># Note that bestglm is picky about how your dataset is structured</span></a>
<a class="sourceLine" id="cb714-3" data-line-number="3"><span class="co"># It expects a dataframe with the response variable in the last column</span></a>
<a class="sourceLine" id="cb714-4" data-line-number="4"><span class="co"># and all other columns are predictors. Don&#39;t include any other &quot;extra&quot;</span></a>
<a class="sourceLine" id="cb714-5" data-line-number="5"><span class="co"># columns. Fortunately, teengamb is already set up that way.</span></a>
<a class="sourceLine" id="cb714-6" data-line-number="6"></a>
<a class="sourceLine" id="cb714-7" data-line-number="7">tg.AIC =<span class="st"> </span><span class="kw">bestglm</span>(teengamb, <span class="dt">IC=</span><span class="st">&quot;AIC&quot;</span>)</a>
<a class="sourceLine" id="cb714-8" data-line-number="8"></a>
<a class="sourceLine" id="cb714-9" data-line-number="9"><span class="co"># this will provide the best model</span></a>
<a class="sourceLine" id="cb714-10" data-line-number="10">tg.AIC</a></code></pre></div>
<pre><code>## AIC
## BICq equivalent for q in (0.672366796081496, 0.87054246206156)
## Best Model:
##               Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)  24.138972 14.7685884  1.634481 1.094591e-01
## sex         -22.960220  6.7705747 -3.391177 1.502436e-03
## income        4.898090  0.9551179  5.128256 6.643750e-06
## verbal       -2.746817  1.8252807 -1.504874 1.396672e-01</code></pre>
<p>Notice that <code>verbal</code> is included in the best fit model even though its p-value is &gt; 0.05. Using <code>summary()</code>, we get a likelihood-ratio test for the best model compared to the null model.</p>
<div class="sourceCode" id="cb716"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb716-1" data-line-number="1"><span class="kw">summary</span>(tg.AIC)</a></code></pre></div>
<pre><code>## Fitting algorithm:  AIC-leaps
## Best Model:
##            df deviance
## Null Model 43 21641.54
## Full Model 46 45689.49
## 
##  likelihood-ratio test - GLM
## 
## data:  H0: Null Model vs. H1: Best Fit AIC-leaps
## X = 24048, df = 3, p-value &lt; 2.2e-16</code></pre>
<p>To get the best model in a <code>lm()</code> format:</p>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb718-1" data-line-number="1">tg.AIC<span class="op">$</span>BestModel</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ ., data = data.frame(Xy[, c(bestset[-1], FALSE), 
##     drop = FALSE], y = y))
## 
## Coefficients:
## (Intercept)          sex       income       verbal  
##      24.139      -22.960        4.898       -2.747</code></pre>
<p>We can also see a comparison of the best model (model 1) to the next 4 best models.</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb720-1" data-line-number="1">tg.AIC<span class="op">$</span>BestModels</a></code></pre></div>
<pre><code>##     sex status income verbal Criterion
## 1  TRUE  FALSE   TRUE   TRUE  294.2145
## 2  TRUE  FALSE   TRUE  FALSE  294.6268
## 3  TRUE   TRUE   TRUE   TRUE  296.1758
## 4  TRUE   TRUE   TRUE  FALSE  296.2086
## 5 FALSE   TRUE   TRUE   TRUE  301.6659</code></pre>
<p>We can also see the best model (row 3) and its subsets. Row 0 contains just the y-intercept, and in each successive row one predictor is added at a time.</p>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb722-1" data-line-number="1">tg.AIC<span class="op">$</span>Subsets</a></code></pre></div>
<pre><code>##    (Intercept)   sex status income verbal logLikelihood      AIC
## 0         TRUE FALSE  FALSE  FALSE  FALSE     -161.6677 323.3354
## 1         TRUE FALSE  FALSE   TRUE  FALSE     -150.1678 302.3356
## 2         TRUE  TRUE  FALSE   TRUE  FALSE     -145.3134 294.6268
## 3*        TRUE  TRUE  FALSE   TRUE   TRUE     -144.1072 294.2145
## 4         TRUE  TRUE   TRUE   TRUE   TRUE     -144.0879 296.1758</code></pre>
<p>Using BIC, however, <code>verbal</code> is excluded from the best fit model.</p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb724-1" data-line-number="1">tg.BIC =<span class="st"> </span><span class="kw">bestglm</span>(teengamb, <span class="dt">IC=</span><span class="st">&quot;BIC&quot;</span>)</a>
<a class="sourceLine" id="cb724-2" data-line-number="2">tg.BIC</a></code></pre></div>
<pre><code>## BIC
## BICq equivalent for q in (0.0507226962510261, 0.672366796081496)
## Best Model:
##               Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)   4.040829  6.3943499  0.6319374 5.306977e-01
## sex         -21.634391  6.8087973 -3.1774174 2.717320e-03
## income        5.171584  0.9510477  5.4377755 2.244878e-06</code></pre>
<p>For Mallow’s Cp, we can use the <code>leaps</code> package.</p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb726-1" data-line-number="1"><span class="kw">library</span>(leaps)</a>
<a class="sourceLine" id="cb726-2" data-line-number="2"></a>
<a class="sourceLine" id="cb726-3" data-line-number="3"><span class="co"># leaps expects x and y to be passed separately</span></a>
<a class="sourceLine" id="cb726-4" data-line-number="4">tg.cp =<span class="st"> </span><span class="kw">leaps</span>(<span class="dt">x=</span>teengamb[<span class="op">-</span><span class="dv">5</span>], <span class="dt">y=</span>teengamb<span class="op">$</span>gamble, <span class="dt">method=</span><span class="st">&quot;Cp&quot;</span>)</a>
<a class="sourceLine" id="cb726-5" data-line-number="5">tg.cp</a></code></pre></div>
<pre><code>## $which
##       1     2     3     4
## 1 FALSE FALSE  TRUE FALSE
## 1  TRUE FALSE FALSE FALSE
## 1 FALSE FALSE FALSE  TRUE
## 1 FALSE  TRUE FALSE FALSE
## 2  TRUE FALSE  TRUE FALSE
## 2 FALSE  TRUE  TRUE FALSE
## 2 FALSE FALSE  TRUE  TRUE
## 2  TRUE  TRUE FALSE FALSE
## 2  TRUE FALSE FALSE  TRUE
## 2 FALSE  TRUE FALSE  TRUE
## 3  TRUE FALSE  TRUE  TRUE
## 3  TRUE  TRUE  TRUE FALSE
## 3 FALSE  TRUE  TRUE  TRUE
## 3  TRUE  TRUE FALSE  TRUE
## 4  TRUE  TRUE  TRUE  TRUE
## 
## $label
## [1] &quot;(Intercept)&quot; &quot;1&quot;           &quot;2&quot;           &quot;3&quot;           &quot;4&quot;          
## 
## $size
##  [1] 2 2 2 2 3 3 3 3 3 3 4 4 4 4 5
## 
## $Cp
##  [1] 11.401283 30.984606 41.445676 45.517426  3.248323 12.003293 12.276400
##  [8] 25.967108 26.743051 42.897591  3.034526  4.856329 10.256053 26.416920
## [15]  5.000000</code></pre>
<p>It takes a little finagling to get the predictors that we should include in the best model. Columns 1, 2, and 4 correspond to <code>sex</code>, <code>status</code>, and <code>verbal</code>, which is the same as the AIC result.</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb728-1" data-line-number="1">tg.cp<span class="op">$</span>which[<span class="kw">which.min</span>(tg.cp<span class="op">$</span>Cp), ]</a></code></pre></div>
<pre><code>##     1     2     3     4 
##  TRUE FALSE  TRUE  TRUE</code></pre>
<div id="criterion-problem-set" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Criterion Problem Set</h3>
<p>The problem set for this section is located <a href = "/_Chapter8_ProblemSets/Criterion_ProblemSet_Questions.html">here</a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = "/_Chapter8_ProblemSets/Criterion_ProblemSet_Questions.Rmd">here</a>.</p>
<p>The solutions for this problem set are located <a href = "/_Chapter8_ProblemSets/Criterion_ProblemSet_Solutions.html">here</a>.</p>
</div>
</div>
<div id="cross-validation" class="section level2">
<h2><span class="header-section-number">8.5</span> Cross Validation</h2>
<p>An alternative approach to using AIC, BIC, or Cp is to use cross validation (CV) to select the best model. The idea is that we randomly divide our data into a <strong>training set</strong> and a <strong>test set</strong>. An 80/20 split between the training set and test set is common but will depend on your sample size. For very large sample sizes (in the millions), the training set can contain a larger percentage, while for relatively small sample sizes, the split may be closer to 50/50. The training set is further randomly divided into <span class="math inline">\(k\)</span> subsets (called <strong>folds</strong>), and one of these folds is withheld as the <strong>validation set</strong>. We fit a model to the remaining training set, and then measure the prediction error using the validation set. Typically, the prediction error is measured by the mean squared error (MSE) for a quantitative response variable. We repeat this process by cycling though each of the folds and holding it out as the validation set. The cross validated error (CV error) is then the average prediction error for the <span class="math inline">\(k\)</span> folds.</p>
<p>The website for the <code>scikit-learn</code> module for Python has a good visualization (shown below) of these various data sets and a <a href="https://scikit-learn.org/stable/modules/cross_validation.html">good explanation</a> of this and other cross validation methods. A more thorough, academic treatment of cross validation may be found in <a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">Chapter 7.10</a> in Elements of Statistical Learning written by Trevor Hastie, Robert Tibshirani, and Jerome Friedman.</p>
<p><img src="https://scikit-learn.org/stable/_images/grid_search_cross_validation.png" /></p>
<p>Once the CV process is complete, we re-combine each of the folds into a single training set for a final evaluation against the test set. With this approach, we can compare multiple CV methods and choose the method with the best performance.</p>
<p>Notice that we are not using an Information Criterion (IC) anywhere in this method. Another difference is that with criterion-based methods, we chose the model with the lowest IC score, but with CV, we don’t choose the model with the lowest CV error. Instead, we calculate the standard deviation (<span class="math inline">\(\sigma\)</span>) of the CV error for each of the <span class="math inline">\(p\)</span> predictors and then choose the smallest model that’s CV error is within one standard error of the lowest. Standard error is defined as <span class="math inline">\(se = \sigma/\sqrt(k)\)</span>. This is best shown graphically, which you’ll see below.</p>
<p>CV techniques are particularly useful for datasets with many predictors, but for consistency, we’ll stick with the <code>teengamb</code> dataset. Below, we’ll perform k-fold cross validation on the <code>teamgamb</code> dataset, once again using <code>bestglm()</code>. We’ll use an 80/20 train/test split.</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb730-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb730-2" data-line-number="2">test_set =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">47</span>, <span class="dv">10</span>, <span class="dt">replace=</span><span class="ot">FALSE</span>)  <span class="co"># randomly select row indices</span></a>
<a class="sourceLine" id="cb730-3" data-line-number="3">tg_test =<span class="st"> </span>teengamb[test_set, ]              <span class="co"># create test set</span></a>
<a class="sourceLine" id="cb730-4" data-line-number="4">tg_train =<span class="st"> </span>teengamb[<span class="op">-</span>test_set, ]            <span class="co"># create training set </span></a></code></pre></div>
<p>The training set has only 24 observations, so if we further partition it into a large number of folds, we’ll have a small number of observations in each of the validation folds. For this example, we’ll choose just 3 folds. In the <code>bestglm()</code> function, we specify <code>CV</code> as the IC and pass three arguments to specify cross validation parameters. As mentioned, there are a variety of cross validation methods to choose from. For the method described above, we specify <code>Method=&quot;HTF&quot;</code>, which you might have noticed are the first letters of the last names of the authors mentioned in the “Elements of Statistical Learning” reference above. <code>K=3</code> specifies the number of k-folds, and we can chose one or more repetition with <code>REP</code>. Remember that cross validation randomly partitions the data into folds, so if we want to repeat the CV process with different random partitions, we increase the <code>REP</code> value. Due to the small sample size and number of folds, we’ll do 10 repetitions.</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb731-1" data-line-number="1">tg.cv =<span class="st"> </span><span class="kw">bestglm</span>(tg_train, <span class="dt">IC=</span><span class="st">&quot;CV&quot;</span>, <span class="dt">CVArgs=</span><span class="kw">list</span>(<span class="dt">Method=</span><span class="st">&quot;HTF&quot;</span>, <span class="dt">K=</span><span class="dv">3</span>, <span class="dt">REP=</span><span class="dv">10</span>))</a>
<a class="sourceLine" id="cb731-2" data-line-number="2">tg.cv</a></code></pre></div>
<pre><code>## CV(K = 3, REP = 10)
## BICq equivalent for q in (0.000199326484859652, 0.329344259543028)
## Best Model:
##              Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept) -6.132874   6.892883 -0.8897401 3.796805e-01
## income       5.877955   1.149221  5.1147292 1.134028e-05</code></pre>
<p>The model above is the model with the fewest predictors that is within one standard error of the model with the lowest CV error. To illustrate this relationship, next we’ll visualize how this model was determined based on the CV and standard errors. We can get the CV errors and the <span class="math inline">\(se\)</span> from the <code>tg.cv</code> object.</p>
<p><img src="06-Model_Selection_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div id="what-about-the-test-set" class="section level3">
<h3><span class="header-section-number">8.5.1</span> What About The Test Set?</h3>
<p>This model selection method included <code>income</code> as the only predictor variable in their respective best model. However, the coefficients differ between the two models, so now we can bring in the test set to compare Best BIC model. For a fair comparison with the CV results, we’ll find the best model using BIC on the training set only.</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb733-1" data-line-number="1"><span class="co"># get the BIC model on the training set only</span></a>
<a class="sourceLine" id="cb733-2" data-line-number="2">tg_train.BIC =<span class="st"> </span><span class="kw">bestglm</span>(tg_train, <span class="dt">IC=</span><span class="st">&quot;BIC&quot;</span>)</a>
<a class="sourceLine" id="cb733-3" data-line-number="3">bic_preds =<span class="st"> </span><span class="kw">predict</span>(tg_train.BIC<span class="op">$</span>BestModel, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(tg_test[, <span class="dv">-5</span>]))</a>
<a class="sourceLine" id="cb733-4" data-line-number="4"></a>
<a class="sourceLine" id="cb733-5" data-line-number="5"><span class="kw">print</span>(<span class="st">&quot;BIC predictors included are:&quot;</span>)</a></code></pre></div>
<pre><code>## [1] &quot;BIC predictors included are:&quot;</code></pre>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb735-1" data-line-number="1"><span class="kw">print</span>(tg_train.BIC<span class="op">$</span>BestModel<span class="op">$</span>coefficients)</a></code></pre></div>
<pre><code>## (Intercept)         sex      income 
##    3.515245  -19.116151    5.362915</code></pre>
<p>Now we’ll get the CV model.</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb737-1" data-line-number="1"><span class="co"># based on the CV results, only income should be included as a factor</span></a>
<a class="sourceLine" id="cb737-2" data-line-number="2">cv.glm =<span class="st"> </span><span class="kw">glm</span>(gamble<span class="op">~</span>income, <span class="dt">data=</span>tg_train)</a>
<a class="sourceLine" id="cb737-3" data-line-number="3">cv_preds =<span class="st"> </span><span class="kw">predict</span>(cv.glm, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(tg_test[, <span class="dv">-5</span>]))</a></code></pre></div>
<p>We’ll use mean absolute error as our measure of error.</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb738-1" data-line-number="1"><span class="co"># calculate and compare mean absolute error</span></a>
<a class="sourceLine" id="cb738-2" data-line-number="2"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;BIC mean absolute error:&quot;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(<span class="kw">abs</span>(bic_preds <span class="op">-</span><span class="st"> </span>tg_test<span class="op">$</span>gamble)), <span class="dv">1</span>)))</a></code></pre></div>
<pre><code>## [1] &quot;BIC mean absolute error: 10.9&quot;</code></pre>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb740-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;CV mean absolute error:&quot;</span>, <span class="kw">round</span>(<span class="kw">mean</span>(<span class="kw">abs</span>(cv_preds <span class="op">-</span><span class="st"> </span>tg_test<span class="op">$</span>gamble)), <span class="dv">1</span>)))</a></code></pre></div>
<pre><code>## [1] &quot;CV mean absolute error: 16.3&quot;</code></pre>
<p>Using mean absolute error, BIC out-performed the cross-validated model. This result shouldn’t be too surprising given that the BIC model contained additional predictor variables that appeared to be statistically significant.</p>
</div>
</div>
<div id="lasso-regression" class="section level2">
<h2><span class="header-section-number">8.6</span> Lasso Regression</h2>
<p>Ridge and lasso regression are closely related regularization techniques to reduce model complexity. The primary difference between the two methods is that ridge regression reduces factor coefficients close to (but not equal to) zero, while lasso regression reduces the coefficients all the way to zero, which makes it useful for reducing model complexity by eliminating factors.</p>
<div id="background-reading" class="section level3">
<h3><span class="header-section-number">8.6.1</span> Background Reading</h3>
<p>For the theoretical framework, please read <a href = "https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b">this article</a>. Don’t worry about the Python code. Just read the text portions of the article that explain the how ridge and, more importantly, lasso regression work.</p>
</div>
<div id="lasso-regression-in-r" class="section level3">
<h3><span class="header-section-number">8.6.2</span> Lasso Regression In R</h3>
<p>Lasso regression is particularly useful when a dataset has many factors, but we’ll continue to use the <code>teengamb</code> data so we can compare the results with the <code>stepAIC()</code> method. Performing lasso regression with the <code>glmnet</code> package is straight forward. The function has two required arguments, an <code>x</code> and a <code>y</code>, where <code>x</code> are the data associated with the predictors (note <code>x</code> must be a <code>data.matrix</code>, not a <code>data.frame</code>), and <code>y</code> is the response as a vector. By default, <code>glmnet</code> automatically scales and centers the data, and then converts them back to the original scale when providing results. If we plot the results, we get the following.</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb742-1" data-line-number="1"><span class="kw">library</span>(glmnet)</a>
<a class="sourceLine" id="cb742-2" data-line-number="2"></a>
<a class="sourceLine" id="cb742-3" data-line-number="3"><span class="co"># for some reason, glmnet works best with data.matrix instead of as.matrix</span></a>
<a class="sourceLine" id="cb742-4" data-line-number="4">x =<span class="st"> </span><span class="kw">data.matrix</span>(tg_train[<span class="op">-</span><span class="dv">5</span>])</a>
<a class="sourceLine" id="cb742-5" data-line-number="5">y =<span class="st"> </span>tg_train<span class="op">$</span>gamble</a>
<a class="sourceLine" id="cb742-6" data-line-number="6"></a>
<a class="sourceLine" id="cb742-7" data-line-number="7">tg.lasso =<span class="st"> </span><span class="kw">glmnet</span>(x, y)</a>
<a class="sourceLine" id="cb742-8" data-line-number="8"><span class="kw">plot</span>(tg.lasso, <span class="dt">xvar=</span><span class="st">&quot;lambda&quot;</span>, <span class="dt">label=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="06-Model_Selection_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Each of the above lines represents a predictor. The number next to each line on the left side of the plot refers to the column number in the <code>x</code> matrix. The vertical axis represents the factor coefficient. The bottom x axis is <span class="math inline">\(log(\lambda)\)</span>, and the top x axis is the associated number of predictors included in the model.</p>
<p>So how do we interpret this plot? At the far right, we can see that the coefficient for every predictor is zero. In other words, this is the null model. As <span class="math inline">\(\lambda\)</span> decreases, predictors are added one at a time to the model. Since predictor #3 (income) is the first to have a non-zero coefficient, it is the most significant. Sex (predictor #1) is the next non-zero coefficient followed by verbal (predictor #4) and then status (predictor #2). If we compare this order with the p-values from the best fit linear model, we see that there is consistency. Note that income was the first non-zero coefficient, and it has the lowest p-value in the linear model. Also note that the maximum coefficients in the lasso regression plot are also consistent with the linear model coefficients.</p>
<p>Our task now is to find the model that has good predictive power while including only the most significant predictors. In other words, we need a method to find the right <span class="math inline">\(\lambda\)</span> value. Before we get to how we identify that <span class="math inline">\(\lambda\)</span>, let’s look at some other useful information from <code>tg.lasso</code>. If we print our glmnet object, we see (going by columns from left to right) the number of predictors included in the model (Df, not to be confused with the degrees of freedom in a linear model summary), the percent of null deviance explained, and the associated <span class="math inline">\(\lambda\)</span> value.</p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb743-1" data-line-number="1"><span class="kw">print</span>(tg.lasso)</a></code></pre></div>
<pre><code>## 
## Call:  glmnet(x = x, y = y) 
## 
##    Df  %Dev  Lambda
## 1   0  0.00 21.9800
## 2   1  7.26 20.0300
## 3   1 13.29 18.2500
## 4   1 18.30 16.6300
## 5   1 22.45 15.1500
## 6   1 25.90 13.8100
## 7   1 28.77 12.5800
## 8   1 31.15 11.4600
## 9   2 34.07 10.4400
## 10  2 36.78  9.5160
## 11  2 39.03  8.6710
## 12  2 40.90  7.9010
## 13  2 42.46  7.1990
## 14  2 43.75  6.5590
## 15  2 44.82  5.9770
## 16  2 45.71  5.4460
## 17  3 46.46  4.9620
## 18  3 47.38  4.5210
## 19  3 48.14  4.1190
## 20  3 48.77  3.7530
## 21  3 49.30  3.4200
## 22  3 49.73  3.1160
## 23  3 50.10  2.8390
## 24  3 50.40  2.5870
## 25  3 50.65  2.3570
## 26  3 50.85  2.1480
## 27  3 51.03  1.9570
## 28  3 51.17  1.7830
## 29  3 51.29  1.6250
## 30  3 51.39  1.4800
## 31  3 51.47  1.3490
## 32  3 51.54  1.2290
## 33  3 51.59  1.1200
## 34  3 51.64  1.0200
## 35  3 51.68  0.9298
## 36  3 51.71  0.8472
## 37  3 51.74  0.7719
## 38  3 51.76  0.7033
## 39  3 51.78  0.6409
## 40  3 51.79  0.5839
## 41  3 51.80  0.5320
## 42  4 51.83  0.4848
## 43  4 51.85  0.4417
## 44  4 51.87  0.4025
## 45  4 51.89  0.3667
## 46  4 51.90  0.3341
## 47  4 51.91  0.3045
## 48  4 51.92  0.2774
## 49  4 51.93  0.2528
## 50  4 51.93  0.2303
## 51  4 51.94  0.2099
## 52  4 51.94  0.1912
## 53  4 51.95  0.1742
## 54  4 51.95  0.1587
## 55  4 51.95  0.1446
## 56  4 51.95  0.1318
## 57  4 51.96  0.1201
## 58  4 51.96  0.1094
## 59  4 51.96  0.0997
## 60  4 51.96  0.0908
## 61  4 51.96  0.0828
## 62  4 51.96  0.0754
## 63  4 51.96  0.0687
## 64  4 51.96  0.0626</code></pre>
<p>We can also see the coefficient values for any given <span class="math inline">\(\lambda\)</span> with <code>coef</code>. We can see that small values of <span class="math inline">\(\lambda\)</span> include more predictors and so correspond with the right side of the plot above. We can get the coefficients for any given <span class="math inline">\(\lambda\)</span> value with <code>coef()</code>. If we choose the smallest values of <span class="math inline">\(\lambda\)</span> from the above data, we get:</p>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb745-1" data-line-number="1"><span class="co"># Note that we specify lambda with s</span></a>
<a class="sourceLine" id="cb745-2" data-line-number="2"><span class="kw">coef</span>(tg.lasso, <span class="dt">s=</span><span class="fl">0.0626</span>)</a></code></pre></div>
<pre><code>## 5 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        1
## (Intercept)  18.03799848
## sex         -18.24900253
## status        0.08230075
## income        5.20255057
## verbal       -2.69223049</code></pre>
<p>Now we can more directly compare these coefficients to the full linear model coefficients. Recall that we withheld a test set prior to performing lasso regression, so the coefficients are close, but not equal to the linear model coefficients.</p>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb747-1" data-line-number="1"><span class="kw">sumary</span>(<span class="kw">lm</span>(gamble<span class="op">~</span>., <span class="dt">data=</span>teengamb))</a></code></pre></div>
<pre><code>##               Estimate Std. Error t value  Pr(&gt;|t|)
## (Intercept)  22.555651  17.196803  1.3116   0.19677
## sex         -22.118330   8.211115 -2.6937   0.01011
## status        0.052234   0.281112  0.1858   0.85349
## income        4.961979   1.025392  4.8391 1.792e-05
## verbal       -2.959493   2.172150 -1.3625   0.18031
## 
## n = 47, p = 5, Residual SE = 22.69034, R-Squared = 0.53</code></pre>
<p>If we choose a <span class="math inline">\(\lambda\)</span> associated with 2 Df, we see that only two predictors have non-zero coefficients.</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb749-1" data-line-number="1"><span class="kw">coef</span>(tg.lasso, <span class="dt">s=</span><span class="fl">5.9770</span>)</a></code></pre></div>
<pre><code>## 5 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     1
## (Intercept)  5.858393
## sex         -8.912086
## status       .       
## income       4.039764
## verbal       .</code></pre>
<p>To find the optimal value for <span class="math inline">\(\lambda\)</span>, we use cross validation again. We can include cross validation in the <code>glmnet()</code> function by prepending <code>cv.</code> as shown below. The default number of folds in the <code>cv.glmnet</code> function is 10, which is fine for this example. There’s a built-in method for plotting the results as we did manually above.</p>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb751-1" data-line-number="1">tg.cv =<span class="st"> </span><span class="kw">cv.glmnet</span>(x, y)</a>
<a class="sourceLine" id="cb751-2" data-line-number="2"><span class="kw">plot</span>(tg.cv)</a></code></pre></div>
<p><img src="06-Model_Selection_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>What we get is the cross validation curve (red dots) and two values for <span class="math inline">\(\lambda\)</span> (vertical dashed lines). The left dashed line is the value of lambda that gives the minimum mean cross-validated error. The right dashed line is the value of <span class="math inline">\(\lambda\)</span> whose error is within one standard deviation of the minimum. This is the <span class="math inline">\(\lambda\)</span> we’ve been after. We can get the coefficients associated with this <span class="math inline">\(\lambda\)</span> by specifying <code>s = &quot;lambda.1se&quot;</code>. Our cross validated best fit lasso regression model is shown below.</p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb752-1" data-line-number="1"><span class="kw">coef</span>(tg.cv, <span class="dt">s =</span> <span class="st">&quot;lambda.1se&quot;</span>)</a></code></pre></div>
<pre><code>## 5 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     1
## (Intercept) 12.864028
## sex          .       
## status       .       
## income       1.826509
## verbal       .</code></pre>
<p>For a more thorough discussion of the <code>glmnet</code> package, including its use with non-Gaussian data, refer to the <a href = "https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html">vignette</a> written by Trevor Hastie and Junyang Qian.</p>
</div>
</div>
<div id="parting-thought" class="section level2">
<h2><span class="header-section-number">8.7</span> Parting Thought</h2>
<p>In this chapter, we have seen that different methods for model selection can produce different “best” models, which might make you leery about the whole thing. Remember the George Box quote:</p>
<blockquote>
<p>All models are wrong…</p>
</blockquote>
<p>We’re just trying to find one that’s useful.</p>
</div>
<div id="lasso-regression-problem-set" class="section level2">
<h2><span class="header-section-number">8.8</span> Lasso Regression Problem Set</h2>
<p>The problem set for this section is located <a href = "/_Chapter8_ProblemSets/Lasso_ProblemSet_Questions.html">here</a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = "/_Chapter8_ProblemSets/Lasso_ProblemSet_Questions.Rmd">here</a>.</p>
<p>The solutions for this problem set are located <a href = "/_Chapter8_ProblemSets/Lasso_ProblemSet_Solutions.html">here</a>.</p>
<!--chapter:end:06-Model_Selection.Rmd-->
</div>
</div>
<div id="application-of-doe-to-the-advanced-warfighting-simulation" class="section level1">
<h1><span class="header-section-number">9</span> Application of DoE to the Advanced Warfighting Simulation</h1>
<p>By this point in the tutorial, you have all the skills needed to design experiments for two-level factors and fit a linear model to the results. Depending on the study, these may be the only analytic skills needed to meet the study objectives. So far, the datasets we’ve been working with have largely been built-in datasets from <em>R</em> packages or results from a simplified combat model. In this chapter, we’ll make the leap from interacting with the simplified combat model to interacting with the Advanced Warfighting Simulation (AWARS). As a result, this chapter consists of a stand-alone R Markdown file on MCN-S.</p>
<p>Topics covered in this chapter include:</p>
<ul>
<li>Working With AWARS Input Files
<ul>
<li>Text Files (input files and .ctl files)</li>
<li>Working With Strings and Regular Expressions</li>
</ul></li>
<li>APE Database</li>
<li>Automating AWARS Runs With Bash</li>
<li>Working With AWARS Output
<ul>
<li>Postprocessor Database</li>
<li>Playback Database</li>
<li>Efficient Queries</li>
</ul></li>
</ul>
<!--chapter:end:07-Applications.Rmd-->
</div>
<div id="advanced-experimental-designs" class="section level1">
<h1><span class="header-section-number">10</span> Advanced Experimental Designs</h1>
<p>So far, we have considered designs with just two levels per factor, which is fine for inherently binary factors. However, if our study requires us to include a factor that can take on more than two values, or even a continuous range of values, or if we suspect that the relationship between a predictor and a response is non-linear, we need a different experimental design.</p>
<div id="admin-5" class="section level2">
<h2><span class="header-section-number">10.1</span> Admin</h2>
<p>For any errors associated with this section, please contact <a href="mailto:john.f.king1.mil@mail.mil">John King</a>.</p>
<p>This chapter was published using the following software:</p>
<ul>
<li>R version 3.6.0 (2019-04-26).</li>
<li>On x86_64-pc-linux-gnu (64-bit) running Ubuntu 18.04.2 LTS.</li>
<li>Packages are explicitly shown in the code snippets with the exception of the <code>tidyverse</code> version 1.3.0.</li>
</ul>
</div>
<div id="introduction-and-background" class="section level2">
<h2><span class="header-section-number">10.2</span> Introduction and Background</h2>
<p>In this chapter, we will design experiments that can accommodate factors with three or more levels (up to continuous). The designs presented in this chapter belong to two broad categories: central composite designs (CCD) and nearly orthogonal Latin hypercube (NOLH) designs. These designs are particularly useful if we find ourselves in one (or both) of the following situations:</p>
<ol style="list-style-type: decimal">
<li><p>We suspect there may be non-linear relationships between one or more predictors and the response variable.</p></li>
<li><p>The levels of one or more predictors are not well known or clearly defined. This is often the case when developing requirements for a future system. For example, perhaps the Army is considering developing a new helicopter, and the developers are interested in identifying the optimal combination of speed, fuel capacity, range, and various weapon and sensor systems.</p></li>
</ol>
<p>For background, please read the following:</p>
<ul>
<li><p>From <a href = "https://www.informs-sim.org/wsc15papers/187.pdf"> Work Smarter, Not Harder: A Tutorial On Designing And Conducting Simulation Experiments</a>, skim Sections 1 and 2, and then carefully read Sections 3, 4, and 5.</p></li>
<li><p>From <a href = "https://nps.edu/documents/106696734/108129281/UserGuideSimExpts.pdf/6bf10d35-b507-4554-b77a-6f4a443e4025?t=1475088085000"> A User’s Guide to the Brave New World of Designing Simulation Experiments</a>, read Sections 2.2 - 2.4, and all of Sections 3 and 4. Figure 1 is a nice visual guide for design selection. Note that the authors prefer designs towards the top of the figure.</p></li>
</ul>
<p>From the readings, you can see that there is an entire field of study regarding design generation and that the properties of the various designs make them well or poorly suited for a given study. The authors of both articles discussed gridded designs, which are simple to construct and allow for the evaluation of non-linear relationships. The main drawback of gridded designs, especially when it comes to applying them to combat simulations, is that they are very inefficient. For example, a gridded design for 10 factors at 4 levels each requires <span class="math inline">\(4^{10} = 1,048,576\)</span> design points, and due to this property we will not consider them further for AWARS applications. Instead, we’ll focus on CCDs and NOLH-based designs.</p>
</div>
<div id="central-composite-designs" class="section level2">
<h2><span class="header-section-number">10.3</span> Central Composite Designs</h2>
<p>To detect non-linearity in the response, at a minimum, we need to add a center point to a factorial design. One option is to add a single center point that is shared by multiple factors to minimize the number of runs. Using <code>plotly</code> to plot in three dimensions, this design is visualized as follows (this is an interactive plot, so click and drag the plot to rotate the points):</p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb754-1" data-line-number="1"><span class="kw">library</span>(plotly)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;plotly&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     last_plot</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     layout</code></pre>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb759-1" data-line-number="1">centerPoint =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb759-2" data-line-number="2">  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">4</span>), <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb759-3" data-line-number="3">  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">2</span>), <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb759-4" data-line-number="4">  <span class="dt">x3 =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">each=</span><span class="dv">4</span>), <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb759-5" data-line-number="5">  <span class="dt">center =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;y&quot;</span>, <span class="dv">8</span>), <span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb759-6" data-line-number="6">)</a>
<a class="sourceLine" id="cb759-7" data-line-number="7"></a>
<a class="sourceLine" id="cb759-8" data-line-number="8"><span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb759-9" data-line-number="9"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> centerPoint, <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>x3,</a>
<a class="sourceLine" id="cb759-10" data-line-number="10">            <span class="dt">color=</span><span class="op">~</span>center, </a>
<a class="sourceLine" id="cb759-11" data-line-number="11">            <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">&#39;#0C4B8E&#39;</span>, <span class="st">&#39;#BF382A&#39;</span>), </a>
<a class="sourceLine" id="cb759-12" data-line-number="12">            <span class="dt">type=</span><span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb759-13" data-line-number="13"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&#39;CCD With Center Point&#39;</span>, <span class="dt">showlegend =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb759-14" data-line-number="14">         <span class="dt">scene =</span> <span class="kw">list</span>(<span class="dt">camera =</span> <span class="kw">list</span>(<span class="dt">eye =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="fl">-1.0</span>, <span class="dt">y =</span> <span class="fl">1.25</span>, <span class="dt">z =</span> <span class="fl">0.3</span>))))</a></code></pre></div>
<div id="htmlwidget-6a1acc5b82c7a4123125" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-6a1acc5b82c7a4123125">{"x":{"visdat":{"8cffb09487":["function () ","plotlyVisDat"],"8cf56cb807d":["function () ","data"]},"cur_data":"8cf56cb807d","attrs":{"8cf56cb807d":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"color":{},"colors":["#0C4B8E","#BF382A"],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"CCD With Center Point","showlegend":false,"scene":{"camera":{"eye":{"x":-1,"y":1.25,"z":0.29999999999999999}},"xaxis":{"title":"x1"},"yaxis":{"title":"x2"},"zaxis":{"title":"x3"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[0],"y":[0],"z":[0],"type":"scatter3d","mode":"markers","name":"n","marker":{"color":"rgba(12,75,142,1)","line":{"color":"rgba(12,75,142,1)"}},"textfont":{"color":"rgba(12,75,142,1)"},"error_y":{"color":"rgba(12,75,142,1)"},"error_x":{"color":"rgba(12,75,142,1)"},"line":{"color":"rgba(12,75,142,1)"},"frame":null},{"x":[-1,1,-1,1,-1,1,-1,1],"y":[-1,-1,1,1,-1,-1,1,1],"z":[-1,-1,-1,-1,1,1,1,1],"type":"scatter3d","mode":"markers","name":"y","marker":{"color":"rgba(191,56,42,1)","line":{"color":"rgba(191,56,42,1)"}},"textfont":{"color":"rgba(191,56,42,1)"},"error_y":{"color":"rgba(191,56,42,1)"},"error_x":{"color":"rgba(191,56,42,1)"},"line":{"color":"rgba(191,56,42,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>This design projected on to any of the 2D faces of the cube appears as:</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb760-1" data-line-number="1"><span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb760-2" data-line-number="2"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> centerPoint, <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2,</a>
<a class="sourceLine" id="cb760-3" data-line-number="3">            <span class="dt">color=</span><span class="op">~</span>center, </a>
<a class="sourceLine" id="cb760-4" data-line-number="4">            <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">&#39;#0C4B8E&#39;</span>, <span class="st">&#39;#BF382A&#39;</span>), </a>
<a class="sourceLine" id="cb760-5" data-line-number="5">            <span class="dt">type=</span><span class="st">&#39;scatter&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, <span class="dt">size=</span><span class="dv">10</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb760-6" data-line-number="6"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&#39;CCD With Center Point&#39;</span>, <span class="dt">showlegend =</span> <span class="ot">FALSE</span>, </a>
<a class="sourceLine" id="cb760-7" data-line-number="7">         <span class="dt">xaxis=</span><span class="kw">list</span>(<span class="dt">zeroline=</span>F), <span class="dt">yaxis=</span><span class="kw">list</span>(<span class="dt">zeroline=</span>F))</a></code></pre></div>
<div id="htmlwidget-a720cd143317f315dad5" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-a720cd143317f315dad5">{"x":{"visdat":{"8cf91792f6":["function () ","plotlyVisDat"],"8cf427c378e":["function () ","data"]},"cur_data":"8cf427c378e","attrs":{"8cf427c378e":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"color":{},"colors":["#0C4B8E","#BF382A"],"type":"scatter","mode":"markers","size":10,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"CCD With Center Point","showlegend":false,"xaxis":{"domain":[0,1],"automargin":true,"zeroline":false,"title":"x1"},"yaxis":{"domain":[0,1],"automargin":true,"zeroline":false,"title":"x2"},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[0],"y":[0],"type":"scatter","mode":"markers","name":"n","marker":{"color":"rgba(12,75,142,1)","size":[55],"sizemode":"area","line":{"color":"rgba(12,75,142,1)"}},"textfont":{"color":"rgba(12,75,142,1)","size":55},"error_y":{"color":"rgba(12,75,142,1)","width":55},"error_x":{"color":"rgba(12,75,142,1)","width":55},"line":{"color":"rgba(12,75,142,1)","width":55},"xaxis":"x","yaxis":"y","frame":null},{"x":[-1,1,-1,1,-1,1,-1,1],"y":[-1,-1,1,1,-1,-1,1,1],"type":"scatter","mode":"markers","name":"y","marker":{"color":"rgba(191,56,42,1)","size":[55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(191,56,42,1)"}},"textfont":{"color":"rgba(191,56,42,1)","size":55},"error_y":{"color":"rgba(191,56,42,1)","width":55},"error_x":{"color":"rgba(191,56,42,1)","width":55},"line":{"color":"rgba(191,56,42,1)","width":55},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb761-1" data-line-number="1"><span class="kw">rm</span>(centerPoint)</a></code></pre></div>
<p>Two considerations with this design:</p>
<ol style="list-style-type: decimal">
<li><p>This design contains the minimum number of design points to identify non-linear relationships. If no non-linear relationships exist, we simply continue with the modeling methods presented earlier in this tutorial.</p></li>
<li><p>If one or more non-linear relationships exist, this design does not allow you to determine which factors are non-linear.</p></li>
</ol>
<p>To address #2, we need to add a point to each face of the cube, which are collectively referred to as <strong>star points</strong>. You can also think of this design as starting with a gridded design and removing unnecessary design points to make it more efficient. For comparison, a 3-factor, 3-level gridded design has <span class="math inline">\(3^{3} = 27\)</span> design points compared to 15 design points for a CCD (8 for the corners and 7 for the star). Below is the CCD with star points shown in blue and connected with black lines.</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb762-1" data-line-number="1">ccdGrid =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb762-2" data-line-number="2">  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="dv">4</span>)),</a>
<a class="sourceLine" id="cb762-3" data-line-number="3">  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">rep</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">each =</span> <span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb762-4" data-line-number="4">  <span class="dt">x3 =</span> <span class="kw">c</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>), <span class="kw">rep</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">4</span>), <span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">4</span>)),</a>
<a class="sourceLine" id="cb762-5" data-line-number="5">  <span class="dt">star =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;y&#39;</span>, <span class="dv">7</span>), <span class="kw">rep</span>(<span class="st">&#39;n&#39;</span>,<span class="dv">8</span>)),</a>
<a class="sourceLine" id="cb762-6" data-line-number="6">  <span class="dt">line =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&#39;line1&#39;</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;line2&#39;</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;line3&#39;</span>,<span class="dv">2</span>), <span class="kw">rep</span>(<span class="st">&#39;none&#39;</span>,<span class="dv">9</span>))</a>
<a class="sourceLine" id="cb762-7" data-line-number="7">)</a>
<a class="sourceLine" id="cb762-8" data-line-number="8"></a>
<a class="sourceLine" id="cb762-9" data-line-number="9"><span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb762-10" data-line-number="10"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> ccdGrid, <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>x3,</a>
<a class="sourceLine" id="cb762-11" data-line-number="11">            <span class="dt">color=</span><span class="op">~</span>star, </a>
<a class="sourceLine" id="cb762-12" data-line-number="12">            <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">&#39;#BF382A&#39;</span>, <span class="st">&#39;#0C4B8E&#39;</span>), </a>
<a class="sourceLine" id="cb762-13" data-line-number="13">            <span class="dt">type=</span><span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb762-14" data-line-number="14"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> ccdGrid <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(line<span class="op">==</span><span class="st">&#39;line1&#39;</span>), </a>
<a class="sourceLine" id="cb762-15" data-line-number="15">            <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>x3,</a>
<a class="sourceLine" id="cb762-16" data-line-number="16">            <span class="dt">line =</span> <span class="kw">list</span>(<span class="dt">color =</span> <span class="st">&#39;black&#39;</span>, <span class="dt">width =</span> <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb762-17" data-line-number="17">            <span class="dt">type =</span> <span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;lines&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb762-18" data-line-number="18"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> ccdGrid <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(line<span class="op">==</span><span class="st">&#39;line2&#39;</span>), </a>
<a class="sourceLine" id="cb762-19" data-line-number="19">            <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>x3,</a>
<a class="sourceLine" id="cb762-20" data-line-number="20">            <span class="dt">line =</span> <span class="kw">list</span>(<span class="dt">color =</span> <span class="st">&#39;black&#39;</span>, <span class="dt">width =</span> <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb762-21" data-line-number="21">            <span class="dt">type =</span> <span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;lines&#39;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb762-22" data-line-number="22"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> ccdGrid <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(line<span class="op">==</span><span class="st">&#39;line3&#39;</span>), </a>
<a class="sourceLine" id="cb762-23" data-line-number="23">            <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>x3,</a>
<a class="sourceLine" id="cb762-24" data-line-number="24">            <span class="dt">line =</span> <span class="kw">list</span>(<span class="dt">color =</span> <span class="st">&#39;black&#39;</span>, <span class="dt">width =</span> <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb762-25" data-line-number="25">            <span class="dt">type =</span> <span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;lines&#39;</span>)<span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb762-26" data-line-number="26"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&#39;Central Composite Design&#39;</span>, <span class="dt">showlegend =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb762-27" data-line-number="27">         <span class="dt">scene =</span> <span class="kw">list</span>(<span class="dt">camera =</span> <span class="kw">list</span>(<span class="dt">eye =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="fl">-1.0</span>, <span class="dt">y =</span> <span class="fl">1.25</span>, <span class="dt">z =</span> <span class="fl">0.3</span>))))</a></code></pre></div>
<div id="htmlwidget-e6c2a5ab8310989370cc" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-e6c2a5ab8310989370cc">{"x":{"visdat":{"8cf5e00c5e6":["function () ","plotlyVisDat"],"8cf2c69214d":["function () ","data"],"8cf5d2eb52c":["function () ","data"],"8cf4e35882a":["function () ","data"],"8cf2427ec13":["function () ","data"]},"cur_data":"8cf2427ec13","attrs":{"8cf2c69214d":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"color":{},"colors":["#BF382A","#0C4B8E"],"type":"scatter3d","mode":"markers","inherit":true},"8cf5d2eb52c":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"line":{"color":"black","width":2},"type":"scatter3d","mode":"lines","inherit":true},"8cf4e35882a":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"line":{"color":"black","width":2},"type":"scatter3d","mode":"lines","inherit":true},"8cf2427ec13":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"line":{"color":"black","width":2},"type":"scatter3d","mode":"lines","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Central Composite Design","showlegend":false,"scene":{"camera":{"eye":{"x":-1,"y":1.25,"z":0.29999999999999999}},"xaxis":{"title":"x1"},"yaxis":{"title":"x2"},"zaxis":{"title":"x3"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[-1,1,-1,1,-1,1,-1,1],"y":[-1,-1,1,1,-1,-1,1,1],"z":[-1,-1,-1,-1,1,1,1,1],"type":"scatter3d","mode":"markers","name":"n","marker":{"color":"rgba(191,56,42,1)","line":{"color":"rgba(191,56,42,1)"}},"textfont":{"color":"rgba(191,56,42,1)"},"error_y":{"color":"rgba(191,56,42,1)"},"error_x":{"color":"rgba(191,56,42,1)"},"line":{"color":"rgba(191,56,42,1)"},"frame":null},{"x":[-1,1,0,0,0,0,0],"y":[0,0,-1,1,0,0,0],"z":[0,0,0,0,-1,1,0],"type":"scatter3d","mode":"markers","name":"y","marker":{"color":"rgba(12,75,142,1)","line":{"color":"rgba(12,75,142,1)"}},"textfont":{"color":"rgba(12,75,142,1)"},"error_y":{"color":"rgba(12,75,142,1)"},"error_x":{"color":"rgba(12,75,142,1)"},"line":{"color":"rgba(12,75,142,1)"},"frame":null},{"x":[-1,1],"y":[0,0],"z":[0,0],"line":{"color":"black","width":2},"type":"scatter3d","mode":"lines","marker":{"color":"rgba(44,160,44,1)","line":{"color":"rgba(44,160,44,1)"}},"error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"frame":null},{"x":[0,0],"y":[-1,1],"z":[0,0],"line":{"color":"black","width":2},"type":"scatter3d","mode":"lines","marker":{"color":"rgba(214,39,40,1)","line":{"color":"rgba(214,39,40,1)"}},"error_y":{"color":"rgba(214,39,40,1)"},"error_x":{"color":"rgba(214,39,40,1)"},"frame":null},{"x":[0,0],"y":[0,0],"z":[-1,1],"line":{"color":"black","width":2},"type":"scatter3d","mode":"lines","marker":{"color":"rgba(148,103,189,1)","line":{"color":"rgba(148,103,189,1)"}},"error_y":{"color":"rgba(148,103,189,1)"},"error_x":{"color":"rgba(148,103,189,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<div id="augmented-central-composite-designs" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Augmented Central Composite Designs</h3>
<p>The design generated above can be used to identify several kinds of non-linear relationships, <span class="math inline">\(log(x)\)</span>, <span class="math inline">\(e^x\)</span>, <span class="math inline">\(1/x\)</span>, and <span class="math inline">\(x^2\)</span>. It can not, however, be used to identify trends with more than one bend in the curve (e.g., <span class="math inline">\(x^3\)</span>). The CCD generated above can be further augmented with additional design points to either capture higher order relationships or to obtain additional data for use in response surface methodology (presented later in this section). Additionally, since these designs are increasing in complexity, we will make use of the <code>rsm</code> package to generate them.</p>
<p>To get a feel for the <code>rsm</code> package, we’ll re-generate the CCD with the star points as in the previous section. According to the documentation, the preferred method for generating this design is to follow a two-step process. First, we generate the corner points with <code>cube()</code>.</p>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb763-1" data-line-number="1"><span class="kw">library</span>(rsm)</a>
<a class="sourceLine" id="cb763-2" data-line-number="2"></a>
<a class="sourceLine" id="cb763-3" data-line-number="3">cu =<span class="st"> </span><span class="kw">cube</span>(<span class="dv">3</span>, <span class="dt">n0=</span><span class="dv">0</span>) <span class="co"># 3 factors and 0 center points</span></a>
<a class="sourceLine" id="cb763-4" data-line-number="4">cu</a></code></pre></div>
<pre><code>##   run.order std.order x1.as.is x2.as.is x3.as.is
## 1         1         2        1       -1       -1
## 2         2         5       -1       -1        1
## 3         3         8        1        1        1
## 4         4         7       -1        1        1
## 5         5         3       -1        1       -1
## 6         6         4        1        1       -1
## 7         7         6        1       -1        1
## 8         8         1       -1       -1       -1
## 
## Data are stored in coded form using these coding formulas ...
## x1 ~ x1.as.is
## x2 ~ x2.as.is
## x3 ~ x3.as.is</code></pre>
<p>Then we combine the cube points using <code>djoin()</code> with the star points using <code>star()</code></p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb765-1" data-line-number="1"><span class="co"># alpha = 1 generates the &quot;face&quot; points, n0 gives the central point</span></a>
<a class="sourceLine" id="cb765-2" data-line-number="2">ccd =<span class="st"> </span><span class="kw">djoin</span>(cu, <span class="kw">star</span>(<span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">n0=</span><span class="dv">1</span>)) </a>
<a class="sourceLine" id="cb765-3" data-line-number="3">ccd</a></code></pre></div>
<pre><code>##    run.order std.order x1.as.is x2.as.is x3.as.is Block
## 1          1         2        1       -1       -1     1
## 2          2         5       -1       -1        1     1
## 3          3         8        1        1        1     1
## 4          4         7       -1        1        1     1
## 5          5         3       -1        1       -1     1
## 6          6         4        1        1       -1     1
## 7          7         6        1       -1        1     1
## 8          8         1       -1       -1       -1     1
## 9          1         7        0        0        0     2
## 10         2         3        0       -1        0     2
## 11         3         2        1        0        0     2
## 12         4         1       -1        0        0     2
## 13         5         4        0        1        0     2
## 14         6         5        0        0       -1     2
## 15         7         6        0        0        1     2
## 
## Data are stored in coded form using these coding formulas ...
## x1 ~ x1.as.is
## x2 ~ x2.as.is
## x3 ~ x3.as.is</code></pre>
<p>Plotting this design demonstrates that it’s equivalent to what we produced manually.</p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb767-1" data-line-number="1"><span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-2" data-line-number="2"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> ccd, <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2, <span class="dt">z =</span> <span class="op">~</span>x3, </a>
<a class="sourceLine" id="cb767-3" data-line-number="3">            <span class="dt">color=</span><span class="op">~</span>Block, <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">&#39;#BF382A&#39;</span>, <span class="st">&#39;#0C4B8E&#39;</span>), </a>
<a class="sourceLine" id="cb767-4" data-line-number="4">            <span class="dt">type=</span><span class="st">&#39;scatter3d&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>)<span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb767-5" data-line-number="5"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&#39;rsm Central Composite Design&#39;</span>, <span class="dt">showlegend =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb767-6" data-line-number="6">         <span class="dt">scene =</span> <span class="kw">list</span>(<span class="dt">camera =</span> <span class="kw">list</span>(<span class="dt">eye =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="fl">-1.0</span>, <span class="dt">y =</span> <span class="fl">1.25</span>, <span class="dt">z =</span> <span class="fl">0.3</span>))))</a></code></pre></div>
<div id="htmlwidget-3cb9a3cd6e532b5213bb" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-3cb9a3cd6e532b5213bb">{"x":{"visdat":{"8cf33015af5":["function () ","plotlyVisDat"],"8cf4c4e8e1f":["function () ","data"]},"cur_data":"8cf4c4e8e1f","attrs":{"8cf4c4e8e1f":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"color":{},"colors":["#BF382A","#0C4B8E"],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"rsm Central Composite Design","showlegend":false,"scene":{"camera":{"eye":{"x":-1,"y":1.25,"z":0.29999999999999999}},"xaxis":{"title":"x1"},"yaxis":{"title":"x2"},"zaxis":{"title":"x3"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[1,-1,1,-1,-1,1,1,-1],"y":[-1,-1,1,1,1,1,-1,-1],"z":[-1,1,1,1,-1,-1,1,-1],"type":"scatter3d","mode":"markers","name":"1","marker":{"color":"rgba(191,56,42,1)","line":{"color":"rgba(191,56,42,1)"}},"textfont":{"color":"rgba(191,56,42,1)"},"error_y":{"color":"rgba(191,56,42,1)"},"error_x":{"color":"rgba(191,56,42,1)"},"line":{"color":"rgba(191,56,42,1)"},"frame":null},{"x":[0,0,1,-1,0,0,0],"y":[0,-1,0,0,1,0,0],"z":[0,0,0,0,0,-1,1],"type":"scatter3d","mode":"markers","name":"2","marker":{"color":"rgba(12,75,142,1)","line":{"color":"rgba(12,75,142,1)"}},"textfont":{"color":"rgba(12,75,142,1)"},"error_y":{"color":"rgba(12,75,142,1)"},"error_x":{"color":"rgba(12,75,142,1)"},"line":{"color":"rgba(12,75,142,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>An interesting feature of the CCD we just generated is that we can modify it slightly to accommodate additional factor levels without increasing the number of design points. We can do this by moving the corner points closer to the central point. In a <strong>spherical design</strong> as shown below, the corner point at <span class="math inline">\((1 ,1)\)</span> moves to <span class="math inline">\((1/\sqrt{k}, 1/\sqrt{k})\)</span> where <span class="math inline">\(k\)</span> is the number of factors in the design. Since <span class="math inline">\(1/\sqrt{3} = 0.577\)</span>, the new point becomes <span class="math inline">\((0.577, 0.577)\)</span>.</p>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb768-1" data-line-number="1">cu2 =<span class="st"> </span><span class="kw">cube</span>(<span class="dv">3</span>, <span class="dt">n0=</span><span class="dv">0</span>, <span class="dt">inscribed =</span> <span class="ot">TRUE</span>)  <span class="co"># inscribed limits the axis points to +/- 1</span></a>
<a class="sourceLine" id="cb768-2" data-line-number="2">ccd_s =<span class="st"> </span><span class="kw">djoin</span>(cu2, <span class="kw">star</span>(<span class="dt">alpha=</span><span class="st">&quot;spherical&quot;</span>, <span class="dt">n0=</span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb768-3" data-line-number="3"></a>
<a class="sourceLine" id="cb768-4" data-line-number="4">pt &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span><span class="fl">0.6</span>, <span class="dt">y =</span> <span class="fl">0.6</span>)</a>
<a class="sourceLine" id="cb768-5" data-line-number="5"></a>
<a class="sourceLine" id="cb768-6" data-line-number="6"><span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb768-7" data-line-number="7"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> ccd_s, <span class="dt">x =</span> <span class="op">~</span>x1, <span class="dt">y =</span> <span class="op">~</span>x2,</a>
<a class="sourceLine" id="cb768-8" data-line-number="8">            <span class="dt">color=</span><span class="op">~</span>Block, <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">&#39;#BF382A&#39;</span>, <span class="st">&#39;#0C4B8E&#39;</span>), </a>
<a class="sourceLine" id="cb768-9" data-line-number="9">            <span class="dt">type=</span><span class="st">&#39;scatter&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, <span class="dt">size =</span><span class="dv">10</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb768-10" data-line-number="10"><span class="st">  </span><span class="kw">add_annotations</span>(<span class="dt">data=</span>pt, <span class="dt">ax=</span><span class="dv">1</span>, <span class="dt">ay=</span><span class="dv">1</span>, <span class="dt">axref=</span><span class="st">&quot;x&quot;</span>, <span class="dt">ayref=</span><span class="st">&quot;y&quot;</span>, <span class="dt">x=</span>pt<span class="op">$</span>x, <span class="dt">y=</span>pt<span class="op">$</span>y, <span class="dt">text=</span><span class="st">&quot;Moved Point&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb768-11" data-line-number="11"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&#39;Spherical Design&#39;</span>, <span class="dt">showlegend =</span> <span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb768-12" data-line-number="12">    <span class="dt">xaxis=</span><span class="kw">list</span>(<span class="dt">zeroline=</span>F), <span class="dt">yaxis=</span><span class="kw">list</span>(<span class="dt">zeroline=</span>F))</a></code></pre></div>
<div id="htmlwidget-de2778c98496fc65bbb8" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-de2778c98496fc65bbb8">{"x":{"visdat":{"8cf7fa22371":["function () ","plotlyVisDat"],"8cf5fbcc7dc":["function () ","data"],"8cf605009d5":["function () ","data"]},"cur_data":"8cf605009d5","attrs":{"8cf5fbcc7dc":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"color":{},"colors":["#BF382A","#0C4B8E"],"type":"scatter","mode":"markers","size":10,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"annotations":[{"text":"Moved Point","ax":1,"ay":1,"axref":"x","ayref":"y","x":0.59999999999999998,"y":0.59999999999999998}],"title":"Spherical Design","showlegend":false,"xaxis":{"domain":[0,1],"automargin":true,"zeroline":false,"title":"x1"},"yaxis":{"domain":[0,1],"automargin":true,"zeroline":false,"title":"x2"},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[0.57735026918962584,0.57735026918962584,0.57735026918962584,0.57735026918962584,-0.57735026918962584,-0.57735026918962584,-0.57735026918962584,-0.57735026918962584],"y":[0.57735026918962584,0.57735026918962584,-0.57735026918962584,-0.57735026918962584,-0.57735026918962584,0.57735026918962584,0.57735026918962584,-0.57735026918962584],"type":"scatter","mode":"markers","name":"1","marker":{"color":"rgba(191,56,42,1)","size":[55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(191,56,42,1)"}},"textfont":{"color":"rgba(191,56,42,1)","size":55},"error_y":{"color":"rgba(191,56,42,1)","width":55},"error_x":{"color":"rgba(191,56,42,1)","width":55},"line":{"color":"rgba(191,56,42,1)","width":55},"xaxis":"x","yaxis":"y","frame":null},{"x":[0,0,-1,0,0,1,0],"y":[-1,0,0,1,0,0,0],"type":"scatter","mode":"markers","name":"2","marker":{"color":"rgba(12,75,142,1)","size":[55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(12,75,142,1)"}},"textfont":{"color":"rgba(12,75,142,1)","size":55},"error_y":{"color":"rgba(12,75,142,1)","width":55},"error_x":{"color":"rgba(12,75,142,1)","width":55},"line":{"color":"rgba(12,75,142,1)","width":55},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Below, we see that the design still consists of 15 design points, and each factor has levels of -1.0, -0.58, 0, 0.58, and 1.0. Clearly, this is much more efficient than a gridded design, which would have <span class="math inline">\(5^3 = 125\)</span> design points.</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb769-1" data-line-number="1">ccd_s</a></code></pre></div>
<pre><code>##    run.order std.order   x1.as.is   x2.as.is   x3.as.is Block
## 1          1         4  0.5773503  0.5773503 -0.5773503     1
## 2          2         8  0.5773503  0.5773503  0.5773503     1
## 3          3         2  0.5773503 -0.5773503 -0.5773503     1
## 4          4         6  0.5773503 -0.5773503  0.5773503     1
## 5          5         1 -0.5773503 -0.5773503 -0.5773503     1
## 6          6         7 -0.5773503  0.5773503  0.5773503     1
## 7          7         3 -0.5773503  0.5773503 -0.5773503     1
## 8          8         5 -0.5773503 -0.5773503  0.5773503     1
## 9          1         3  0.0000000 -1.0000000  0.0000000     2
## 10         2         6  0.0000000  0.0000000  1.0000000     2
## 11         3         1 -1.0000000  0.0000000  0.0000000     2
## 12         4         4  0.0000000  1.0000000  0.0000000     2
## 13         5         7  0.0000000  0.0000000  0.0000000     2
## 14         6         2  1.0000000  0.0000000  0.0000000     2
## 15         7         5  0.0000000  0.0000000 -1.0000000     2
## 
## Data are stored in coded form using these coding formulas ...
## x1 ~ x1.as.is
## x2 ~ x2.as.is
## x3 ~ x3.as.is</code></pre>
<p>Notice that although the design consists of five levels for each factor, the number of design points at each level varies. For example, <code>x1</code> at levels -1 and 1 are only represented once each in the design matrix, whereas <code>x1</code> at level 0 is represented 5 times. Therefore, if multiple measurements at the extreme high and low ranges of the factor ranges is important, a standard CCD is a better choice than a spherical design. Alternatively, the spherical design can be replicated using the <code>dupe()</code> function to provide an additional design point at the extreme high and low factor levels.</p>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb771-1" data-line-number="1"><span class="kw">djoin</span>(ccd_s, <span class="kw">dupe</span>(ccd_s))</a></code></pre></div>
<pre><code>##    run.order std.order   x1.as.is   x2.as.is   x3.as.is Block
## 1          1         4  0.5773503  0.5773503 -0.5773503     1
## 2          2         8  0.5773503  0.5773503  0.5773503     1
## 3          3         2  0.5773503 -0.5773503 -0.5773503     1
## 4          4         6  0.5773503 -0.5773503  0.5773503     1
## 5          5         1 -0.5773503 -0.5773503 -0.5773503     1
## 6          6         7 -0.5773503  0.5773503  0.5773503     1
## 7          7         3 -0.5773503  0.5773503 -0.5773503     1
## 8          8         5 -0.5773503 -0.5773503  0.5773503     1
## 9          1         3  0.0000000 -1.0000000  0.0000000     2
## 10         2         6  0.0000000  0.0000000  1.0000000     2
## 11         3         1 -1.0000000  0.0000000  0.0000000     2
## 12         4         4  0.0000000  1.0000000  0.0000000     2
## 13         5         7  0.0000000  0.0000000  0.0000000     2
## 14         6         2  1.0000000  0.0000000  0.0000000     2
## 15         7         5  0.0000000  0.0000000 -1.0000000     2
## 16         1         1 -0.5773503 -0.5773503 -0.5773503     3
## 17         2         8  0.5773503  0.5773503  0.5773503     3
## 18         3         5 -0.5773503 -0.5773503  0.5773503     3
## 19         4         2  0.5773503 -0.5773503 -0.5773503     3
## 20         5         3 -0.5773503  0.5773503 -0.5773503     3
## 21         6         6  0.5773503 -0.5773503  0.5773503     3
## 22         7         7 -0.5773503  0.5773503  0.5773503     3
## 23         8         4  0.5773503  0.5773503 -0.5773503     3
## 24         1         6  0.0000000  0.0000000  1.0000000     4
## 25         2         7  0.0000000  0.0000000  0.0000000     4
## 26         3         5  0.0000000  0.0000000 -1.0000000     4
## 27         4         1 -1.0000000  0.0000000  0.0000000     4
## 28         5         2  1.0000000  0.0000000  0.0000000     4
## 29         6         3  0.0000000 -1.0000000  0.0000000     4
## 30         7         4  0.0000000  1.0000000  0.0000000     4
## 
## Data are stored in coded form using these coding formulas ...
## x1 ~ x1.as.is
## x2 ~ x2.as.is
## x3 ~ x3.as.is</code></pre>
</div>
</div>
<div id="response-surface-methodology" class="section level2">
<h2><span class="header-section-number">10.4</span> Response Surface Methodology</h2>
<p>As mentioned in the introduction, suppose we are interested in assisting with developing requirements for a future Army helicopter. For simplicity, say we’re only interested in determining how speed, stealth, and sensor range contribute to lethality (measured in the number of kills achieved by the helicopter). One can imagine that a low amount of stealth might result in few kills. As stealth increases, we would expect the number of kills to increase, but it may also be that increasing stealth beyond some threshold might begin to reduce the number of kills - perhaps the pilot spends so much effort remaining stealthy, that it becomes difficult to detect and engage targets. In this case, there is some optimal combination stealth, speed and sensor range that produces the greatest number of kills, and this optimal combination is not the maximum levels of each factor. Response surface methodology in conjunction with efficient experimental design can be applied in a situation like this to identify the optimal combination of factor levels.</p>
<p>For our example, we will consider the following ranges of predictor values:</p>
<ul>
<li>Speed ranges from 100 to 300 km/hr.</li>
<li>Stealth ranges from 0, which represents no stealth, to 1, which represents full ninja.</li>
<li>Sensor detection ranges from 5 to 15 km.</li>
</ul>
<p>Response surface methodology involves plotting pairs of factors on the x and y axes and the response on the z axis. We can accomplish this using either a contour or a 3D plot. Since we don’t know what the optimal factor values are, ideally, we’d like to evaluate as many factor value combinations as possible. One consideration when choosing a design for this purpose is the design’s <strong>space-filling properties</strong>, which is demonstrated in the following plots using just speed and stealth. From left to right, the space-filling properties of the designs improve, which means that if the optimal values for speed and stealth are 261 and 0.81 (shown in red on the plots), respectively, then the design on the right will most accurately identify these optimal values.</p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb773-1" data-line-number="1">ss3 =<span class="st"> </span><span class="kw">expand_grid</span>(<span class="dt">speed=</span><span class="kw">seq</span>(<span class="dv">100</span>, <span class="dv">300</span>, <span class="dv">100</span>), <span class="dt">stealth=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.5</span>))</a>
<a class="sourceLine" id="cb773-2" data-line-number="2">ss5 =<span class="st"> </span><span class="kw">expand_grid</span>(<span class="dt">speed=</span><span class="kw">seq</span>(<span class="dv">100</span>, <span class="dv">300</span>, <span class="dv">50</span>), <span class="dt">stealth=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.25</span>))</a>
<a class="sourceLine" id="cb773-3" data-line-number="3">ss10=<span class="st"> </span><span class="kw">expand_grid</span>(<span class="dt">speed=</span><span class="kw">seq</span>(<span class="dv">100</span>, <span class="dv">300</span>, <span class="dv">20</span>), <span class="dt">stealth=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>))</a>
<a class="sourceLine" id="cb773-4" data-line-number="4"></a>
<a class="sourceLine" id="cb773-5" data-line-number="5">get_plot =<span class="st"> </span><span class="cf">function</span>(df){</a>
<a class="sourceLine" id="cb773-6" data-line-number="6">  <span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb773-7" data-line-number="7"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> df, <span class="dt">x=</span><span class="op">~</span>speed, <span class="dt">y=</span><span class="op">~</span>stealth, <span class="dt">type=</span><span class="st">&#39;scatter&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, </a>
<a class="sourceLine" id="cb773-8" data-line-number="8">            <span class="dt">marker=</span><span class="kw">list</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">size=</span><span class="dv">5</span>), <span class="dt">showlegend=</span><span class="ot">FALSE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb773-9" data-line-number="9"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">x=</span><span class="dv">261</span>, <span class="dt">y=</span><span class="fl">0.81</span>, <span class="dt">type=</span><span class="st">&#39;scatter&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, </a>
<a class="sourceLine" id="cb773-10" data-line-number="10">            <span class="dt">marker=</span><span class="kw">list</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="dv">5</span>), <span class="dt">showlegend=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb773-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb773-12" data-line-number="12"></a>
<a class="sourceLine" id="cb773-13" data-line-number="13">f1 =<span class="st"> </span><span class="kw">get_plot</span>(ss3)</a>
<a class="sourceLine" id="cb773-14" data-line-number="14">f2 =<span class="st"> </span><span class="kw">get_plot</span>(ss5)</a>
<a class="sourceLine" id="cb773-15" data-line-number="15">f3 =<span class="st"> </span><span class="kw">get_plot</span>(ss10)</a>
<a class="sourceLine" id="cb773-16" data-line-number="16"></a>
<a class="sourceLine" id="cb773-17" data-line-number="17"><span class="kw">subplot</span>(f1, f2, f3, <span class="dt">heights=</span><span class="fl">0.5</span>, <span class="dt">shareY =</span> <span class="ot">TRUE</span>, <span class="dt">shareX=</span><span class="ot">TRUE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb773-18" data-line-number="18"><span class="st">  </span><span class="kw">layout</span>(<span class="dt">xaxis=</span><span class="kw">list</span>(<span class="dt">zeroline=</span>F), <span class="dt">yaxis=</span><span class="kw">list</span>(<span class="dt">zeroline=</span>F))</a></code></pre></div>
<div id="htmlwidget-0f3baac357ad0b7a1813" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-0f3baac357ad0b7a1813">{"x":{"data":[{"x":[100,100,100,200,200,200,300,300,300],"y":[0,0.5,1,0,0.5,1,0,0.5,1],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(31,119,180,1)"}},"showlegend":false,"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(255,127,14,1)"}},"showlegend":false,"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[100,100,100,100,100,150,150,150,150,150,200,200,200,200,200,250,250,250,250,250,300,300,300,300,300],"y":[0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(44,160,44,1)"}},"showlegend":false,"error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"line":{"color":"rgba(44,160,44,1)"},"xaxis":"x2","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(214,39,40,1)"}},"showlegend":false,"error_y":{"color":"rgba(214,39,40,1)"},"error_x":{"color":"rgba(214,39,40,1)"},"line":{"color":"rgba(214,39,40,1)"},"xaxis":"x2","yaxis":"y","frame":null},{"x":[100,100,100,100,100,100,100,100,100,100,100,120,120,120,120,120,120,120,120,120,120,120,140,140,140,140,140,140,140,140,140,140,140,160,160,160,160,160,160,160,160,160,160,160,180,180,180,180,180,180,180,180,180,180,180,200,200,200,200,200,200,200,200,200,200,200,220,220,220,220,220,220,220,220,220,220,220,240,240,240,240,240,240,240,240,240,240,240,260,260,260,260,260,260,260,260,260,260,260,280,280,280,280,280,280,280,280,280,280,280,300,300,300,300,300,300,300,300,300,300,300],"y":[0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(148,103,189,1)"}},"showlegend":false,"error_y":{"color":"rgba(148,103,189,1)"},"error_x":{"color":"rgba(148,103,189,1)"},"line":{"color":"rgba(148,103,189,1)"},"xaxis":"x3","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(140,86,75,1)"}},"showlegend":false,"error_y":{"color":"rgba(140,86,75,1)"},"error_x":{"color":"rgba(140,86,75,1)"},"line":{"color":"rgba(140,86,75,1)"},"xaxis":"x3","yaxis":"y","frame":null}],"layout":{"xaxis":{"domain":[0,0.3133333333333333],"automargin":true,"title":"speed","anchor":"y","zeroline":false},"xaxis2":{"domain":[0.35333333333333333,0.64666666666666661],"automargin":true,"title":"speed","anchor":"y"},"xaxis3":{"domain":[0.68666666666666665,1],"automargin":true,"title":"speed","anchor":"y"},"yaxis":{"domain":[0.25,0.75],"automargin":true,"title":"stealth","anchor":"x","zeroline":false},"annotations":[],"shapes":[],"images":[],"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"attrs":{"8cf6fd0f1b9":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf6fd0f1b9.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true},"8cf54bc589d":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf54bc589d.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true},"8cf3aabbcf1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf3aabbcf1.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true}},"source":"A","config":{"showSendToCloud":false},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"subplot":true,"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>If we were to use the designs that generated for the above three plots in a simulation, then we could measure the response variable for each factor value combination to produce the following three response surfaces.</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb774-1" data-line-number="1">get_kills =<span class="st"> </span><span class="cf">function</span>(df){</a>
<a class="sourceLine" id="cb774-2" data-line-number="2">  df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">kills =</span> <span class="kw">case_when</span>(</a>
<a class="sourceLine" id="cb774-3" data-line-number="3">  stealth<span class="op">&lt;=</span><span class="fl">0.81</span> <span class="op">&amp;</span><span class="st"> </span>speed<span class="op">&lt;=</span><span class="dv">261</span> <span class="op">~</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span>stealth <span class="op">+</span><span class="st"> </span>speed<span class="op">/</span><span class="dv">100</span>, </a>
<a class="sourceLine" id="cb774-4" data-line-number="4">  stealth<span class="op">&lt;=</span><span class="fl">0.81</span> <span class="op">&amp;</span><span class="st"> </span>speed<span class="op">&gt;</span><span class="dv">261</span> <span class="op">~</span><span class="dv">600</span><span class="op">/</span>speed,</a>
<a class="sourceLine" id="cb774-5" data-line-number="5">  stealth<span class="op">&gt;</span><span class="fl">0.81</span> <span class="op">&amp;</span><span class="st"> </span>speed<span class="op">&gt;</span><span class="dv">261</span> <span class="op">~</span><span class="st"> </span>stealth<span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">400</span><span class="op">/</span>speed,</a>
<a class="sourceLine" id="cb774-6" data-line-number="6">  stealth<span class="op">&gt;</span><span class="fl">0.81</span> <span class="op">&amp;</span><span class="st"> </span>speed<span class="op">&lt;</span><span class="dv">261</span> <span class="op">~</span><span class="st"> </span>stealth<span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>speed<span class="op">/</span><span class="dv">100</span>))</a>
<a class="sourceLine" id="cb774-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb774-8" data-line-number="8"></a>
<a class="sourceLine" id="cb774-9" data-line-number="9">ss3 =<span class="st"> </span><span class="kw">get_kills</span>(ss3)</a>
<a class="sourceLine" id="cb774-10" data-line-number="10">ss5 =<span class="st"> </span><span class="kw">get_kills</span>(ss5)</a>
<a class="sourceLine" id="cb774-11" data-line-number="11">ss10 =<span class="st"> </span><span class="kw">get_kills</span>(ss10)</a>
<a class="sourceLine" id="cb774-12" data-line-number="12"></a>
<a class="sourceLine" id="cb774-13" data-line-number="13">get_contours =<span class="st"> </span><span class="cf">function</span>(df){</a>
<a class="sourceLine" id="cb774-14" data-line-number="14">  <span class="kw">plot_ly</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb774-15" data-line-number="15"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> df, <span class="dt">x=</span><span class="op">~</span>speed, <span class="dt">y=</span><span class="op">~</span>stealth, <span class="dt">z=</span><span class="op">~</span>kills, <span class="dt">type =</span> <span class="st">&quot;contour&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb774-16" data-line-number="16"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">data =</span> df, <span class="dt">x=</span><span class="op">~</span>speed, <span class="dt">y=</span><span class="op">~</span>stealth, <span class="dt">type=</span><span class="st">&#39;scatter&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, </a>
<a class="sourceLine" id="cb774-17" data-line-number="17">            <span class="dt">marker=</span><span class="kw">list</span>(<span class="dt">color=</span><span class="st">&#39;black&#39;</span>, <span class="dt">size=</span><span class="dv">5</span>), <span class="dt">showlegend=</span><span class="ot">FALSE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb774-18" data-line-number="18"><span class="st">  </span><span class="kw">add_trace</span>(<span class="dt">x=</span><span class="dv">261</span>, <span class="dt">y=</span><span class="fl">0.81</span>, <span class="dt">type=</span><span class="st">&#39;scatter&#39;</span>, <span class="dt">mode=</span><span class="st">&#39;markers&#39;</span>, </a>
<a class="sourceLine" id="cb774-19" data-line-number="19">            <span class="dt">marker=</span><span class="kw">list</span>(<span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="dv">5</span>), <span class="dt">showlegend=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb774-20" data-line-number="20">}</a>
<a class="sourceLine" id="cb774-21" data-line-number="21"></a>
<a class="sourceLine" id="cb774-22" data-line-number="22">f1 =<span class="st"> </span><span class="kw">get_contours</span>(ss3)</a>
<a class="sourceLine" id="cb774-23" data-line-number="23">f2 =<span class="st"> </span><span class="kw">get_contours</span>(ss5)</a>
<a class="sourceLine" id="cb774-24" data-line-number="24">f3 =<span class="st"> </span><span class="kw">get_contours</span>(ss10)</a>
<a class="sourceLine" id="cb774-25" data-line-number="25"></a>
<a class="sourceLine" id="cb774-26" data-line-number="26"><span class="kw">subplot</span>(f1, f2, f3, <span class="dt">heights=</span><span class="fl">0.5</span>, <span class="dt">shareY =</span> <span class="ot">TRUE</span>, <span class="dt">shareX=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<div id="htmlwidget-b4a51201e81ed4da5cec" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-b4a51201e81ed4da5cec">{"x":{"data":[{"colorbar":{"title":"kills","ticklen":2,"len":0.25,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[100,100,100,200,200,200,300,300,300],"y":[0,0.5,1,0,0.5,1,0,0.5,1],"z":[1,2.5,1.5,2,3.5,2.5,2,2,1.8333333333333333],"type":"contour","line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[100,100,100,200,200,200,300,300,300],"y":[0,0.5,1,0,0.5,1,0,0.5,1],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(255,127,14,1)"}},"showlegend":false,"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(44,160,44,1)"}},"showlegend":false,"error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"line":{"color":"rgba(44,160,44,1)"},"xaxis":"x","yaxis":"y","frame":null},{"colorbar":{"title":"kills","ticklen":2,"len":0.25,"lenmode":"fraction","y":0.75,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[100,100,100,100,100,150,150,150,150,150,200,200,200,200,200,250,250,250,250,250,300,300,300,300,300],"y":[0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1],"z":[1,1.75,2.5,3.25,1.5,1.5,2.25,3,3.75,2,2,2.75,3.5,4.25,2.5,2.5,3.25,4,4.75,3,2,2,2,2,1.8333333333333333],"type":"contour","line":{"color":"rgba(214,39,40,1)"},"xaxis":"x2","yaxis":"y","frame":null},{"x":[100,100,100,100,100,150,150,150,150,150,200,200,200,200,200,250,250,250,250,250,300,300,300,300,300],"y":[0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1,0,0.25,0.5,0.75,1],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(148,103,189,1)"}},"showlegend":false,"error_y":{"color":"rgba(148,103,189,1)"},"error_x":{"color":"rgba(148,103,189,1)"},"line":{"color":"rgba(148,103,189,1)"},"xaxis":"x2","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(140,86,75,1)"}},"showlegend":false,"error_y":{"color":"rgba(140,86,75,1)"},"error_x":{"color":"rgba(140,86,75,1)"},"line":{"color":"rgba(140,86,75,1)"},"xaxis":"x2","yaxis":"y","frame":null},{"colorbar":{"title":"kills","ticklen":2,"len":0.25,"lenmode":"fraction","y":0.5,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[100,100,100,100,100,100,100,100,100,100,100,120,120,120,120,120,120,120,120,120,120,120,140,140,140,140,140,140,140,140,140,140,140,160,160,160,160,160,160,160,160,160,160,160,180,180,180,180,180,180,180,180,180,180,180,200,200,200,200,200,200,200,200,200,200,200,220,220,220,220,220,220,220,220,220,220,220,240,240,240,240,240,240,240,240,240,240,240,260,260,260,260,260,260,260,260,260,260,260,280,280,280,280,280,280,280,280,280,280,280,300,300,300,300,300,300,300,300,300,300,300],"y":[0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1],"z":[1,1.3,1.6000000000000001,1.9000000000000001,2.2000000000000002,2.5,2.8000000000000003,3.1000000000000001,3.4000000000000004,1.45,1.5,1.2,1.5,1.8,2.1000000000000001,2.4000000000000004,2.7000000000000002,3,3.2999999999999998,3.6000000000000005,1.6499999999999999,1.7,1.3999999999999999,1.7,2,2.2999999999999998,2.6000000000000001,2.8999999999999999,3.2000000000000002,3.5,3.8000000000000003,1.8499999999999999,1.8999999999999999,1.6000000000000001,1.9000000000000001,2.2000000000000002,2.5,2.8000000000000003,3.1000000000000001,3.4000000000000004,3.7000000000000002,4,2.0500000000000003,2.1000000000000001,1.8,2.1000000000000001,2.4000000000000004,2.7000000000000002,3,3.2999999999999998,3.6000000000000005,3.9000000000000004,4.2000000000000002,2.25,2.2999999999999998,2,2.2999999999999998,2.6000000000000001,2.9000000000000004,3.2000000000000002,3.5,3.8000000000000003,4.0999999999999996,4.4000000000000004,2.4500000000000002,2.5,2.2000000000000002,2.5,2.8000000000000003,3.1000000000000005,3.4000000000000004,3.7000000000000002,4,4.3000000000000007,4.6000000000000005,2.6500000000000004,2.7000000000000002,2.3999999999999999,2.7000000000000002,3,3.2999999999999998,3.6000000000000001,3.8999999999999999,4.2000000000000002,4.5,4.8000000000000007,2.8500000000000001,2.8999999999999999,2.6000000000000001,2.9000000000000004,3.2000000000000002,3.5,3.8000000000000003,4.0999999999999996,4.4000000000000004,4.7000000000000002,5,3.0500000000000003,3.1000000000000001,2.1428571428571428,2.1428571428571428,2.1428571428571428,2.1428571428571428,2.1428571428571428,2.1428571428571428,2.1428571428571428,2.1428571428571428,2.1428571428571428,1.8785714285714286,1.9285714285714286,2,2,2,2,2,2,2,2,2,1.7833333333333332,1.8333333333333333],"type":"contour","line":{"color":"rgba(227,119,194,1)"},"xaxis":"x3","yaxis":"y","frame":null},{"x":[100,100,100,100,100,100,100,100,100,100,100,120,120,120,120,120,120,120,120,120,120,120,140,140,140,140,140,140,140,140,140,140,140,160,160,160,160,160,160,160,160,160,160,160,180,180,180,180,180,180,180,180,180,180,180,200,200,200,200,200,200,200,200,200,200,200,220,220,220,220,220,220,220,220,220,220,220,240,240,240,240,240,240,240,240,240,240,240,260,260,260,260,260,260,260,260,260,260,260,280,280,280,280,280,280,280,280,280,280,280,300,300,300,300,300,300,300,300,300,300,300],"y":[0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1,0,0.10000000000000001,0.20000000000000001,0.30000000000000004,0.40000000000000002,0.5,0.60000000000000009,0.70000000000000007,0.80000000000000004,0.90000000000000002,1],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(127,127,127,1)"}},"showlegend":false,"error_y":{"color":"rgba(127,127,127,1)"},"error_x":{"color":"rgba(127,127,127,1)"},"line":{"color":"rgba(127,127,127,1)"},"xaxis":"x3","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(188,189,34,1)"}},"showlegend":false,"error_y":{"color":"rgba(188,189,34,1)"},"error_x":{"color":"rgba(188,189,34,1)"},"line":{"color":"rgba(188,189,34,1)"},"xaxis":"x3","yaxis":"y","frame":null}],"layout":{"xaxis":{"domain":[0,0.3133333333333333],"automargin":true,"title":"speed","anchor":"y"},"xaxis2":{"domain":[0.35333333333333333,0.64666666666666661],"automargin":true,"title":"speed","anchor":"y"},"xaxis3":{"domain":[0.68666666666666665,1],"automargin":true,"title":"speed","anchor":"y"},"yaxis":{"domain":[0.25,0.75],"automargin":true,"title":"stealth","anchor":"x"},"annotations":[],"shapes":[],"images":[],"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"zaxis":{"title":"kills"}},"hovermode":"closest","showlegend":true,"legend":{"yanchor":"top","y":0.25}},"attrs":{"8cf4a5c5178":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"contour","inherit":true},"8cf6729ffcf":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf6729ffcf.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true},"8cf5373e46e":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"contour","inherit":true},"8cf29a6375d":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf29a6375d.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true},"8cf3174aa54":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"contour","inherit":true},"8cf560f58aa":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf560f58aa.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true}},"source":"A","config":{"showSendToCloud":false},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"subplot":true,"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Given the above three plots, if you didn’t know the true optimal values for speed and stealth, clearly the plot on the right with the best space-filling properties provides the best estimates. To determine the optimal values from the plot, we simply find the speed and stealth values that result in the maximum number of kills, which appears to be approximately speed = 220 and stealth = 0.70. The 2D contour plot on the right can also be plotted as a 3D surface, as shown below.</p>
<div class="sourceCode" id="cb775"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb775-1" data-line-number="1">killz =<span class="st"> </span><span class="kw">as.matrix</span>(ss10 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> speed, <span class="dt">values_from =</span> kills))</a>
<a class="sourceLine" id="cb775-2" data-line-number="2"></a>
<a class="sourceLine" id="cb775-3" data-line-number="3"><span class="kw">plot_ly</span>(<span class="dt">z=</span><span class="op">~</span>killz) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb775-4" data-line-number="4"><span class="st">  </span><span class="kw">add_surface</span>(<span class="dt">contours =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb775-5" data-line-number="5">    <span class="dt">z =</span> <span class="kw">list</span>(<span class="dt">show =</span> <span class="ot">TRUE</span>)), <span class="dt">z =</span> <span class="op">~</span>killz) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb775-6" data-line-number="6"><span class="st">  </span><span class="kw">layout</span>(</a>
<a class="sourceLine" id="cb775-7" data-line-number="7">    <span class="dt">title =</span> <span class="st">&quot;3D Response Surface&quot;</span>,</a>
<a class="sourceLine" id="cb775-8" data-line-number="8">    <span class="dt">scene =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb775-9" data-line-number="9">      <span class="dt">xaxis =</span> <span class="kw">list</span>(<span class="dt">title =</span> <span class="st">&quot;Speed&quot;</span>),</a>
<a class="sourceLine" id="cb775-10" data-line-number="10">      <span class="dt">yaxis =</span> <span class="kw">list</span>(<span class="dt">title =</span> <span class="st">&quot;Stealth&quot;</span>),</a>
<a class="sourceLine" id="cb775-11" data-line-number="11">      <span class="dt">zaxis =</span> <span class="kw">list</span>(<span class="dt">title =</span> <span class="st">&quot;Kills&quot;</span>, <span class="dt">nticks=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb775-12" data-line-number="12">    ))</a></code></pre></div>
<div id="htmlwidget-91022fc7d7ca7d7b346b" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-91022fc7d7ca7d7b346b">{"x":{"visdat":{"8cf7faa327e":["function () ","plotlyVisDat"]},"cur_data":"8cf7faa327e","attrs":{"8cf7faa327e":{"z":{},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"surface","contours":{"z":{"show":true}},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"3D Response Surface","scene":{"xaxis":{"title":"Speed"},"yaxis":{"title":"Stealth"},"zaxis":{"title":"Kills","nticks":10}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"showSendToCloud":false},"data":[{"colorbar":{"title":"killz","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"z":[[0,1,1.2,1.3999999999999999,1.6000000000000001,1.8,2,2.2000000000000002,2.3999999999999999,2.6000000000000001,2.1428571428571428,2],[0.10000000000000001,1.3,1.5,1.7,1.9000000000000001,2.1000000000000001,2.2999999999999998,2.5,2.7000000000000002,2.9000000000000004,2.1428571428571428,2],[0.20000000000000001,1.6000000000000001,1.8,2,2.2000000000000002,2.4000000000000004,2.6000000000000001,2.8000000000000003,3,3.2000000000000002,2.1428571428571428,2],[0.30000000000000004,1.9000000000000001,2.1000000000000001,2.2999999999999998,2.5,2.7000000000000002,2.9000000000000004,3.1000000000000005,3.2999999999999998,3.5,2.1428571428571428,2],[0.40000000000000002,2.2000000000000002,2.4000000000000004,2.6000000000000001,2.8000000000000003,3,3.2000000000000002,3.4000000000000004,3.6000000000000001,3.8000000000000003,2.1428571428571428,2],[0.5,2.5,2.7000000000000002,2.8999999999999999,3.1000000000000001,3.2999999999999998,3.5,3.7000000000000002,3.8999999999999999,4.0999999999999996,2.1428571428571428,2],[0.60000000000000009,2.8000000000000003,3,3.2000000000000002,3.4000000000000004,3.6000000000000005,3.8000000000000003,4,4.2000000000000002,4.4000000000000004,2.1428571428571428,2],[0.70000000000000007,3.1000000000000001,3.2999999999999998,3.5,3.7000000000000002,3.9000000000000004,4.0999999999999996,4.3000000000000007,4.5,4.7000000000000002,2.1428571428571428,2],[0.80000000000000004,3.4000000000000004,3.6000000000000005,3.8000000000000003,4,4.2000000000000002,4.4000000000000004,4.6000000000000005,4.8000000000000007,5,2.1428571428571428,2],[0.90000000000000002,1.45,1.6499999999999999,1.8499999999999999,2.0500000000000003,2.25,2.4500000000000002,2.6500000000000004,2.8500000000000001,3.0500000000000003,1.8785714285714286,1.7833333333333332],[1,1.5,1.7,1.8999999999999999,2.1000000000000001,2.2999999999999998,2.5,2.7000000000000002,2.8999999999999999,3.1000000000000001,1.9285714285714286,1.8333333333333333]],"type":"surface","contours":{"z":{"show":true}},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>The designs for the plots above are gridded designs, which we’ve demonstrated to be inefficient. Therefore, we’ll replace the gridded design with a spherical CCD.</p>
<p>When creating the design matrix with the <code>rsm</code> functions, we can convert the default factor codings into the ranges we’re interested in using the formulas shown in the following code chunk. We set the ranges of the factor levels using the <code>coding</code> parameter. The formula <code>(speed-200)/100</code> centers the <code>speed</code> factor on 200 and varies it by +/- 100.</p>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb776-1" data-line-number="1">helo =<span class="st"> </span><span class="kw">cube</span>(<span class="dv">3</span>,                        <span class="co"># 3 factors</span></a>
<a class="sourceLine" id="cb776-2" data-line-number="2">            <span class="dt">n0=</span><span class="dv">0</span>,                     <span class="co"># no center point to the cube</span></a>
<a class="sourceLine" id="cb776-3" data-line-number="3">            <span class="dt">inscribed=</span><span class="ot">TRUE</span>,           <span class="co"># required when using alpha=&quot;spherical&quot;</span></a>
<a class="sourceLine" id="cb776-4" data-line-number="4">            <span class="dt">coding =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb776-5" data-line-number="5">              x1<span class="op">~</span>(speed<span class="dv">-200</span>)<span class="op">/</span><span class="dv">100</span>,     <span class="co"># center on 200 and vary by 100</span></a>
<a class="sourceLine" id="cb776-6" data-line-number="6">              x2<span class="op">~</span>(stealth<span class="fl">-0.5</span>)<span class="op">/</span><span class="fl">0.5</span>,   <span class="co"># center on 0.5 and vary by 0.5</span></a>
<a class="sourceLine" id="cb776-7" data-line-number="7">              x3<span class="op">~</span>(sensor<span class="dv">-10</span>)<span class="op">/</span><span class="dv">5</span>))      <span class="co"># center on 10 and vary by 5</span></a>
<a class="sourceLine" id="cb776-8" data-line-number="8">helo =<span class="st"> </span><span class="kw">djoin</span>(helo,                    <span class="co"># join the cube with the star points</span></a>
<a class="sourceLine" id="cb776-9" data-line-number="9">             <span class="kw">star</span>(<span class="dt">alpha=</span><span class="st">&quot;spherical&quot;</span>,  <span class="co"># brings corner points in</span></a>
<a class="sourceLine" id="cb776-10" data-line-number="10">                  <span class="dt">n0=</span><span class="dv">1</span>))              <span class="co"># add a center point to the star</span></a>
<a class="sourceLine" id="cb776-11" data-line-number="11">helo</a></code></pre></div>
<pre><code>##    run.order std.order   speed   stealth    sensor Block
## 1          1         7 142.265 0.7886751 12.886751     1
## 2          2         2 257.735 0.2113249  7.113249     1
## 3          3         6 257.735 0.2113249 12.886751     1
## 4          4         5 142.265 0.2113249 12.886751     1
## 5          5         1 142.265 0.2113249  7.113249     1
## 6          6         4 257.735 0.7886751  7.113249     1
## 7          7         8 257.735 0.7886751 12.886751     1
## 8          8         3 142.265 0.7886751  7.113249     1
## 9          1         7 200.000 0.5000000 10.000000     2
## 10         2         1 100.000 0.5000000 10.000000     2
## 11         3         5 200.000 0.5000000  5.000000     2
## 12         4         4 200.000 1.0000000 10.000000     2
## 13         5         2 300.000 0.5000000 10.000000     2
## 14         6         3 200.000 0.0000000 10.000000     2
## 15         7         6 200.000 0.5000000 15.000000     2
## 
## Data are stored in coded form using these coding formulas ...
## x1 ~ (speed - 200)/100
## x2 ~ (stealth - 0.5)/0.5
## x3 ~ (sensor - 10)/5</code></pre>
<p>Oddly (to me, anyway), this doesn’t preserve the factor names and coded values as shown above. For example, <code>helo$speed</code> doesn’t exist.</p>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb778-1" data-line-number="1">helo<span class="op">$</span>speed    <span class="co"># doesn&#39;t exist</span></a></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb780-1" data-line-number="1"><span class="kw">names</span>(helo)   <span class="co"># what does exist?</span></a></code></pre></div>
<pre><code>## [1] &quot;run.order&quot; &quot;std.order&quot; &quot;x1&quot;        &quot;x2&quot;        &quot;x3&quot;        &quot;Block&quot;</code></pre>
<p>To get the factor names and coded values, we must use <code>decode.data()</code> as shown.</p>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb782-1" data-line-number="1">helo_coded =<span class="st"> </span><span class="kw">decode.data</span>(helo)</a>
<a class="sourceLine" id="cb782-2" data-line-number="2"></a>
<a class="sourceLine" id="cb782-3" data-line-number="3"><span class="kw">names</span>(helo_coded)</a></code></pre></div>
<pre><code>## [1] &quot;run.order&quot; &quot;std.order&quot; &quot;speed&quot;     &quot;stealth&quot;   &quot;sensor&quot;    &quot;Block&quot;</code></pre>
<p>Now we get the number of kills based on our design and plot it.</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb784-1" data-line-number="1">ccd_results =<span class="st"> </span><span class="kw">get_kills</span>(helo_coded)</a>
<a class="sourceLine" id="cb784-2" data-line-number="2"></a>
<a class="sourceLine" id="cb784-3" data-line-number="3"><span class="kw">get_contours</span>(ccd_results) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">layout</span>(<span class="dt">title =</span> <span class="st">&quot;CCD Response Surface&quot;</span>)</a></code></pre></div>
<div id="htmlwidget-a934675b758ed5dbb339" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-a934675b758ed5dbb339">{"x":{"visdat":{"8cf2e08d60a":["function () ","plotlyVisDat"],"8cf669efb73":["function () ","data"],"8cf2a94be37":["function () ","data"]},"cur_data":"8cf2a94be37","attrs":{"8cf669efb73":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"contour","inherit":true},"8cf2a94be37":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"type":"scatter","mode":"markers","marker":{"color":"black","size":5},"showlegend":false,"inherit":true},"8cf2a94be37.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":261,"y":0.81000000000000005,"type":"scatter","mode":"markers","marker":{"color":"red","size":5},"showlegend":false,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"CCD Response Surface","xaxis":{"domain":[0,1],"automargin":true,"title":"speed"},"yaxis":{"domain":[0,1],"automargin":true,"title":"stealth"},"scene":{"zaxis":{"title":"kills"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"showSendToCloud":false},"data":[{"colorbar":{"title":"kills","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333334","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[142.26497308103743,257.7350269189626,257.7350269189626,142.26497308103743,142.26497308103743,257.7350269189626,257.7350269189626,142.26497308103743,200,100,200,200,300,200,200],"y":[0.78867513459481287,0.21132486540518708,0.21132486540518708,0.21132486540518708,0.21132486540518708,0.78867513459481287,0.78867513459481287,0.78867513459481287,0.5,0.5,0.5,1,0.5,0,0.5],"z":[3.7886751345948126,3.2113248654051874,3.2113248654051874,2.0566243270259355,2.0566243270259355,4.9433756729740645,4.9433756729740645,3.7886751345948126,3.5,2.5,3.5,2.5,2,2,3.5],"type":"contour","line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[142.26497308103743,257.7350269189626,257.7350269189626,142.26497308103743,142.26497308103743,257.7350269189626,257.7350269189626,142.26497308103743,200,100,200,200,300,200,200],"y":[0.78867513459481287,0.21132486540518708,0.21132486540518708,0.21132486540518708,0.21132486540518708,0.78867513459481287,0.78867513459481287,0.78867513459481287,0.5,0.5,0.5,1,0.5,0,0.5],"type":"scatter","mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(255,127,14,1)"}},"showlegend":false,"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[261],"y":[0.81000000000000005],"type":"scatter","mode":"markers","marker":{"color":"red","size":5,"line":{"color":"rgba(44,160,44,1)"}},"showlegend":false,"error_y":{"color":"rgba(44,160,44,1)"},"error_x":{"color":"rgba(44,160,44,1)"},"line":{"color":"rgba(44,160,44,1)"},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<div id="ccd-problem-set" class="section level3">
<h3><span class="header-section-number">10.4.1</span> CCD Problem Set</h3>
<p>The problem set for this section is located <a href = "/_Chapter10_ProblemSets/CCD_ProblemSet_Questions.html">here</a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = "/_Chapter10_ProblemSets/CCD_ProblemSet_Questions.Rmd">here</a>.</p>
<p>The solutions for this problem set is located <a href = "/_Chapter10_ProblemSets/CCD_ProblemSet_Solutions.html">here</a>.</p>
</div>
</div>
<div id="nearly-orthogonal-latin-hypercube-designs" class="section level2">
<h2><span class="header-section-number">10.5</span> Nearly Orthogonal Latin Hypercube Designs</h2>
<p>In the CCD section, we saw the benefit of the good space filling properties of gridded designs when using response surface methodology. A benefit of CCDs is that they are much more efficient than gridded designs; however, their space-filling properties are not as good. Latin hypercube-based designs combine the efficiency of CCDs with the space-filling properties of gridded designs. As such, they are well-suited for response surface methodology.</p>
<p>If we take a step back for a moment, how might we construct a design matrix that uniformly covers the range of the predictor variables? Why not just select randomly from uniform distributions? This is referred to as a <strong>random Latin hypercube</strong>.</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb785-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb785-2" data-line-number="2">dm =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb785-3" data-line-number="3">  <span class="dt">x1 =</span> <span class="kw">runif</span>(<span class="dv">10</span>),</a>
<a class="sourceLine" id="cb785-4" data-line-number="4">  <span class="dt">x2 =</span> <span class="kw">runif</span>(<span class="dv">10</span>),</a>
<a class="sourceLine" id="cb785-5" data-line-number="5">  <span class="dt">x3 =</span> <span class="kw">runif</span>(<span class="dv">10</span>),</a>
<a class="sourceLine" id="cb785-6" data-line-number="6">  <span class="dt">x4 =</span> <span class="kw">runif</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb785-7" data-line-number="7">)</a>
<a class="sourceLine" id="cb785-8" data-line-number="8"></a>
<a class="sourceLine" id="cb785-9" data-line-number="9"><span class="kw">pairs</span>(dm)</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>That’s not bad. We have a design matrix for 4 factors at 10 levels each, and we only needed 10 design points! However, if we take a closer look, we discover a significant issue.</p>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb786-1" data-line-number="1"><span class="kw">library</span>(GGally)</a>
<a class="sourceLine" id="cb786-2" data-line-number="2"></a>
<a class="sourceLine" id="cb786-3" data-line-number="3">smooth_fn &lt;-<span class="st"> </span><span class="cf">function</span>(data, mapping, ...){</a>
<a class="sourceLine" id="cb786-4" data-line-number="4">  <span class="kw">ggplot</span>(<span class="dt">data =</span> data, <span class="dt">mapping =</span> mapping) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb786-5" data-line-number="5"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb786-6" data-line-number="6"><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">formula =</span> y<span class="op">~</span>x, <span class="dt">method=</span>lm, <span class="dt">fill=</span><span class="st">&quot;red&quot;</span>, <span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, ...)</a>
<a class="sourceLine" id="cb786-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb786-8" data-line-number="8"></a>
<a class="sourceLine" id="cb786-9" data-line-number="9">GGally<span class="op">::</span><span class="kw">ggpairs</span>(dm, <span class="dt">lower=</span><span class="kw">list</span>(<span class="dt">continuous=</span>smooth_fn), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb786-10" data-line-number="10"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Random Latin Hypercube&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb786-11" data-line-number="11"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Even though we randomly selected the values, some factor combinations have a significant amount of correlation. <code>x2</code> and <code>x3</code> have a correlation of -0.411, for example. Also notice that factor combination doesn’t have any design points in the upper right corner. Orthogonal and nearly-orthogonal Latin hypercubes were developed to overcome this issue using optimization techniques that minimize correlations and maximize space-filling properties.</p>
<p>In this section, we’ll focus on the nearly orthogonal Latin hypercube (NOLH) designs developed by <a href = "http://hdl.handle.net/10945/9808">Cioppa</a> and <a href = "https://link.springer.com/article/10.1057/jos.2016.8">MacCalman</a>. Since NOLH designs efficiently accommodate a large number of factors, they are particularly useful for screening purposes. Excel-based tools for generating Cioppa’s and MacCalman’s designs are available to <a href = "https://nps.edu/web/seed/software-downloads">download</a> from the Naval Postgraduate School’s Simulation Experiments and Efficient Designs (SEED) center.</p>
<p>A few things to be aware of when considering these designs:</p>
<ul>
<li>Cioppa’s designs are <i>for continuous factors only</i>, although discrete factors can be included if the number of discrete values is at least nine or ten.</li>
<li>Each of Cioppa’s designs can accommodate <i>up to</i> the number of stated factors, so you can use fewer factors if needed. (e.g., the 17-point design can accommodate anywhere from 1 to 7 factors). However, <i>you cannot remove design points</i>.</li>
<li>Cioppa’s designs are not intended to be used to study quadratic effects or interactions. If you need to include these terms, use MacCalman’s designs instead.</li>
<li>MacCalman’s designs <i>can accommodate continuous, discrete, binary, and categorical variables</i>.</li>
<li>With MacCalman’s designs, you <i>can specify the number of design points</i>.</li>
<li>MacCalman’s designs <i>nearly guarantee that all first and second order terms are not confounded with others</i>. Second order effects include both two-way interactions and quadratic effects.</li>
</ul>
<div id="factor-codings" class="section level3">
<h3><span class="header-section-number">10.5.1</span> Factor Codings</h3>
<p>The tools for generating Cioppa’s and MacCalman’s designs provide a user interface for naming factors, setting minimum and maximum factor values, and specifying the number of decimal places. The Excel tools both generate the resulting design as a .csv file, which you can then read into <em>R</em> for further use. In my experience, generating a design matrix for a study can sometimes be an iterative process. This requires switching back and forth between Excel and <em>R</em> and generating a new .csv file for each change to the design, which can be somewhat time consuming. When creating designs using the Excel tool for MacCalman’s design, there’s no getting around this because of the stochastic processes contained within the tool. With Cioppa’s Excel file, however, the entire iterative process can be conducted in <em>R</em> by using the underlying factor codings.</p>
<p>Cioppa’s designs are the result of a Mixed Integer Program and therefore produce integer values (aka, factor codings) for each design point. The Excel tool then converts these integers into the ranges and significant figures specified by the user to generate a .csv file. This is a straight forward conversion that we can perform in an <em>R</em> script, so all we really need are the factor codings themselves to do everything in an <em>R</em> session.</p>
<p>Factor codings for Cioppa’s 17-point design are as follows:</p>
<div id="htmlwidget-d8a23164e9303d469eba" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-d8a23164e9303d469eba">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17"],[6,2,3,4,13,17,11,10,9,12,16,15,14,5,1,7,8],[17,5,8,11,16,6,4,15,9,1,13,10,7,2,12,14,3],[14,15,2,6,8,7,17,13,9,4,3,16,12,10,11,1,5],[7,10,5,17,3,14,6,16,9,11,8,13,1,15,4,12,2],[5,1,11,10,6,2,15,14,9,13,17,7,8,12,16,3,4],[16,6,14,3,1,13,8,11,9,2,12,4,15,17,5,10,7],[10,11,17,13,14,15,16,12,9,8,7,1,5,4,3,2,6]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>f4<\/th>\n      <th>f5<\/th>\n      <th>f7<\/th>\n      <th>f2<\/th>\n      <th>f3<\/th>\n      <th>f6<\/th>\n      <th>f1<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":17,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[10,17,25,50,100]},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<p>A pairs plot of factor codings for Cioppa’s 17-point design is shown below. Compare this plot with the pairs plot for the random Latin hypercube design.</p>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb787-1" data-line-number="1">GGally<span class="op">::</span><span class="kw">ggpairs</span>(dm17, <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> <span class="kw">wrap</span>(<span class="st">&quot;points&quot;</span>, <span class="dt">size=</span><span class="fl">0.1</span>)), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb787-2" data-line-number="2"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;OLH With 17 Design Points&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb787-3" data-line-number="3"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Next is Cioppa’s 257-point design. To reduce the size of the plot, just the first 7 of the possible 29 factors are shown. Note the improved space-filling properties compared to the 17-point design.</p>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb788-1" data-line-number="1"><span class="kw">ggpairs</span>(dm257 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>), <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> <span class="kw">wrap</span>(<span class="st">&quot;points&quot;</span>, <span class="dt">size=</span><span class="fl">0.1</span>)), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb788-2" data-line-number="2"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;NOLH With 257 Design Points&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb788-3" data-line-number="3"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
</div>
<div id="orthogonality-and-variance-inflation-factors" class="section level2">
<h2><span class="header-section-number">10.6</span> Orthogonality and Variance Inflation Factors</h2>
<p>Cioppa’s 17-point design is, in fact, strictly orthogonal, which we can confirm by calculating the dot product of each factor pair.</p>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb789-1" data-line-number="1"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>){</a>
<a class="sourceLine" id="cb789-2" data-line-number="2">  <span class="cf">for</span> (j <span class="cf">in</span> (i<span class="op">+</span><span class="dv">1</span>)<span class="op">:</span><span class="dv">7</span>){</a>
<a class="sourceLine" id="cb789-3" data-line-number="3">    <span class="kw">print</span>(dm17[[i]] <span class="op">%*%</span><span class="st"> </span>dm17[[j]])</a>
<a class="sourceLine" id="cb789-4" data-line-number="4">  }</a>
<a class="sourceLine" id="cb789-5" data-line-number="5">}</a></code></pre></div>
<pre><code>##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377
##      [,1]
## [1,] 1377</code></pre>
<p>We can also see that the pair-wise correlation coefficients are all zero.</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb791-1" data-line-number="1"><span class="kw">cor</span>(dm17)</a></code></pre></div>
<pre><code>##    f4 f5 f7 f2 f3 f6 f1
## f4  1  0  0  0  0  0  0
## f5  0  1  0  0  0  0  0
## f7  0  0  1  0  0  0  0
## f2  0  0  0  1  0  0  0
## f3  0  0  0  0  1  0  0
## f6  0  0  0  0  0  1  0
## f1  0  0  0  0  0  0  1</code></pre>
<p>A common method to check for multicollinearity in a design is to calculate the variance inflation factor (VIF) for each predictor. Penn State has a good <a href='https://online.stat.psu.edu/stat462/node/180/'> online resource </a> that describes VIF, which I’ll paraphrase. When multicollinearity exists, the standard errors of the estimated coefficients are inflated, which means the variances are also inflated. The VIF for the estimated regression coefficient <span class="math inline">\(\beta_i\)</span> is the amount the variance of <span class="math inline">\(\beta_i\)</span> is “inflated” by the existence of correlation among the predictor variables in the model. The VIF for the ith predictor is:</p>
<p><span class="math display">\[VIF_i = \frac{1}{1-R^{2}_{i}}\]</span></p>
<p>where <span class="math inline">\(R^{2}_{i}\)</span> is the <span class="math inline">\(R^2\)</span> obtained by regressing the ith predictor on the remaining predictors. If no multicollinearity exists, then each predictor’s VIF will equal 1. A rule of thumb is that a VIF above about 5 should be investigated, and a VIF above 10 indicates strong multicollinearity that should be corrected. In <em>R</em>, we can use the <code>vif()</code> function from the <code>faraway</code> package. With the 17-point design, we see that no multicollinearity exists.</p>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb793-1" data-line-number="1">faraway<span class="op">::</span><span class="kw">vif</span>(dm17)</a></code></pre></div>
<pre><code>## f4 f5 f7 f2 f3 f6 f1 
##  1  1  1  1  1  1  1</code></pre>
<p>Repeating the tests on the 257-point design, we see that not every column is exactly orthogonal. For example, these two dot products are not equal.</p>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb795-1" data-line-number="1">dm257<span class="op">$</span>f1 <span class="op">%*%</span><span class="st"> </span>dm257<span class="op">$</span>f17</a></code></pre></div>
<pre><code>##         [,1]
## [1,] 4274287</code></pre>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb797-1" data-line-number="1">dm257<span class="op">$</span>f2 <span class="op">%*%</span><span class="st"> </span>dm257<span class="op">$</span>f23</a></code></pre></div>
<pre><code>##         [,1]
## [1,] 4275511</code></pre>
<p>We also see that the correlation coefficients are slightly greater than zero. For example, the first four columns:</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb799-1" data-line-number="1"><span class="kw">cor</span>(dm257)[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]</a></code></pre></div>
<pre><code>##                f1            f2            f3            f4
## f1   1.000000e+00  0.0000000000  0.000000e+00  0.000000e+00
## f2   0.000000e+00  1.0000000000  0.000000e+00  0.000000e+00
## f3   0.000000e+00  0.0000000000  1.000000e+00  0.000000e+00
## f4   0.000000e+00  0.0000000000  0.000000e+00  1.000000e+00
## f5   0.000000e+00  0.0000000000  0.000000e+00  0.000000e+00
## f6   0.000000e+00  0.0000000000  0.000000e+00  0.000000e+00
## f7   0.000000e+00  0.0000000000  0.000000e+00  0.000000e+00
## f8   0.000000e+00  0.0000000000  0.000000e+00  0.000000e+00
## f9  -1.269681e-03  0.0010575966 -2.209924e-03  4.496199e-04
## f10 -1.384207e-03  0.0014831803  1.411071e-03 -1.272509e-05
## f11  1.286648e-04 -0.0009416569  1.286648e-04 -2.324450e-03
## f12 -3.152995e-04 -0.0016302258  1.969562e-03 -4.510338e-04
## f13 -8.638924e-04 -0.0005994933 -7.126052e-04 -1.852208e-03
## f14  1.573670e-03 -0.0012908900 -1.979459e-04  3.017261e-03
## f15  7.196747e-04 -0.0003124717  1.894625e-03 -8.780314e-04
## f16  1.823930e-04  0.0022141661  5.132454e-04 -2.323036e-03
## f17 -1.732027e-03  0.0010830468  7.210886e-05 -8.200615e-04
## f18 -8.907565e-04  0.0016061895 -5.980794e-04 -6.263573e-04
## f19 -9.063094e-04  0.0002757103  5.160732e-04  2.465840e-03
## f20 -2.813659e-04 -0.0007055357  8.214754e-04 -9.770043e-04
## f21 -7.069496e-06 -0.0005500068 -5.273844e-04  2.573297e-04
## f22  8.356144e-04  0.0011452583  1.531253e-03 -3.492331e-04
## f23 -3.803389e-04 -0.0008667202 -1.979459e-04 -5.528346e-04
## f24  6.207017e-04  0.0004086169 -5.655597e-04  4.001335e-04
## f25  1.241403e-03  0.0002403629  7.635056e-05 -6.150461e-04
## f26  1.173536e-04 -0.0003916501 -1.428038e-03 -5.245566e-04
## f27  1.320582e-03 -0.0001399760  1.172122e-03 -1.905936e-03
## f28  5.316261e-04 -0.0016443648  1.148086e-03  1.324824e-03
## f29  5.104176e-04 -0.0006207017 -1.527011e-04  5.217288e-04</code></pre>
<p>The VIF for each predictor is also slightly greater than one. Notice that the VIFs are nowhere near our rule of thumb values.</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb801-1" data-line-number="1">faraway<span class="op">::</span><span class="kw">vif</span>(dm257)</a></code></pre></div>
<pre><code>##       f1       f2       f3       f4       f5       f6       f7       f8 
## 1.000017 1.000024 1.000024 1.000040 1.000013 1.000033 1.000028 1.000017 
##       f9      f10      f11      f12      f13      f14      f15      f16 
## 1.000064 1.000049 1.000030 1.000033 1.000038 1.000039 1.000026 1.000060 
##      f17      f18      f19      f20      f21      f22      f23      f24 
## 1.000062 1.000056 1.000037 1.000039 1.000027 1.000040 1.000029 1.000027 
##      f25      f26      f27      f28      f29 
## 1.000024 1.000034 1.000050 1.000030 1.000042</code></pre>
<p>Of Cioppa’s designs, only the 17-point design is strictly orthogonal. Why is that? The short answer is that he needed to slightly relax the orthogonality requirement in the mixed integer program that generated the larger designs, hence the term “nearly orthogonal”. For the long answer, read his Ph.D. dissertation at the link provided earlier. MacCalman took the same approach, so designs from his Excel tool are also nearly orthogonal.</p>
</div>
<div id="shifting-and-stacking" class="section level2">
<h2><span class="header-section-number">10.7</span> Shifting and Stacking</h2>
<p>Say we have a design matrix with a relatively small number of factors, in this case four. A 17-point OLH could easily accommodate just four factors, but what if we have the time and resources available for more than 17 runs? We wouldn’t want to just replicate the 17-point design as is because if we’re going to do more runs, we might as well improve the space-filling properties of the design. There are two common approaches in this situation. First, we can select a design that accommodates more factors than necessary and just keep the four factors that we need. For example, the 17-point design:</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb803-1" data-line-number="1"><span class="kw">ggpairs</span>(dm17 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>), <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> <span class="kw">wrap</span>(<span class="st">&quot;points&quot;</span>, <span class="dt">size=</span><span class="fl">0.1</span>)), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb803-2" data-line-number="2"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;NOLH With 17 Design Points&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb803-3" data-line-number="3"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Compare that to four factors from the 257-point design.</p>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb804-1" data-line-number="1"><span class="kw">ggpairs</span>(dm257 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>), <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> <span class="kw">wrap</span>(<span class="st">&quot;points&quot;</span>, <span class="dt">size=</span><span class="fl">0.1</span>)), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb804-2" data-line-number="2"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;NOLH With 257 Design Points&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb804-3" data-line-number="3"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>Another technique is to apply shifting and stacking to a base design. Starting with the 17-point design, we make a copy of the design, move the last column to the first column and <strong>shift</strong> the other columns to the right. Then we <strong>stack</strong> the original design on top of the shifted design.</p>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb805-1" data-line-number="1">original_dm =<span class="st"> </span>dm17 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(f1, f2, f3, f4) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">design=</span><span class="st">&quot;original&quot;</span>)</a>
<a class="sourceLine" id="cb805-2" data-line-number="2"></a>
<a class="sourceLine" id="cb805-3" data-line-number="3">shifted_dm =<span class="st"> </span>dm17 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(f4, f1, f2, f3) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">design=</span><span class="st">&quot;shifted&quot;</span>)</a>
<a class="sourceLine" id="cb805-4" data-line-number="4"><span class="kw">colnames</span>(shifted_dm) =<span class="st"> </span><span class="kw">colnames</span>(original_dm)</a>
<a class="sourceLine" id="cb805-5" data-line-number="5"></a>
<a class="sourceLine" id="cb805-6" data-line-number="6">stacked_dm =<span class="st"> </span><span class="kw">bind_rows</span>(original_dm, shifted_dm)</a>
<a class="sourceLine" id="cb805-7" data-line-number="7"></a>
<a class="sourceLine" id="cb805-8" data-line-number="8"><span class="kw">ggpairs</span>(stacked_dm, <span class="dt">mapping =</span> ggplot2<span class="op">::</span><span class="kw">aes</span>(<span class="dt">color =</span> design),</a>
<a class="sourceLine" id="cb805-9" data-line-number="9">        <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">continuous =</span> <span class="kw">wrap</span>(<span class="st">&quot;points&quot;</span>, <span class="dt">size=</span><span class="dv">1</span>)), <span class="dt">progress=</span><span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb805-10" data-line-number="10"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Shifted and Stacked Design Matrix&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb805-11" data-line-number="11"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="08-Advanced_Designs_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<div id="nolh-problem-set" class="section level3">
<h3><span class="header-section-number">10.7.1</span> NOLH Problem Set</h3>
<p>The problem set for this section is located <a href = "/_Chapter10_ProblemSets/NOLH_ProblemSet_Questions.html">here</a>.</p>
<p>For your convenience, the problem set as an R markdown is located <a href = "/_Chapter10_ProblemSets/NOLH_ProblemSet_Questions.Rmd">here</a>.</p>
<p>The solutions for this problem set is located <a href = "/_Chapter10_ProblemSets/NOLH_ProblemSet_Solutions.html">here</a>.</p>
<!--chapter:end:08-Advanced_Designs.Rmd-->
</div>
</div>
</div>
<div id="non-parametric-regression" class="section level1">
<h1><span class="header-section-number">11</span> Non-Parametric Regression</h1>
<p>As we’ve seen in the last few chapters, linear models can be successfully applied to many data sets. However, there may be times when even after transforming variables, your model clearly violates the assumptions of linear models. Alternatively, you may have evidence that there is a complex relationship between predictor and response that is difficult to capture through transformation. In these cases, non-parametric regression techniques offer alternative methods for modeling your data.</p>
<div id="admin-6" class="section level2">
<h2><span class="header-section-number">11.1</span> Admin</h2>
<p>For any errors associated with this section, please contact <a href="mailto:john.f.king1.mil@mail.mil">John King</a>.</p>
<p>This chapter was published using the following software:</p>
<ul>
<li>R version 3.6.0 (2019-04-26).</li>
<li>On x86_64-pc-linux-gnu (64-bit) running Ubuntu 18.04.2 LTS.</li>
<li>Packages used in this chapter are explicitly shown in the code snippets.</li>
</ul>
</div>
<div id="non-parametric-anova" class="section level2">
<h2><span class="header-section-number">11.2</span> Non-Parametric ANOVA</h2>
<p>In Chapter 4, we applied ANOVA to problems where we had a factor with three or more levels, and we wanted to test for a difference in response among the levels. One of the assumptions of parametric ANOVA is that the underlying data are normally distributed. If we have a data set that violates that assumption, as is often the case with counts (especially of relatively rare events), then we’ll need to use a non-parametric method such as the Kruskal-Wallis (KW) test.</p>
<p>The setup for the KW test is as follows:</p>
<ul>
<li>Level 1: <span class="math inline">\(X_{11}, X_{12}, ...,X_{1J_{1}} \sim F_{1}\)</span></li>
<li>Level 2: <span class="math inline">\(X_{21}, X_{22}, ...,X_{2J_{2}} \sim F_{2}\)</span></li>
<li>…</li>
<li>Level I: <span class="math inline">\(X_{I1}, X_{I2}, ...,X_{IJ_{I}} \sim F_{I}\)</span></li>
</ul>
<p><strong>Null hypothesis</strong> <span class="math inline">\(H_{o}: F_{1} = F_{2} = ... = F_{I}\)</span></p>
<p><strong>Alternative hypothesis</strong> <span class="math inline">\(H_{a}:\)</span> not <span class="math inline">\(H{o}\)</span> (i.e., at least two of the distributions are different).</p>
<p>The idea behind the KW test is to sort the data and use an observation’s rank instead of the value itself. If we have a sample size <span class="math inline">\(N = J_{1}, J_{2}, ... J_{I}\)</span>, we first rank the observations (the lowest value gets a 1, second lowest a 2, etc.). If there are ties, then use the mid-rank (the mean of the two ranks). Then, separate the samples into their respective levels and sum the ranks for each level. For example, if we have three levels:</p>
<ul>
<li>Level 1: <span class="math inline">\(R_{11} + R_{12} + ... + R_{1J_{1}}=\)</span> sum of ranks</li>
<li>Level 2: <span class="math inline">\(R_{21} + R_{22} + ... + R_{2J_{1}}=\)</span> sum of ranks</li>
<li>Level 3: <span class="math inline">\(R_{31} + R_{32} + ... + R_{3J_{1}}=\)</span> sum of ranks</li>
</ul>
<p>Now we do the non-parametric equivalent of a sum of squares for treatment (SSTr) using these ranks. The KW test statistic takes the form:</p>
<p><span class="math display">\[K=\frac{12}{N(N+1)}\sum\limits_{i=1}^{I}{\frac{R^2_{i}}{J_{i}}-3(N+1)}\]</span></p>
<p>For hypothesis testing, we calculate a p-value where large values of K signal rejection. We do this by approximating K with a chi-square distribution having <span class="math inline">\(I-1\)</span> degrees of freedom. According to <span class="citation">Devore (<a href="#ref-devore2015">2015</a>)</span> (p. 672), chi-square is a good approximation for K if:</p>
<ol style="list-style-type: decimal">
<li>If there are I = 3 treatments and each sample size is &gt;= 6, or</li>
<li>If there are I &gt; 3 treatments and each sample size is &gt;= 5</li>
</ol>
<p>Let’s look at an example. Say we are a weapon manufacturer that produces rifles on three different assembly lines, and we want to know if there’s a difference in the number of times a weapon jams. We select 10 random weapons from each assembly line and perform our weapon jamming test identically on all 30 weapons. I’ll make up some dummy data for this situation by drawing random numbers from Poisson distributions with two different <span class="math inline">\(\lambda\)</span>s.</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb806-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb806-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb806-3" data-line-number="3"></a>
<a class="sourceLine" id="cb806-4" data-line-number="4">j =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rpois</span>(<span class="dv">10</span>, <span class="dv">10</span>), <span class="kw">rpois</span>(<span class="dv">10</span>, <span class="dv">10</span>), <span class="kw">rpois</span>(<span class="dv">10</span>, <span class="dv">15</span>))</a>
<a class="sourceLine" id="cb806-5" data-line-number="5">r =<span class="st"> </span><span class="kw">rank</span>(j, <span class="dt">ties.method=</span><span class="st">&quot;average&quot;</span>)</a>
<a class="sourceLine" id="cb806-6" data-line-number="6">l =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;line&quot;</span>, <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">each =</span> <span class="dv">10</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb806-7" data-line-number="7"></a>
<a class="sourceLine" id="cb806-8" data-line-number="8"><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb806-9" data-line-number="9">  <span class="dt">jams1 =</span> j[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>],</a>
<a class="sourceLine" id="cb806-10" data-line-number="10">  <span class="dt">rank1 =</span> r[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>],</a>
<a class="sourceLine" id="cb806-11" data-line-number="11">  <span class="dt">jams2 =</span> j[<span class="dv">11</span><span class="op">:</span><span class="dv">20</span>],</a>
<a class="sourceLine" id="cb806-12" data-line-number="12">  <span class="dt">rank2 =</span> r[<span class="dv">11</span><span class="op">:</span><span class="dv">20</span>],</a>
<a class="sourceLine" id="cb806-13" data-line-number="13">  <span class="dt">jams3 =</span> j[<span class="dv">21</span><span class="op">:</span><span class="dv">30</span>],</a>
<a class="sourceLine" id="cb806-14" data-line-number="14">  <span class="dt">rank3 =</span> r[<span class="dv">21</span><span class="op">:</span><span class="dv">30</span>])</a></code></pre></div>
<pre><code>## # A tibble: 10 x 6
##    jams1 rank1 jams2 rank2 jams3 rank3
##    &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
##  1    14  19.5    14  19.5     8   3.5
##  2     8   3.5    17  27      21  30  
##  3    11  10.5     5   1      16  23.5
##  4    12  13.5    14  19.5    16  23.5
##  5    11  10.5    13  16      13  16  
##  6     9   6.5    12  13.5    18  29  
##  7    14  19.5    11  10.5    17  27  
##  8     9   6.5    13  16      11  10.5
##  9    16  23.5     7   2      16  23.5
## 10     9   6.5     9   6.5    17  27</code></pre>
<p>For this data,</p>
<ul>
<li><span class="math inline">\(I = 3\)</span></li>
<li><span class="math inline">\(J_{1} = J_{2} = J_{3} = 10\)</span></li>
<li><span class="math inline">\(N = 10 + 10 + 10 = 30\)</span></li>
<li><span class="math inline">\(R_{1} =\)</span> 120</li>
<li><span class="math inline">\(R_{2} =\)</span> 131.5</li>
<li><span class="math inline">\(R_{3} =\)</span> 213.5</li>
</ul>
<p>Which gives the K statistic:</p>
<p><span class="math display">\[K=\frac{12}{30(31)} \left[\frac{120^2}{10} + \frac{131.5^2}{10} + \frac{213.5^2}{10}\right] - 3(31)\]</span></p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb808-1" data-line-number="1">K =<span class="st"> </span><span class="dv">12</span><span class="op">/</span>(<span class="dv">30</span><span class="op">*</span><span class="dv">31</span>) <span class="op">*</span><span class="st"> </span>(<span class="kw">sum</span>(r[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>])<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(r[<span class="dv">11</span><span class="op">:</span><span class="dv">20</span>])<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(r[<span class="dv">21</span><span class="op">:</span><span class="dv">30</span>])<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">10</span>) <span class="op">-</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="dv">31</span></a>
<a class="sourceLine" id="cb808-2" data-line-number="2"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;K =&quot;</span>, K), <span class="dt">quote=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] K = 6.70903225806452</code></pre>
<p>Then, compute an approximate p-value using the chi-square test with two degrees of freedom.</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb810-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(K, <span class="dt">df=</span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## [1] 0.03492627</code></pre>
<p>We therefore reject the null hypothesis at the <span class="math inline">\(\alpha = 0.5\)</span> test level. Of course, there’s an <em>R</em> function <code>kruskall.test()</code> so we don’t have to do all that by hand.</p>
<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb812-1" data-line-number="1">rifles =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">jams =</span> j, <span class="dt">line =</span> l)</a>
<a class="sourceLine" id="cb812-2" data-line-number="2"></a>
<a class="sourceLine" id="cb812-3" data-line-number="3"><span class="kw">kruskal.test</span>(jams <span class="op">~</span><span class="st"> </span>line, <span class="dt">data =</span> rifles)</a></code></pre></div>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  jams by line
## Kruskal-Wallis chi-squared = 6.7845, df = 2, p-value = 0.03363</code></pre>
<div id="multiple-comparisons-2" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Multiple Comparisons</h3>
<p>The KW test can also be used for multiple comparisons. Recall that we applied the Tukey Test to the parametric case, and it took into account that there is an increase in the probability of a Type I error when conducting multiple comparisons. The non-parametric equivalent is to combine the Bonferroni Method with the KW test. Consider the case where we conduct <span class="math inline">\(m\)</span> tests of the null hypothesis. We calculate the probability that at least one of the null hypotheses is rejected (<span class="math inline">\(P(\bar{A})\)</span>) as follows:</p>
<p><span class="math display">\[P(\bar{A}) = 1-P(A) = 1-P(A_{1} \cap A_{2} \cap...\cap A_{m})\]</span></p>
<p><span class="math display">\[=1-P(A_{1})P(A_{2})\cdot\cdot\cdot P(A_{m})\]</span></p>
<p><span class="math display">\[=1-(1-\alpha)^{m}\]</span></p>
<p>So if our individual test level target is <span class="math inline">\(\alpha=0.05\)</span> and we conduct <span class="math inline">\(m=10\)</span> tests, then <span class="math inline">\(P(\bar{A})=1-(1-0.05)^{10}=\)</span> 0.4012631. If we want to establish a <strong>family-wide Type I error rate</strong>, <span class="math inline">\(\Psi=P(\bar{A})=0.05\)</span>, then the individual test levels should be:</p>
<p><span class="math display">\[\alpha=P(\bar{A}_{i})=1-(1-\Psi)^{1/m}\]</span></p>
<p>For example, if <span class="math inline">\(\Psi=0.05\)</span> and we again conduct <span class="math inline">\(m=10\)</span> tests, then <span class="math inline">\(\alpha=1-(1-0.05)^{1/10}=\)</span> 0.0051162. The downfall of this approach is that the same data are used to test the collection of hypotheses, which violates the independence assumption. The Bonferroni Inequality saves us from this situation because it doesn’t rely on the assumption of independence. Using the Bonferroni method, we simply calculate <span class="math inline">\(\alpha=\Psi/m = 0.005\)</span>. Note that this is almost identical to the result when we assumed independence. Unfortunately, the method isn’t perfect. As noted in <a href="https://www.stat.berkeley.edu/~mgoldman/Section0402.pdf">Section 2 of this paper</a> the Bonferroni method tends to be overly conservative, which increases the chance of a false negative.</p>
<p>Using the <code>rifles</code> data from earlier, if we wanted to conduct all three pair-wise hypothesis tests, then <span class="math inline">\(\alpha=0.05/3=0.01667\)</span> for the individual KW tests.</p>
<p>The <code>dunn.test()</code> function from the aptly-named <code>dunn.test</code> package performs the multiple pair-wise tests and offers several methods for accounting for performing multiple tests, including Bonferroni. For example (and notice we get the KW test results also):</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb814-1" data-line-number="1">dunn.test<span class="op">::</span><span class="kw">dunn.test</span>(rifles<span class="op">$</span>jams, rifles<span class="op">$</span>line, <span class="dt">method=</span><span class="st">&quot;bonferroni&quot;</span>)</a></code></pre></div>
<pre><code>##   Kruskal-Wallis rank sum test
## 
## data: x and group
## Kruskal-Wallis chi-squared = 6.7845, df = 2, p-value = 0.03
## 
## 
##                            Comparison of x by group                            
##                                  (Bonferroni)                                  
## Col Mean-|
## Row Mean |      line1      line2
## ---------+----------------------
##    line2 |  -0.293738
##          |     1.0000
##          |
##    line3 |  -2.388222  -2.094483
##          |     0.0254     0.0543
## 
## alpha = 0.05
## Reject Ho if p &lt;= alpha/2</code></pre>
<p>According to the <code>dunn.test</code> documentation, the null hypothesis for the Dunn test is:</p>
<blockquote>
<p>The null hypothesis for each pairwise comparison is that the probability of observing a randomly selected value from the first group that is larger than a randomly selected value from the second group equals one half; this null hypothesis corresponds to that of the Wilcoxon-Mann-Whitney rank-sum test. Like the ranksum test, if the data can be assumed to be continuous, and the distributions are assumed identical except for a difference in location, Dunn’s test may be understood as a test for median difference. ‘dunn.test’ accounts for tied ranks.</p>
</blockquote>
</div>
<div id="non-parametric-anova-problem-set" class="section level3">
<h3><span class="header-section-number">11.2.2</span> Non-Parametric ANOVA Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter11_ProblemSets/KW_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter11_ProblemSets/kw_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter11_ProblemSets/KW_PS_Solutions.html'>here</a>.</p>
</div>
</div>
<div id="generalized-additive-models" class="section level2">
<h2><span class="header-section-number">11.3</span> Generalized Additive Models</h2>
<p>Recall that if there is a non-linear relationship between predictor and response, we can attempt to transform the predictor using a known function (log, reciprocal, polynomial, etc.) to improve the model structure and fit. What if the relationship is more complex and is not well captured with a known function? Generalized additive models may be used in these cases.</p>
<p>Recall that a linear model takes the form:</p>
<p><span class="math display">\[y=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+...+\varepsilon\]</span></p>
<p>Additive models replace the linear terms (the <span class="math inline">\(\beta\)</span>s) with flexible smoothing functions and take the form:</p>
<p><span class="math display">\[y=\beta_{0}+f_{1}(x_{1})+f_{2}(x_{2})+...+\varepsilon\]</span></p>
<p>There are many techniques and options for selecting the smoothing functions, but for this tutorial, we’ll discuss two: locally weighted error sum of squares (lowess and also commonly abbreviated as loess) and smoothing splines.</p>
<div id="loess" class="section level3">
<h3><span class="header-section-number">11.3.1</span> Loess</h3>
<p>For the theory behind loess smoothing, please read <a href="https://www.itl.nist.gov/div898/handbook/pmd/section1/pmd144.htm">this page</a> on the NIST website. This chapter will focus on implementing loess smoothing in <em>R</em>.</p>
<p>All smoothers have a tuning parameter that controls how smooth the smoother is. The tuning parameter in loess is referred to as the span with larger values producing more smoothness.</p>
<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb816-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb816-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb816-3" data-line-number="3"></a>
<a class="sourceLine" id="cb816-4" data-line-number="4">df =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb816-5" data-line-number="5">  <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dv">100</span>, <span class="fl">1.5</span>, <span class="fl">5.5</span>),</a>
<a class="sourceLine" id="cb816-6" data-line-number="6">  <span class="dt">y =</span> <span class="kw">sin</span>(x<span class="op">*</span>pi) <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb816-7" data-line-number="7">)</a>
<a class="sourceLine" id="cb816-8" data-line-number="8"></a>
<a class="sourceLine" id="cb816-9" data-line-number="9">ex1.ls =<span class="st"> </span><span class="kw">loess</span>(y<span class="op">~</span>x, <span class="dt">span=</span><span class="fl">0.25</span>, <span class="dt">data=</span>df)</a>
<a class="sourceLine" id="cb816-10" data-line-number="10">ex2.ls =<span class="st"> </span><span class="kw">loess</span>(y<span class="op">~</span>x, <span class="dt">span=</span><span class="fl">0.5</span>, <span class="dt">data=</span>df)</a>
<a class="sourceLine" id="cb816-11" data-line-number="11">ex3.ls =<span class="st"> </span><span class="kw">loess</span>(y<span class="op">~</span>x, <span class="dt">span=</span><span class="fl">0.75</span>, <span class="dt">data=</span>df)</a>
<a class="sourceLine" id="cb816-12" data-line-number="12">xseq =<span class="st"> </span><span class="kw">seq</span>(<span class="fl">1.6</span>, <span class="fl">5.4</span>,<span class="dt">length=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb816-13" data-line-number="13"></a>
<a class="sourceLine" id="cb816-14" data-line-number="14">df =<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb816-15" data-line-number="15">  <span class="dt">span25 =</span> <span class="kw">predict</span>(ex1.ls, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">x=</span>xseq)),</a>
<a class="sourceLine" id="cb816-16" data-line-number="16">  <span class="dt">span50 =</span> <span class="kw">predict</span>(ex2.ls, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">x=</span>xseq)),</a>
<a class="sourceLine" id="cb816-17" data-line-number="17">  <span class="dt">span75 =</span> <span class="kw">predict</span>(ex3.ls, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">x=</span>xseq))</a>
<a class="sourceLine" id="cb816-18" data-line-number="18">  )</a>
<a class="sourceLine" id="cb816-19" data-line-number="19"></a>
<a class="sourceLine" id="cb816-20" data-line-number="20"><span class="kw">ggplot</span>(df) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-21" data-line-number="21"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(x, y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-22" data-line-number="22"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>xseq, span25, <span class="dt">linetype=</span><span class="st">&#39;span = 0.25&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-23" data-line-number="23"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>xseq, span50, <span class="dt">linetype=</span><span class="st">&#39;span = 0.50&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-24" data-line-number="24"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>xseq, span75, <span class="dt">linetype=</span><span class="st">&#39;span = 0.75&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-25" data-line-number="25"><span class="st">  </span><span class="kw">scale_linetype_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-26" data-line-number="26"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Loess Smoother Example&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb816-27" data-line-number="27"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>From this plot, a span of 0.75 provided too much smoothness, whereas the lower values of span we tested appear to be a better fit. Now let’s apply this to the <code>airqaulity</code> data set from the previous chapter. Initially, we’ll just consider the response(<code>Ozone</code>) and one predictor (<code>Solar.R</code>).</p>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb817-1" data-line-number="1">aq1.ls =<span class="st"> </span><span class="kw">loess</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">span=</span><span class="fl">0.25</span>, <span class="dt">data=</span>airquality)</a>
<a class="sourceLine" id="cb817-2" data-line-number="2">aq2.ls =<span class="st"> </span><span class="kw">loess</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">span=</span><span class="fl">0.5</span>, <span class="dt">data=</span>airquality)</a>
<a class="sourceLine" id="cb817-3" data-line-number="3">aq3.ls =<span class="st"> </span><span class="kw">loess</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">span=</span><span class="fl">0.75</span>, <span class="dt">data=</span>airquality)</a>
<a class="sourceLine" id="cb817-4" data-line-number="4">srseq =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">10</span>, <span class="dv">330</span>, <span class="dt">length=</span><span class="kw">nrow</span>(airquality))</a>
<a class="sourceLine" id="cb817-5" data-line-number="5"></a>
<a class="sourceLine" id="cb817-6" data-line-number="6">aq =<span class="st"> </span>airquality <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(</a>
<a class="sourceLine" id="cb817-7" data-line-number="7">  <span class="dt">span25 =</span> <span class="kw">predict</span>(aq1.ls, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">Solar.R=</span>srseq)),</a>
<a class="sourceLine" id="cb817-8" data-line-number="8">  <span class="dt">span50 =</span> <span class="kw">predict</span>(aq2.ls, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">Solar.R=</span>srseq)),</a>
<a class="sourceLine" id="cb817-9" data-line-number="9">  <span class="dt">span75 =</span> <span class="kw">predict</span>(aq3.ls, <span class="dt">newdata=</span><span class="kw">tibble</span>(<span class="dt">Solar.R=</span>srseq))</a>
<a class="sourceLine" id="cb817-10" data-line-number="10">  )</a>
<a class="sourceLine" id="cb817-11" data-line-number="11"></a>
<a class="sourceLine" id="cb817-12" data-line-number="12"><span class="kw">ggplot</span>(aq) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Solar.R, Ozone)) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-14" data-line-number="14"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>srseq, span25, <span class="dt">linetype=</span><span class="st">&#39;span = 0.25&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>srseq, span50, <span class="dt">linetype=</span><span class="st">&#39;span = 0.50&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>srseq, span75, <span class="dt">linetype=</span><span class="st">&#39;span = 0.75&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-17" data-line-number="17"><span class="st">  </span><span class="kw">scale_linetype_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-18" data-line-number="18"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Loess Smoother Example&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb817-19" data-line-number="19"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Here we can see that the higher span values appear to provide a better fit. In this case, choosing a low span value would be akin to over fitting a linear model with too high of a degree of polynomial. We can repeat this process to determine appropriate values of span for the other predictors.</p>
<p>Including loess smoothers in a GAM is as simple as including the non-linear terms within <code>lo()</code>. The <code>gam</code> package provides the needed functionality. The script below applies loess smoothers to three of the predictors and displays the model summary (note that the default value for span is 0.5).</p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb818-1" data-line-number="1"><span class="kw">library</span>(gam)</a>
<a class="sourceLine" id="cb818-2" data-line-number="2"></a>
<a class="sourceLine" id="cb818-3" data-line-number="3">aq.gam =<span class="st"> </span><span class="kw">gam</span>(Ozone <span class="op">~</span><span class="st"> </span><span class="kw">lo</span>(Solar.R, <span class="dt">span=</span><span class="fl">0.75</span>) <span class="op">+</span><span class="st"> </span><span class="kw">lo</span>(Wind) <span class="op">+</span><span class="st"> </span><span class="kw">lo</span>(Temp), <span class="dt">data=</span>airquality, <span class="dt">na=</span>na.gam.replace)</a>
<a class="sourceLine" id="cb818-4" data-line-number="4"><span class="kw">summary</span>(aq.gam)</a></code></pre></div>
<pre><code>## 
## Call: gam(formula = Ozone ~ lo(Solar.R, span = 0.75) + lo(Wind) + lo(Temp), 
##     data = airquality, na.action = na.gam.replace)
## Deviance Residuals:
##     Min      1Q  Median      3Q     Max 
## -47.076  -9.601  -2.721   8.977  76.583 
## 
## (Dispersion Parameter for gaussian family taken to be 319.3603)
## 
##     Null Deviance: 125143.1 on 115 degrees of freedom
## Residual Deviance: 33679.85 on 105.4604 degrees of freedom
## AIC: 1010.117 
## 
## Number of Local Scoring Iterations: NA 
## 
## Anova for Parametric Effects
##                              Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## lo(Solar.R, span = 0.75)   1.00  14248   14248  44.615 1.160e-09 ***
## lo(Wind)                   1.00  35734   35734 111.894 &lt; 2.2e-16 ***
## lo(Temp)                   1.00  15042   15042  47.099 4.794e-10 ***
## Residuals                105.46  33680     319                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Anova for Nonparametric Effects
##                          Npar Df Npar F     Pr(F)    
## (Intercept)                                          
## lo(Solar.R, span = 0.75)     1.2 2.9766 0.0804893 .  
## lo(Wind)                     2.8 9.2752 2.617e-05 ***
## lo(Temp)                     2.5 6.8089 0.0006584 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb820-1" data-line-number="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb820-2" data-line-number="2"><span class="kw">plot</span>(aq.gam, <span class="dt">se=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-10-1.png" width="960" /></p>
</div>
<div id="splines" class="section level3">
<h3><span class="header-section-number">11.3.2</span> Splines</h3>
<p>Spline smoothing can be conceptualized by imagining that your task is to bend a strip of soft metal into a curved shape. One way to do this would be to place pegs on a board (referred to as “knots” in non-linear regression parlance) to control the bends, and then guide the strip of metal over and under the pegs. Mathematically, this is accomplished by combining cubic regression at each knot with calculus to smoothly join the individual bends. The tuning parameter in the <code>smooth.splines</code> function is <code>spar</code>.</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb821-1" data-line-number="1">aq =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>()</a>
<a class="sourceLine" id="cb821-2" data-line-number="2"></a>
<a class="sourceLine" id="cb821-3" data-line-number="3">ss25 =<span class="st"> </span><span class="kw">smooth.spline</span>(aq<span class="op">$</span>Solar.R,aq<span class="op">$</span>Ozone,<span class="dt">spar=</span><span class="fl">0.25</span>)</a>
<a class="sourceLine" id="cb821-4" data-line-number="4">ss50 =<span class="st"> </span><span class="kw">smooth.spline</span>(aq<span class="op">$</span>Solar.R,aq<span class="op">$</span>Ozone,<span class="dt">spar=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb821-5" data-line-number="5">ss75 =<span class="st"> </span><span class="kw">smooth.spline</span>(aq<span class="op">$</span>Solar.R,aq<span class="op">$</span>Ozone,<span class="dt">spar=</span><span class="fl">0.75</span>)</a>
<a class="sourceLine" id="cb821-6" data-line-number="6"></a>
<a class="sourceLine" id="cb821-7" data-line-number="7"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb821-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>aq, <span class="kw">aes</span>(Solar.R, Ozone)) <span class="op">+</span></a>
<a class="sourceLine" id="cb821-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>ss25<span class="op">$</span>x, ss25<span class="op">$</span>y, <span class="dt">linetype=</span><span class="st">&#39;spar = 0.25&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb821-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>ss50<span class="op">$</span>x, ss50<span class="op">$</span>y, <span class="dt">linetype=</span><span class="st">&#39;spar = 0.50&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb821-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>ss75<span class="op">$</span>x, ss75<span class="op">$</span>y, <span class="dt">linetype=</span><span class="st">&#39;spar = 0.75&#39;</span>), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb821-12" data-line-number="12"><span class="st">  </span><span class="kw">scale_linetype_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb821-13" data-line-number="13"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Spline Smoother Example&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb821-14" data-line-number="14"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="cross-validation-1" class="section level3">
<h3><span class="header-section-number">11.3.3</span> Cross Validation</h3>
<p>Comparing the spline smoother plot to the one generated with loess smoothers, we can see that the two methods essentially accomplish the same thing. It’s just a matter of finding the right amount of smoothness, which can be done through cross validation. The <code>fANCOVA</code> package contains a function <code>loess.aq()</code> that includes a criterion parameter that we can set to <code>gcv</code> for generalized cross validation, which is an approximation for leave-one-out cross-validation <span class="citation">Trevor Hastie and Friedman (<a href="#ref-hastie2008">2008</a>)</span>. Applying this function to the <code>airquality</code> data with <code>Solar.R</code> as the predictor and <code>Ozone</code> as the response, we can obtain a cross validated value for span.</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb822-1" data-line-number="1"><span class="kw">library</span>(fANCOVA)</a></code></pre></div>
<pre><code>## fANCOVA 0.6-1 loaded</code></pre>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb824-1" data-line-number="1">aq.solar.cv =<span class="st"> </span><span class="kw">loess.as</span>(aq<span class="op">$</span>Solar.R, aq<span class="op">$</span>Ozone, <span class="dt">criterion=</span><span class="st">&quot;gcv&quot;</span>)</a>
<a class="sourceLine" id="cb824-2" data-line-number="2"><span class="kw">summary</span>(aq.solar.cv)</a></code></pre></div>
<pre><code>## Call:
## loess(formula = y ~ x, data = data.bind, span = span1, degree = degree, 
##     family = family)
## 
## Number of Observations: 111 
## Equivalent Number of Parameters: 3.09 
## Residual Standard Error: 29.42 
## Trace of smoother matrix: 3.56  (exact)
## 
## Control settings:
##   span     :  0.6991628 
##   degree   :  1 
##   family   :  gaussian
##   surface  :  interpolate      cell = 0.2
##   normalize:  TRUE
##  parametric:  FALSE
## drop.square:  FALSE</code></pre>
<p><code>loess.as</code> also includes a plot method so we can visualize the loess smoother.</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb826-1" data-line-number="1"><span class="kw">loess.as</span>(aq<span class="op">$</span>Solar.R, aq<span class="op">$</span>Ozone, <span class="dt">criterion=</span><span class="st">&quot;gcv&quot;</span>, <span class="dt">plot=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre><code>## Call:
## loess(formula = y ~ x, data = data.bind, span = span1, degree = degree, 
##     family = family)
## 
## Number of Observations: 111 
## Equivalent Number of Parameters: 3.09 
## Residual Standard Error: 29.42</code></pre>
<p>Cross validation is also built in to <code>smooth.spline()</code> and is set to generalized cross validation by default. Instead of specifying <code>spar</code> in the call to <code>smooth.spline()</code>, we just leave it out to invoke cross validation.</p>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb828-1" data-line-number="1">aq.spl =<span class="st"> </span><span class="kw">smooth.spline</span>(aq<span class="op">$</span>Solar.R, aq<span class="op">$</span>Ozone)</a>
<a class="sourceLine" id="cb828-2" data-line-number="2">aq.spl</a></code></pre></div>
<pre><code>## Call:
## smooth.spline(x = aq$Solar.R, y = aq$Ozone)
## 
## Smoothing Parameter  spar= 0.9837718  lambda= 0.01867197 (12 iterations)
## Equivalent Degrees of Freedom (Df): 4.060081
## Penalized Criterion (RSS): 66257.74
## GCV: 892.29</code></pre>
<p>Plotting the cross validated spline smoother, we get a line that looks very similar to the lasso smoother.</p>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb830-1" data-line-number="1"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb830-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>aq, <span class="kw">aes</span>(Solar.R, Ozone)) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>aq.spl<span class="op">$</span>x, aq.spl<span class="op">$</span>y), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-4" data-line-number="4"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;CV Spline Smoother&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb830-5" data-line-number="5"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="gam-problem-set" class="section level3">
<h3><span class="header-section-number">11.3.4</span> GAM Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter11_ProblemSets/Loess_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter11_ProblemSets/Loess_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter11_ProblemSets/Loess_PS_Solutions.html'>here</a>.</p>
</div>
</div>
<div id="support-vector-machines" class="section level2">
<h2><span class="header-section-number">11.4</span> Support Vector Machines</h2>
<p>If you have already been introduced to support vector machines (SVM), chances are that the methodology was applied to a classification problem, which is referred to as support vector classification (SVC). Support vector regression (SVR) is closely related to SVC but is used for linear and non-linear regression problems. We’ll begin with regression, and then move to classification.</p>
<div id="support-vector-regression" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Support Vector Regression</h3>
<p>SVR attempts to include as many data points as possible in the area between two lines. The following figure demonstrates this using dummy data with a linear relationship. The two parallel lines are the <strong>margin</strong>, and it’s width is a hyperparameter <span class="math inline">\(\varepsilon\)</span> that we can tune. If you draw a line through one of the points that fall outside the margin so that it is perpendicular to the margin, you have a <strong>support vector</strong>. A <strong>cost</strong> is applied to each point that falls outside the margin, and minimizing the cost determines the slope of the margin. Cost is another tunable hyperparameter, which is sometimes represented as <span class="math inline">\(1/\lambda\)</span>. Notice that unlike linear regression, if we were to add more points inside the margin, it would have no impact on the slope. SVR is also much less influence by outliers than linear regression. For the mathematical details behind SVR, refer to Section 12.3.6 in <span class="citation">Trevor Hastie and Friedman (<a href="#ref-hastie2008">2008</a>)</span>.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Choosing values for the hyperparameters <span class="math inline">\(\varepsilon\)</span> and <span class="math inline">\(\lambda\)</span> is once again done through cross validation. To do this in <em>R</em>, we’ll use some functions from the <code>e1071</code> package (another option is the <code>LiblineaR</code> package). Before we get to cross validation, let’s just look at how to build an SVR model. The syntax is the same as for linear models, we just replace <code>lm()</code> with <code>svm()</code>. Note that the function is not <code>svr()</code> because the function can do both regression and classification. To make this more interesting, we’ll switch back to the <code>airquality</code> data. From the model summary below, <code>SVM-type:  eps-regression</code> tells us that the function is performing regression and not classification, then we see the hyperparameter values and the number of support vectors used to fit the model.</p>
<p>For the kernel, we have four choices: linear, polynomial, radial basis, and sigmoid. Selecting a linear kernel will force a straight line fit, and the other three kernels are different methods for adding curvature to the regression line<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a>. The theory behind SVR kernels is beyond the scope of this tutorial, but if you want to dig deeper:</p>
<ul>
<li><p>Here are some slides titled <a href="http://www.robots.ox.ac.uk/~az/lectures/ml/lect3.pdf">SVM dual, kernels and regression</a> from The University of Oxford.</p></li>
<li><p>Here’s <a href="http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf">An Idiot’s Guide to Support Vector Machines</a>, a catchy title from MIT.</p></li>
<li><p>Here’s post titled <a href="https://towardsdatascience.com/understanding-support-vector-machine-part-2-kernel-trick-mercers-theorem-e1e6848c6c4d">Support Vector Machine: Kernel Trick; Mercer’s Theorem</a> at towardsdatascience.com.</p></li>
</ul>
<p>For our purposes, we just need to know that the three non-linear kernels have <code>gamma</code> as a hyperparameter that controls curvature.</p>
<p>To force a straight regression line, specify <code>kernel='linear'</code>. Also, the <code>svm()</code> by default scales all variables in the data set to have a mean of zero and equal variance. Scaling the variables will improve the model’s performance, but we’ll turn that off in this example so we can directly compare the coefficients to those produced by <code>lm()</code>.</p>
<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb831-1" data-line-number="1"><span class="kw">library</span>(e1071)</a>
<a class="sourceLine" id="cb831-2" data-line-number="2"></a>
<a class="sourceLine" id="cb831-3" data-line-number="3">aq.svm =<span class="st"> </span><span class="kw">svm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">data=</span>aq, <span class="dt">kernel=</span><span class="st">&#39;linear&#39;</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb831-4" data-line-number="4"><span class="kw">summary</span>(aq.svm)</a></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = Ozone ~ Solar.R, data = aq, kernel = &quot;linear&quot;, scale = FALSE)
## 
## 
## Parameters:
##    SVM-Type:  eps-regression 
##  SVM-Kernel:  linear 
##        cost:  1 
##       gamma:  1 
##     epsilon:  0.1 
## 
## 
## Number of Support Vectors:  110</code></pre>
<p>We can then extract the coefficients with <code>coef()</code>.</p>
<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb833-1" data-line-number="1">(<span class="dt">coeffs =</span> <span class="kw">coef</span>(aq.svm))</a></code></pre></div>
<pre><code>## (Intercept)     Solar.R 
## 12.52321429  0.09107143</code></pre>
<p>Using <code>lm()</code>, we get the following coefficients.</p>
<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb835-1" data-line-number="1">aq.lm =<span class="st"> </span><span class="kw">lm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">data=</span>aq)</a>
<a class="sourceLine" id="cb835-2" data-line-number="2"><span class="kw">summary</span>(aq.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Ozone ~ Solar.R, data = aq)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.292 -21.361  -8.864  16.373 119.136 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 18.59873    6.74790   2.756 0.006856 ** 
## Solar.R      0.12717    0.03278   3.880 0.000179 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 31.33 on 109 degrees of freedom
## Multiple R-squared:  0.1213, Adjusted R-squared:  0.1133 
## F-statistic: 15.05 on 1 and 109 DF,  p-value: 0.0001793</code></pre>
<p>The coefficients produced by the two models might seem fairly different. The following plot shows the data with the two regression lines for comparison. Notice how the linear model is more influenced by the extreme high ozone values (possible outliers).</p>
<div class="sourceCode" id="cb837"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb837-1" data-line-number="1"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb837-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> aq, <span class="kw">aes</span>(<span class="dt">x=</span>Solar.R, <span class="dt">y=</span>Ozone)) <span class="op">+</span></a>
<a class="sourceLine" id="cb837-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope=</span>coeffs[<span class="dv">2</span>], <span class="dt">intercept=</span>coeffs[<span class="dv">1</span>], <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb837-4" data-line-number="4"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">315</span>, <span class="dt">y=</span><span class="dv">50</span>, <span class="dt">label=</span><span class="st">&quot;svm()&quot;</span>, <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb837-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">slope=</span>aq.lm<span class="op">$</span>coefficients[<span class="dv">2</span>], <span class="dt">intercept=</span>aq.lm<span class="op">$</span>coefficients[<span class="dv">1</span>], <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb837-6" data-line-number="6"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">315</span>, <span class="dt">y=</span><span class="dv">70</span>, <span class="dt">label=</span><span class="st">&quot;lm()&quot;</span>, <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb837-7" data-line-number="7"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Now we’ll re-fit the model with a non-linear regression line and invoking scaling. To extract the predicted response, we use the <code>predict()</code> function just like with linear models. Plotting the predicted response gives is the following.</p>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb838-1" data-line-number="1">aq.svm2 =<span class="st"> </span><span class="kw">svm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">data=</span>aq)</a>
<a class="sourceLine" id="cb838-2" data-line-number="2"></a>
<a class="sourceLine" id="cb838-3" data-line-number="3">aq =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">svrY =</span> <span class="kw">predict</span>(aq.svm2, <span class="dt">data=</span>aq))</a>
<a class="sourceLine" id="cb838-4" data-line-number="4"></a>
<a class="sourceLine" id="cb838-5" data-line-number="5"><span class="kw">ggplot</span>(aq) <span class="op">+</span></a>
<a class="sourceLine" id="cb838-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Solar.R, Ozone), <span class="dt">color=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb838-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(Solar.R, svrY), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb838-8" data-line-number="8"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;SVR With Default Hyperparameters&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb838-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_fixed</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb838-10" data-line-number="10"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>To tune the hyperparameters with cross validation, we can use the <code>tune</code> function from the <code>e1017</code> package. If we give the <code>tune</code> function a range of values for the hyperparameters, it will perform a grid search of those values. In the following example, we’re therefore fitting 100 different models. If we print the object returned from <code>tune</code>, we see that it performed 10-fold cross validation, the best hyperparameter values, and the mean squared error of the best performing model.</p>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb839-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb839-2" data-line-number="2">aq.tune =<span class="st"> </span><span class="kw">tune.svm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">data =</span> aq, <span class="dt">gamma=</span><span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="dt">cost =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb839-3" data-line-number="3"><span class="kw">print</span>(aq.tune)</a></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  gamma cost
##    0.1   91
## 
## - best performance: 909.1502</code></pre>
<p>We can visualize the tune results as well by printing the <code>aq.tune</code> object. Here we see the range of cost and epsilon values with their associated mean squared error. The lower the error, the better, and those are indicated by the darkest blue regions.</p>
<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb841-1" data-line-number="1"><span class="kw">plot</span>(aq.tune)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>I prefer to choose a wide range of tuning parameter values initially, and then do a finer search in the area with the lowest error. It looks like we need a low gamma and a high cost.</p>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb842-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb842-2" data-line-number="2">aq.tune =<span class="st"> </span><span class="kw">tune.svm</span>(Ozone <span class="op">~</span><span class="st"> </span>Solar.R, <span class="dt">data =</span> aq, <span class="dt">gamma=</span><span class="kw">seq</span>(<span class="fl">0.02</span>, <span class="fl">0.22</span>, <span class="fl">0.05</span>), <span class="dt">cost =</span> <span class="kw">seq</span>(<span class="dv">80</span>, <span class="dv">100</span>, <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb842-3" data-line-number="3"><span class="kw">print</span>(aq.tune)</a></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  gamma cost
##   0.22   96
## 
## - best performance: 907.4115</code></pre>
<p>The best model from the tuning call can be obtained with <code>aq.tune$best.model</code>, and we can then apply the <code>predict</code> function to get the best fit regression.</p>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb844-1" data-line-number="1">aq<span class="op">$</span>svrY =<span class="st"> </span><span class="kw">predict</span>(aq.tune<span class="op">$</span>best.model, <span class="dt">data=</span>aq)</a>
<a class="sourceLine" id="cb844-2" data-line-number="2"></a>
<a class="sourceLine" id="cb844-3" data-line-number="3"><span class="kw">ggplot</span>(aq) <span class="op">+</span></a>
<a class="sourceLine" id="cb844-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Solar.R, Ozone), <span class="dt">color=</span><span class="st">&#39;black&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb844-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(Solar.R, svrY), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb844-6" data-line-number="6"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;SVR With Tuned Hyperparameters&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb844-7" data-line-number="7"><span class="st">  </span><span class="kw">coord_fixed</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb844-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
</div>
<div id="support-vector-classification" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Support Vector Classification</h3>
<p>Classification problems have either a binary or categorical response variable. To demonstrate how SVC works, we’ll start with the <code>iris</code> data set, which contains four predictors and one categorical response variable. Plotting petal length versus petal width for the setosa and versicolor species shows that the two species are <strong>linearly separable</strong>, meaning we can draw a straight line on the plot that completely separates the two species. If we want to train an SVC to make predictions on new data, the question becomes: how do we draw the line that separates the data? There are infinitely many options, three of which are shown on the plot.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Support vector classification uses margins, but in a different way than SVR, to find a line that separates the data. If you think of the two parallel margin lines as a street, the idea is that we want to fit the widest possible street between the species because doing so results in the rest of the data points being as far off the street as possible. The two points below that fall on the margin determine the location of the support vectors.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>What happens when two categories aren’t linearly separable, as is the case when we look at versicolor and virginica below?</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>We still want to draw two parallel lines through the data sets, but the only way to do it is to have some observations in the middle of the street, or even on the wrong side of the line (called <strong>margin violations</strong>). We still want to fit as wide of a street as possible through the data points, but now we must also limit the number of margin violations. As with SVR, we can assign a <strong>cost</strong> for each margin violation. Since margin violations are generally bad, we might be tempted to apply a large cost; however, we must also consider how well the model will generalize. Below are the linear boundaries for two choices of cost. Support vectors are based on the points surrounded by black.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-29-1.png" width="768" /></p>
<p>Interestingly, the margins (and therefore the decision boundary) don’t have to be straight lines. SVC also accommodates a curved boundary as in the example below. With a polynomial kernel, the curvature is controlled by the degree of the polynomial. In the plot, note that the support vectors are the <code>X</code> points.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<div id="example-in-r" class="section level4">
<h4><span class="header-section-number">11.4.2.1</span> Example In <em>R</em></h4>
<p>In this section, we’ll walk through an example using the full <code>iris</code> data set. First, we’ll split the data set into a training set that includes 80% of the data, and a test set with the remaining 20% using the <code>caTools</code> package.</p>
<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb845-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb845-2" data-line-number="2">train =<span class="st"> </span>caTools<span class="op">::</span><span class="kw">sample.split</span>(iris, <span class="dt">SplitRatio =</span> <span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb845-3" data-line-number="3">iris_train =<span class="st"> </span><span class="kw">subset</span>(iris, train <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb845-4" data-line-number="4">iris_test =<span class="st"> </span><span class="kw">subset</span>(iris, train <span class="op">==</span><span class="st"> </span><span class="ot">FALSE</span>)</a></code></pre></div>
<p>Next, we’ll tune two models using a linear kernel and a radial basis function (which allows for curvature). We’ll tune both models over a range of gamma and cost values.</p>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb846-1" data-line-number="1">iris.lin =<span class="st"> </span><span class="kw">tune.svm</span>(Species<span class="op">~</span>., <span class="dt">data=</span>iris_train, </a>
<a class="sourceLine" id="cb846-2" data-line-number="2">                    <span class="dt">kernel=</span><span class="st">&quot;linear&quot;</span>, </a>
<a class="sourceLine" id="cb846-3" data-line-number="3">                    <span class="dt">gamma =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), </a>
<a class="sourceLine" id="cb846-4" data-line-number="4">                    <span class="dt">cost =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb846-5" data-line-number="5"></a>
<a class="sourceLine" id="cb846-6" data-line-number="6">iris.rbf =<span class="st"> </span><span class="kw">tune.svm</span>(Species<span class="op">~</span>., <span class="dt">data=</span>iris_train, </a>
<a class="sourceLine" id="cb846-7" data-line-number="7">                    <span class="dt">kernel=</span><span class="st">&quot;radial&quot;</span>, </a>
<a class="sourceLine" id="cb846-8" data-line-number="8">                    <span class="dt">gamma =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), </a>
<a class="sourceLine" id="cb846-9" data-line-number="9">                    <span class="dt">cost =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">10</span>))</a>
<a class="sourceLine" id="cb846-10" data-line-number="10"></a>
<a class="sourceLine" id="cb846-11" data-line-number="11">iris.lin<span class="op">$</span>best.model</a></code></pre></div>
<pre><code>## 
## Call:
## best.svm(x = Species ~ ., data = iris_train, gamma = seq(0.1, 1, 
##     0.1), cost = seq(1, 100, 10), kernel = &quot;linear&quot;)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  1 
## 
## Number of Support Vectors:  25</code></pre>
<div class="sourceCode" id="cb848"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb848-1" data-line-number="1">iris.rbf<span class="op">$</span>best.model</a></code></pre></div>
<pre><code>## 
## Call:
## best.svm(x = Species ~ ., data = iris_train, gamma = seq(0.1, 1, 
##     0.1), cost = seq(1, 100, 10), kernel = &quot;radial&quot;)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  1 
## 
## Number of Support Vectors:  48</code></pre>
<p>Both models are using a low cost, but the radial basis function model has twice as many support vectors. To compare model performance, we’ll make predictions using the test set and display each model’s <strong>confusion matrix</strong> using the <code>cvms</code> package (note: we could also create a simple confusion matrix with <code>table(iris_test[, 5], predictions)</code>).</p>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb850-1" data-line-number="1"><span class="co"># get the confusion matrix for the linear kernel</span></a>
<a class="sourceLine" id="cb850-2" data-line-number="2">lin_conf_mat =<span class="st"> </span>cvms<span class="op">::</span><span class="kw">confusion_matrix</span>(</a>
<a class="sourceLine" id="cb850-3" data-line-number="3">  <span class="dt">targets =</span> iris_test[, <span class="dv">5</span>], </a>
<a class="sourceLine" id="cb850-4" data-line-number="4">  <span class="dt">predictions =</span> <span class="kw">predict</span>(iris.lin<span class="op">$</span>best.model, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>, <span class="dt">newdata =</span> iris_test[<span class="op">-</span><span class="dv">5</span>]))</a>
<a class="sourceLine" id="cb850-5" data-line-number="5"></a>
<a class="sourceLine" id="cb850-6" data-line-number="6"><span class="co"># get the confusion matrix for the radial kernel</span></a>
<a class="sourceLine" id="cb850-7" data-line-number="7">rbf_conf_mat =<span class="st"> </span>cvms<span class="op">::</span><span class="kw">confusion_matrix</span>(</a>
<a class="sourceLine" id="cb850-8" data-line-number="8">  <span class="dt">targets =</span> iris_test[, <span class="dv">5</span>],</a>
<a class="sourceLine" id="cb850-9" data-line-number="9">  <span class="dt">predictions =</span> <span class="kw">predict</span>(iris.rbf<span class="op">$</span>best.model, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>, <span class="dt">newdata =</span> iris_test[<span class="op">-</span><span class="dv">5</span>]))</a>
<a class="sourceLine" id="cb850-10" data-line-number="10"></a>
<a class="sourceLine" id="cb850-11" data-line-number="11"><span class="co"># plot the confusion matrix for the linear kernel (it&#39;s a ggplot2 object!)</span></a>
<a class="sourceLine" id="cb850-12" data-line-number="12">cvms<span class="op">::</span><span class="kw">plot_confusion_matrix</span>(lin_conf_mat<span class="op">$</span><span class="st">`</span><span class="dt">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Linear Kernel&quot;</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>The SVC model with the linear kernel did a great job! Of the 30 observations in the test set, only two were incorrectly classified. If this is the first time you’ve seen a confusion matrix, then what you see are the target (or actual) species by column and the species predictions from the SVC by row. In each cell, we see the percent and count of the total observations that fell into that cell. From this plot, we can identify true positives, false positives, etc. using the following guide.</p>
<p><span class="math inline">\(~\)</span></p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}
.tg td{border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;
  padding:10px 5px;word-break:normal;}
.tg th{border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-18eh{border-color:#000000;font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-wp8o{border-color:#000000;text-align:center;vertical-align:top}
.tg .tg-xs2q{border-color:#000000;font-size:medium;text-align:center;vertical-align:middle}
.tg .tg-mqa1{border-color:#000000;font-weight:bold;text-align:center;vertical-align:top}
.tg .tg-1tol{border-color:#000000;font-weight:bold;text-align:left;vertical-align:middle}
</style>
<table class="tg" style="undefined;table-layout: fixed; width: 354px">
<colgroup>
<col style="width: 109px">
<col style="width: 54px">
<col style="width: 95px">
<col style="width: 95px">
</colgroup>
<tbody>
<tr>
<td class="tg-xs2q" colspan="2" rowspan="2">
<span style="font-weight:bold">Confusion</span><br><span style="font-weight:bold">Matrix</span>
</td>
<td class="tg-mqa1" colspan="2">
Target
</td>
</tr>
<tr>
<td class="tg-mqa1">
Yes
</td>
<td class="tg-mqa1">
No
</td>
</tr>
<tr>
<td class="tg-1tol" rowspan="2">
Prediction
</td>
<td class="tg-18eh">
Yes
</td>
<td class="tg-wp8o">
True<br>Positive
</td>
<td class="tg-wp8o">
False<br>Positive
</td>
</tr>
<tr>
<td class="tg-18eh">
No
</td>
<td class="tg-wp8o">
False<br>Negative
</td>
<td class="tg-wp8o">
True<br>Positive
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(~\)</span></p>
<p>A perfect classifier will have zeros everywhere in the table except the diagonal. In our case, it’s close to perfect. We just have two false negatives because two flowers that were actually virginica, were predicted to be versicolor. Now let’s look at the radial kernel results.</p>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb851-1" data-line-number="1">cvms<span class="op">::</span><span class="kw">plot_confusion_matrix</span>(rbf_conf_mat<span class="op">$</span><span class="st">`</span><span class="dt">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Radial Kernel&quot;</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
</div>
</div>
<div id="svm-problem-set" class="section level3">
<h3><span class="header-section-number">11.4.3</span> SVM Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter11_ProblemSets/SVM_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter11_ProblemSets/SVM_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter11_ProblemSets/SVM_PS_Solutions.html'>here</a>.</p>
</div>
</div>
<div id="classification-and-regression-trees" class="section level2">
<h2><span class="header-section-number">11.5</span> Classification and Regression Trees</h2>
<p>As with support vector machines, and as the name implies, classification and regression trees<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a> (CART) can be used for either classification or regression tasks. Again, we’ll start with regression and then move to classification.</p>
<div id="regression-trees" class="section level3">
<h3><span class="header-section-number">11.5.1</span> Regression Trees</h3>
<p>The algorithm is best explained as we walk through an example, and we’ll continue to use the <code>airquality</code> data set. The basic machine learning algorithm used in tree-based methods follows these steps:</p>
<ol style="list-style-type: decimal">
<li><p>Consider the entire data set including all predictors and the response. We call this the <strong>root node</strong>, and it is represented by the top center node in the figure below. The information displayed in the node includes the mean response for that node (42.1 is the mean of <code>Ozone</code> for the whole data set), the number of observations in the node (<code>n=116</code>), and the percent of the overall observations in the node.</p></li>
<li><p>Iterate through each predictor, <span class="math inline">\(k\)</span>, and split the data into two subsets (referred to as the left and right <strong>child nodes</strong>) using some threshold, <span class="math inline">\(t_k\)</span>. For example, with the <code>airquality</code> data set, the predictor and threshold could be <code>Temp &gt;= 83</code>. The choice of <span class="math inline">\(k\)</span> and <span class="math inline">\(t_k\)</span> for a given split is the pair that increases the “purity” of the child nodes (weighted by their size) the most. We’ll explicitly define purity shortly. If you equate a data split with a decision, then at this point, we have a basic decision tree.</p></li>
</ol>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<ol start="3" style="list-style-type: decimal">
<li>Each child node in turn becomes the new parent node and the process is repeated. Below is the decision tree produced by the first two splits. Notice that the first split is on the <code>Temp</code> predictor, and the second split is on the <code>Wind</code> predictor. Although we don’t have coefficients for these two predictors like we would in a linear model, we can still interpret the order of the splits as the predictor’s relative significance. In this case, <code>Temp</code> is the most significant predictor of <code>Ozone</code> followed by <code>Wind</code>. After two splits, the decision tree has three <strong>leaf nodes</strong>, which are those in the bottom row. We can also define the <strong>depth</strong> of the tree as the number rows in the tree below the root node (in this case depth = 2). Note that the sum of the observations in the leaf nodes equals the total number of observations (69 + 10 + 37 = 116), and so the percentages shown in the leaf nodes sum to 100%.</li>
</ol>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<ol start="4" style="list-style-type: decimal">
<li>Continuing the process once more, we see that the third split is again on <code>Temp</code> but at a different <span class="math inline">\(t_k\)</span>.</li>
</ol>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>If we continued to repeat the process until each observation was in its own node, then we would have drastically over-fit the model. To control over-fitting, we stop the splitting process when some user-defined condition (or set of conditions) is met. Example stopping conditions include a minimum number of observations in a node or a maximum depth of the tree. We can also use cross validation with a 1 standard error rule to limit the complexity of the final model.</p>
<p>We’ll stop at this point and visually represent this model as a scatter plot. The above leaves from left to right are labeled as Leaf 1 - 4 on the scatter plot.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Plotting predicted <code>Ozone</code> on the z-axis produces the following response surface, which highlights the step-like characteristic of regression tree predictions.</p>
<div id="htmlwidget-bd6d752361be19e012d0" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-bd6d752361be19e012d0">{"x":{"visdat":{"8e85ef37879":["function () ","plotlyVisDat"],"8e848e9cd0b":["function () ","data"]},"cur_data":"8e848e9cd0b","attrs":{"8e85ef37879":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"y":[57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97],"z":{},"type":"surface","opacity":0.90000000000000002,"showlegend":false,"inherit":true},"8e848e9cd0b":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"color":"black","size":3},"showlegend":false,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"CART Response Surface","showlegend":false,"scene":{"xaxis":{"title":"Wind"},"yaxis":{"title":"Temp"},"zaxis":{"title":"z"}},"hovermode":"closest"},"source":"A","config":{"showSendToCloud":false},"data":[{"colorbar":{"title":"z<br />Ozone","ticklen":2},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"y":[57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97],"z":[[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,55.600000000000001,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332,22.333333333333332],[62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003],[62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003],[62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003],[62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003],[62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003,62.950000000000003],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768],[90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768,90.058823529411768]],"type":"surface","opacity":0.90000000000000002,"showlegend":false,"frame":null},{"x":[7.4000000000000004,8,12.6,11.5,8.5999999999999996,13.800000000000001,20.100000000000001,9.6999999999999993,9.1999999999999993,10.9,13.199999999999999,11.5,12,18.399999999999999,11.5,9.6999999999999993,9.6999999999999993,16.600000000000001,9.6999999999999993,12,12,14.9,5.7000000000000002,7.4000000000000004,9.6999999999999993,13.800000000000001,11.5,8,14.9,20.699999999999999,9.1999999999999993,11.5,10.300000000000001,4.0999999999999996,9.1999999999999993,9.1999999999999993,4.5999999999999996,10.9,5.0999999999999996,6.2999999999999998,5.7000000000000002,7.4000000000000004,14.300000000000001,14.9,14.300000000000001,6.9000000000000004,10.300000000000001,6.2999999999999998,5.0999999999999996,11.5,6.9000000000000004,8.5999999999999996,8,8.5999999999999996,12,7.4000000000000004,7.4000000000000004,7.4000000000000004,9.1999999999999993,6.9000000000000004,13.800000000000001,7.4000000000000004,4,10.300000000000001,8,11.5,11.5,9.6999999999999993,10.300000000000001,6.2999999999999998,7.4000000000000004,10.9,10.300000000000001,15.5,14.300000000000001,9.6999999999999993,3.3999999999999999,8,9.6999999999999993,2.2999999999999998,6.2999999999999998,6.2999999999999998,6.9000000000000004,5.0999999999999996,2.7999999999999998,4.5999999999999996,7.4000000000000004,15.5,10.9,10.300000000000001,10.9,9.6999999999999993,14.9,15.5,6.2999999999999998,10.9,11.5,6.9000000000000004,13.800000000000001,10.300000000000001,10.300000000000001,8,12.6,9.1999999999999993,10.300000000000001,10.300000000000001,16.600000000000001,6.9000000000000004,14.300000000000001,8,11.5],"y":[67,72,74,62,65,59,61,69,66,68,58,64,66,57,68,62,59,73,61,61,67,81,79,76,82,90,87,82,77,72,65,73,76,84,85,81,83,83,88,92,92,89,73,81,80,81,82,84,87,85,74,86,85,82,86,88,86,83,81,81,81,82,89,90,90,86,82,80,77,79,76,78,78,77,72,79,81,86,97,94,96,94,91,92,93,93,87,84,80,78,75,73,81,76,77,71,71,78,67,76,68,82,64,71,81,69,63,70,75,76,68],"z":[41,36,12,18,23,19,8,16,11,14,18,14,34,6,30,11,1,11,4,32,23,45,115,37,29,71,39,23,21,37,20,12,13,135,49,32,64,40,77,97,97,85,10,27,7,48,35,61,79,63,16,80,108,20,52,82,50,64,59,39,9,16,122,89,110,44,28,65,22,59,23,31,44,21,9,45,168,73,76,118,84,85,96,78,73,91,47,32,20,23,21,24,44,21,28,9,13,46,18,13,24,16,13,23,36,7,14,30,14,18,20],"type":"scatter3d","mode":"markers","marker":{"color":"black","size":3,"line":{"color":"rgba(255,127,14,1)"}},"showlegend":false,"error_y":{"color":"rgba(255,127,14,1)"},"error_x":{"color":"rgba(255,127,14,1)"},"line":{"color":"rgba(255,127,14,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Plotting just <code>Temp</code> versus <code>Ozone</code> in two dimensions further highlights a difference between this method and linear regression. From this plot we can infer that linear regression may outperform CART if there is a smooth trend in the relationship between the predictors and response because CART does not produce smooth estimates.</p>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<div id="impurity-measure" class="section level4">
<h4><span class="header-section-number">11.5.1.1</span> Impurity Measure</h4>
<p>Previously, it was stated that the predictor-threshold pair chosen for a split was the pair that most increased the purity (or, decreased the impurity) of the child nodes. A node with all identical response values will have an impurity of 0, so that as a node becomes more impure, it’s impurity value increases. We will then define a node’s impurity to be proportional to the <strong>residual deviance</strong>, which for a continuous response variable like <code>Ozone</code>, is the residual sum of squares (RSS).</p>
<p><span class="math display">\[RSS = \sum\limits_{i\:in\: Node}{(y_{i} - \bar{y})^2}\]</span></p>
<p>where <span class="math inline">\(\bar{y}\)</span> is the mean of the y’s in the node.</p>
<p>We’ll start with the first split. To determine which predictor-threshold pair decreases impurity the most, start with the first factor, send the lowest <code>Ozone</code> value to the left node and the remainder to the right node, and calculate RSS for each child node (<span class="math inline">\(RSS_{left}\)</span> and <span class="math inline">\(RSS_{right}\)</span>). The decrease in impurity for this split is <span class="math inline">\(RSS_{root} - (RSS_{left} + RSS_{right})\)</span>. Then send the lowest two <code>Ozone</code> values to the left node and the remainder to the right. Repeat this process for each predictor-threshold pair, and split the data based using the pair that decreased impurity the most. Any regression tree package will iterate through all of these combinations for you, but to demonstrate the process explicitly, We’ll just consider the <code>Temp</code> predictor for the first split.</p>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb852-1" data-line-number="1"><span class="co"># we&#39;ll do a lot of filtering, so convert dataframe to tibble for convenience</span></a>
<a class="sourceLine" id="cb852-2" data-line-number="2"><span class="co"># we&#39;ll also drop the NA&#39;s for the calculations (but the regression tree</span></a>
<a class="sourceLine" id="cb852-3" data-line-number="3"><span class="co"># methodology itself doesn&#39;t care if there are NA&#39;s or not)</span></a>
<a class="sourceLine" id="cb852-4" data-line-number="4">aq  =<span class="st"> </span><span class="kw">as_tibble</span>(airquality) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>(Ozone)</a>
<a class="sourceLine" id="cb852-5" data-line-number="5"></a>
<a class="sourceLine" id="cb852-6" data-line-number="6"><span class="co"># root node deviance</span></a>
<a class="sourceLine" id="cb852-7" data-line-number="7">root_dev =<span class="st"> </span><span class="kw">sum</span>((aq<span class="op">$</span>Ozone <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(aq<span class="op">$</span>Ozone))<span class="op">^</span><span class="dv">2</span>) </a>
<a class="sourceLine" id="cb852-8" data-line-number="8"></a>
<a class="sourceLine" id="cb852-9" data-line-number="9"><span class="co"># keep track of the highest decrease</span></a>
<a class="sourceLine" id="cb852-10" data-line-number="10">best_split =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb852-11" data-line-number="11"></a>
<a class="sourceLine" id="cb852-12" data-line-number="12"><span class="co"># iterate through all the unique Temp values</span></a>
<a class="sourceLine" id="cb852-13" data-line-number="13"><span class="cf">for</span>(s <span class="cf">in</span> <span class="kw">sort</span>(<span class="kw">unique</span>(aq<span class="op">$</span>Temp))){</a>
<a class="sourceLine" id="cb852-14" data-line-number="14">  left_node =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Temp <span class="op">&lt;=</span><span class="st"> </span>s) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>Ozone</a>
<a class="sourceLine" id="cb852-15" data-line-number="15">  left_dev =<span class="st"> </span><span class="kw">sum</span>((left_node <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(left_node))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb852-16" data-line-number="16">  right_node =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Temp <span class="op">&gt;</span><span class="st"> </span>s) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>Ozone</a>
<a class="sourceLine" id="cb852-17" data-line-number="17">  right_dev =<span class="st"> </span><span class="kw">sum</span>((right_node <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(right_node))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb852-18" data-line-number="18">  split_dev =<span class="st"> </span>root_dev <span class="op">-</span><span class="st"> </span>(left_dev <span class="op">+</span><span class="st"> </span>right_dev)</a>
<a class="sourceLine" id="cb852-19" data-line-number="19">  <span class="cf">if</span>(split_dev <span class="op">&gt;</span><span class="st"> </span>best_split){</a>
<a class="sourceLine" id="cb852-20" data-line-number="20">    best_split =<span class="st"> </span>split_dev</a>
<a class="sourceLine" id="cb852-21" data-line-number="21">    temp =<span class="st"> </span>s <span class="op">+</span><span class="st"> </span><span class="dv">1</span>}  <span class="co"># + 1 because we filtered Temp &lt;= s and Temp is integer</span></a>
<a class="sourceLine" id="cb852-22" data-line-number="22">}</a>
<a class="sourceLine" id="cb852-23" data-line-number="23"></a>
<a class="sourceLine" id="cb852-24" data-line-number="24"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;Best split at Temp &lt;&quot;</span>, temp), <span class="dt">quote=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] Best split at Temp &lt; 83</code></pre>
</div>
<div id="tree-deviance" class="section level4">
<h4><span class="header-section-number">11.5.1.2</span> Tree Deviance</h4>
<p>Armed with our impurity measure, we can also calculate the tree deviance, which we’ll use to calculate the regression tree equivalent of <span class="math inline">\(R^2\)</span>. For the tree with the four leaf nodes, we calculate the deviance for each leaf.</p>
<div class="sourceCode" id="cb854"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb854-1" data-line-number="1"><span class="co"># leaf 1</span></a>
<a class="sourceLine" id="cb854-2" data-line-number="2">leaf_<span class="dv">1</span> =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Temp <span class="op">&lt;</span><span class="st"> </span><span class="dv">83</span> <span class="op">&amp;</span><span class="st"> </span>Wind <span class="op">&gt;=</span><span class="st"> </span><span class="fl">7.15</span>) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>Ozone</a>
<a class="sourceLine" id="cb854-3" data-line-number="3">leaf_<span class="dv">1</span>_dev =<span class="st"> </span><span class="kw">sum</span>((leaf_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(leaf_<span class="dv">1</span>))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb854-4" data-line-number="4"><span class="co"># leaf 2</span></a>
<a class="sourceLine" id="cb854-5" data-line-number="5">leaf_<span class="dv">2</span> =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Temp <span class="op">&lt;</span><span class="st"> </span><span class="dv">83</span> <span class="op">&amp;</span><span class="st"> </span>Wind <span class="op">&lt;</span><span class="st"> </span><span class="fl">7.15</span>) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>Ozone</a>
<a class="sourceLine" id="cb854-6" data-line-number="6">leaf_<span class="dv">2</span>_dev =<span class="st"> </span><span class="kw">sum</span>((leaf_<span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(leaf_<span class="dv">2</span>))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb854-7" data-line-number="7"><span class="co"># leaf 3</span></a>
<a class="sourceLine" id="cb854-8" data-line-number="8">leaf_<span class="dv">3</span> =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Temp <span class="op">&gt;=</span><span class="st"> </span><span class="dv">83</span> <span class="op">&amp;</span><span class="st"> </span>Temp <span class="op">&lt;</span><span class="st"> </span><span class="dv">88</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>(Ozone) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>Ozone</a>
<a class="sourceLine" id="cb854-9" data-line-number="9">leaf_<span class="dv">3</span>_dev =<span class="st"> </span><span class="kw">sum</span>((leaf_<span class="dv">3</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(leaf_<span class="dv">3</span>))<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb854-10" data-line-number="10"><span class="co"># leaf 4</span></a>
<a class="sourceLine" id="cb854-11" data-line-number="11">leaf_<span class="dv">4</span> =<span class="st"> </span>aq <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Temp <span class="op">&gt;=</span><span class="st"> </span><span class="dv">88</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>(Ozone) <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>Ozone</a>
<a class="sourceLine" id="cb854-12" data-line-number="12">leaf_<span class="dv">4</span>_dev =<span class="st"> </span><span class="kw">sum</span>((leaf_<span class="dv">4</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(leaf_<span class="dv">4</span>))<span class="op">^</span><span class="dv">2</span>)</a></code></pre></div>
<p>The tree deviance is the sum of the leaf node deviances, which we use to determine how much the entire tree decreases the root deviance.</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb855-1" data-line-number="1">tree_dev =<span class="st"> </span><span class="kw">sum</span>(leaf_<span class="dv">1</span>_dev, leaf_<span class="dv">2</span>_dev, leaf_<span class="dv">3</span>_dev, leaf_<span class="dv">4</span>_dev)</a>
<a class="sourceLine" id="cb855-2" data-line-number="2"></a>
<a class="sourceLine" id="cb855-3" data-line-number="3">(root_dev <span class="op">-</span><span class="st"> </span>tree_dev) <span class="op">/</span><span class="st"> </span>root_dev</a></code></pre></div>
<pre><code>## [1] 0.6119192</code></pre>
<p>The tree decreases the root deviance by 61.2%, which also means that 61.2% of the variability in <code>Ozone</code> is explained by the tree.</p>
</div>
<div id="prediction" class="section level4">
<h4><span class="header-section-number">11.5.1.3</span> Prediction</h4>
<p>Making a prediction with a new value is easy as following the logic of the decision tree until you end up in a leaf node. The mean of the response values for that leaf node is the prediction for the new value.</p>
</div>
<div id="pros-and-cons" class="section level4">
<h4><span class="header-section-number">11.5.1.4</span> Pros And Cons</h4>
<p>Regression trees have a lot of good things going for them:</p>
<ul>
<li>They are easy to explain combined with an intuitive graphic output</li>
<li>They can handle categorical and numeric predictor and response variables</li>
<li>They easily handle missing data</li>
<li>They are robust to outliers</li>
<li>They make no assumptions about normality</li>
<li>They can accommodate “wide” data (more predictors than observations)</li>
<li>They automatically include interactions</li>
</ul>
<p>Regression trees by themselves and as presented so far have two major drawbacks:</p>
<ul>
<li>They do not tend to perform as well as other methods (but there’s a plan for this that makes them one of the best prediction methods around)</li>
<li>They do not capture simple additive structure (there’s a plan for this, too)</li>
</ul>
</div>
<div id="regression-trees-in-r" class="section level4">
<h4><span class="header-section-number">11.5.1.5</span> Regression Trees in <em>R</em></h4>
<p>The regression trees shown above were grown using the <code>rpart</code> and <code>rpart.plot</code> packages. I didn’t show the code so that we could focus on the algorithm first. Growing a regression tree is as easy as a linear model. The object created by <code>rpart()</code> contains some useful information.</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb857-1" data-line-number="1"><span class="kw">library</span>(rpart)</a>
<a class="sourceLine" id="cb857-2" data-line-number="2"><span class="kw">library</span>(rpart.plot)</a>
<a class="sourceLine" id="cb857-3" data-line-number="3"></a>
<a class="sourceLine" id="cb857-4" data-line-number="4">aq.tree =<span class="st"> </span><span class="kw">rpart</span>(Ozone <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>airquality)</a>
<a class="sourceLine" id="cb857-5" data-line-number="5"></a>
<a class="sourceLine" id="cb857-6" data-line-number="6">aq.tree</a></code></pre></div>
<pre><code>## n=116 (37 observations deleted due to missingness)
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 116 125143.1000 42.12931  
##    2) Temp&lt; 82.5 79  42531.5900 26.54430  
##      4) Wind&gt;=7.15 69  10919.3300 22.33333  
##        8) Solar.R&lt; 79.5 18    777.1111 12.22222 *
##        9) Solar.R&gt;=79.5 51   7652.5100 25.90196  
##         18) Temp&lt; 77.5 33   2460.9090 21.18182 *
##         19) Temp&gt;=77.5 18   3108.4440 34.55556 *
##      5) Wind&lt; 7.15 10  21946.4000 55.60000 *
##    3) Temp&gt;=82.5 37  22452.9200 75.40541  
##      6) Temp&lt; 87.5 20  12046.9500 62.95000  
##       12) Wind&gt;=8.9 7    617.7143 45.57143 *
##       13) Wind&lt; 8.9 13   8176.7690 72.30769 *
##      7) Temp&gt;=87.5 17   3652.9410 90.05882 *</code></pre>
<p>First, we see that the NAs were deleted, and then we see the tree structure in a text format that includes the node number, how the node was split, the number of observations in the node, the deviance, and the mean response. To plot the tree, use <code>rpart.plot()</code> or <code>prp()</code>.</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb859-1" data-line-number="1"><span class="kw">rpart.plot</span>(aq.tree)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p><code>rpart.plot()</code> provides several options for customizing the plot, among them are <code>digits</code>, <code>type</code>, and <code>extra</code>, which I invoked to produce the earlier plots. Refer to the help to see all of the options.</p>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb860-1" data-line-number="1"><span class="kw">rpart.plot</span>(aq.tree, <span class="dt">digits =</span> <span class="dv">3</span>, <span class="dt">type=</span><span class="dv">4</span>, <span class="dt">extra=</span><span class="dv">101</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Another useful function is <code>printcp()</code>, which provides a deeper glimpse into what’s going on in the algorithm. Here we see that just three predictors were used to grow the tree (<code>Solar.R</code>, <code>Temp</code>, and <code>Wind</code>). This means that the other predictors did not significantly contribute to increasing node purity, which is equivalent to a predictor in a linear model with a high p-value. We also see the root node error (weighted by the number of observations in the root node).</p>
<p>In the table, <code>printcp()</code> provides optimal tuning based on a <strong>complexity parameter</strong> (<code>CP</code>), which we can manipulate to manually “prune” the tree, if desired. The relative error column is the amount of reduction in root deviance for each split. For example, in our earlier example with three splits and four leaf nodes, we had a 61.2% reduction in root deviance, and below we see that at an <code>nsplit</code> of 3, we also get <span class="math inline">\(1.000 - 0.388 = 61.2\)</span>%.<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a> <code>xerror</code> and <code>xstd</code> are cross-validation error and standard deviation, respectfully, so we get cross validation built-in for free!</p>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb861-1" data-line-number="1"><span class="kw">printcp</span>(aq.tree)</a></code></pre></div>
<pre><code>## 
## Regression tree:
## rpart(formula = Ozone ~ ., data = airquality)
## 
## Variables actually used in tree construction:
## [1] Solar.R Temp    Wind   
## 
## Root node error: 125143/116 = 1078.8
## 
## n=116 (37 observations deleted due to missingness)
## 
##         CP nsplit rel error  xerror    xstd
## 1 0.480718      0   1.00000 1.01865 0.16890
## 2 0.077238      1   0.51928 0.61672 0.19729
## 3 0.053962      2   0.44204 0.68502 0.18631
## 4 0.025990      3   0.38808 0.53568 0.15111
## 5 0.019895      4   0.36209 0.53216 0.15103
## 6 0.016646      5   0.34220 0.54833 0.16382
## 7 0.010000      6   0.32555 0.53996 0.16385</code></pre>
<p>With <code>plotcp()</code> we can see the 1 standard error rule implemented in the same manner we’ve seen before to identify the best fit model. At the top of the plot, the number of splits is displayed so that we can choose two splits when defining the best fit model.</p>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb863-1" data-line-number="1"><span class="kw">plotcp</span>(aq.tree, <span class="dt">upper =</span> <span class="st">&quot;splits&quot;</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>Specify the best fit model using the <code>cp</code> parameter with a value slightly greater than shown in the table.</p>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb864-1" data-line-number="1">best_aq.tree =<span class="st"> </span><span class="kw">rpart</span>(Ozone <span class="op">~</span><span class="st"> </span>., <span class="dt">cp=</span><span class="fl">0.055</span>, <span class="dt">data=</span>airquality)</a>
<a class="sourceLine" id="cb864-2" data-line-number="2"></a>
<a class="sourceLine" id="cb864-3" data-line-number="3"><span class="kw">rpart.plot</span>(best_aq.tree)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<p>As with <code>lm()</code> objects, the <code>summary()</code> function provides a wealth of information. Note the results following variable importance. Earlier we opined that the first split on <code>Temp</code> indicated that is was the most significant predictor followed by <code>Wind</code>. The <code>rpart</code> documentation provides a detailed description of variable importance:</p>
<blockquote>
<p>An overall measure of variable importance is the sum of the goodness of split measures for each split for which it was the primary variable, plus goodness * (adjusted agreement) for all splits in which it was a surrogate.</p>
</blockquote>
<p>Note that the results are scaled so that they sum to 100, which is useful for directly comparing each predictor’s relative contribution.</p>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb865-1" data-line-number="1"><span class="kw">summary</span>(aq.tree)</a></code></pre></div>
<pre><code>## Call:
## rpart(formula = Ozone ~ ., data = airquality)
##   n=116 (37 observations deleted due to missingness)
## 
##           CP nsplit rel error    xerror      xstd
## 1 0.48071820      0 1.0000000 1.0186538 0.1689020
## 2 0.07723849      1 0.5192818 0.6167174 0.1972945
## 3 0.05396246      2 0.4420433 0.6850207 0.1863083
## 4 0.02598999      3 0.3880808 0.5356794 0.1511121
## 5 0.01989493      4 0.3620909 0.5321568 0.1510310
## 6 0.01664620      5 0.3421959 0.5483283 0.1638152
## 7 0.01000000      6 0.3255497 0.5399625 0.1638533
## 
## Variable importance
##    Temp    Wind     Day Solar.R   Month 
##      60      28       8       2       2 
## 
## Node number 1: 116 observations,    complexity param=0.4807182
##   mean=42.12931, MSE=1078.819 
##   left son=2 (79 obs) right son=3 (37 obs)
##   Primary splits:
##       Temp    &lt; 82.5  to the left,  improve=0.48071820, (0 missing)
##       Wind    &lt; 6.6   to the right, improve=0.40426690, (0 missing)
##       Solar.R &lt; 153   to the left,  improve=0.21080020, (5 missing)
##       Month   &lt; 6.5   to the left,  improve=0.11595770, (0 missing)
##       Day     &lt; 24.5  to the left,  improve=0.08216807, (0 missing)
##   Surrogate splits:
##       Wind &lt; 6.6   to the right, agree=0.776, adj=0.297, (0 split)
##       Day  &lt; 10.5  to the right, agree=0.724, adj=0.135, (0 split)
## 
## Node number 2: 79 observations,    complexity param=0.07723849
##   mean=26.5443, MSE=538.3746 
##   left son=4 (69 obs) right son=5 (10 obs)
##   Primary splits:
##       Wind    &lt; 7.15  to the right, improve=0.22726310, (0 missing)
##       Temp    &lt; 77.5  to the left,  improve=0.22489660, (0 missing)
##       Day     &lt; 24.5  to the left,  improve=0.13807170, (0 missing)
##       Solar.R &lt; 153   to the left,  improve=0.10449720, (2 missing)
##       Month   &lt; 8.5   to the right, improve=0.01924449, (0 missing)
## 
## Node number 3: 37 observations,    complexity param=0.05396246
##   mean=75.40541, MSE=606.8356 
##   left son=6 (20 obs) right son=7 (17 obs)
##   Primary splits:
##       Temp    &lt; 87.5  to the left,  improve=0.300763900, (0 missing)
##       Wind    &lt; 10.6  to the right, improve=0.273929800, (0 missing)
##       Solar.R &lt; 273.5 to the right, improve=0.114526900, (3 missing)
##       Day     &lt; 6.5   to the left,  improve=0.048950680, (0 missing)
##       Month   &lt; 7.5   to the left,  improve=0.007595265, (0 missing)
##   Surrogate splits:
##       Wind  &lt; 6.6   to the right, agree=0.676, adj=0.294, (0 split)
##       Month &lt; 7.5   to the left,  agree=0.649, adj=0.235, (0 split)
##       Day   &lt; 27.5  to the left,  agree=0.622, adj=0.176, (0 split)
## 
## Node number 4: 69 observations,    complexity param=0.01989493
##   mean=22.33333, MSE=158.2512 
##   left son=8 (18 obs) right son=9 (51 obs)
##   Primary splits:
##       Solar.R &lt; 79.5  to the left,  improve=0.22543670, (1 missing)
##       Temp    &lt; 77.5  to the left,  improve=0.21455360, (0 missing)
##       Day     &lt; 27    to the left,  improve=0.05183544, (0 missing)
##       Wind    &lt; 10.6  to the right, improve=0.04850548, (0 missing)
##       Month   &lt; 8.5   to the right, improve=0.01998100, (0 missing)
##   Surrogate splits:
##       Temp &lt; 63.5  to the left,  agree=0.794, adj=0.222, (1 split)
##       Wind &lt; 16.05 to the right, agree=0.750, adj=0.056, (0 split)
## 
## Node number 5: 10 observations
##   mean=55.6, MSE=2194.64 
## 
## Node number 6: 20 observations,    complexity param=0.02598999
##   mean=62.95, MSE=602.3475 
##   left son=12 (7 obs) right son=13 (13 obs)
##   Primary splits:
##       Wind    &lt; 8.9   to the right, improve=0.269982600, (0 missing)
##       Month   &lt; 7.5   to the right, improve=0.078628670, (0 missing)
##       Day     &lt; 18.5  to the left,  improve=0.073966850, (0 missing)
##       Solar.R &lt; 217.5 to the left,  improve=0.058145680, (3 missing)
##       Temp    &lt; 85.5  to the right, improve=0.007674142, (0 missing)
## 
## Node number 7: 17 observations
##   mean=90.05882, MSE=214.8789 
## 
## Node number 8: 18 observations
##   mean=12.22222, MSE=43.17284 
## 
## Node number 9: 51 observations,    complexity param=0.0166462
##   mean=25.90196, MSE=150.0492 
##   left son=18 (33 obs) right son=19 (18 obs)
##   Primary splits:
##       Temp    &lt; 77.5  to the left,  improve=0.27221870, (0 missing)
##       Wind    &lt; 10.6  to the right, improve=0.09788213, (0 missing)
##       Day     &lt; 22.5  to the left,  improve=0.07292523, (0 missing)
##       Month   &lt; 8.5   to the right, improve=0.04981065, (0 missing)
##       Solar.R &lt; 255   to the right, improve=0.03603008, (1 missing)
##   Surrogate splits:
##       Month &lt; 6.5   to the left,  agree=0.686, adj=0.111, (0 split)
##       Wind  &lt; 10.6  to the right, agree=0.667, adj=0.056, (0 split)
## 
## Node number 12: 7 observations
##   mean=45.57143, MSE=88.2449 
## 
## Node number 13: 13 observations
##   mean=72.30769, MSE=628.9822 
## 
## Node number 18: 33 observations
##   mean=21.18182, MSE=74.573 
## 
## Node number 19: 18 observations
##   mean=34.55556, MSE=172.6914</code></pre>
<p>The best fit model contains two predictors and explains 55.8% of the variance in <code>Ozone</code> as shown below.</p>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb867-1" data-line-number="1"><span class="kw">printcp</span>(best_aq.tree)</a></code></pre></div>
<pre><code>## 
## Regression tree:
## rpart(formula = Ozone ~ ., data = airquality, cp = 0.055)
## 
## Variables actually used in tree construction:
## [1] Temp Wind
## 
## Root node error: 125143/116 = 1078.8
## 
## n=116 (37 observations deleted due to missingness)
## 
##         CP nsplit rel error  xerror    xstd
## 1 0.480718      0   1.00000 1.00498 0.16717
## 2 0.077238      1   0.51928 0.56181 0.17679
## 3 0.055000      2   0.44204 0.58220 0.18019</code></pre>
<p>How does it compare to a linear model with the same two predictors? The linear model explains 56.1% of the variance in <code>Ozone</code>, which is only slightly more than the regression tree. Earlier I claimed there was a plan for improving the performance of regression trees. That plan is revealed in the next section on Random Forests.</p>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb869-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">lm</span>(Ozone<span class="op">~</span>Wind <span class="op">+</span><span class="st"> </span>Temp, <span class="dt">data=</span>airquality))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Ozone ~ Wind + Temp, data = airquality)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -41.251 -13.695  -2.856  11.390 100.367 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -71.0332    23.5780  -3.013   0.0032 ** 
## Wind         -3.0555     0.6633  -4.607 1.08e-05 ***
## Temp          1.8402     0.2500   7.362 3.15e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.85 on 113 degrees of freedom
##   (37 observations deleted due to missingness)
## Multiple R-squared:  0.5687, Adjusted R-squared:  0.5611 
## F-statistic:  74.5 on 2 and 113 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="random-forest-regression" class="section level3">
<h3><span class="header-section-number">11.5.2</span> Random Forest Regression</h3>
<p>In 1994, Leo Breiman at UC, Berkeley published <a href="https://www.stat.berkeley.edu/~breiman/bagging.pdf">this paper</a> in which he presented a method he called <strong>Bootstrap AGGregation</strong> (or BAGGing) that improves the predictive power of regression trees by growing many trees (a forest) using bootstrapping techniques (thereby making it a random forest). The details are explained in the link to the paper above, but in short, we grow many trees, each on a bootstrapped sample of the training set (i.e., sample <span class="math inline">\(n\)</span> times <em>with replacement</em> from a data set of size <span class="math inline">\(n\)</span>). Then, to make a prediction, we either let each tree “vote” and predict based on the most votes, or we use the average of the estimated responses. Cross-validation isn’t necessary with this method because each bootstrapped tree has an internal error, referred to as the <strong>out-of-bag (OOB) error</strong>. With this method, about a third of the samples are left out of the bootstrapped sample, a prediction is made, and the OOB error calculated. The algorithm stops when the OOB error begins to increase.</p>
<p>A drawback of the method is that larger trees tend to be correlated with each other, and so <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">in a 2001 paper</a>, Breiman developed a method to lower the correlation between trees. For each bootstrapped sample, his idea was to use a random selection of predictors to split each node. The number of randomly selected predictors, <strong>mtry</strong>, is a function of the total number of predictors in the data set. For regression, the <code>randomForest()</code> function from the <code>randomForest</code> package uses <span class="math inline">\(1/k\)</span> as the default <code>mtry</code> value, but this can be manually specified. The following code chunks demonstrate the use of some of the <code>randomForest</code> functions. First, we fit a random forest model and specify that we want to assess the importance of predictors, omit <code>NA</code>s, and randomly sample two predictors at each split (<code>mtry</code>). There are a host of other parameters that can be specified, but we’ll keep them all at their default settings for this example.</p>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb871-1" data-line-number="1"><span class="kw">library</span>(randomForest)</a>
<a class="sourceLine" id="cb871-2" data-line-number="2"></a>
<a class="sourceLine" id="cb871-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb871-4" data-line-number="4"></a>
<a class="sourceLine" id="cb871-5" data-line-number="5">aq.rf&lt;-<span class="st"> </span><span class="kw">randomForest</span>(Ozone<span class="op">~</span>., <span class="dt">importance=</span><span class="ot">TRUE</span>, <span class="dt">na.action=</span>na.omit, <span class="dt">mtry=</span><span class="dv">2</span>, <span class="dt">data=</span>airquality)</a>
<a class="sourceLine" id="cb871-6" data-line-number="6">aq.rf</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Ozone ~ ., data = airquality, importance = TRUE,      mtry = 2, na.action = na.omit) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##           Mean of squared residuals: 301.7377
##                     % Var explained: 72.5</code></pre>
<p>This random forest model consists of 500 trees and explains 72.% of the variance in <code>Ozone</code>, which is a nice improvement over the 55.8% we got with the single regression tree. Plotting the <code>aq.rf</code> object shows the error as a function of the size of the forest. We want to see the error stabilize as the number of trees increases, which it does in the plot below.</p>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb873-1" data-line-number="1"><span class="kw">plot</span>(aq.rf)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<div id="interpretation" class="section level4">
<h4><span class="header-section-number">11.5.2.1</span> Interpretation</h4>
<p>When the relationships between predictors and response are non-linear and complex, random forest models generally perform better than standard linear models. However, the increase in predictive power comes with a corresponding decrease in interpretability. For this reason, random forests and some other machine learning-based models such as neural networks are sometimes referred to as “black box” models. If you are applying machine learning techniques to build a model that performs optical character recognition, you might not be terribly concerned about the interpretability of your model. However, if your model will be used to inform a decision maker, interpretability is much more important - especially if you are asked to explain the model to the decision maker. In fact, some machine learning practitioners argue against using black box models for all high stakes decision making. For example, read <a href="https://arxiv.org/pdf/1811.10154.pdf">this paper</a> by Cynthia Rudin, a computer scientist at Duke University. Recently, advancements have been made in improving the interpretability of some types of machine learning models (for example, download and read <a href="https://www.h2o.ai/resources/ebook/introduction-to-machine-learning-interpretability/">this paper from h2o.ai</a> or <a href="https://christophm.github.io/interpretable-ml-book/">this e-book</a> by Christoph Molnar, a Ph.D. candidate at the University of Munich), and we will explore these techniques below.</p>
<p>Linear models have coefficients (the <span class="math inline">\(\beta\)</span>s) that explain the nature of the relationship between predictors and the response. Classification and regression trees have an analogous concept of variable importance, which can be extended to random forest models. The documentation for <code>importance()</code> from the <code>randomForest</code> package provides the following definitions of two variable importance measures:</p>
<blockquote>
<p>The first measure is computed from permuting OOB data: For each tree, the prediction error on the out-of-bag portion of the data is recorded (error rate for classification, MSE for regression). Then the same is done after permuting each predictor variable. The difference between the two are then averaged over all trees, and normalized by the standard deviation of the differences. If the standard deviation of the differences is equal to 0 for a variable, the division is not done (but the average is almost always equal to 0 in that case).</p>
</blockquote>
<blockquote>
<p>The second measure is the total decrease in node impurities from splitting on the variable, averaged over all trees. For classification, the node impurity is measured by the Gini index. For regression, it is measured by residual sum of squares.</p>
</blockquote>
<p>These two measures can be accessed with:</p>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb874-1" data-line-number="1"><span class="kw">importance</span>(aq.rf)</a></code></pre></div>
<pre><code>##           %IncMSE IncNodePurity
## Solar.R 13.495267     15939.238
## Wind    19.989633     39498.922
## Temp    37.489127     48112.583
## Month    4.053344      4160.278
## Day      3.052987      9651.722</code></pre>
<p>Alternatively, we can plot variable importance with <code>varImpPlot()</code>.</p>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb876-1" data-line-number="1"><span class="kw">varImpPlot</span>(aq.rf)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<p>Variable importance can be related to a linear model coefficient in that a large variable importance value is akin to a large coefficient value. However, it doesn’t indicate whether the coefficient is positive or negative. For example, from the above plot, we see that <code>Temp</code> is an important predictor of <code>Ozone</code>, but we don’t know if increasing temperatures result in increasing or decreasing ozone measurements (or if it’s a non-linear relationship). <strong>Partial dependence</strong> plots (PDP) were developed to solve this problem, and they can be interpreted in the same way as a loess or spline smoother.</p>
<p>For the <code>airquality</code> data, one would expect that increasing temperatures would increase ozone concentrations, and that increasing wind speed would decrease ozone concentrations. The <code>partialPlot()</code> function provided with the <code>randomForest</code> package produces PDPs, but they are basic and difficult to customize. Instead, we’ll use the <code>pdp</code> package, which works nicely with <code>ggplot2</code> and includes a loess smoother (another option is the <code>iml</code> package - for interpretable machine learning - which we’ll also explore).</p>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb877-1" data-line-number="1"><span class="co">#library(pdp)</span></a>
<a class="sourceLine" id="cb877-2" data-line-number="2"></a>
<a class="sourceLine" id="cb877-3" data-line-number="3">p3 =<span class="st"> </span>aq.rf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb877-4" data-line-number="4"><span class="st">  </span>pdp<span class="op">::</span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Temp&quot;</span>) <span class="op">%&gt;%</span><span class="st">                        </span><span class="co"># from the pdp package</span></a>
<a class="sourceLine" id="cb877-5" data-line-number="5"><span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">smooth =</span> <span class="ot">TRUE</span>, <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">f</span>(Temp))) <span class="op">+</span></a>
<a class="sourceLine" id="cb877-6" data-line-number="6"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb877-7" data-line-number="7"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Partial Dependence of Temp&quot;</span>)</a>
<a class="sourceLine" id="cb877-8" data-line-number="8"></a>
<a class="sourceLine" id="cb877-9" data-line-number="9">p4 =<span class="st"> </span>aq.rf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb877-10" data-line-number="10"><span class="st">  </span>pdp<span class="op">::</span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Wind&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb877-11" data-line-number="11"><span class="st">  </span><span class="kw">autoplot</span>(<span class="dt">smooth =</span> <span class="ot">TRUE</span>, <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">f</span>(Temp))) <span class="op">+</span></a>
<a class="sourceLine" id="cb877-12" data-line-number="12"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb877-13" data-line-number="13"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Partial Dependence of Wind&quot;</span>)</a>
<a class="sourceLine" id="cb877-14" data-line-number="14"></a>
<a class="sourceLine" id="cb877-15" data-line-number="15">gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p3, p4, <span class="dt">ncol=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<p>Earlier, we produced a response surface plot based on a regression tree. Now we can produce a response surface based on the random forest model, which looks similar but more detailed. Specifying <code>chull = TRUE</code> (chull stands for convex hull) limits the plot to the range of values in the training data set, which prevents predictions being shown for regions in which there is no data. A 2D heat map and a 3D mesh are shown below.</p>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb878-1" data-line-number="1"><span class="co"># Compute partial dependence data for Wind and Temp</span></a>
<a class="sourceLine" id="cb878-2" data-line-number="2">pd =<span class="st"> </span>pdp<span class="op">::</span><span class="kw">partial</span>(aq.rf, <span class="dt">pred.var =</span> <span class="kw">c</span>(<span class="st">&quot;Wind&quot;</span>, <span class="st">&quot;Temp&quot;</span>), <span class="dt">chull =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb878-3" data-line-number="3"></a>
<a class="sourceLine" id="cb878-4" data-line-number="4"><span class="co"># Default PDP</span></a>
<a class="sourceLine" id="cb878-5" data-line-number="5">pdp1 =<span class="st"> </span>pdp<span class="op">::</span><span class="kw">plotPartial</span>(pd)</a>
<a class="sourceLine" id="cb878-6" data-line-number="6"></a>
<a class="sourceLine" id="cb878-7" data-line-number="7"><span class="co"># 3-D surface</span></a>
<a class="sourceLine" id="cb878-8" data-line-number="8">pdp2 =<span class="st"> </span>pdp<span class="op">::</span><span class="kw">plotPartial</span>(pd, <span class="dt">levelplot =</span> <span class="ot">FALSE</span>, <span class="dt">zlab =</span> <span class="st">&quot;Ozone&quot;</span>,</a>
<a class="sourceLine" id="cb878-9" data-line-number="9">                    <span class="dt">screen =</span> <span class="kw">list</span>(<span class="dt">z =</span> <span class="dv">-20</span>, <span class="dt">x =</span> <span class="dv">-60</span>))</a>
<a class="sourceLine" id="cb878-10" data-line-number="10"></a>
<a class="sourceLine" id="cb878-11" data-line-number="11">gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(pdp1, pdp2, <span class="dt">ncol=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<p>The <code>iml</code> package was developed by Christoph Molnar, the Ph.D. candidate referred to earlier, and contains a number of useful functions to aid in model interpretation. In machine learning vernacular, predictors are commonly called features, so instead of variable importance, we’ll get feature importance. With this package, we can calculate feature importance and produce PDPs as well, and a grid of partial dependence plots are shown below. Note the addition of a rug plot at the bottom of each subplot, which helps identify regions where observations are sparse and where the model might not perform as well.</p>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb879-1" data-line-number="1"><span class="co">#library(iml) # for interpretable machine learning</span></a>
<a class="sourceLine" id="cb879-2" data-line-number="2"><span class="co">#library(patchwork) # for arranging plots - similar to gridExtra</span></a>
<a class="sourceLine" id="cb879-3" data-line-number="3"></a>
<a class="sourceLine" id="cb879-4" data-line-number="4"><span class="co"># iml doesn&#39;t like NAs, so we&#39;ll drop them from the data and re-fit the model</span></a>
<a class="sourceLine" id="cb879-5" data-line-number="5">aq =<span class="st"> </span>airquality <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>()</a>
<a class="sourceLine" id="cb879-6" data-line-number="6">aq.rf2 =<span class="st"> </span><span class="kw">randomForest</span>(Ozone<span class="op">~</span>., <span class="dt">importance=</span><span class="ot">TRUE</span>, <span class="dt">na.action=</span>na.omit, <span class="dt">mtry=</span><span class="dv">2</span>, <span class="dt">data=</span>aq)</a>
<a class="sourceLine" id="cb879-7" data-line-number="7"></a>
<a class="sourceLine" id="cb879-8" data-line-number="8"><span class="co"># provide the random forest model, the features, and the response</span></a>
<a class="sourceLine" id="cb879-9" data-line-number="9">predictor =<span class="st"> </span>iml<span class="op">::</span>Predictor<span class="op">$</span><span class="kw">new</span>(aq.rf2, <span class="dt">data =</span> aq[, <span class="dv">2</span><span class="op">:</span><span class="dv">6</span>], <span class="dt">y =</span> aq<span class="op">$</span>Ozone)</a>
<a class="sourceLine" id="cb879-10" data-line-number="10"></a>
<a class="sourceLine" id="cb879-11" data-line-number="11">PDP =<span class="st"> </span>iml<span class="op">::</span>FeatureEffects<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">method=</span><span class="st">&#39;pdp&#39;</span>)</a>
<a class="sourceLine" id="cb879-12" data-line-number="12">PDP<span class="op">$</span><span class="kw">plot</span>() <span class="op">&amp;</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<pre><code>## Warning: UNRELIABLE VALUE: Future (&#39;future_lapply-1&#39;) unexpectedly generated
## random numbers without specifying argument &#39;future.seed&#39;. There is a risk that
## those random numbers are not statistically sound and the overall results might
## be invalid. To fix this, specify &#39;future.seed=TRUE&#39;. This ensures that proper,
## parallel-safe random numbers are produced via the L&#39;Ecuyer-CMRG method. To
## disable this check, use &#39;future.seed=NULL&#39;, or set option &#39;future.rng.onMisuse&#39;
## to &quot;ignore&quot;.</code></pre>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>PDPs show the average feature effect, but if we’re interested in the effect for one or more individual observations, then an Individual Conditional Expectation (ICE) plot is useful. In the following plot, each black line represents one of the 111 observations in the data set, and the global partial dependence is shown in yellow. Since the individual lines are generally parallel, we can see that each individual observation follows the same general trend: increasing temperatures have little effect on ozone until around 76 degrees, at which point all observations increase. In the mid 80s, there are a few observations that have a decreasing trend while the majority continue to increase, which indicates temperature may be interacting with one or more other features. Generally speaking, however, since the individual lines are largely parallel, we can conclude that the partial dependence measure is a good representation of the whole data set.</p>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb881-1" data-line-number="1">ice =<span class="st"> </span>iml<span class="op">::</span>FeatureEffect<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">feature =</span> <span class="st">&quot;Temp&quot;</span>, <span class="dt">method=</span><span class="st">&#39;pdp+ice&#39;</span>) <span class="co">#center.at = min(aq$Temp))</span></a>
<a class="sourceLine" id="cb881-2" data-line-number="2">ice<span class="op">$</span><span class="kw">plot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>One of the nice attributes of tree-based models is their ability to capture interactions. The interaction effects can be explicitly measured and plotted as shown below. The x-axis scale is the percent of variance explained by interaction for each feature, so <code>Wind</code>, <code>Temp</code>, and <code>Solar.R</code> all have more than 10% of their variance explained by an interaction.</p>
<div class="sourceCode" id="cb882"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb882-1" data-line-number="1">interact =<span class="st"> </span>iml<span class="op">::</span>Interaction<span class="op">$</span><span class="kw">new</span>(predictor)</a>
<a class="sourceLine" id="cb882-2" data-line-number="2"><span class="kw">plot</span>(interact) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>To identify what the feature is interacting with, just specify the feature name. For example, <code>Temp</code> interactions are shown below.</p>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb883-1" data-line-number="1">interact =<span class="st"> </span>iml<span class="op">::</span>Interaction<span class="op">$</span><span class="kw">new</span>(predictor, <span class="dt">feature=</span><span class="st">&#39;Temp&#39;</span>)</a>
<a class="sourceLine" id="cb883-2" data-line-number="2"><span class="kw">plot</span>(interact) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
</div>
<div id="predictions" class="section level4">
<h4><span class="header-section-number">11.5.2.2</span> Predictions</h4>
<p>Predictions for new data are made the usual way with <code>predict()</code>, which is demonstrated below using the first two rows of the <code>airquality</code> data set.</p>
<div class="sourceCode" id="cb884"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb884-1" data-line-number="1"><span class="kw">predict</span>(aq.rf, airquality[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">6</span>)])</a></code></pre></div>
<pre><code>##        1        2 
## 38.50243 31.39827</code></pre>
</div>
</div>
<div id="random-forest-classification" class="section level3">
<h3><span class="header-section-number">11.5.3</span> Random Forest Classification</h3>
<p>For a classification example, we’ll skip over simple classification trees and jump straight to random forests. There is very little difference in syntax with the <code>randomForest()</code> function when performing classification instead of regression. For this demonstration, we’ll use the <code>iris</code> data set so we can compare results with the SVC results. We’ll use the same training and test sets as earlier.</p>
<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb886-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb886-2" data-line-number="2">iris.rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>iris_train, <span class="dt">importance=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb886-3" data-line-number="3"><span class="kw">print</span>(iris.rf)</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Species ~ ., data = iris_train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 4.17%
## Confusion matrix:
##            setosa versicolor virginica class.error
## setosa         40          0         0       0.000
## versicolor      0         37         3       0.075
## virginica       0          2        38       0.050</code></pre>
<p>The model seems to have a little trouble distinguishing virginica from versicolor. The linear SVC misclassified two observations in the test set, and the radial SVC misclassified one. Before we see how the random forest does, let’s make sure we grew enough trees. We can make a visual check by plotting the random forest object.</p>
<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb888-1" data-line-number="1"><span class="kw">plot</span>(iris.rf)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>No issue there! Looks like 500 trees was plenty. Taking a look at variable importance shows that petal width and length are far more important than sepal width and length.</p>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb889-1" data-line-number="1"><span class="kw">varImpPlot</span>(iris.rf)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<p>Since the response variable is categorical with three levels, a little work is required to get partial dependence plots for each predictor-response combination. Below are the partial dependence plots for <code>Petal.Width</code> for each species. The relationship between petal width and species varies significantly based on the species, which is what makes petal width have a high variable importance.</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb890-1" data-line-number="1"><span class="kw">as_tibble</span>(iris.rf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-2" data-line-number="2"><span class="st">  </span>pdp<span class="op">::</span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Petal.Width&quot;</span>, <span class="dt">which.class=</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># which.class refers to the factor level</span></a>
<a class="sourceLine" id="cb890-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> <span class="kw">levels</span>(iris<span class="op">$</span>Species)[<span class="dv">1</span>])) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-4" data-line-number="4"><span class="st">  </span><span class="kw">bind_rows</span>(<span class="kw">as_tibble</span>(iris.rf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-5" data-line-number="5"><span class="st">  </span>pdp<span class="op">::</span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Petal.Width&quot;</span>, <span class="dt">which.class=</span><span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> <span class="kw">levels</span>(iris<span class="op">$</span>Species)[<span class="dv">2</span>]))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-7" data-line-number="7"><span class="st">  </span><span class="kw">bind_rows</span>(<span class="kw">as_tibble</span>(iris.rf <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-8" data-line-number="8"><span class="st">  </span>pdp<span class="op">::</span><span class="kw">partial</span>(<span class="dt">pred.var =</span> <span class="st">&quot;Petal.Width&quot;</span>, <span class="dt">which.class=</span><span class="dv">3</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-9" data-line-number="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> <span class="kw">levels</span>(iris<span class="op">$</span>Species)[<span class="dv">3</span>]))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb890-10" data-line-number="10"><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb890-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Petal.Width, <span class="dt">y=</span>yhat, <span class="dt">col=</span>Species), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb890-12" data-line-number="12"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Partial Dependence of Petal.Width&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb890-13" data-line-number="13"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>Enough visualizing. Time to get the confusion matrix for the random forest model using the test set.</p>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb891-1" data-line-number="1"><span class="co"># get the confusion matrix</span></a>
<a class="sourceLine" id="cb891-2" data-line-number="2">rf_conf_mat =<span class="st"> </span>cvms<span class="op">::</span><span class="kw">confusion_matrix</span>(</a>
<a class="sourceLine" id="cb891-3" data-line-number="3">  <span class="dt">targets =</span> iris_test[, <span class="dv">5</span>],</a>
<a class="sourceLine" id="cb891-4" data-line-number="4">  <span class="dt">predictions =</span> <span class="kw">predict</span>(iris.rf, <span class="dt">newdata =</span> iris_test[<span class="op">-</span><span class="dv">5</span>]))</a>
<a class="sourceLine" id="cb891-5" data-line-number="5"></a>
<a class="sourceLine" id="cb891-6" data-line-number="6"><span class="co"># plot the confusion matrix</span></a>
<a class="sourceLine" id="cb891-7" data-line-number="7">cvms<span class="op">::</span><span class="kw">plot_confusion_matrix</span>(rf_conf_mat<span class="op">$</span><span class="st">`</span><span class="dt">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]]) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Random Forest&quot;</span>)</a></code></pre></div>
<p><img src="09-Non_Parametric_Regression_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>Two observations were misclassified just like with the linear SVC. Let’s see if they’re the same two observations.</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb892-1" data-line-number="1"><span class="co"># the indices of the misclassified flowers from SVC</span></a>
<a class="sourceLine" id="cb892-2" data-line-number="2"><span class="kw">which</span>(iris_test[, <span class="dv">5</span>] <span class="op">!=</span><span class="st"> </span><span class="kw">predict</span>(iris.lin<span class="op">$</span>best.model, <span class="dt">newdata =</span> iris_test[<span class="op">-</span><span class="dv">5</span>]))</a></code></pre></div>
<pre><code>## [1] 24 27</code></pre>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb894-1" data-line-number="1"><span class="co"># the indices of the misclassified flowers from random forest</span></a>
<a class="sourceLine" id="cb894-2" data-line-number="2"><span class="kw">which</span>(iris_test[, <span class="dv">5</span>] <span class="op">!=</span><span class="st"> </span><span class="kw">predict</span>(iris.rf, <span class="dt">newdata =</span> iris_test[<span class="op">-</span><span class="dv">5</span>]))</a></code></pre></div>
<pre><code>## [1] 24 27</code></pre>
</div>
<div id="cart-problem-set" class="section level3">
<h3><span class="header-section-number">11.5.4</span> CART Problem Set</h3>
<p>The problem set for this section is located <a href = '/_Chapter11_ProblemSets/RF_PS_Questions.html'>here</a>.</p>
<p>For your convenience, the R markdown version is <a href = '/_Chapter11_ProblemSets/RF_PS_Questions.Rmd'>here</a>.</p>
<p>The solutions are located <a href = '/_Chapter11_ProblemSets/RF_PS_Solutions.html'>here</a>.</p>
<!--chapter:end:09-Non_Parametric_Regression.Rmd-->
</div>
</div>
</div>
<div id="optional-advanced-doe-topics" class="section level1">
<h1><span class="header-section-number">12</span> Optional Advanced DOE Topics</h1>
<div class="sourceCode" id="cb896"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb896-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<div id="robust-design" class="section level2">
<h2><span class="header-section-number">12.1</span> Robust Design</h2>
</div>
<div id="sequential-designs" class="section level2">
<h2><span class="header-section-number">12.2</span> Sequential Designs</h2>
</div>
<div id="ridge-regression" class="section level2">
<h2><span class="header-section-number">12.3</span> Ridge Regression</h2>
</div>
<div id="neural-network-regression" class="section level2">
<h2><span class="header-section-number">12.4</span> Neural Network Regression</h2>
<p>Like support vector machines and tree-based models, neural networks can be applied to both regression and classification tasks. Neural networks originated in the field of neurophysiology as an attempt to model human brain activity <span class="citation">(Warren S. McCulloch <a href="#ref-mcculloch1943">1943</a>)</span> at the neuron level, but it wasn’t until the 1980s and 1990s <span class="citation">(see David E. Rumelhart <a href="#ref-rumel1986">1986</a>; Bishop <a href="#ref-bishop1995">1995</a>)</span> that they began to be developed into their current form. Neural network models are fit using a training algorithm that slowly reduces prediction error using a process called gradient descent.</p>
<div id="simple-neural-network-model" class="section level3">
<h3><span class="header-section-number">12.4.1</span> Simple Neural Network Model</h3>
<p>Before we get into that, let’s look at visualization of a neural network regression model in it’s simplest form: one to solve for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> given the equation <span class="math inline">\(y = \beta_0 x_0 + \beta_1 x_1 + \epsilon\)</span> where we know <span class="math inline">\(x_0 = 1\)</span>. Below, the two blue circles are referred to as the <strong>input layer</strong> and consist of two <strong>nodes</strong>: an input node that will be used to solve for <span class="math inline">\(\beta_1\)</span>, and a bias node to solve for <span class="math inline">\(\beta_0\)</span>, the y-intercept. Each node of the input layer is connected to the output layer, which consists of just one node because we’ll be predicting a single continuous variable, <span class="math inline">\(\hat{y}\)</span>. If this was a classification problem, and we were trying to classify the three types of irises found in the <code>iris</code> data set, then the output layer would have three nodes, each producing a probability. There is a model parameter, referred to as a <strong>weight</strong>, associated with each connected node as indicated by the <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> terms. The output node produces a prediction, <span class="math inline">\(\hat{y}\)</span>, using an <strong>activation function</strong>. In the case of linear regression, we use a linear activation function of the form <span class="math inline">\(f(\sum\limits_{h}{\omega_h} x_h)\)</span>. That’s it - that’s the model!</p>
<p><img src="_Admin/simple_nn.png" width="500" /></p>
</div>
<div id="gradient-descent" class="section level3">
<h3><span class="header-section-number">12.4.2</span> Gradient Descent</h3>
<p>The algorithm used to train the model is called gradient descent, and to demonstrate how it works, we need to set the stage first. Let’s assume that we’re trying to find the <span class="math inline">\(\beta\)</span>s that have the following relationship with the predictor:</p>
<p><span class="math display">\[y = 1 + 0.5x + \epsilon\]</span>
We’ll create a data set with 10 observations and fit a linear model for comparison later.</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb897-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb897-2" data-line-number="2">nn_reg =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb897-3" data-line-number="3">  <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb897-4" data-line-number="4">  <span class="dt">y =</span> <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>x <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dt">sd=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb897-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb897-6" data-line-number="6"><span class="kw">ggplot</span>(nn_reg, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb897-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb897-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">formula=</span><span class="st">&#39;y~x&#39;</span>, <span class="dt">method=</span><span class="st">&#39;lm&#39;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb897-9" data-line-number="9"><span class="st">  </span><span class="kw">coord_fixed</span>(<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb897-10" data-line-number="10"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Linear Model Fit&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb897-11" data-line-number="11"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<div class="sourceCode" id="cb898"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb898-1" data-line-number="1">nn.lm =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>nn_reg)</a>
<a class="sourceLine" id="cb898-2" data-line-number="2"><span class="kw">summary</span>(nn.lm)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = nn_reg)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.67369 -0.38063 -0.08963  0.41550  0.75801 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.4127     0.4516   0.914 0.387494    
## x             0.7641     0.1324   5.773 0.000418 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5164 on 8 degrees of freedom
## Multiple R-squared:  0.8064, Adjusted R-squared:  0.7822 
## F-statistic: 33.32 on 1 and 8 DF,  p-value: 0.000418</code></pre>
<p>Before the model is trained, its weights are initialized with random numbers. I’ll just pick two random numbers between -1 and 1.</p>
<div class="sourceCode" id="cb900"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb900-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb900-2" data-line-number="2">(<span class="dt">w0 =</span> <span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>))</a></code></pre></div>
<pre><code>## [1] 0.8296121</code></pre>
<div class="sourceCode" id="cb902"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb902-1" data-line-number="1">(<span class="dt">w1 =</span> <span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>))</a></code></pre></div>
<pre><code>## [1] 0.8741508</code></pre>
<p>Since these model parameters are just random numbers, the predictions will not be very accurate. That’s ok, though, and it’s the starting point for all untrained neural network models. We’ll go through the following iterative process to slowly train the model to make more and more accurate predictions.</p>
<p><strong>The Training Process</strong></p>
<ol style="list-style-type: decimal">
<li>Make predictions for input values.</li>
<li>Measure the difference between those predictions and the true values (called the <strong>loss</strong>).</li>
<li>Compute the partial derivative (gradient) of the loss with respect to the model parameters.</li>
<li>Update the model parameters using the partial derivative values computed in the previous step.</li>
<li>Repeat this process until the loss is either unchanged or is sufficiently low.</li>
</ol>
<p>The next several code chunks demonstrate this process one step at a time.</p>
<p><strong>Step 1. Make predictions.</strong></p>
<p>We can make predictions manually using the randomly initialized weight and bias.</p>
<div class="sourceCode" id="cb904"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb904-1" data-line-number="1">get_estimate =<span class="st"> </span><span class="cf">function</span>(omega0, omega1){nn_reg<span class="op">$</span>x <span class="op">*</span><span class="st"> </span>omega1 <span class="op">+</span><span class="st"> </span>omega0}</a>
<a class="sourceLine" id="cb904-2" data-line-number="2">(<span class="dt">y_hat =</span> <span class="kw">get_estimate</span>(w0, w1))</a></code></pre></div>
<pre><code>##  [1] 4.828004 4.925338 2.080258 4.459294 3.634524 3.098453 4.049059 1.418207
##  [9] 3.701164 3.911277</code></pre>
<p><strong>Step 2. Calculate the loss.</strong></p>
<p>There are a number of ways we could do this, but for this example, we’ll calculate the loss by determining the mean squared error of the predictions and the target values. Mean squared error is defined as:</p>
<p><span class="math display">\[MSE = \frac{1}{n} \sum\limits_{i=1}^{n}{(y_i - \hat{y}_i)^2}\]</span></p>
<div class="sourceCode" id="cb906"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb906-1" data-line-number="1">mse =<span class="st"> </span><span class="cf">function</span>(predicted){<span class="dv">1</span><span class="op">/</span><span class="kw">length</span>(predicted)<span class="op">*</span><span class="st"> </span><span class="kw">sum</span>((nn_reg<span class="op">$</span>y <span class="op">-</span><span class="st"> </span>predicted)<span class="op">^</span><span class="dv">2</span>)}</a>
<a class="sourceLine" id="cb906-2" data-line-number="2"><span class="co"># the loss</span></a>
<a class="sourceLine" id="cb906-3" data-line-number="3">(<span class="dt">loss =</span> <span class="kw">mse</span>(y_hat))</a></code></pre></div>
<pre><code>## [1] 0.8201885</code></pre>
<p><strong>Step 3. Compute the partial derivatives of the loss.</strong></p>
<p>At this point, we have two random values for <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> and an associated loss (error). Now we need to find new values for the <span class="math inline">\(\omega\)</span>s that will decrease the loss. How do we do that? For each <span class="math inline">\(\omega\)</span>, we need to determine whether we should increase or decrease it’s value and by how much. We determine whether to increase or decrease its value by calculating the gradient of the loss function at the current <span class="math inline">\(\omega\)</span> values. To demonstrate graphically, the loss as a function of <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> are plotted below.</p>
<div class="sourceCode" id="cb908"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb908-1" data-line-number="1"><span class="co"># sequence of w0 values</span></a>
<a class="sourceLine" id="cb908-2" data-line-number="2">Bvec =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span>(w0<span class="dv">-1</span>), <span class="dt">to=</span>(w0<span class="op">+</span><span class="dv">1</span>), <span class="dt">length.out =</span> <span class="dv">21</span>)</a>
<a class="sourceLine" id="cb908-3" data-line-number="3"><span class="co"># calculate loss while holding w1 constant</span></a>
<a class="sourceLine" id="cb908-4" data-line-number="4">Bloss =<span class="st"> </span>Bvec <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map</span>(<span class="cf">function</span>(x) <span class="kw">get_estimate</span>(x, w1)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map_dbl</span>(<span class="cf">function</span>(x) <span class="kw">mse</span>(x))</a>
<a class="sourceLine" id="cb908-5" data-line-number="5"><span class="co"># get a curve through the points and get the gradient</span></a>
<a class="sourceLine" id="cb908-6" data-line-number="6">Bspl =<span class="st"> </span><span class="kw">smooth.spline</span>(Bloss <span class="op">~</span><span class="st"> </span>Bvec)</a>
<a class="sourceLine" id="cb908-7" data-line-number="7"><span class="co"># get the gradient at w0</span></a>
<a class="sourceLine" id="cb908-8" data-line-number="8">Bgrad =<span class="st"> </span><span class="kw">predict</span>(Bspl, <span class="dt">x=</span>w0, <span class="dt">deriv=</span><span class="dv">1</span>)<span class="op">$</span>y</a>
<a class="sourceLine" id="cb908-9" data-line-number="9"><span class="co"># same thing for w1</span></a>
<a class="sourceLine" id="cb908-10" data-line-number="10">Wvec =<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span>(w1<span class="dv">-1</span>), <span class="dt">to=</span>(w1<span class="op">+</span><span class="dv">1</span>), <span class="dt">length.out =</span> <span class="dv">21</span>)</a>
<a class="sourceLine" id="cb908-11" data-line-number="11">Wloss =<span class="st"> </span>Wvec <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map</span>(<span class="cf">function</span>(x) <span class="kw">get_estimate</span>(w0,x)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map_dbl</span>(<span class="cf">function</span>(x) <span class="kw">mse</span>(x))</a>
<a class="sourceLine" id="cb908-12" data-line-number="12">Wspl =<span class="st"> </span><span class="kw">smooth.spline</span>(Wloss <span class="op">~</span><span class="st"> </span>Wvec)</a>
<a class="sourceLine" id="cb908-13" data-line-number="13">Wgrad =<span class="st"> </span><span class="kw">predict</span>(Wspl, <span class="dt">x=</span>w1, <span class="dt">deriv=</span><span class="dv">1</span>)<span class="op">$</span>y</a>
<a class="sourceLine" id="cb908-14" data-line-number="14">w0plot =<span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb908-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Bvec, <span class="dt">y=</span>Bloss), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb908-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">c</span>(w0<span class="fl">-0.5</span>, w0<span class="fl">+0.5</span>), <span class="dt">y=</span><span class="kw">c</span>(Bloss[<span class="dv">11</span>]<span class="op">-</span>Bgrad<span class="op">/</span><span class="dv">2</span>, Bloss[<span class="dv">11</span>]<span class="op">+</span>Bgrad<span class="op">/</span><span class="dv">2</span>)), <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Bvec[<span class="dv">11</span>], <span class="dt">y =</span> Bloss[<span class="dv">11</span>]), <span class="dt">size=</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-18" data-line-number="18"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="fl">0.5</span>, <span class="dt">y=</span><span class="dv">2</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Slope =&quot;</span>, <span class="kw">round</span>(Bgrad, <span class="dv">2</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-19" data-line-number="19"><span class="st">  </span><span class="kw">coord_fixed</span>(<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">3.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-20" data-line-number="20"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;w0&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Loss&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-21" data-line-number="21"><span class="st">  </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb908-22" data-line-number="22">w1plot =<span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb908-23" data-line-number="23"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Wvec, <span class="dt">y=</span>Wloss), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb908-24" data-line-number="24"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">c</span>(w1<span class="fl">-0.5</span>, w1<span class="fl">+0.5</span>), <span class="dt">y=</span><span class="kw">c</span>(Wloss[<span class="dv">11</span>]<span class="op">-</span>Wgrad<span class="op">/</span><span class="dv">2</span>, Wloss[<span class="dv">11</span>]<span class="op">+</span>Wgrad<span class="op">/</span><span class="dv">2</span>)), <span class="dt">color=</span><span class="st">&#39;blue&#39;</span>, <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-25" data-line-number="25"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Wvec[<span class="dv">11</span>], <span class="dt">y=</span>Wloss[<span class="dv">11</span>]), <span class="dt">size=</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-26" data-line-number="26"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="fl">1.4</span>, <span class="dt">y=</span><span class="fl">0.5</span>, <span class="dt">label=</span><span class="kw">paste</span>(<span class="st">&quot;Slope =&quot;</span>, <span class="kw">round</span>(Wgrad, <span class="dv">2</span>))) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-27" data-line-number="27"><span class="st">  </span><span class="kw">coord_fixed</span>(<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">3.5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-28" data-line-number="28"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;w1&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Loss&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb908-29" data-line-number="29"><span class="st">  </span><span class="kw">theme_bw</span>()</a>
<a class="sourceLine" id="cb908-30" data-line-number="30">gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(w0plot, w1plot, <span class="dt">nrow=</span><span class="dv">1</span>, <span class="dt">ncol=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>In practice, the partial derivatives are calculated as follows:</p>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb909-1" data-line-number="1">(<span class="dt">Bpartial =</span> <span class="kw">sum</span>(<span class="op">-</span>(nn_reg<span class="op">$</span>y <span class="op">-</span><span class="st"> </span>y_hat)))</a></code></pre></div>
<pre><code>## [1] 7.670526</code></pre>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb911-1" data-line-number="1">(<span class="dt">Wpartial =</span> <span class="kw">sum</span>(<span class="op">-</span>(nn_reg<span class="op">$</span>y <span class="op">-</span><span class="st"> </span>y_hat) <span class="op">*</span><span class="st"> </span>nn_reg<span class="op">$</span>x))</a></code></pre></div>
<pre><code>## [1] 26.07812</code></pre>
<p><strong>Step 4. Update the model parameters.</strong></p>
<p>From the above plots, we can see that to decrease the loss, we need to decrease both <span class="math inline">\(\omega\)</span>s. In fact, the following rules always apply:</p>
<ul>
<li><p>With a <em>positive</em> gradient, <em>decrease</em> the parameter value.</p></li>
<li><p>With a <em>negative</em> gradient, <em>increase</em> the parameter value.</p></li>
</ul>
<p>We know we need to decrease the parameter values, so now we need to determine <em>how much</em> to decrease them. Right now, all we have to go on are the magnitude of the gradients. If we decreased the parameters by their respective gradients, the new parameter values would be far to the left on both plots above - we would overshoot the bottom of the curve in both cases. Instead of using the full gradient value, it appears that the parameters should be updated as follows:</p>
<p><span class="math display">\[\omega_{new} = (\omega_{old}) - (\omega_{gradient})(\alpha)\]</span></p>
<p>Where <span class="math inline">\(\alpha\)</span> is a multiplier in the range [0, 1], and is referred to as the <strong>learning rate</strong>. For our example, <span class="math inline">\(\alpha=0.01\)</span> will suffice, but keep in mind that <span class="math inline">\(\alpha\)</span> is a hyperparameter that often must be tuned. The code below selects <span class="math inline">\(\alpha\)</span>, updates the parameter values, and recalculates the loss. Notice that the loss has decreased as expected.</p>
<div class="sourceCode" id="cb913"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb913-1" data-line-number="1">alpha =<span class="st"> </span><span class="fl">0.001</span></a>
<a class="sourceLine" id="cb913-2" data-line-number="2">w0 =<span class="st"> </span>w0 <span class="op">-</span><span class="st"> </span>Bpartial <span class="op">*</span><span class="st"> </span>alpha</a>
<a class="sourceLine" id="cb913-3" data-line-number="3">w1 =<span class="st"> </span>w1 <span class="op">-</span><span class="st"> </span>Wpartial <span class="op">*</span><span class="st"> </span>alpha</a>
<a class="sourceLine" id="cb913-4" data-line-number="4"><span class="kw">mse</span>(<span class="kw">get_estimate</span>(w0, w1))</a></code></pre></div>
<pre><code>## [1] 0.6816571</code></pre>
<p>Next we’ll put all this in a loop, iterate through a number of times, and see what we get for parameter estimates. I’ll start from the beginning and capture the parameters and loss as training progresses through 5000 iterations. Below, the parameter estimates are plotted for each iteration and compared to the linear model coefficients.</p>
<div class="sourceCode" id="cb915"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb915-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb915-2" data-line-number="2">w0 =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb915-3" data-line-number="3">w1 =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb915-4" data-line-number="4">alpha =<span class="st"> </span><span class="fl">0.001</span></a>
<a class="sourceLine" id="cb915-5" data-line-number="5">w0s =<span class="st"> </span>w0</a>
<a class="sourceLine" id="cb915-6" data-line-number="6">w1s =<span class="st"> </span>w1</a>
<a class="sourceLine" id="cb915-7" data-line-number="7"><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">500</span>){</a>
<a class="sourceLine" id="cb915-8" data-line-number="8">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(nn_reg)){</a>
<a class="sourceLine" id="cb915-9" data-line-number="9">    y_hat =<span class="st"> </span><span class="kw">get_estimate</span>(w0, w1)</a>
<a class="sourceLine" id="cb915-10" data-line-number="10">    Bgrad =<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span>(nn_reg<span class="op">$</span>y <span class="op">-</span><span class="st"> </span>y_hat))</a>
<a class="sourceLine" id="cb915-11" data-line-number="11">    Wgrad =<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span>(nn_reg<span class="op">$</span>y <span class="op">-</span><span class="st"> </span>y_hat) <span class="op">*</span><span class="st"> </span>nn_reg<span class="op">$</span>x)</a>
<a class="sourceLine" id="cb915-12" data-line-number="12">    w0 =<span class="st"> </span>w0 <span class="op">-</span><span class="st"> </span>Bgrad <span class="op">*</span><span class="st"> </span><span class="fl">0.001</span></a>
<a class="sourceLine" id="cb915-13" data-line-number="13">    w1 =<span class="st"> </span>w1 <span class="op">-</span><span class="st"> </span>Wgrad <span class="op">*</span><span class="st"> </span><span class="fl">0.001</span></a>
<a class="sourceLine" id="cb915-14" data-line-number="14">    w0s =<span class="st"> </span><span class="kw">c</span>(w0s, w0)</a>
<a class="sourceLine" id="cb915-15" data-line-number="15">    w1s =<span class="st"> </span><span class="kw">c</span>(w1s, w1)</a>
<a class="sourceLine" id="cb915-16" data-line-number="16">  }</a>
<a class="sourceLine" id="cb915-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb915-18" data-line-number="18"></a>
<a class="sourceLine" id="cb915-19" data-line-number="19">wHistory =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb915-20" data-line-number="20">  <span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(w0s),</a>
<a class="sourceLine" id="cb915-21" data-line-number="21">  <span class="dt">b =</span> w0s,</a>
<a class="sourceLine" id="cb915-22" data-line-number="22">  <span class="dt">w =</span> w1s</a>
<a class="sourceLine" id="cb915-23" data-line-number="23">)</a>
<a class="sourceLine" id="cb915-24" data-line-number="24"></a>
<a class="sourceLine" id="cb915-25" data-line-number="25"><span class="kw">library</span>(gganimate)</a></code></pre></div>
<pre><code>## No renderer backend detected. gganimate will default to writing frames to separate files
## Consider installing:
## - the `gifski` package for gif output
## - the `av` package for video output
## and restarting the R session</code></pre>
<div class="sourceCode" id="cb917"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb917-1" data-line-number="1"><span class="kw">ggplot</span>(wHistory) <span class="op">+</span></a>
<a class="sourceLine" id="cb917-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>iter, <span class="dt">y=</span>w0s, <span class="dt">color=</span><span class="st">&#39;w_0 Estimate&#39;</span>, <span class="dt">group=</span><span class="kw">seq_along</span>(iter))) <span class="op">+</span></a>
<a class="sourceLine" id="cb917-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="kw">coef</span>(nn.lm)[<span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb917-4" data-line-number="4"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">1200</span>, <span class="dt">y=</span><span class="fl">0.43</span>, <span class="dt">label=</span><span class="st">&quot;Linear Model Intercept Coefficient&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb917-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>iter, <span class="dt">y=</span>w1s, <span class="dt">color=</span><span class="st">&#39;w_1 Estimate&#39;</span>, <span class="dt">group=</span><span class="kw">seq_along</span>(iter))) <span class="op">+</span></a>
<a class="sourceLine" id="cb917-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="kw">coef</span>(nn.lm)[<span class="dv">2</span>]) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb917-7" data-line-number="7"><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">1300</span>, <span class="dt">y=</span><span class="fl">0.785</span>, <span class="dt">label=</span><span class="st">&quot;Linear Model Slope Coefficient&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb917-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb917-9" data-line-number="9"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Iteration&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Parameter Value&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb917-10" data-line-number="10"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb917-11" data-line-number="11"><span class="st">  </span><span class="kw">transition_reveal</span>(iter)</a></code></pre></div>
<pre><code>## Warning: No renderer available. Please install the gifski, av, or magick
## package to create animated output</code></pre>
<pre><code>## NULL</code></pre>
<p>To visualize the gradient descent methodology, calculate the loss for a range of <span class="math inline">\(\omega_0\)</span> and <span class="math inline">\(\omega_1\)</span> values and plot the loss function as a surface.</p>
<div class="sourceCode" id="cb920"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb920-1" data-line-number="1">loss_fn =<span class="st"> </span><span class="kw">expand_grid</span>(<span class="dt">bs=</span><span class="kw">seq</span>(<span class="fl">0.3</span>,<span class="fl">0.9</span>,<span class="dt">length.out=</span><span class="dv">20</span>), <span class="dt">ws=</span><span class="kw">seq</span>(<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dt">length.out=</span><span class="dv">20</span>))</a>
<a class="sourceLine" id="cb920-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb920-3" data-line-number="3">loss_fn<span class="op">$</span>Loss =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(loss_fn) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb920-4" data-line-number="4"><span class="st">  </span><span class="kw">map</span>(<span class="cf">function</span>(x) <span class="kw">get_estimate</span>(loss_fn[x,<span class="st">&#39;bs&#39;</span>] <span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>bs, loss_fn[x,<span class="st">&#39;ws&#39;</span>]<span class="op">%&gt;%</span><span class="st"> </span>.<span class="op">$</span>ws)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb920-5" data-line-number="5"><span class="st">  </span><span class="kw">map_dbl</span>(<span class="cf">function</span>(x) <span class="kw">mse</span>(x))</a>
<a class="sourceLine" id="cb920-6" data-line-number="6"></a>
<a class="sourceLine" id="cb920-7" data-line-number="7"><span class="kw">ggplot</span>(wHistory) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_raster</span>(<span class="dt">data=</span>loss_fn, <span class="kw">aes</span>(<span class="dt">x=</span>bs, <span class="dt">y=</span>ws, <span class="dt">fill=</span>Loss)) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_contour</span>(<span class="dt">data=</span>loss_fn, <span class="kw">aes</span>(<span class="dt">x=</span>bs, <span class="dt">y=</span>ws, <span class="dt">z=</span>Loss), <span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">bins=</span><span class="dv">28</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>b, <span class="dt">y=</span>w, <span class="dt">group=</span><span class="kw">seq_along</span>(iter)), <span class="dt">color=</span><span class="st">&#39;yellow&#39;</span>, <span class="dt">size=</span><span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-11" data-line-number="11"><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Intercept&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Slope&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-12" data-line-number="12"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb920-13" data-line-number="13"><span class="st">  </span><span class="kw">transition_time</span>(iter) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-14" data-line-number="14"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste</span>(<span class="st">&quot;Gradient Descent Iteration:&quot;</span>, <span class="st">&quot;{round(frame_time, 0)}&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb920-15" data-line-number="15"><span class="st">  </span><span class="kw">shadow_wake</span>(<span class="dt">wake_length =</span> <span class="fl">0.2</span>)</a></code></pre></div>
<pre><code>## Warning: No renderer available. Please install the gifski, av, or magick
## package to create animated output</code></pre>
<pre><code>## NULL</code></pre>
<p>We can also see the regression line update as training progresses.</p>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb923-1" data-line-number="1"><span class="kw">ggplot</span>(wHistory) <span class="op">+</span></a>
<a class="sourceLine" id="cb923-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data=</span>nn_reg, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y), <span class="dt">formula=</span><span class="st">&#39;y~x&#39;</span>, <span class="dt">method=</span><span class="st">&#39;lm&#39;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb923-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept=</span>b, <span class="dt">slope=</span>w), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb923-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>nn_reg, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb923-5" data-line-number="5"><span class="st">  </span><span class="kw">coord_fixed</span>(<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb923-6" data-line-number="6"><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb923-7" data-line-number="7"><span class="st">  </span><span class="kw">transition_time</span>(iter) <span class="op">+</span></a>
<a class="sourceLine" id="cb923-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste</span>(<span class="st">&quot;Gradient Descent Iteration:&quot;</span>, <span class="st">&quot;{round(frame_time, 0)}&quot;</span>)) </a></code></pre></div>
<pre><code>## Warning: No renderer available. Please install the gifski, av, or magick
## package to create animated output</code></pre>
<pre><code>## NULL</code></pre>
<p>Let’s compare the final parameter estimates from the neural network model to the linear model coefficients.</p>
<div class="sourceCode" id="cb926"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb926-1" data-line-number="1"><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb926-2" data-line-number="2">  <span class="dt">Model =</span> <span class="kw">c</span>(<span class="st">&quot;Linear&quot;</span>, <span class="st">&quot;Neural Network&quot;</span>),</a>
<a class="sourceLine" id="cb926-3" data-line-number="3">  <span class="dt">w_0 =</span> <span class="kw">c</span>(<span class="kw">coef</span>(nn.lm)[<span class="dv">1</span>], <span class="kw">tail</span>(w0s, <span class="dv">1</span>)),</a>
<a class="sourceLine" id="cb926-4" data-line-number="4">  <span class="dt">w_1 =</span> <span class="kw">c</span>(<span class="kw">coef</span>(nn.lm)[<span class="dv">2</span>], <span class="kw">tail</span>(w1s, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb926-5" data-line-number="5">)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   Model            w_0   w_1
##   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;
## 1 Linear         0.413 0.764
## 2 Neural Network 0.414 0.764</code></pre>
<p>There are a variety of <em>R</em> packages to simplify the process of fitting a neural network model. Since we’re doing regression and not something for complicated like image classification, natural language processing, or reinforcement learning, a package like <code>nnet</code> provides everything we need.</p>
<div class="sourceCode" id="cb928"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb928-1" data-line-number="1">nnModel =<span class="st"> </span>nnet<span class="op">::</span><span class="kw">nnet</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> nn_reg,   <span class="co"># formula notation is the same as lm()</span></a>
<a class="sourceLine" id="cb928-2" data-line-number="2">                     <span class="dt">linout =</span> <span class="ot">TRUE</span>,          <span class="co"># specifies linear output (instead of logistic)</span></a>
<a class="sourceLine" id="cb928-3" data-line-number="3">                     <span class="dt">decay =</span> <span class="fl">0.001</span>,          <span class="co"># weight decay</span></a>
<a class="sourceLine" id="cb928-4" data-line-number="4">                     <span class="dt">maxit =</span> <span class="dv">100</span>,            <span class="co"># stop training after 100 iterations</span></a>
<a class="sourceLine" id="cb928-5" data-line-number="5">                     <span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">skip =</span> <span class="ot">TRUE</span>)  <span class="co"># no hidden layer (covered later)</span></a></code></pre></div>
<pre><code>## # weights:  2
## initial  value 31.444863 
## final  value 2.134476 
## converged</code></pre>
<div class="sourceCode" id="cb930"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb930-1" data-line-number="1"><span class="kw">summary</span>(nnModel)</a></code></pre></div>
<pre><code>## a 1-0-1 network with 2 weights
## options were - skip-layer connections  linear output units  decay=0.001
##  b-&gt;o i1-&gt;o 
##  0.41  0.76</code></pre>
<p>From the model summary, we see that has two weights: one for <span class="math inline">\(\omega_0\)</span> and one for <span class="math inline">\(\omega_1\)</span>. The initial and final values are model error terms. Converged means that training stopped before it reached <code>maxit</code>. The model takes the form 1-0-1, which means it has one input node (the bias, or intercept, node is automatically included) in the input layer, 0 nodes in the hidden layer (we’ll cover hidden layers later), and one node in the output layer. The <code>b-&gt;o</code> term is our <span class="math inline">\(\omega_0\)</span> (intercept) parameter value, and <code>i1-&gt;o</code> is our <span class="math inline">\(\omega_1\)</span> (slope) parameter value. We can extract the coefficients the usual way.</p>
<div class="sourceCode" id="cb932"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb932-1" data-line-number="1"><span class="kw">coef</span>(nnModel)</a></code></pre></div>
<pre><code>##      b-&gt;o     i1-&gt;o 
## 0.4125070 0.7641276</code></pre>
</div>
<div id="multiple-linear-regression-1" class="section level3">
<h3><span class="header-section-number">12.4.3</span> Multiple Linear Regression</h3>
<p>The neural network model can be easily expanded to accommodate additional predictors by adding a node to the input layer for each additional predictor and connecting it to the output node. Below is a comparison of coefficients obtained from a linear model and a neural network model for a data set with three predictors.</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb934-1" data-line-number="1"><span class="co"># make up data</span></a>
<a class="sourceLine" id="cb934-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">42</span>)</a>
<a class="sourceLine" id="cb934-3" data-line-number="3">mlr =<span class="st"> </span><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb934-4" data-line-number="4">  <span class="dt">x1 =</span> <span class="kw">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb934-5" data-line-number="5">  <span class="dt">x2 =</span> <span class="kw">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb934-6" data-line-number="6">  <span class="dt">x3 =</span> <span class="kw">runif</span>(<span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb934-7" data-line-number="7">  <span class="dt">y =</span> <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>x1 <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span><span class="op">*</span>x2 <span class="op">+</span><span class="st"> </span>x3 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dt">sd=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb934-8" data-line-number="8">)</a>
<a class="sourceLine" id="cb934-9" data-line-number="9"></a>
<a class="sourceLine" id="cb934-10" data-line-number="10"><span class="co"># linear model coefficients</span></a>
<a class="sourceLine" id="cb934-11" data-line-number="11"><span class="kw">coef</span>(<span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data=</span>mlr))</a></code></pre></div>
<pre><code>## (Intercept)          x1          x2          x3 
##   2.0447549   0.5355719  -0.7312496   0.8035532</code></pre>
<div class="sourceCode" id="cb936"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb936-1" data-line-number="1"><span class="co"># neural network coefficients</span></a>
<a class="sourceLine" id="cb936-2" data-line-number="2"><span class="kw">coef</span>(nnet<span class="op">::</span><span class="kw">nnet</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> mlr, <span class="dt">linout =</span> <span class="ot">TRUE</span>, <span class="dt">decay =</span> <span class="fl">0.001</span>, <span class="dt">maxit =</span> <span class="dv">100</span>,</a>
<a class="sourceLine" id="cb936-3" data-line-number="3">                     <span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">skip =</span> <span class="ot">TRUE</span>))</a></code></pre></div>
<pre><code>## # weights:  4
## initial  value 195.927838 
## final  value 4.149504 
## converged</code></pre>
<pre><code>##       b-&gt;o      i1-&gt;o      i2-&gt;o      i3-&gt;o 
##  2.0399505  0.5361400 -0.7307887  0.8040190</code></pre>
<p>If you think this seems like overkill just to model a linear relationship between two variables, I’d agree with you. But consider this:</p>
<ul>
<li><p>What if the relationship between two variables isn’t linear?</p></li>
<li><p>What if there are dozens of predictor variables and dozens of response variables and the underlying relationships are highly complex?</p></li>
</ul>
<p>In cases like these, neural networks models can be very beneficial. To make that leap, however, we need to give our neural network model more power by giving it the ability to model these complexities. We do that by adding one or more <strong>hidden layers</strong> to the model.</p>
</div>
<div id="hidden-layer" class="section level3">
<h3><span class="header-section-number">12.4.4</span> Hidden Layer</h3>
<p>Neural network models become <strong>universal function approximators</strong> with the addition of one or more hidden layers. Hidden layers fall between the input layer and the output layer. Adding more predictor variables and one hidden layer, we get the following network.</p>
<p><img src="_Admin/hidden_nn.png" width="800" /></p>
<p>We’ve introduced a new variable <span class="math inline">\(\nu\)</span>, and a new function <span class="math inline">\(u\)</span>. The <span class="math inline">\(\nu\)</span> variables are trainable weights just like the <span class="math inline">\(w\)</span> variables. The <span class="math inline">\(u\)</span> functions are activation functions as described earlier. Typically, all nodes in a hidden layer share a common type of activation function. A variety of activation functions have been developed, a few of which are shown below. For many applications, a rectified linear, activation function is a good choice for hidden layers.</p>
<table>
<colgroup>
<col width="33%" />
<col width="46%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th>Activation Function</th>
<th>Activation Function Formula</th>
<th>Output Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Threshold</td>
<td><span class="math inline">\(f(u) = \begin{Bmatrix} 1, u&gt;0 \\ 0, u\le0 \end{Bmatrix}\)</span></td>
<td>Binary</td>
</tr>
<tr class="even">
<td>Linear</td>
<td><span class="math inline">\(f(u) = u\)</span></td>
<td>Numeric</td>
</tr>
<tr class="odd">
<td>Logistic</td>
<td><span class="math inline">\(f(u) = \frac{e^u}{1+e^u}\)</span></td>
<td>Numeric Between 0 &amp; 1</td>
</tr>
<tr class="even">
<td>Rectified Linear</td>
<td><span class="math inline">\(f(u) = \begin{Bmatrix} u, u&gt;0 \\ 0, u\le0 \end{Bmatrix}\)</span></td>
<td>Numeric Positive</td>
</tr>
</tbody>
</table>
<p>As stated, adding a hidden layer turns the neural network model into a universal function approximator. For the case of regression, we can think of this as giving the neural network the ability to model non-linear functions without knowing what the nature of the nonlinear relationship is. Compare that to linear regression. If we had the relationship <span class="math inline">\(y = x^2\)</span>, we would need to transform either the response or predictor variable in a linear regression model, and this requires knowing the order of the polynomial to get a good fit. With neural network regression, we don’t need this knowledge. Instead, we allow the hidden layer to learn the nature of the relationship through the model training process. To demonstrate, we’ll use the <code>exa</code> data set from the <code>faraway</code> package, which looks like this.</p>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb939-1" data-line-number="1">exa =<span class="st"> </span>faraway<span class="op">::</span>exa</a>
<a class="sourceLine" id="cb939-2" data-line-number="2"></a>
<a class="sourceLine" id="cb939-3" data-line-number="3"><span class="kw">ggplot</span>(exa) <span class="op">+</span></a>
<a class="sourceLine" id="cb939-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>m), <span class="dt">color=</span><span class="st">&#39;red&#39;</span>, <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb939-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb939-6" data-line-number="6"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Simulated Data (Black) and True Function (Red)&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb939-7" data-line-number="7"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>To fit a linear model with a 10-node hidden layer, we specify <code>size = 10</code>, and since 100 iterations might not be enough to converge, we’ll increase <code>maxit</code> to 500. Otherwise, everything else is the same. With 2 nodes in the input layer (1 for the bias, 1 for x) and 11 nodes in the hidden layer (1 for the bias, and 10 for those we specified), the model will have 31 weights to train.</p>
<div class="sourceCode" id="cb940"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb940-1" data-line-number="1">nnModel2 =<span class="st"> </span>nnet<span class="op">::</span><span class="kw">nnet</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> exa, <span class="dt">linout =</span> <span class="ot">TRUE</span>, <span class="dt">decay =</span> <span class="dv">10</span><span class="op">^</span>(<span class="op">-</span><span class="dv">4</span>), <span class="dt">maxit =</span> <span class="dv">500</span>, <span class="dt">size =</span> <span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # weights:  31
## initial  value 499.220789 
## iter  10 value 78.378021
## iter  20 value 48.290911
## iter  30 value 40.726235
## iter  40 value 27.840931
## iter  50 value 26.694405
## iter  60 value 25.771775
## iter  70 value 25.636491
## iter  80 value 25.582305
## iter  90 value 25.470552
## iter 100 value 25.224183
## iter 110 value 24.521006
## iter 120 value 24.090293
## iter 130 value 23.790948
## iter 140 value 23.700198
## iter 150 value 23.655064
## iter 160 value 23.604385
## iter 170 value 23.523641
## iter 180 value 23.447751
## iter 190 value 23.374363
## iter 200 value 23.334554
## iter 210 value 23.328928
## iter 220 value 23.299974
## iter 230 value 23.236649
## iter 240 value 23.202253
## iter 250 value 23.140707
## iter 260 value 23.113750
## iter 270 value 23.112667
## iter 280 value 23.098585
## iter 290 value 23.091294
## iter 300 value 23.078402
## iter 310 value 23.076582
## iter 320 value 23.073208
## iter 330 value 23.072469
## iter 340 value 23.072050
## iter 350 value 23.071342
## iter 360 value 23.070678
## iter 370 value 23.070162
## iter 380 value 23.069796
## iter 390 value 23.069353
## iter 390 value 23.069353
## final  value 23.069351 
## converged</code></pre>
<div class="sourceCode" id="cb942"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb942-1" data-line-number="1">preds =<span class="st"> </span><span class="kw">predict</span>(nnModel2, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">x=</span>exa<span class="op">$</span>x))</a>
<a class="sourceLine" id="cb942-2" data-line-number="2"></a>
<a class="sourceLine" id="cb942-3" data-line-number="3"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb942-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data=</span>exa, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>m, <span class="dt">color=</span><span class="st">&#39;True Function&#39;</span>), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb942-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>exa<span class="op">$</span>x, <span class="dt">y=</span>preds, <span class="dt">color=</span><span class="st">&#39;Model Fit&#39;</span>), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb942-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>exa, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb942-7" data-line-number="7"><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb942-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_bw</span>()</a></code></pre></div>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>The plot above indicates the model over fit the data somewhat, although we only know this because we have the benefit of knowing the true function. We could reduce the amount of over fitting by choosing different hyperparameter values (decay, or the number of hidden layer nodes) or by changing the default training stopping criteria.</p>
<p>The trained model’s weights are saved with the model, and all 31 are shown below. This highlights a significant drawback of neural network regression. Earlier when we used a neural network model to estimate the slope and intercept, the model weights had meaning: we could directly interpret the weights as slope and intercept. How do we interpret the weights below? I have no idea! The point is that neural network models can be trained to make highly accurate predictions…but at the cost of interpretability.</p>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb943-1" data-line-number="1">nnModel2<span class="op">$</span>wts</a></code></pre></div>
<pre><code>##  [1] -16.9725673  20.8097910 -29.5370775  34.5222783 -20.7276175  28.4041875
##  [7] -28.7287379  40.1850426   0.4509965   0.9949686  -6.7984091   9.0542803
## [13]   2.7378634 -14.7593037   0.5132994  -0.9159351   3.7162426 -21.0383138
## [19]   1.0052389  -3.2571286   0.4460657  18.5160472 -11.5102823 -22.7474633
## [25]   9.8426558   1.1112220   6.1837956   6.4103313  -0.8137049  -4.3845932
## [31]  -3.1923620</code></pre>
</div>
</div>
<div id="neural-network-classification" class="section level2">
<h2><span class="header-section-number">12.5</span> Neural Network Classification</h2>
<p>Neural network models have been extremely successful when applied to classification tasks such as image classification and natural language processing. These models are highly complex and are built using sophisticated packages such as TensorFlow (developed by Google) and PyTorch (developed by Facebook). Building complex models for those kinds of classification tasks are beyond the scope of this tutorial. Instead, this section provides a high-level overview of classification using the <code>nnet</code> package and the <code>iris</code> data set.</p>
<p>The neural network training algorithm for classification is the same as for regression, but for classification, we need to change some of the attributes of the model itself. Instead of a linear activation function in the output layer, we need to use the softmax function. Doing so will cause the output layer to produce probabilities for each of the three flower species (this is accomplished by simply removing <code>linout = TRUE</code> from the <code>nnet()</code> function. Additionally, we use a categorical cross entropy loss function instead of mean squared error. Below, I also set <code>rang = 0.1</code> to scale the predictors to be in the range recommended in the function help. We’ll also create the same training/test split as in the non-parametric regression chapter so we can directly compare results.</p>
<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb945-1" data-line-number="1"><span class="co"># create a training and a test set</span></a>
<a class="sourceLine" id="cb945-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb945-3" data-line-number="3">train =<span class="st"> </span>caTools<span class="op">::</span><span class="kw">sample.split</span>(iris, <span class="dt">SplitRatio =</span> <span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb945-4" data-line-number="4">iris_train =<span class="st"> </span><span class="kw">subset</span>(iris, train <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb945-5" data-line-number="5">iris_test =<span class="st"> </span><span class="kw">subset</span>(iris, train <span class="op">==</span><span class="st"> </span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb945-6" data-line-number="6"></a>
<a class="sourceLine" id="cb945-7" data-line-number="7"><span class="co"># train the model</span></a>
<a class="sourceLine" id="cb945-8" data-line-number="8">irisModel =<span class="st"> </span>nnet<span class="op">::</span><span class="kw">nnet</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris_train, </a>
<a class="sourceLine" id="cb945-9" data-line-number="9">                       <span class="dt">size=</span><span class="dv">2</span>,       <span class="co"># only two nodes in the hidden layer</span></a>
<a class="sourceLine" id="cb945-10" data-line-number="10">                       <span class="dt">maxit=</span><span class="dv">200</span>,    <span class="co"># stopping criteria</span></a>
<a class="sourceLine" id="cb945-11" data-line-number="11">                       <span class="dt">entropy=</span><span class="ot">TRUE</span>, <span class="co"># switch for entropy</span></a>
<a class="sourceLine" id="cb945-12" data-line-number="12">                       <span class="dt">decay=</span><span class="fl">5e-4</span>,   <span class="co"># weight decay hyperparameter</span></a>
<a class="sourceLine" id="cb945-13" data-line-number="13">                       <span class="dt">rang=</span><span class="fl">0.1</span>)     <span class="co"># scale input values</span></a></code></pre></div>
<pre><code>## # weights:  19
## initial  value 131.916499 
## iter  10 value 75.933787
## iter  20 value 56.873818
## iter  30 value 55.958531
## iter  40 value 55.852468
## iter  50 value 55.797951
## iter  60 value 51.382669
## iter  70 value 11.286807
## iter  80 value 7.667108
## iter  90 value 7.657444
## iter 100 value 7.643547
## iter 110 value 7.642436
## iter 120 value 7.641672
## iter 130 value 7.640995
## iter 140 value 7.640338
## iter 150 value 7.627436
## iter 160 value 7.377523
## iter 170 value 5.672073
## iter 180 value 4.882416
## iter 190 value 4.810307
## iter 200 value 4.793242
## final  value 4.793242 
## stopped after 200 iterations</code></pre>
<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb947-1" data-line-number="1"><span class="co"># make predictions on test data</span></a>
<a class="sourceLine" id="cb947-2" data-line-number="2">iris_preds =<span class="st"> </span><span class="kw">predict</span>(irisModel, <span class="dt">newdata=</span>iris_test)</a>
<a class="sourceLine" id="cb947-3" data-line-number="3"><span class="kw">head</span>(iris_preds)</a></code></pre></div>
<pre><code>##       setosa  versicolor    virginica
## 5  0.9956736 0.004326355 6.389963e-16
## 10 0.9911208 0.008879241 2.890320e-15
## 15 0.9976183 0.002381730 1.829078e-16
## 20 0.9957229 0.004277111 6.238407e-16
## 25 0.9739590 0.026040969 2.797958e-14
## 30 0.9901588 0.009841242 3.588147e-15</code></pre>
<p>This first six predictions for the test set are shown above, and notice that the values are in fact probabilities. The model is highly confident that each one of these first six predictions are setosa. Recall from the SVM and CART sections of the non-parametric regression chapter that both of those models misclassified test set observations #24 and #27 as versicolor that are actually virginica. Below we see that the neural network model correctly predicts both observations but is less confident about observation #24.</p>
<div class="sourceCode" id="cb949"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb949-1" data-line-number="1">iris_preds[<span class="kw">c</span>(<span class="dv">24</span>,<span class="dv">27</span>), ]</a></code></pre></div>
<pre><code>##           setosa versicolor virginica
## 120 7.348409e-11 0.18917739 0.8108226
## 135 5.486873e-13 0.03107722 0.9689228</code></pre>
<p>The confusion matrix for the entire test set reveals that the model has an accuracy of 100%.</p>
<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb951-1" data-line-number="1">iris_cm =<span class="st"> </span>cvms<span class="op">::</span><span class="kw">confusion_matrix</span>(</a>
<a class="sourceLine" id="cb951-2" data-line-number="2">  <span class="dt">targets =</span> iris_test[, <span class="dv">5</span>], </a>
<a class="sourceLine" id="cb951-3" data-line-number="3">  <span class="dt">predictions =</span> <span class="kw">colnames</span>(iris_preds)[<span class="kw">max.col</span>(iris_preds)])</a>
<a class="sourceLine" id="cb951-4" data-line-number="4"></a>
<a class="sourceLine" id="cb951-5" data-line-number="5">cvms<span class="op">::</span><span class="kw">plot_confusion_matrix</span>(iris_cm<span class="op">$</span><span class="st">`</span><span class="dt">Confusion Matrix</span><span class="st">`</span>[[<span class="dv">1</span>]], <span class="dt">add_zero_shading =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb951-6" data-line-number="6"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Neural Network Confusion Matrix&quot;</span>)</a></code></pre></div>
<pre><code>## Warning in cvms::plot_confusion_matrix(iris_cm$`Confusion Matrix`[[1]], :
## &#39;ggimage&#39; is missing. Will not plot arrows and zero-shading.</code></pre>
<pre><code>## Warning in cvms::plot_confusion_matrix(iris_cm$`Confusion Matrix`[[1]], :
## &#39;rsvg&#39; is missing. Will not plot arrows and zero-shading.</code></pre>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
</div>
<div id="multivariate-adaptive-regression-splines" class="section level2">
<h2><span class="header-section-number">12.6</span> Multivariate Adaptive Regression Splines</h2>
<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb954-1" data-line-number="1">marsFit =<span class="st"> </span>earth<span class="op">::</span><span class="kw">earth</span>(exa<span class="op">$</span>x, exa<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb954-2" data-line-number="2">marsFit</a></code></pre></div>
<pre><code>## Selected 7 of 12 terms, and 1 of 1 predictors
## Termination condition: Reached nk 21
## Importance: exa$x
## Number of terms at each degree of interaction: 1 6 (additive model)
## GCV 0.09986259    RSS 23.03432    GRSq 0.6894275    RSq 0.71797</code></pre>
<div class="sourceCode" id="cb956"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb956-1" data-line-number="1"><span class="kw">summary</span>(marsFit)</a></code></pre></div>
<pre><code>## Call: earth(x=exa$x, y=exa$y)
## 
##                 coefficients
## (Intercept)       -0.0097451
## h(exa$x-0.236)    -0.9896598
## h(exa$x-0.3972)    6.4260664
## h(exa$x-0.6421)  -14.2707959
## h(exa$x-0.7821)   12.6408844
## h(exa$x-0.8351)  -19.7830105
## h(exa$x-0.9105)   29.6611872
## 
## Selected 7 of 12 terms, and 1 of 1 predictors
## Termination condition: Reached nk 21
## Importance: exa$x
## Number of terms at each degree of interaction: 1 6 (additive model)
## GCV 0.09986259    RSS 23.03432    GRSq 0.6894275    RSq 0.71797</code></pre>
<div class="sourceCode" id="cb958"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb958-1" data-line-number="1">mars_preds =<span class="st"> </span><span class="kw">predict</span>(marsFit, exa<span class="op">$</span>x)</a>
<a class="sourceLine" id="cb958-2" data-line-number="2"></a>
<a class="sourceLine" id="cb958-3" data-line-number="3"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb958-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data=</span>exa, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>m, <span class="dt">color=</span><span class="st">&#39;True Function&#39;</span>), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb958-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>exa<span class="op">$</span>x, <span class="dt">y=</span>mars_preds, <span class="dt">color=</span><span class="st">&#39;MARS Fit&#39;</span>), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb958-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>exa, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb958-7" data-line-number="7"><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb958-8" data-line-number="8"><span class="st">  </span><span class="kw">theme_bw</span>() </a></code></pre></div>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>With bootstrap aggregation.</p>
<div class="sourceCode" id="cb959"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb959-1" data-line-number="1">marsFit2 =<span class="st"> </span>caret<span class="op">::</span><span class="kw">bagEarth</span>(exa<span class="op">$</span>x, exa<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb959-2" data-line-number="2"></a>
<a class="sourceLine" id="cb959-3" data-line-number="3">mars_preds2 =<span class="st"> </span><span class="kw">predict</span>(marsFit2, exa<span class="op">$</span>x)</a>
<a class="sourceLine" id="cb959-4" data-line-number="4"></a>
<a class="sourceLine" id="cb959-5" data-line-number="5"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb959-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data=</span>exa, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>m, <span class="dt">color=</span><span class="st">&#39;True Function&#39;</span>), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb959-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>exa<span class="op">$</span>x, <span class="dt">y=</span>mars_preds2, <span class="dt">color=</span><span class="st">&#39;Bagged MARS Fit&#39;</span>), <span class="dt">size=</span><span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb959-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data=</span>exa, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb959-9" data-line-number="9"><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">name=</span><span class="st">&quot;Legend&quot;</span>, <span class="dt">values=</span><span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb959-10" data-line-number="10"><span class="st">  </span><span class="kw">theme_bw</span>() </a></code></pre></div>
<p><img src="10-Optional_Advanced_Topics_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
</div>
<div id="non-parametric-statistics" class="section level2">
<h2><span class="header-section-number">12.7</span> Non-Parametric Statistics</h2>
<!--chapter:end:10-Optional_Advanced_Topics.Rmd-->
<div id="refs" class="references">
<div id="ref-akaike1974">
<p>Akaike, Hirotugu. 1974. “A New Look at the Statistical Model Identification.” <em>IEEE Transactions on Automatic Control</em> 19(6).</p>
</div>
<div id="ref-bishop1995">
<p>Bishop, Christopher. 1995. <em>Neural Networks for Pattern Recognition</em>. Oxford University Press.</p>
</div>
<div id="ref-rumel1986">
<p>David E. Rumelhart, James L. McClelland. 1986. <em>Parallel Distributed Processing</em>. MIT Press.</p>
</div>
<div id="ref-devore2015">
<p>Devore, Jay. 2015. <em>Probability and Statisticsfor Engineering and the Sciences</em>. 9th ed. Cengage Learning.</p>
</div>
<div id="ref-faraway2006">
<p>Faraway, Julian. 2006. <em>Extending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models</em>. CRC Press.</p>
</div>
<div id="ref-faraway2014">
<p>———. 2014. <em>Linear Models with R</em>. Chapman &amp; Hall.</p>
</div>
<div id="ref-box2005">
<p>George Box, William G. Hunter, J. Stuart Hunter. 2005. <em>Statistics for Experimenters</em>. Wiley.</p>
</div>
<div id="ref-law2015">
<p>Law, Averill. 2015. <em>Simulation Modeling and Analysis</em>. McGraw Hill Education.</p>
</div>
<div id="ref-montgomery2017">
<p>Montgomery, Douglas C. 2017. <em>Design and Analysis of Experiments</em>. John wiley &amp; sons.</p>
</div>
<div id="ref-hastie2008">
<p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2008. <em>The Elements of Statistical Learning</em>. Springer.</p>
</div>
<div id="ref-mcculloch1943">
<p>Warren S. McCulloch, Walter H. Pitts. 1943. “A Logical Calculus of the Ideas Immanent in Nervous Activity.” <em>Bulletin of Mathematical Biophysics</em> 5.</p>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Added 7 April 2020<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>One may say it is a minefield!<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Note: All numbers are notional. They were made using a random number generator.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Note - you will often see data for ANOVA problems written in this way, particularly in textbooks. This is perfectly accurate, but not how <em>R</em> needs to read the data. We’ll cover how to convert this into a useful manner.<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>The terms “treatment effect” and “effect” are often used interchangeably<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Note, it may sound odd to call this a treatment as you are not doing anything to the person. The treatment is that you are selecting from a specific population.<a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>As of 27 March 2020<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Note, these are simply examples, any reputable probability and statistics book will have this<a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>Note, we have not used the Bartlett test for homoscedasticity yet. If you are unfamiliar, please read about it at the link provided.<a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>Read more about this fact <a href = 'https://mathworld.wolfram.com/NormalSumDistribution.html'> here </a><a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>Recall, the variance of a set of the same numbers is 0.<a href="#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>Recall, this is just a heuristic; there is no math to state this definitively<a href="#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>There are, of course, other ways to gain knowledge. For example, observing the social and natural world cannot truly be considered an experiment in the sense that there is no design or observer input.<a href="#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>Note that this video was made by a company called EMS Consulting. I know nothing of them and am not endorsing the company, I simply like easy videos. Also, as noted by John King, we don’t think Einstein had a British accent.<a href="#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>JMP (pronounced “jump” is a statistical software produced by SAS. It is powerful, but costs money. I do not know if it has the capability to do anything <em>R</em> cannot, but I doubt it.)<a href="#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p><a href = 'https://asq.org/about-asq/honorary-members/hunter'> J. Stuart Hunter </a> was a professor and well known statistician who was influential in the DOE community. He is known for, among other things, authoring <a href = 'https://www.wiley.com/en-us/Statistics+for+Experimenters%3A+Design%2C+Innovation%2C+and+Discovery%2C+2nd+Edition-p-9780471718130'> <em>Statistics for Experimenters</em> </a> with George Box and William Hunter (no relation).<a href="#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p>Note: These videos were produced in the 1960s and assume, among other things, that all engineers are men, etc. Obviously, this is incorrect, but the math and explanations are still correct.<a href="#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>This is a particular problem in the military where there is a tendency to conflate rank and expertise.<a href="#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>This is often a flaw not only in the military, but in many industries where there are competing interests that may cause people to desire a particular result.<a href="#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>The same George Box who said “All models are wrong…” that gets quoted at all modeling disucssions.<a href="#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p>This is not an exhaustive list.<a href="#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>Note: for a factorial experiment, we must have a finite number of levels for each factor.<a href="#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>Unruly, of course is not a technical term, but I like to use it when talking about numbers that are annoying to work with<a href="#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>This may or may not be a good assumption.<a href="#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p>Specifically constructive, computer simulations.<a href="#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p>At this point, it is worth noting that there is a very useful <a href = 'https://nps.edu/documents/106696734/108129281/UserGuideSimExpts.pdf/6bf10d35-b507-4554-b77a-6f4a443e4025?t=1475088085000'> paper </a> by Kleijnen, et al. discussing the various considerations for design choice in simulation. This will be required reading later in the course, but it is worth perusing in your spare time.<a href="#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>This order is sometimes called standard order or Yate’s order<a href="#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p>Note this link is from Minitab a proprietary statistical software. Their explanation of orthoginality is useful, and Minitab is a good tool, but we are not using it in this course.<a href="#fnref28" class="footnote-back">↩</a></p></li>
<li id="fn29"><p>We’ll formalize what we mean by this later in the section.<a href="#fnref29" class="footnote-back">↩</a></p></li>
<li id="fn30"><p>Note this uses the <code>plotly</code> package for 3D graphing. This is beyond the scope of this section but you can read more about it <a href = 'https://plotly-r.com'> here </a> fore example<a href="#fnref30" class="footnote-back">↩</a></p></li>
<li id="fn31"><p>Note, at this point, we have not done too much statistical modeling. We will return to these types of results when we begin regression in this course.<a href="#fnref31" class="footnote-back">↩</a></p></li>
<li id="fn32"><p>This model is linear in <span class="math inline">\(\beta\)</span> <strong>and</strong> <span class="math inline">\(x\)</span><a href="#fnref32" class="footnote-back">↩</a></p></li>
<li id="fn33"><p>This is actually logistic regression, which is covered later.<a href="#fnref33" class="footnote-back">↩</a></p></li>
<li id="fn34"><p>The variable was excluded for simplicity at this point, not because we can’t include binary predictors in a linear model. We’ll cover this in a later section.<a href="#fnref34" class="footnote-back">↩</a></p></li>
<li id="fn35"><p>This is also called one-hot encoding<a href="#fnref35" class="footnote-back">↩</a></p></li>
<li id="fn36"><p>Changing the kernel to specify the type of fit is known as the kernel trick.<a href="#fnref36" class="footnote-back">↩</a></p></li>
<li id="fn37"><p>Sometimes referred to as partition trees.<a href="#fnref37" class="footnote-back">↩</a></p></li>
<li id="fn38"><p>It’s always nice to see that I didn’t mess up the manual calculations.<a href="#fnref38" class="footnote-back">↩</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
