---
title: "Model Selection Problem Set"
author: 'Your Name Here'
output: 
  html_document:
    number_sections: T
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This problem set corresponds to the chapter on model selection in the course https://jacobshermansd.github.io/parametric-trades. For this problem set, we will use the following packages:

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(bestglm)
library(glmnet)
```

# Data Familiarization

We will also use the `SAheart` dataset from the `bestglm` package. From the help documentation, we find that the data consists of 462 observations of 10 variables. The response is `chd`, which is a binary variable indicating the presence (1) or absence (0) of coronary heart disease. Familiarize yourself with the data first by displaying the top few rows and note the predictor variable types.

```{r}
head(SAheart)
```

## NAs

Are there any missing values? 

```{r}
# no NAs.
print(paste("Number of NAs:", sum(is.na(SAheart))))
```

## Prep

Do you need to do anything to clean or prepare the data before fitting a model?

```{r}
summary(SAheart)
# no sign we need to clean anything up.
```

## Model Fit

Fit a linear model that includes all predictors and main effects only (remember that the response is binary). 

```{r}
summary(glm(chd ~ ., family=binomial, data=SAheart))
```

# Criterion-Based Model Selection

The dataset has 9 predictors, so test-based methods to reduce model complexity should be avoided. Instead, we'll focus on criterion-based methods. We've seen that there are several factors with low p-values in the full model. 

## AIC

Find the best model using AIC. Are any p-values > 0.05? Are any predictors included in the best model that you didn't expect?

```{r}
sa.AIC = bestglm(SAheart, IC="AIC", family=binomial)
sa.AIC
# no p-value > 0.05
# no unexpected predictors
```

## AIC Predictors

Which predictor contributes most to the presence of coronary heart disease? Which contributes second most? Describe both predictor's contribution in plain English.

```{r}
# Contributes most: the presence of a family history of CHD (based on its coefficient).
# Contributes second most: ldl.
# Interpretation: the presence of a family history increases the odds of CHD by 0.98. 
# For every unit increase in ldl, the odds of CHD increases by 0.16.
```

## AIC Best Model

Perform a liklihood-ratio test for the best model compared to the null model and comment on the significance of the test.

```{r}
summary(sa.AIC)
```

## BIC

Find the best model using BIC. Is there a difference?

```{r}
bestglm(SAheart, IC="BIC", family=binomial)
# exact same results
```

## Mallow's Cp

Now find the best model using Mallow's Cp. `leaps` expects numeric predictors, so convert variable types as necessary. What predictors does the model contain?

```{r}
library(leaps)

# convert to tibble
saheart = as_tibble(SAheart)
# change categorical variable to binary
saheart = saheart %>% mutate(famhist = ifelse(famhist=="Present", 1, 0))
# do Mallow's Cp
sa.cp = leaps(x=saheart[-10], y=saheart$chd, method="Cp")
# print predoctors
colnames(SAheart)[sa.cp$which[which.min(sa.cp$Cp), ]]

# obesity has been added
```

## Model Summary

Fit and summarize a model based on the factors identified using Mallow's Cp.

```{r}
summary(glm(chd ~ tobacco + ldl + famhist + typea + obesity + age, family=binomial, data=SAheart))
```

## Assessment

If a new predictor is included in the above model, does it make sense to keep it? Why or why not?

```{r}
# obesity was added. It doesn't make sense to me to include this predictor.
# The negative coefficient means that for every unit increase in obesity,
# there is a DECREASE in CHD, which doesn't make intuitive sense. Furthermore,
# the standard error is relatively large compared to the coefficient and almost 
# spans 0.0.
```

